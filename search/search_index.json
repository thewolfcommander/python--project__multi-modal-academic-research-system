{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Multi-Modal Academic Research System","text":"![Python Version](https://img.shields.io/badge/python-3.9+-blue.svg) ![License](https://img.shields.io/badge/license-MIT-green.svg) ![Documentation](https://img.shields.io/badge/docs-MkDocs-brightgreen.svg)  **A comprehensive Python application for collecting, processing, and querying academic content from multiple sources using RAG (Retrieval-Augmented Generation) with OpenSearch and Google Gemini.**  [Get Started](setup/quick-start.md){ .md-button .md-button--primary } [View on GitHub](https://github.com/yourusername/multi-modal-academic-research-system){ .md-button }"},{"location":"#what-is-this","title":"\ud83c\udfaf What is This?","text":"<p>The Multi-Modal Academic Research System is a sophisticated platform that enables researchers, students, and professionals to:</p> <ul> <li>\ud83d\udcda Collect academic papers from ArXiv, PubMed Central, and Semantic Scholar</li> <li>\ud83d\udd2c Process PDFs with text extraction and AI-powered diagram analysis</li> <li>\ud83d\udd0d Index content using hybrid search (keyword + semantic) with OpenSearch</li> <li>\ud83d\udcac Query your knowledge base with natural language using Google Gemini</li> <li>\ud83d\udcca Track citations automatically with bibliography export (BibTeX, APA)</li> <li>\ud83d\udcc8 Visualize your collection with interactive dashboards</li> </ul>"},{"location":"#key-features","title":"\u2728 Key Features","text":"<ul> <li> <p> Multi-Source Collection</p> <p>Collect from ArXiv, PubMed, Semantic Scholar, YouTube, and podcasts</p> <p> Learn more</p> </li> <li> <p> AI-Powered Processing</p> <p>Gemini Vision for diagram analysis and content understanding</p> <p> Learn more</p> </li> <li> <p> Hybrid Search</p> <p>BM25 + semantic vector search for optimal relevance</p> <p> Learn more</p> </li> <li> <p> Citation Tracking</p> <p>Automatic extraction and bibliography export</p> <p> Learn more</p> </li> <li> <p> Interactive UI</p> <p>Gradio web interface + FastAPI REST API</p> <p> Learn more</p> </li> <li> <p> Data Visualization</p> <p>Real-time statistics and analytics dashboard</p> <p> Learn more</p> </li> </ul>"},{"location":"#quick-start","title":"\ud83d\ude80 Quick Start","text":"<p>Get up and running in 5 minutes:</p> <pre><code># 1. Clone and setup\ngit clone https://github.com/yourusername/multi-modal-academic-research-system.git\ncd multi-modal-academic-research-system\npython -m venv venv &amp;&amp; source venv/bin/activate\n\n# 2. Install dependencies\npip install -r requirements.txt\n\n# 3. Configure environment\ncp .env.example .env\n# Edit .env and add your GEMINI_API_KEY\n\n# 4. Start OpenSearch\ndocker run -p 9200:9200 -e \"discovery.type=single-node\" opensearchproject/opensearch:latest\n\n# 5. Run the application\npython main.py\n</code></pre> <p>Ready!</p> <p>The Gradio UI will open at http://localhost:7860</p> <p> Detailed Installation Guide</p>"},{"location":"#documentation-structure","title":"\ud83d\udcd6 Documentation Structure","text":"<p>This documentation is organized into several sections:</p> Getting StartedCore ConceptsUser GuidesReference <ul> <li>Installation - Complete setup instructions</li> <li>Quick Start - Get running in 5 minutes</li> <li>Configuration - Environment and settings</li> </ul> <ul> <li>Architecture - System design</li> <li>Data Flow - How data moves</li> <li>Technology Stack - Technologies used</li> </ul> <ul> <li>Collecting Papers - Step-by-step collection</li> <li>Custom Searches - Advanced queries</li> <li>Export Citations - Bibliography management</li> </ul> <ul> <li>Module API - Complete API reference</li> <li>REST API - HTTP endpoints</li> <li>Database Schema - SQLite structure</li> </ul>"},{"location":"#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    A[User Interfaces] --&gt; B[Orchestration Layer]\n    B --&gt; C[OpenSearch Index]\n    B --&gt; D[SQLite Database]\n    B --&gt; E[Collectors]\n    B --&gt; F[Processors]\n    E --&gt; G[ArXiv]\n    E --&gt; H[YouTube]\n    E --&gt; I[Podcasts]\n    F --&gt; J[Gemini Vision]\n\n    style A fill:#e1f5ff\n    style B fill:#fff4e1\n    style C fill:#e8f5e9\n    style D fill:#f3e5f5</code></pre> <p> Detailed Architecture</p>"},{"location":"#code-example","title":"\ud83d\udcbb Code Example","text":"<pre><code>from multi_modal_rag.data_collectors import AcademicPaperCollector\nfrom multi_modal_rag.indexing import OpenSearchManager\nfrom multi_modal_rag.orchestration import ResearchOrchestrator\n\n# Collect papers\ncollector = AcademicPaperCollector()\npapers = collector.collect_arxiv_papers(\"machine learning\", max_results=10)\n\n# Index papers\nopensearch = OpenSearchManager()\nfor paper in papers:\n    opensearch.index_document(\"research_assistant\", {\n        'content_type': 'paper',\n        'title': paper['title'],\n        'abstract': paper['abstract'],\n        'authors': paper['authors']\n    })\n\n# Query system\norchestrator = ResearchOrchestrator(\"your-gemini-api-key\", opensearch)\nresult = orchestrator.process_query(\n    \"What is retrieval-augmented generation?\",\n    \"research_assistant\"\n)\n\nprint(result['answer'])\nprint(result['citations'])\n</code></pre> <p> More Examples</p>"},{"location":"#technology-stack","title":"\ud83d\udee0\ufe0f Technology Stack","text":"CoreAI/MLWebData <ul> <li>Python 3.9+ - Main language</li> <li>OpenSearch - Search &amp; vector DB</li> <li>Google Gemini - AI generation</li> <li>SQLite - Metadata tracking</li> </ul> <ul> <li>LangChain - AI orchestration</li> <li>SentenceTransformers - Embeddings</li> <li>Gemini Vision - Image analysis</li> <li>Whisper - Audio transcription</li> </ul> <ul> <li>FastAPI - REST API</li> <li>Gradio - Web UI</li> <li>Uvicorn - ASGI server</li> <li>Material UI - Documentation</li> </ul> <ul> <li>PyMuPDF - PDF processing</li> <li>yt-dlp - YouTube extraction</li> <li>arxiv - ArXiv API</li> <li>feedparser - RSS feeds</li> </ul> <p> Full Stack Details</p>"},{"location":"#project-stats","title":"\ud83d\udcca Project Stats","text":"<ul> <li> <p>3,000+</p> <p>Lines of Python code</p> </li> <li> <p>40+</p> <p>Documentation files</p> </li> <li> <p>31,000+</p> <p>Lines of documentation</p> </li> <li> <p>250+</p> <p>Code examples</p> </li> </ul>"},{"location":"#learning-paths","title":"\ud83c\udf93 Learning Paths","text":"<p>Choose your path based on your role:</p> <p>For Researchers</p> <ol> <li>Quick Start</li> <li>Collecting Papers</li> <li>Citation Management</li> </ol> <p>For Developers</p> <ol> <li>Architecture Overview</li> <li>Module Documentation</li> <li>API Reference</li> </ol> <p>For DevOps</p> <ol> <li>Local Deployment</li> <li>Docker Setup</li> <li>Production Guide</li> </ol>"},{"location":"#common-issues","title":"\ud83d\udc1b Common Issues","text":"<p>Having trouble? Check these first:</p> OpenSearch won't connect <pre><code># Check if OpenSearch is running\ncurl -X GET \"localhost:9200\"\n\n# Restart OpenSearch\ndocker restart opensearch\n</code></pre> <p>Full OpenSearch troubleshooting \u2192</p> Gemini API errors <ul> <li>Verify API key in <code>.env</code></li> <li>Check rate limits</li> <li>Ensure internet connection</li> </ul> <p>API troubleshooting guide \u2192</p> Import errors <pre><code># Reinstall dependencies\npip install -r requirements.txt --force-reinstall\n</code></pre> <p>Common issues \u2192</p> <p> Full Troubleshooting Guide</p>"},{"location":"#contributing","title":"\ud83e\udd1d Contributing","text":"<p>We welcome contributions! Here's how to get started:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Submit a pull request</li> </ol> <p> Contributing Guide</p>"},{"location":"#license","title":"\ud83d\udcdd License","text":"<p>This project is licensed under the MIT License.</p>"},{"location":"#acknowledgments","title":"\ud83d\ude4f Acknowledgments","text":"<ul> <li>OpenSearch - Powerful search and analytics</li> <li>LangChain - AI orchestration framework</li> <li>Google Gemini - Advanced AI capabilities</li> <li>ArXiv - Open-access scientific papers</li> </ul>   **Made with \u2764\ufe0f for the research community**  [Get Started](setup/quick-start.md){ .md-button .md-button--primary } [View Documentation](README.md){ .md-button }"},{"location":"DOCUMENTATION_INDEX/","title":"Multi-Modal Academic Research System - Documentation Index","text":""},{"location":"DOCUMENTATION_INDEX/#overview","title":"Overview","text":"<p>Comprehensive documentation for all modules in the Multi-Modal Academic Research System. This index provides quick access to detailed module documentation with code examples, API references, and integration guides.</p>"},{"location":"DOCUMENTATION_INDEX/#documentation-files","title":"Documentation Files","text":""},{"location":"DOCUMENTATION_INDEX/#1-data-collectors-module","title":"1. Data Collectors Module","text":"<p>File: <code>docs/modules/data-collectors.md</code> (16KB)</p> <p>Key Sections: - AcademicPaperCollector   - <code>collect_arxiv_papers()</code> - Collect from ArXiv with PDF download   - <code>collect_pubmed_central()</code> - PubMed Central Open Access papers   - <code>collect_semantic_scholar()</code> - Semantic Scholar API integration</p> <ul> <li>YouTubeLectureCollector</li> <li><code>search_youtube_lectures()</code> - Search educational videos</li> <li><code>collect_video_metadata()</code> - Extract metadata and transcripts</li> <li> <p><code>extract_video_id()</code> - Parse YouTube URLs</p> </li> <li> <p>PodcastCollector</p> </li> <li><code>collect_podcast_episodes()</code> - RSS feed parsing</li> <li><code>transcribe_audio()</code> - Whisper-based transcription</li> <li><code>get_educational_podcasts()</code> - Curated podcast list</li> </ul> <p>Topics Covered: - API integration examples (ArXiv, YouTube, RSS) - Rate limiting and best practices - Error handling patterns - Complete code examples for each collector - Troubleshooting common issues</p>"},{"location":"DOCUMENTATION_INDEX/#2-data-processors-module","title":"2. Data Processors Module","text":"<p>File: <code>docs/modules/data-processors.md</code> (21KB)</p> <p>Key Sections: - PDFProcessor   - <code>extract_text_and_images()</code> - PyMuPDF-based extraction   - <code>analyze_with_gemini()</code> - AI-powered content analysis   - Gemini Vision for diagram understanding</p> <ul> <li>VideoProcessor</li> <li><code>analyze_video_content()</code> - Transcript and metadata analysis</li> <li><code>extract_key_frames()</code> - Frame extraction (placeholder)</li> </ul> <p>Topics Covered: - PDF text and image extraction with PyMuPDF - Gemini Vision integration for diagrams - Multimodal AI prompts and responses - Document structuring for indexing - Performance optimization tips - Gemini SDK usage patterns</p>"},{"location":"DOCUMENTATION_INDEX/#3-indexing-module","title":"3. Indexing Module","text":"<p>File: <code>docs/modules/indexing.md</code> (25KB)</p> <p>Key Sections: - OpenSearchManager   - <code>create_index()</code> - Index schema creation   - <code>index_document()</code> - Single document indexing   - <code>bulk_index()</code> - Efficient batch indexing   - <code>hybrid_search()</code> - Multi-field text search</p> <p>Topics Covered: - Index schema design for multi-modal content - Embedding generation with SentenceTransformer - Hybrid search strategy (BM25 + vector search) - Field boosting and relevance tuning - Performance optimization - Advanced search queries and aggregations - kNN vector search concepts</p>"},{"location":"DOCUMENTATION_INDEX/#4-database-module","title":"4. Database Module","text":"<p>File: <code>docs/modules/database.md</code> (24KB)</p> <p>Key Sections: - CollectionDatabaseManager   - <code>add_collection()</code> - Track new collections   - <code>add_paper()</code>, <code>add_video()</code>, <code>add_podcast()</code> - Type-specific data   - <code>mark_as_indexed()</code> - Update indexing status   - <code>get_statistics()</code> - Analytics and reporting   - <code>search_collections()</code> - Database search</p> <p>Topics Covered: - Complete database schema (SQLite) - CRUD operations for all content types - Collection statistics and analytics - Search and filtering - Data export (JSON, CSV) - Performance considerations - Backup and recovery</p>"},{"location":"DOCUMENTATION_INDEX/#5-api-module","title":"5. API Module","text":"<p>File: <code>docs/modules/api.md</code> (22KB)</p> <p>Key Sections: - FastAPI Endpoints   - <code>GET /api/collections</code> - Retrieve collections with filtering   - <code>GET /api/collections/{id}</code> - Get collection details   - <code>GET /api/statistics</code> - Database statistics   - <code>GET /api/search</code> - Search collections   - <code>GET /viz</code> - Visualization dashboard   - <code>GET /health</code> - Health check</p> <p>Topics Covered: - Complete REST API reference - Request/response formats - Query parameters and validation - Error handling and status codes - CORS configuration - Frontend integration examples (React, Python) - CLI tool example - Deployment guides (Docker, Kubernetes) - Security considerations</p>"},{"location":"DOCUMENTATION_INDEX/#6-orchestration-module","title":"6. Orchestration Module","text":"<p>File: <code>docs/modules/orchestration.md</code> (24KB)</p> <p>Key Sections: - ResearchOrchestrator   - <code>process_query()</code> - End-to-end query pipeline   - <code>format_context_with_citations()</code> - Context formatting   - <code>extract_citations()</code> - Citation extraction from responses   - <code>generate_related_queries()</code> - Suggestion generation</p> <ul> <li>CitationTracker</li> <li><code>add_citation()</code> - Track citation usage</li> <li><code>get_citation_report()</code> - Analytics</li> <li><code>export_bibliography()</code> - BibTeX/APA export</li> </ul> <p>Topics Covered: - LangChain integration patterns - Prompt engineering for research - Citation extraction with regex - Conversation memory management - Related query generation - Bibliography export formats - Multi-turn conversations</p>"},{"location":"DOCUMENTATION_INDEX/#7-ui-module","title":"7. UI Module","text":"<p>File: <code>docs/modules/ui.md</code> (23KB)</p> <p>Key Sections: - ResearchAssistantUI   - <code>create_interface()</code> - Gradio app creation   - <code>handle_search()</code> - Research query processing   - <code>handle_data_collection()</code> - Content collection workflow   - <code>get_database_statistics()</code> - Statistics display</p> <p>Topics Covered: - Complete Gradio interface guide - 5 main tabs (Research, Data Collection, Citation Manager, Settings, Visualization) - Event handlers and workflows - UI customization and theming - Launch configurations - User workflows and examples - Performance optimization - Accessibility features</p>"},{"location":"DOCUMENTATION_INDEX/#quick-start-guide","title":"Quick Start Guide","text":""},{"location":"DOCUMENTATION_INDEX/#1-reading-order-for-new-users","title":"1. Reading Order for New Users","text":"<ol> <li>Start with: <code>data-collectors.md</code> - Understand data sources</li> <li>Then: <code>data-processors.md</code> - Learn content processing</li> <li>Next: <code>indexing.md</code> - Understand search infrastructure</li> <li>Follow with: <code>orchestration.md</code> - See how queries work</li> <li>Finally: <code>ui.md</code> - Explore the user interface</li> </ol>"},{"location":"DOCUMENTATION_INDEX/#2-reading-order-for-developers","title":"2. Reading Order for Developers","text":"<ol> <li>Architecture: <code>indexing.md</code> + <code>database.md</code> - Core infrastructure</li> <li>Data Flow: <code>data-collectors.md</code> \u2192 <code>data-processors.md</code> \u2192 <code>indexing.md</code></li> <li>Query Pipeline: <code>orchestration.md</code> - LangChain integration</li> <li>Interfaces: <code>ui.md</code> + <code>api.md</code> - User/programmatic access</li> </ol>"},{"location":"DOCUMENTATION_INDEX/#3-reading-order-for-api-users","title":"3. Reading Order for API Users","text":"<ol> <li>API Reference: <code>api.md</code> - REST endpoints</li> <li>Data Structure: <code>database.md</code> - Schema and models</li> <li>Search: <code>indexing.md</code> - Query capabilities</li> <li>Integration: Examples in <code>api.md</code></li> </ol>"},{"location":"DOCUMENTATION_INDEX/#code-examples-index","title":"Code Examples Index","text":""},{"location":"DOCUMENTATION_INDEX/#data-collection-examples","title":"Data Collection Examples","text":"<p><pre><code># Collect papers from ArXiv\nfrom multi_modal_rag.data_collectors import AcademicPaperCollector\n\ncollector = AcademicPaperCollector()\npapers = collector.collect_arxiv_papers(\"machine learning\", max_results=50)\n</code></pre> See: <code>data-collectors.md</code> - Section: AcademicPaperCollector</p>"},{"location":"DOCUMENTATION_INDEX/#pdf-processing-examples","title":"PDF Processing Examples","text":"<p><pre><code># Extract and analyze PDF\nfrom multi_modal_rag.data_processors import PDFProcessor\n\nprocessor = PDFProcessor(gemini_api_key=\"your_key\")\ncontent = processor.extract_text_and_images(\"paper.pdf\")\nanalysis = processor.analyze_with_gemini(content)\n</code></pre> See: <code>data-processors.md</code> - Section: PDFProcessor</p>"},{"location":"DOCUMENTATION_INDEX/#search-examples","title":"Search Examples","text":"<p><pre><code># Hybrid search\nfrom multi_modal_rag.indexing import OpenSearchManager\n\nmanager = OpenSearchManager()\nresults = manager.hybrid_search(\"research_assistant\", \"transformers\", k=10)\n</code></pre> See: <code>indexing.md</code> - Section: hybrid_search()</p>"},{"location":"DOCUMENTATION_INDEX/#research-query-examples","title":"Research Query Examples","text":"<p><pre><code># Process research query\nfrom multi_modal_rag.orchestration import ResearchOrchestrator\n\norchestrator = ResearchOrchestrator(api_key, opensearch_manager)\nresult = orchestrator.process_query(\"How do transformers work?\", \"research_assistant\")\n</code></pre> See: <code>orchestration.md</code> - Section: process_query()</p>"},{"location":"DOCUMENTATION_INDEX/#api-usage-examples","title":"API Usage Examples","text":"<p><pre><code># Fetch collections via API\nimport requests\n\nresponse = requests.get(\"http://localhost:8000/api/collections?content_type=paper\")\npapers = response.json()['collections']\n</code></pre> See: <code>api.md</code> - Section: GET /api/collections</p>"},{"location":"DOCUMENTATION_INDEX/#integration-patterns","title":"Integration Patterns","text":""},{"location":"DOCUMENTATION_INDEX/#complete-pipeline-example","title":"Complete Pipeline Example","text":"<p>Location in docs: - Collection: <code>data-collectors.md</code> - Integration Example section - Processing: <code>data-processors.md</code> - Integration Workflow section - Indexing: <code>indexing.md</code> - Usage examples - Querying: <code>orchestration.md</code> - Complete Research Workflow section</p>"},{"location":"DOCUMENTATION_INDEX/#ui-integration","title":"UI Integration","text":"<p>Location: <code>ui.md</code> - Section: Integration with Main Application</p> <p>Example: <code>main.py</code> setup connecting all components</p>"},{"location":"DOCUMENTATION_INDEX/#api-integration","title":"API Integration","text":"<p>Location: <code>api.md</code> - Section: Integration Examples</p> <p>Examples: React frontend, Python client, CLI tool</p>"},{"location":"DOCUMENTATION_INDEX/#architecture-diagrams","title":"Architecture Diagrams","text":""},{"location":"DOCUMENTATION_INDEX/#data-flow","title":"Data Flow","text":"<pre><code>Data Sources \u2192 Collectors \u2192 Processors \u2192 Indexing \u2192 Search\n                                \u2193\n                          Database Tracking\n</code></pre> <p>Detailed docs: - Collectors: <code>data-collectors.md</code> - Processors: <code>data-processors.md</code> - Indexing: <code>indexing.md</code> - Database: <code>database.md</code></p>"},{"location":"DOCUMENTATION_INDEX/#query-pipeline","title":"Query Pipeline","text":"<pre><code>User Query \u2192 Orchestrator \u2192 OpenSearch \u2192 Context Formatting\n                \u2193                              \u2193\n            Memory \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Gemini LLM \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2193\n         Citation Extraction\n</code></pre> <p>Detailed docs: - Orchestrator: <code>orchestration.md</code> - Search: <code>indexing.md</code> - Citations: <code>orchestration.md</code> - CitationTracker section</p>"},{"location":"DOCUMENTATION_INDEX/#common-tasks","title":"Common Tasks","text":""},{"location":"DOCUMENTATION_INDEX/#task-collect-and-index-papers","title":"Task: Collect and Index Papers","text":"<p>Docs: 1. <code>data-collectors.md</code> - collect_arxiv_papers() 2. <code>indexing.md</code> - bulk_index() 3. <code>database.md</code> - add_collection()</p>"},{"location":"DOCUMENTATION_INDEX/#task-process-pdf-with-diagram-analysis","title":"Task: Process PDF with Diagram Analysis","text":"<p>Docs: 1. <code>data-processors.md</code> - extract_text_and_images() 2. <code>data-processors.md</code> - analyze_with_gemini()</p>"},{"location":"DOCUMENTATION_INDEX/#task-build-custom-search-interface","title":"Task: Build Custom Search Interface","text":"<p>Docs: 1. <code>indexing.md</code> - hybrid_search() 2. <code>api.md</code> - Frontend Integration 3. <code>orchestration.md</code> - process_query()</p>"},{"location":"DOCUMENTATION_INDEX/#task-export-citations","title":"Task: Export Citations","text":"<p>Docs: 1. <code>orchestration.md</code> - CitationTracker 2. <code>orchestration.md</code> - export_bibliography()</p>"},{"location":"DOCUMENTATION_INDEX/#task-deploy-api-server","title":"Task: Deploy API Server","text":"<p>Docs: 1. <code>api.md</code> - Deployment section 2. <code>api.md</code> - Docker Deployment</p>"},{"location":"DOCUMENTATION_INDEX/#troubleshooting-index","title":"Troubleshooting Index","text":""},{"location":"DOCUMENTATION_INDEX/#by-module","title":"By Module","text":"<ul> <li>Data Collectors: <code>data-collectors.md</code> - Troubleshooting section</li> <li>yt-dlp not found</li> <li>YouTube transcript unavailable</li> <li> <p>RSS feed parsing fails</p> </li> <li> <p>Data Processors: <code>data-processors.md</code> - Troubleshooting section</p> </li> <li>Gemini API authentication</li> <li>PDF extraction errors</li> <li> <p>Image analysis failures</p> </li> <li> <p>Indexing: <code>indexing.md</code> - Troubleshooting section</p> </li> <li>OpenSearch connection refused</li> <li>SSL certificate errors</li> <li> <p>Search returns no results</p> </li> <li> <p>Database: <code>database.md</code> - Troubleshooting section</p> </li> <li>Database locked errors</li> <li>Corrupted database recovery</li> <li> <p>JSON parse errors</p> </li> <li> <p>API: <code>api.md</code> - Troubleshooting section</p> </li> <li>Port already in use</li> <li>CORS errors</li> <li> <p>422 validation errors</p> </li> <li> <p>Orchestration: <code>orchestration.md</code> - Troubleshooting section</p> </li> <li>Related queries not JSON</li> <li>Citations not extracted</li> <li> <p>Memory grows too large</p> </li> <li> <p>UI: <code>ui.md</code> - Troubleshooting section</p> </li> <li>Gradio won't launch</li> <li>Share link doesn't work</li> <li>UI freezes during collection</li> </ul>"},{"location":"DOCUMENTATION_INDEX/#performance-optimization-index","title":"Performance Optimization Index","text":""},{"location":"DOCUMENTATION_INDEX/#indexing-performance","title":"Indexing Performance","text":"<p>Doc: <code>indexing.md</code> - Performance Tuning section</p> <p>Key topics: - Bulk indexing vs single documents - Batch embedding generation - Shard configuration - Query optimization</p>"},{"location":"DOCUMENTATION_INDEX/#search-performance","title":"Search Performance","text":"<p>Doc: <code>indexing.md</code> - Search Performance section</p> <p>Key topics: - Result size limits - Filter optimization - Field selection - Caching strategies</p>"},{"location":"DOCUMENTATION_INDEX/#processing-performance","title":"Processing Performance","text":"<p>Doc: <code>data-processors.md</code> - Performance Optimization section</p> <p>Key topics: - Image limit (5 max) - Batch processing - Result caching - Transcript truncation</p>"},{"location":"DOCUMENTATION_INDEX/#ui-performance","title":"UI Performance","text":"<p>Doc: <code>ui.md</code> - Performance Considerations section</p> <p>Key topics: - Loading states - Result display limits - Async operations - Queue management</p>"},{"location":"DOCUMENTATION_INDEX/#security-best-practices","title":"Security Best Practices","text":""},{"location":"DOCUMENTATION_INDEX/#api-security","title":"API Security","text":"<p>Doc: <code>api.md</code> - Security Considerations section</p> <p>Topics: - CORS configuration - API authentication - Rate limiting - HTTPS deployment</p>"},{"location":"DOCUMENTATION_INDEX/#database-security","title":"Database Security","text":"<p>Doc: <code>database.md</code> - Error Handling section</p> <p>Topics: - Transaction safety - SQL injection prevention - Backup strategies</p>"},{"location":"DOCUMENTATION_INDEX/#dependencies-summary","title":"Dependencies Summary","text":""},{"location":"DOCUMENTATION_INDEX/#core-dependencies","title":"Core Dependencies","text":"Module Key Dependencies Doc Reference Data Collectors arxiv, yt-dlp, feedparser, whisper <code>data-collectors.md</code> Data Processors google-generativeai, pypdf, pymupdf <code>data-processors.md</code> Indexing opensearch-py, sentence-transformers <code>indexing.md</code> Database sqlite3 (built-in) <code>database.md</code> API fastapi, uvicorn <code>api.md</code> Orchestration langchain, langchain-google-genai <code>orchestration.md</code> UI gradio <code>ui.md</code>"},{"location":"DOCUMENTATION_INDEX/#installation-commands","title":"Installation Commands","text":"<pre><code># All dependencies\npip install -r requirements.txt\n\n# By module (see individual docs for details)\npip install arxiv yt-dlp youtube-transcript-api feedparser openai-whisper\npip install google-generativeai pypdf pymupdf pillow\npip install opensearch-py sentence-transformers\npip install fastapi uvicorn\npip install langchain langchain-google-genai\npip install gradio\n</code></pre>"},{"location":"DOCUMENTATION_INDEX/#api-reference-quick-links","title":"API Reference Quick Links","text":""},{"location":"DOCUMENTATION_INDEX/#rest-endpoints","title":"REST Endpoints","text":"<ul> <li><code>GET /</code> - API info \u2192 <code>api.md</code></li> <li><code>GET /api/collections</code> - List collections \u2192 <code>api.md</code></li> <li><code>GET /api/collections/{id}</code> - Get details \u2192 <code>api.md</code></li> <li><code>GET /api/statistics</code> - Statistics \u2192 <code>api.md</code></li> <li><code>GET /api/search</code> - Search \u2192 <code>api.md</code></li> <li><code>GET /viz</code> - Dashboard \u2192 <code>api.md</code></li> <li><code>GET /health</code> - Health check \u2192 <code>api.md</code></li> </ul>"},{"location":"DOCUMENTATION_INDEX/#python-api","title":"Python API","text":"<ul> <li>Collectors: <code>data-collectors.md</code> - Methods section</li> <li>Processors: <code>data-processors.md</code> - Methods section</li> <li>Indexing: <code>indexing.md</code> - Methods section</li> <li>Database: <code>database.md</code> - Methods section</li> <li>Orchestrator: <code>orchestration.md</code> - Methods section</li> <li>UI: <code>ui.md</code> - Event Handler Methods section</li> </ul>"},{"location":"DOCUMENTATION_INDEX/#file-sizes","title":"File Sizes","text":"<ul> <li><code>data-collectors.md</code>: 16KB</li> <li><code>data-processors.md</code>: 21KB</li> <li><code>indexing.md</code>: 25KB</li> <li><code>database.md</code>: 24KB</li> <li><code>api.md</code>: 22KB</li> <li><code>orchestration.md</code>: 24KB</li> <li><code>ui.md</code>: 23KB</li> </ul> <p>Total: 155KB of comprehensive documentation</p>"},{"location":"DOCUMENTATION_INDEX/#documentation-standards","title":"Documentation Standards","text":"<p>Each documentation file includes:</p> <ol> <li>Overview - Module purpose and architecture</li> <li>Class/Function Reference - Complete API documentation</li> <li>Parameters &amp; Returns - Detailed type information</li> <li>Code Examples - Working examples for all features</li> <li>Integration Examples - How modules work together</li> <li>Error Handling - Common errors and solutions</li> <li>Performance Tips - Optimization strategies</li> <li>Troubleshooting - Common issues and fixes</li> <li>Dependencies - Required packages</li> <li>Future Enhancements - Planned features</li> </ol>"},{"location":"DOCUMENTATION_INDEX/#contributing-to-documentation","title":"Contributing to Documentation","text":"<p>When updating documentation:</p> <ol> <li>Follow existing structure and format</li> <li>Include code examples for all new features</li> <li>Add troubleshooting entries for common issues</li> <li>Update this index with new sections</li> <li>Keep examples tested and working</li> <li>Update file sizes if significantly changed</li> </ol>"},{"location":"DOCUMENTATION_INDEX/#feedback-and-issues","title":"Feedback and Issues","text":"<p>For documentation improvements or corrections:</p> <ol> <li>Create issue with <code>documentation</code> label</li> <li>Specify file and section</li> <li>Provide suggested changes</li> <li>Include code examples if applicable</li> </ol> <p>Last Updated: October 2024 Documentation Version: 1.0 Total Modules Documented: 7</p>"},{"location":"MKDOCS_GUIDE/","title":"MkDocs Documentation Guide","text":"<p>This guide explains how to build, serve, and deploy the Multi-Modal Academic Research System documentation using MkDocs with Material theme.</p>"},{"location":"MKDOCS_GUIDE/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li>Python 3.9 or higher</li> <li>pip package manager</li> <li>Git (for deployment to GitHub Pages)</li> </ul>"},{"location":"MKDOCS_GUIDE/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"MKDOCS_GUIDE/#1-install-dependencies","title":"1. Install Dependencies","text":"<pre><code># Install MkDocs and Material theme\npip install -r requirements.txt\n\n# Or install just documentation dependencies\npip install mkdocs==1.5.3 mkdocs-material==9.5.3 mkdocs-material-extensions==1.3.1 pymdown-extensions==10.7\n</code></pre>"},{"location":"MKDOCS_GUIDE/#2-serve-documentation-locally","title":"2. Serve Documentation Locally","text":"<pre><code># From project root\nmkdocs serve\n\n# Documentation will be available at http://127.0.0.1:8000\n</code></pre> <p>The development server includes: - Live reload - Changes automatically reflected - Search - Full-text search functionality - Navigation - Interactive table of contents</p>"},{"location":"MKDOCS_GUIDE/#3-build-static-site","title":"3. Build Static Site","text":"<pre><code># Build documentation to site/ directory\nmkdocs build\n\n# Build with strict mode (fails on warnings)\nmkdocs build --strict\n\n# Clean build (remove site/ directory first)\nmkdocs build --clean\n</code></pre>"},{"location":"MKDOCS_GUIDE/#customization","title":"\ud83c\udfa8 Customization","text":""},{"location":"MKDOCS_GUIDE/#theme-configuration","title":"Theme Configuration","text":"<p>Edit <code>mkdocs.yml</code> to customize:</p> <pre><code>theme:\n  name: material\n  palette:\n    - scheme: default\n      primary: indigo\n      accent: indigo\n  features:\n    - navigation.tabs\n    - navigation.instant\n    - search.suggest\n</code></pre>"},{"location":"MKDOCS_GUIDE/#adding-custom-css","title":"Adding Custom CSS","text":"<ol> <li> <p>Create CSS file in <code>docs/stylesheets/</code>: <pre><code>/* docs/stylesheets/custom.css */\n.custom-class {\n  color: #ff0000;\n}\n</code></pre></p> </li> <li> <p>Reference in <code>mkdocs.yml</code>: <pre><code>extra_css:\n  - stylesheets/custom.css\n</code></pre></p> </li> </ol>"},{"location":"MKDOCS_GUIDE/#adding-custom-javascript","title":"Adding Custom JavaScript","text":"<ol> <li> <p>Create JS file in <code>docs/javascripts/</code>: <pre><code>// docs/javascripts/custom.js\nconsole.log('Custom script loaded');\n</code></pre></p> </li> <li> <p>Reference in <code>mkdocs.yml</code>: <pre><code>extra_javascript:\n  - javascripts/custom.js\n</code></pre></p> </li> </ol>"},{"location":"MKDOCS_GUIDE/#writing-documentation","title":"\ud83d\udcda Writing Documentation","text":""},{"location":"MKDOCS_GUIDE/#markdown-features","title":"Markdown Features","text":"<p>MkDocs Material supports extended Markdown syntax:</p>"},{"location":"MKDOCS_GUIDE/#admonitions","title":"Admonitions","text":"<pre><code>!!! note \"Optional Title\"\n    This is a note admonition.\n\n!!! tip\n    This is a tip without a custom title.\n\n!!! warning \"Caution\"\n    This is a warning.\n\n??? question \"Collapsible Question\"\n    This admonition starts collapsed.\n</code></pre>"},{"location":"MKDOCS_GUIDE/#code-blocks-with-syntax-highlighting","title":"Code Blocks with Syntax Highlighting","text":"<pre><code>```python\ndef hello_world():\n    print(\"Hello, World!\")\n```\n\n```bash\n# Commands with highlighting\ncd /path/to/directory\nls -la\n```\n</code></pre>"},{"location":"MKDOCS_GUIDE/#tabs","title":"Tabs","text":"<pre><code>=== \"Python\"\n\n    ```python\n    print(\"Hello from Python\")\n    ```\n\n=== \"JavaScript\"\n\n    ```javascript\n    console.log(\"Hello from JavaScript\");\n    ```\n</code></pre>"},{"location":"MKDOCS_GUIDE/#mermaid-diagrams","title":"Mermaid Diagrams","text":"<pre><code>```mermaid\ngraph TD\n    A[Start] --&gt; B{Decision}\n    B --&gt;|Yes| C[Action 1]\n    B --&gt;|No| D[Action 2]\n```\n</code></pre>"},{"location":"MKDOCS_GUIDE/#task-lists","title":"Task Lists","text":"<pre><code>- [x] Completed task\n- [ ] Incomplete task\n- [ ] Another task\n</code></pre>"},{"location":"MKDOCS_GUIDE/#emoji","title":"Emoji","text":"<pre><code>:smile: :rocket: :tada:\n</code></pre>"},{"location":"MKDOCS_GUIDE/#file-organization","title":"\ud83d\udcc1 File Organization","text":"<pre><code>project/\n\u251c\u2500\u2500 mkdocs.yml              # Main configuration\n\u251c\u2500\u2500 docs/                   # Documentation source\n\u2502   \u251c\u2500\u2500 index.md            # Home page\n\u2502   \u251c\u2500\u2500 setup/              # Setup guides\n\u2502   \u251c\u2500\u2500 tutorials/          # Tutorials\n\u2502   \u251c\u2500\u2500 api/                # API reference\n\u2502   \u251c\u2500\u2500 stylesheets/        # Custom CSS\n\u2502   \u251c\u2500\u2500 javascripts/        # Custom JS\n\u2502   \u2514\u2500\u2500 assets/             # Images, files\n\u2514\u2500\u2500 site/                   # Built site (generated)\n</code></pre>"},{"location":"MKDOCS_GUIDE/#navigation-structure","title":"\ud83d\udd27 Navigation Structure","text":"<p>Edit navigation in <code>mkdocs.yml</code>:</p> <pre><code>nav:\n  - Home: index.md\n  - Getting Started:\n      - Installation: setup/installation.md\n      - Quick Start: setup/quick-start.md\n  - Tutorials:\n      - Tutorial 1: tutorials/tutorial1.md\n      - Tutorial 2: tutorials/tutorial2.md\n</code></pre>"},{"location":"MKDOCS_GUIDE/#deployment-options","title":"\ud83d\udea2 Deployment Options","text":""},{"location":"MKDOCS_GUIDE/#option-1-github-pages","title":"Option 1: GitHub Pages","text":""},{"location":"MKDOCS_GUIDE/#automatic-deployment","title":"Automatic Deployment","text":"<pre><code># Deploy to GitHub Pages\nmkdocs gh-deploy\n\n# With custom commit message\nmkdocs gh-deploy -m \"Update documentation\"\n</code></pre> <p>This command: 1. Builds the documentation 2. Pushes to <code>gh-pages</code> branch 3. GitHub Pages automatically serves the site</p>"},{"location":"MKDOCS_GUIDE/#manual-deployment","title":"Manual Deployment","text":"<pre><code># Build the site\nmkdocs build\n\n# Commit and push site/ directory\ngit add site/\ngit commit -m \"Update docs\"\ngit push origin gh-pages\n</code></pre>"},{"location":"MKDOCS_GUIDE/#github-actions","title":"GitHub Actions","text":"<p>Create <code>.github/workflows/docs.yml</code>:</p> <pre><code>name: Deploy Documentation\n\non:\n  push:\n    branches: [main]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.9'\n\n      - name: Install dependencies\n        run: |\n          pip install mkdocs-material\n\n      - name: Deploy\n        run: mkdocs gh-deploy --force\n</code></pre>"},{"location":"MKDOCS_GUIDE/#option-2-netlify","title":"Option 2: Netlify","text":"<ol> <li>Connect GitHub repository to Netlify</li> <li>Configure build settings:</li> <li>Build command: <code>mkdocs build</code></li> <li>Publish directory: <code>site</code></li> <li>Deploy</li> </ol>"},{"location":"MKDOCS_GUIDE/#option-3-docker","title":"Option 3: Docker","text":"<p>Create <code>Dockerfile.docs</code>:</p> <pre><code>FROM python:3.9-slim\n\nWORKDIR /docs\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nEXPOSE 8000\n\nCMD [\"mkdocs\", \"serve\", \"--dev-addr=0.0.0.0:8000\"]\n</code></pre> <p>Build and run:</p> <pre><code># Build image\ndocker build -t docs -f Dockerfile.docs .\n\n# Run container\ndocker run -p 8000:8000 docs\n</code></pre>"},{"location":"MKDOCS_GUIDE/#option-4-readthedocs","title":"Option 4: ReadTheDocs","text":"<ol> <li>Create <code>.readthedocs.yml</code>:</li> </ol> <pre><code>version: 2\n\nmkdocs:\n  configuration: mkdocs.yml\n\npython:\n  version: \"3.9\"\n  install:\n    - requirements: requirements.txt\n</code></pre> <ol> <li>Connect repository to ReadTheDocs</li> <li>Documentation builds automatically</li> </ol>"},{"location":"MKDOCS_GUIDE/#search-configuration","title":"\ud83d\udd0d Search Configuration","text":""},{"location":"MKDOCS_GUIDE/#built-in-search","title":"Built-in Search","text":"<p>Enabled by default in <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n  - search:\n      separator: '[\\s\\-,:!=\\[\\]()\"/]+|\\.(?!\\d)|&amp;[lg]t;'\n      lang:\n        - en\n</code></pre>"},{"location":"MKDOCS_GUIDE/#advanced-search-options","title":"Advanced Search Options","text":"<pre><code>plugins:\n  - search:\n      separator: '[\\s\\-,:!=\\[\\]()\"/]+|\\.(?!\\d)|&amp;[lg]t;'\n      lang:\n        - en\n        - es  # Multiple languages\n      prebuild_index: true  # Faster search\n</code></pre>"},{"location":"MKDOCS_GUIDE/#analytics","title":"\ud83d\udcca Analytics","text":""},{"location":"MKDOCS_GUIDE/#google-analytics","title":"Google Analytics","text":"<p>Add to <code>mkdocs.yml</code>:</p> <pre><code>extra:\n  analytics:\n    provider: google\n    property: G-XXXXXXXXXX\n</code></pre>"},{"location":"MKDOCS_GUIDE/#custom-analytics","title":"Custom Analytics","text":"<p>Add tracking code in <code>docs/javascripts/analytics.js</code>:</p> <pre><code>// Custom analytics tracking\nwindow.addEventListener('load', function() {\n  // Your tracking code here\n});\n</code></pre>"},{"location":"MKDOCS_GUIDE/#theming","title":"\ud83c\udfa8 Theming","text":""},{"location":"MKDOCS_GUIDE/#color-schemes","title":"Color Schemes","text":"<pre><code>theme:\n  palette:\n    # Light mode\n    - media: \"(prefers-color-scheme: light)\"\n      scheme: default\n      primary: indigo\n      accent: pink\n      toggle:\n        icon: material/brightness-7\n        name: Switch to dark mode\n\n    # Dark mode\n    - media: \"(prefers-color-scheme: dark)\"\n      scheme: slate\n      primary: indigo\n      accent: pink\n      toggle:\n        icon: material/brightness-4\n        name: Switch to light mode\n</code></pre>"},{"location":"MKDOCS_GUIDE/#logo-and-favicon","title":"Logo and Favicon","text":"<pre><code>theme:\n  logo: assets/logo.png\n  favicon: assets/favicon.png\n</code></pre>"},{"location":"MKDOCS_GUIDE/#plugins","title":"\ud83d\udd27 Plugins","text":""},{"location":"MKDOCS_GUIDE/#essential-plugins","title":"Essential Plugins","text":"<p>Already configured in <code>mkdocs.yml</code>:</p> <ul> <li>search - Full-text search</li> <li>minify - HTML/CSS/JS minification</li> <li>git-revision-date-localized - Show last update dates</li> <li>tags - Tag-based navigation</li> </ul>"},{"location":"MKDOCS_GUIDE/#additional-useful-plugins","title":"Additional Useful Plugins","text":"<pre><code># Install additional plugins\npip install mkdocs-awesome-pages-plugin\npip install mkdocs-macros-plugin\npip install mkdocs-redirects\n</code></pre> <p>Add to <code>mkdocs.yml</code>:</p> <pre><code>plugins:\n  - awesome-pages\n  - macros\n  - redirects:\n      redirect_maps:\n        'old-page.md': 'new-page.md'\n</code></pre>"},{"location":"MKDOCS_GUIDE/#troubleshooting","title":"\ud83d\udc1b Troubleshooting","text":""},{"location":"MKDOCS_GUIDE/#build-warnings","title":"Build Warnings","text":"<pre><code># View warnings in detail\nmkdocs build --strict --verbose\n\n# Common issues:\n# - Broken links: Fix internal links\n# - Missing pages: Add to nav or create file\n# - Invalid YAML: Check mkdocs.yml syntax\n</code></pre>"},{"location":"MKDOCS_GUIDE/#serve-issues","title":"Serve Issues","text":"<pre><code># Port already in use\nmkdocs serve --dev-addr=127.0.0.1:8001\n\n# Permission denied\nsudo mkdocs serve\n</code></pre>"},{"location":"MKDOCS_GUIDE/#deployment-issues","title":"Deployment Issues","text":"<pre><code># GitHub Pages not updating\n# 1. Check gh-pages branch exists\ngit branch -a\n\n# 2. Force rebuild\nmkdocs gh-deploy --force\n\n# 3. Check GitHub Pages settings\n</code></pre>"},{"location":"MKDOCS_GUIDE/#best-practices","title":"\ud83d\udcdd Best Practices","text":""},{"location":"MKDOCS_GUIDE/#1-file-organization","title":"1. File Organization","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md              # Landing page\n\u251c\u2500\u2500 getting-started/      # Tutorial content\n\u251c\u2500\u2500 guides/               # How-to guides\n\u251c\u2500\u2500 reference/            # API reference\n\u2514\u2500\u2500 explanations/         # Conceptual docs\n</code></pre>"},{"location":"MKDOCS_GUIDE/#2-naming-conventions","title":"2. Naming Conventions","text":"<ul> <li>Use lowercase with hyphens: <code>my-page.md</code></li> <li>Avoid spaces and special characters</li> <li>Keep filenames descriptive but concise</li> </ul>"},{"location":"MKDOCS_GUIDE/#3-internal-links","title":"3. Internal Links","text":"<pre><code># Relative links\n[Link to page](../other-page.md)\n\n# Anchor links\n[Link to section](#section-heading)\n\n# Cross-references\n[API Reference](reference/api.md#specific-function)\n</code></pre>"},{"location":"MKDOCS_GUIDE/#4-images","title":"4. Images","text":"<pre><code># With caption\n![Description](images/screenshot.png)\n*Figure 1: Screenshot of the UI*\n\n# With sizing\n![Description](images/logo.png){ width=\"300\" }\n</code></pre>"},{"location":"MKDOCS_GUIDE/#5-code-examples","title":"5. Code Examples","text":"<pre><code># With title and line numbers\n```python title=\"example.py\" linenums=\"1\"\ndef example():\n    return \"Hello\"\n```\n\n# With highlighting\n```python hl_lines=\"2 3\"\ndef example():\n    # This line is highlighted\n    # This line is highlighted\n    return \"Hello\"\n```\n</code></pre>"},{"location":"MKDOCS_GUIDE/#version-control","title":"\ud83d\udd04 Version Control","text":""},{"location":"MKDOCS_GUIDE/#gitignore","title":".gitignore","text":"<p>Add to <code>.gitignore</code>:</p> <pre><code># MkDocs\nsite/\n.cache/\n\n# Python\n__pycache__/\n*.pyc\nvenv/\n</code></pre>"},{"location":"MKDOCS_GUIDE/#commit-messages","title":"Commit Messages","text":"<pre><code># Good commit messages\ngit commit -m \"docs: Add API reference for collectors\"\ngit commit -m \"docs: Update installation guide with Docker\"\ngit commit -m \"docs: Fix broken links in tutorials\"\n</code></pre>"},{"location":"MKDOCS_GUIDE/#resources","title":"\ud83d\udcda Resources","text":""},{"location":"MKDOCS_GUIDE/#official-documentation","title":"Official Documentation","text":"<ul> <li>MkDocs</li> <li>Material for MkDocs</li> <li>PyMdown Extensions</li> </ul>"},{"location":"MKDOCS_GUIDE/#community","title":"Community","text":"<ul> <li>MkDocs Discussion</li> <li>Material Theme Discussion</li> </ul>"},{"location":"MKDOCS_GUIDE/#examples","title":"Examples","text":"<ul> <li>Material Theme Showcase</li> <li>MkDocs Examples</li> </ul>"},{"location":"MKDOCS_GUIDE/#quick-commands-reference","title":"\ud83c\udfaf Quick Commands Reference","text":"<pre><code># Development\nmkdocs serve              # Start dev server\nmkdocs serve --strict     # With strict mode\nmkdocs build              # Build site\nmkdocs build --clean      # Clean build\n\n# Deployment\nmkdocs gh-deploy          # Deploy to GitHub Pages\nmkdocs gh-deploy --force  # Force deploy\n\n# Other\nmkdocs new project-name   # Create new project\nmkdocs --version          # Check version\nmkdocs --help             # Show help\n</code></pre>"},{"location":"MKDOCS_GUIDE/#performance-tips","title":"\ud83d\udcca Performance Tips","text":"<ol> <li>Optimize Images</li> <li>Compress images before adding</li> <li>Use appropriate formats (WebP, PNG, JPG)</li> <li> <p>Resize to appropriate dimensions</p> </li> <li> <p>Minimize Custom Code</p> </li> <li>Keep custom CSS/JS minimal</li> <li> <p>Use built-in features when possible</p> </li> <li> <p>Enable Caching</p> </li> <li>Use browser caching</li> <li> <p>Enable CDN for assets</p> </li> <li> <p>Lazy Loading</p> </li> <li>Defer non-critical scripts</li> <li>Lazy load images when possible</li> </ol> <p>Need Help?</p> <ul> <li>Check MkDocs Material Documentation</li> <li>Visit GitHub Discussions</li> <li>Review Examples and Tutorials</li> </ul>"},{"location":"tags/","title":"Tags","text":"<p>Browse documentation by tags:</p>"},{"location":"tags/#available-tags","title":"Available Tags","text":"<ul> <li>setup - Installation and configuration guides</li> <li>tutorial - Step-by-step tutorials</li> <li>api - API references and endpoints</li> <li>architecture - System design and architecture</li> <li>deployment - Deployment guides</li> <li>troubleshooting - Problem-solving guides</li> <li>advanced - Advanced topics and customization</li> <li>database - Database schema and operations</li> <li>search - Search and retrieval topics</li> <li>ml - Machine learning and AI features</li> <li>performance - Performance optimization</li> <li>security - Security best practices</li> </ul> <p>Back to Documentation</p>"},{"location":"advanced/custom-collectors/","title":"Building Custom Data Collectors","text":"<p>Comprehensive guide to building custom data collectors for the Multi-Modal Academic Research System.</p>"},{"location":"advanced/custom-collectors/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Collector Architecture</li> <li>Building Your First Collector</li> <li>Advanced Collector Patterns</li> <li>Data Source Examples</li> <li>Error Handling</li> <li>Testing Collectors</li> <li>Best Practices</li> </ul>"},{"location":"advanced/custom-collectors/#overview","title":"Overview","text":""},{"location":"advanced/custom-collectors/#what-is-a-data-collector","title":"What is a Data Collector?","text":"<p>A data collector is a module that: 1. Connects to an external data source (API, website, file system) 2. Retrieves content based on search criteria 3. Transforms data into a standard format 4. Returns structured data for indexing</p>"},{"location":"advanced/custom-collectors/#when-to-build-a-custom-collector","title":"When to Build a Custom Collector","text":"<p>Build a custom collector when you want to: - Add a new data source (e.g., Google Scholar, JSTOR) - Collect specific content types (e.g., datasets, code repositories) - Integrate proprietary data sources - Customize existing collectors</p>"},{"location":"advanced/custom-collectors/#collector-architecture","title":"Collector Architecture","text":""},{"location":"advanced/custom-collectors/#standard-data-format","title":"Standard Data Format","text":"<p>All collectors should return data in this format:</p> <pre><code>{\n    'id': 'unique_identifier',\n    'content_type': 'paper|video|podcast|custom',\n    'title': 'Content title',\n    'abstract': 'Brief summary or description',\n    'content': 'Full text content',\n    'authors': ['Author 1', 'Author 2'],\n    'publication_date': '2024-01-15',\n    'source_url': 'https://source.url',\n    'metadata': {\n        # Additional source-specific metadata\n        'journal': 'Journal name',\n        'doi': '10.1234/example',\n        'citations': 42\n    }\n}\n</code></pre>"},{"location":"advanced/custom-collectors/#collector-interface","title":"Collector Interface","text":"<pre><code>from typing import List, Dict, Optional\nfrom abc import ABC, abstractmethod\n\nclass BaseCollector(ABC):\n    \"\"\"Base class for all data collectors.\"\"\"\n\n    def __init__(self, api_key: Optional[str] = None):\n        \"\"\"Initialize collector.\"\"\"\n        self.api_key = api_key\n\n    @abstractmethod\n    def collect(self, query: str, max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"\n        Collect data from source.\n\n        Args:\n            query: Search query\n            max_results: Maximum number of results to return\n\n        Returns:\n            List of documents in standard format\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"\n        Validate that result has required fields.\n\n        Args:\n            result: Document to validate\n\n        Returns:\n            True if valid, False otherwise\n        \"\"\"\n        pass\n\n    def format_date(self, date_string: str) -&gt; str:\n        \"\"\"\n        Convert date to standard format (YYYY-MM-DD).\n\n        Args:\n            date_string: Date in various formats\n\n        Returns:\n            Standardized date string\n        \"\"\"\n        from dateutil import parser\n        try:\n            date_obj = parser.parse(date_string)\n            return date_obj.strftime('%Y-%m-%d')\n        except:\n            return '1970-01-01'  # Default date\n\n    def clean_text(self, text: str) -&gt; str:\n        \"\"\"\n        Clean and normalize text.\n\n        Args:\n            text: Raw text\n\n        Returns:\n            Cleaned text\n        \"\"\"\n        import re\n\n        # Remove extra whitespace\n        text = re.sub(r'\\s+', ' ', text)\n\n        # Remove special characters\n        text = text.strip()\n\n        return text\n</code></pre>"},{"location":"advanced/custom-collectors/#building-your-first-collector","title":"Building Your First Collector","text":""},{"location":"advanced/custom-collectors/#example-google-scholar-collector","title":"Example: Google Scholar Collector","text":"<pre><code>from scholarly import scholarly\nfrom typing import List, Dict\nimport time\n\nclass GoogleScholarCollector(BaseCollector):\n    \"\"\"Collector for Google Scholar papers.\"\"\"\n\n    def __init__(self):\n        \"\"\"Initialize collector.\"\"\"\n        super().__init__()\n\n    def collect(self, query: str, max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"\n        Collect papers from Google Scholar.\n\n        Args:\n            query: Search query\n            max_results: Maximum number of results\n\n        Returns:\n            List of papers in standard format\n        \"\"\"\n        results = []\n\n        try:\n            # Search Google Scholar\n            search_query = scholarly.search_pubs(query)\n\n            # Collect results\n            for i, result in enumerate(search_query):\n                if i &gt;= max_results:\n                    break\n\n                # Fill in details\n                try:\n                    paper = scholarly.fill(result)\n                    formatted = self._format_paper(paper)\n\n                    if self.validate_result(formatted):\n                        results.append(formatted)\n\n                except Exception as e:\n                    print(f\"Error processing paper: {e}\")\n                    continue\n\n                # Rate limiting\n                time.sleep(1)\n\n        except Exception as e:\n            print(f\"Error searching Google Scholar: {e}\")\n\n        return results\n\n    def _format_paper(self, paper: Dict) -&gt; Dict:\n        \"\"\"\n        Convert Scholar paper to standard format.\n\n        Args:\n            paper: Paper from scholarly\n\n        Returns:\n            Formatted paper\n        \"\"\"\n        # Extract data\n        title = paper.get('bib', {}).get('title', '')\n        abstract = paper.get('bib', {}).get('abstract', '')\n        authors = paper.get('bib', {}).get('author', [])\n        year = paper.get('bib', {}).get('pub_year', '1970')\n        url = paper.get('pub_url', '')\n        citations = paper.get('num_citations', 0)\n\n        # Generate ID\n        paper_id = f\"scholar_{hash(title)}\"\n\n        # Format date\n        date = self.format_date(f\"{year}-01-01\")\n\n        return {\n            'id': paper_id,\n            'content_type': 'paper',\n            'title': self.clean_text(title),\n            'abstract': self.clean_text(abstract),\n            'content': abstract,  # Scholar doesn't provide full text\n            'authors': authors if isinstance(authors, list) else [authors],\n            'publication_date': date,\n            'source_url': url,\n            'metadata': {\n                'source': 'Google Scholar',\n                'citations': citations,\n                'year': year\n            }\n        }\n\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"Validate result has required fields.\"\"\"\n        required = ['id', 'title', 'content_type']\n\n        for field in required:\n            if field not in result or not result[field]:\n                return False\n\n        return True\n\n# Usage\ncollector = GoogleScholarCollector()\npapers = collector.collect(\"deep learning\", max_results=5)\n\nfor paper in papers:\n    print(f\"Title: {paper['title']}\")\n    print(f\"Authors: {', '.join(paper['authors'])}\")\n    print(f\"Date: {paper['publication_date']}\")\n    print(f\"Citations: {paper['metadata']['citations']}\")\n    print(\"-\" * 60)\n</code></pre>"},{"location":"advanced/custom-collectors/#advanced-collector-patterns","title":"Advanced Collector Patterns","text":""},{"location":"advanced/custom-collectors/#1-authenticated-collector","title":"1. Authenticated Collector","text":"<p>For APIs requiring authentication:</p> <pre><code>import requests\nfrom typing import Optional\n\nclass AuthenticatedCollector(BaseCollector):\n    \"\"\"Collector for authenticated API.\"\"\"\n\n    def __init__(self, api_key: str, base_url: str):\n        \"\"\"\n        Initialize collector.\n\n        Args:\n            api_key: API key for authentication\n            base_url: Base API URL\n        \"\"\"\n        super().__init__(api_key)\n        self.base_url = base_url\n        self.session = self._create_session()\n\n    def _create_session(self) -&gt; requests.Session:\n        \"\"\"Create authenticated session.\"\"\"\n        session = requests.Session()\n        session.headers.update({\n            'Authorization': f'Bearer {self.api_key}',\n            'Content-Type': 'application/json',\n            'User-Agent': 'ResearchAssistant/1.0'\n        })\n        return session\n\n    def collect(self, query: str, max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"Collect data from authenticated API.\"\"\"\n        try:\n            response = self.session.get(\n                f\"{self.base_url}/search\",\n                params={\n                    'query': query,\n                    'limit': max_results\n                },\n                timeout=30\n            )\n\n            response.raise_for_status()\n            data = response.json()\n\n            return [self._format_result(item) for item in data['results']]\n\n        except requests.exceptions.RequestException as e:\n            print(f\"API request failed: {e}\")\n            return []\n\n    def _format_result(self, item: Dict) -&gt; Dict:\n        \"\"\"Format API result to standard format.\"\"\"\n        # Implementation specific to API\n        pass\n\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"Validate result.\"\"\"\n        return all(k in result for k in ['id', 'title', 'content_type'])\n</code></pre>"},{"location":"advanced/custom-collectors/#2-paginated-collector","title":"2. Paginated Collector","text":"<p>For APIs with pagination:</p> <pre><code>class PaginatedCollector(BaseCollector):\n    \"\"\"Collector that handles pagination.\"\"\"\n\n    def collect(self, query: str, max_results: int = 100) -&gt; List[Dict]:\n        \"\"\"Collect with pagination.\"\"\"\n        all_results = []\n        page = 1\n        per_page = 20\n\n        while len(all_results) &lt; max_results:\n            try:\n                page_results = self._fetch_page(query, page, per_page)\n\n                if not page_results:\n                    break\n\n                all_results.extend(page_results)\n                page += 1\n\n                # Rate limiting\n                time.sleep(1)\n\n            except Exception as e:\n                print(f\"Error fetching page {page}: {e}\")\n                break\n\n        return all_results[:max_results]\n\n    def _fetch_page(\n        self,\n        query: str,\n        page: int,\n        per_page: int\n    ) -&gt; List[Dict]:\n        \"\"\"Fetch single page of results.\"\"\"\n        response = requests.get(\n            f\"{self.api_url}/search\",\n            params={\n                'q': query,\n                'page': page,\n                'per_page': per_page\n            }\n        )\n\n        response.raise_for_status()\n        data = response.json()\n\n        return [self._format_result(item) for item in data['items']]\n\n    def _format_result(self, item: Dict) -&gt; Dict:\n        \"\"\"Format result.\"\"\"\n        pass\n\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"Validate result.\"\"\"\n        return True\n</code></pre>"},{"location":"advanced/custom-collectors/#3-async-collector","title":"3. Async Collector","text":"<p>For concurrent collection:</p> <pre><code>import asyncio\nimport aiohttp\nfrom typing import List, Dict\n\nclass AsyncCollector(BaseCollector):\n    \"\"\"Async collector for concurrent requests.\"\"\"\n\n    async def collect_async(\n        self,\n        queries: List[str],\n        max_results_per_query: int = 10\n    ) -&gt; List[Dict]:\n        \"\"\"\n        Collect from multiple queries concurrently.\n\n        Args:\n            queries: List of search queries\n            max_results_per_query: Max results per query\n\n        Returns:\n            Combined results from all queries\n        \"\"\"\n        async with aiohttp.ClientSession() as session:\n            tasks = [\n                self._fetch_query(session, query, max_results_per_query)\n                for query in queries\n            ]\n\n            results = await asyncio.gather(*tasks)\n\n        # Flatten results\n        all_results = []\n        for query_results in results:\n            all_results.extend(query_results)\n\n        return all_results\n\n    async def _fetch_query(\n        self,\n        session: aiohttp.ClientSession,\n        query: str,\n        max_results: int\n    ) -&gt; List[Dict]:\n        \"\"\"Fetch results for single query.\"\"\"\n        try:\n            async with session.get(\n                f\"{self.api_url}/search\",\n                params={'q': query, 'limit': max_results}\n            ) as response:\n                data = await response.json()\n\n                return [\n                    self._format_result(item)\n                    for item in data['results']\n                ]\n\n        except Exception as e:\n            print(f\"Error fetching query '{query}': {e}\")\n            return []\n\n    def collect(self, query: str, max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"Sync interface for async collection.\"\"\"\n        return asyncio.run(\n            self.collect_async([query], max_results)\n        )\n\n    def _format_result(self, item: Dict) -&gt; Dict:\n        \"\"\"Format result.\"\"\"\n        pass\n\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"Validate result.\"\"\"\n        return True\n\n# Usage\ncollector = AsyncCollector(api_key=\"...\")\nresults = asyncio.run(\n    collector.collect_async(\n        [\"machine learning\", \"deep learning\", \"neural networks\"],\n        max_results_per_query=20\n    )\n)\n</code></pre>"},{"location":"advanced/custom-collectors/#4-cached-collector","title":"4. Cached Collector","text":"<p>With built-in caching:</p> <pre><code>import pickle\nimport os\nfrom datetime import datetime, timedelta\n\nclass CachedCollector(BaseCollector):\n    \"\"\"Collector with result caching.\"\"\"\n\n    def __init__(self, cache_dir: str = 'cache', cache_ttl: int = 86400):\n        \"\"\"\n        Initialize collector.\n\n        Args:\n            cache_dir: Directory for cache files\n            cache_ttl: Cache time-to-live in seconds\n        \"\"\"\n        super().__init__()\n        self.cache_dir = cache_dir\n        self.cache_ttl = cache_ttl\n        os.makedirs(cache_dir, exist_ok=True)\n\n    def collect(self, query: str, max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"Collect with caching.\"\"\"\n        # Check cache\n        cached = self._get_cached(query, max_results)\n        if cached is not None:\n            print(f\"Using cached results for: {query}\")\n            return cached\n\n        # Fetch fresh data\n        results = self._collect_fresh(query, max_results)\n\n        # Cache results\n        self._cache_results(query, max_results, results)\n\n        return results\n\n    def _get_cache_path(self, query: str, max_results: int) -&gt; str:\n        \"\"\"Get cache file path.\"\"\"\n        import hashlib\n        key = f\"{query}_{max_results}\"\n        hash_key = hashlib.md5(key.encode()).hexdigest()\n        return os.path.join(self.cache_dir, f\"{hash_key}.pkl\")\n\n    def _get_cached(self, query: str, max_results: int) -&gt; Optional[List[Dict]]:\n        \"\"\"Get cached results if available and not expired.\"\"\"\n        cache_path = self._get_cache_path(query, max_results)\n\n        if not os.path.exists(cache_path):\n            return None\n\n        # Check if expired\n        file_time = datetime.fromtimestamp(os.path.getmtime(cache_path))\n        if datetime.now() - file_time &gt; timedelta(seconds=self.cache_ttl):\n            os.remove(cache_path)\n            return None\n\n        # Load cache\n        try:\n            with open(cache_path, 'rb') as f:\n                return pickle.load(f)\n        except:\n            return None\n\n    def _cache_results(\n        self,\n        query: str,\n        max_results: int,\n        results: List[Dict]\n    ):\n        \"\"\"Cache results.\"\"\"\n        cache_path = self._get_cache_path(query, max_results)\n\n        try:\n            with open(cache_path, 'wb') as f:\n                pickle.dump(results, f)\n        except Exception as e:\n            print(f\"Error caching results: {e}\")\n\n    def _collect_fresh(self, query: str, max_results: int) -&gt; List[Dict]:\n        \"\"\"Collect fresh data (implement in subclass).\"\"\"\n        raise NotImplementedError\n\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"Validate result.\"\"\"\n        return True\n</code></pre>"},{"location":"advanced/custom-collectors/#data-source-examples","title":"Data Source Examples","text":""},{"location":"advanced/custom-collectors/#1-github-repository-collector","title":"1. GitHub Repository Collector","text":"<pre><code>import requests\n\nclass GitHubCollector(BaseCollector):\n    \"\"\"Collect code repositories from GitHub.\"\"\"\n\n    def __init__(self, api_token: str):\n        \"\"\"Initialize with GitHub API token.\"\"\"\n        super().__init__(api_token)\n        self.api_url = \"https://api.github.com\"\n        self.headers = {\n            'Authorization': f'token {api_token}',\n            'Accept': 'application/vnd.github.v3+json'\n        }\n\n    def collect(self, query: str, max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"Search GitHub repositories.\"\"\"\n        try:\n            response = requests.get(\n                f\"{self.api_url}/search/repositories\",\n                headers=self.headers,\n                params={\n                    'q': query,\n                    'sort': 'stars',\n                    'order': 'desc',\n                    'per_page': max_results\n                }\n            )\n\n            response.raise_for_status()\n            data = response.json()\n\n            return [\n                self._format_repository(repo)\n                for repo in data['items']\n            ]\n\n        except Exception as e:\n            print(f\"GitHub API error: {e}\")\n            return []\n\n    def _format_repository(self, repo: Dict) -&gt; Dict:\n        \"\"\"Format repository to standard format.\"\"\"\n        return {\n            'id': f\"github_{repo['id']}\",\n            'content_type': 'code',\n            'title': repo['full_name'],\n            'abstract': repo.get('description', ''),\n            'content': self._get_readme(repo),\n            'authors': [repo['owner']['login']],\n            'publication_date': self.format_date(repo['created_at']),\n            'source_url': repo['html_url'],\n            'metadata': {\n                'source': 'GitHub',\n                'stars': repo['stargazers_count'],\n                'forks': repo['forks_count'],\n                'language': repo['language'],\n                'topics': repo.get('topics', [])\n            }\n        }\n\n    def _get_readme(self, repo: Dict) -&gt; str:\n        \"\"\"Fetch repository README.\"\"\"\n        try:\n            response = requests.get(\n                f\"{self.api_url}/repos/{repo['full_name']}/readme\",\n                headers=self.headers\n            )\n\n            if response.status_code == 200:\n                import base64\n                content = base64.b64decode(\n                    response.json()['content']\n                ).decode('utf-8')\n                return content\n            else:\n                return repo.get('description', '')\n\n        except:\n            return repo.get('description', '')\n\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"Validate result.\"\"\"\n        return result.get('title') and result.get('content_type') == 'code'\n</code></pre>"},{"location":"advanced/custom-collectors/#2-rss-feed-collector","title":"2. RSS Feed Collector","text":"<pre><code>import feedparser\n\nclass RSSCollector(BaseCollector):\n    \"\"\"Collect articles from RSS feeds.\"\"\"\n\n    def __init__(self, feed_urls: List[str]):\n        \"\"\"\n        Initialize with RSS feed URLs.\n\n        Args:\n            feed_urls: List of RSS feed URLs\n        \"\"\"\n        super().__init__()\n        self.feed_urls = feed_urls\n\n    def collect(self, query: str = \"\", max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"\n        Collect articles from RSS feeds.\n\n        Args:\n            query: Optional filter query\n            max_results: Maximum total results\n\n        Returns:\n            List of articles\n        \"\"\"\n        all_articles = []\n\n        for feed_url in self.feed_urls:\n            try:\n                feed = feedparser.parse(feed_url)\n\n                for entry in feed.entries:\n                    # Filter by query if provided\n                    if query and query.lower() not in entry.title.lower():\n                        continue\n\n                    article = self._format_entry(entry, feed_url)\n                    if self.validate_result(article):\n                        all_articles.append(article)\n\n                    if len(all_articles) &gt;= max_results:\n                        break\n\n            except Exception as e:\n                print(f\"Error parsing feed {feed_url}: {e}\")\n                continue\n\n            if len(all_articles) &gt;= max_results:\n                break\n\n        return all_articles[:max_results]\n\n    def _format_entry(self, entry, feed_url: str) -&gt; Dict:\n        \"\"\"Format RSS entry to standard format.\"\"\"\n        return {\n            'id': f\"rss_{hash(entry.link)}\",\n            'content_type': 'article',\n            'title': entry.title,\n            'abstract': entry.get('summary', '')[:500],\n            'content': entry.get('summary', ''),\n            'authors': [entry.get('author', 'Unknown')],\n            'publication_date': self.format_date(\n                entry.get('published', '1970-01-01')\n            ),\n            'source_url': entry.link,\n            'metadata': {\n                'source': 'RSS',\n                'feed_url': feed_url,\n                'tags': [tag.term for tag in entry.get('tags', [])]\n            }\n        }\n\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"Validate result.\"\"\"\n        return bool(result.get('title') and result.get('source_url'))\n</code></pre>"},{"location":"advanced/custom-collectors/#3-web-scraper-collector","title":"3. Web Scraper Collector","text":"<pre><code>from bs4 import BeautifulSoup\nimport requests\n\nclass WebScraperCollector(BaseCollector):\n    \"\"\"Scrape content from websites.\"\"\"\n\n    def __init__(self, target_urls: List[str]):\n        \"\"\"\n        Initialize with target URLs.\n\n        Args:\n            target_urls: List of URLs to scrape\n        \"\"\"\n        super().__init__()\n        self.target_urls = target_urls\n\n    def collect(self, query: str = \"\", max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"Scrape content from target URLs.\"\"\"\n        results = []\n\n        for url in self.target_urls:\n            if len(results) &gt;= max_results:\n                break\n\n            try:\n                content = self._scrape_url(url)\n\n                # Filter by query if provided\n                if query and query.lower() not in content['content'].lower():\n                    continue\n\n                if self.validate_result(content):\n                    results.append(content)\n\n            except Exception as e:\n                print(f\"Error scraping {url}: {e}\")\n                continue\n\n        return results\n\n    def _scrape_url(self, url: str) -&gt; Dict:\n        \"\"\"Scrape single URL.\"\"\"\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n\n        soup = BeautifulSoup(response.content, 'html.parser')\n\n        # Extract content\n        title = soup.find('h1').get_text() if soup.find('h1') else url\n        paragraphs = soup.find_all('p')\n        content = '\\n\\n'.join([p.get_text() for p in paragraphs])\n\n        return {\n            'id': f\"web_{hash(url)}\",\n            'content_type': 'article',\n            'title': self.clean_text(title),\n            'abstract': content[:500],\n            'content': content,\n            'authors': ['Unknown'],\n            'publication_date': '1970-01-01',\n            'source_url': url,\n            'metadata': {\n                'source': 'Web Scraping',\n                'scraped_at': datetime.now().isoformat()\n            }\n        }\n\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"Validate result.\"\"\"\n        return bool(result.get('content') and len(result['content']) &gt; 100)\n</code></pre>"},{"location":"advanced/custom-collectors/#error-handling","title":"Error Handling","text":""},{"location":"advanced/custom-collectors/#robust-error-handling-pattern","title":"Robust Error Handling Pattern","text":"<pre><code>class RobustCollector(BaseCollector):\n    \"\"\"Collector with comprehensive error handling.\"\"\"\n\n    def collect(self, query: str, max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"Collect with error handling.\"\"\"\n        results = []\n        errors = []\n\n        try:\n            raw_results = self._fetch_data(query, max_results)\n\n            for item in raw_results:\n                try:\n                    formatted = self._format_result(item)\n\n                    if self.validate_result(formatted):\n                        results.append(formatted)\n                    else:\n                        errors.append({\n                            'item': item,\n                            'error': 'Validation failed'\n                        })\n\n                except Exception as e:\n                    errors.append({\n                        'item': item,\n                        'error': str(e)\n                    })\n\n        except Exception as e:\n            print(f\"Fatal error in collect: {e}\")\n            return []\n\n        # Log errors\n        if errors:\n            self._log_errors(errors)\n\n        return results\n\n    def _log_errors(self, errors: List[Dict]):\n        \"\"\"Log collection errors.\"\"\"\n        import logging\n\n        logging.basicConfig(filename='collector_errors.log')\n        for error in errors:\n            logging.error(f\"Collection error: {error}\")\n\n    def _fetch_data(self, query: str, max_results: int):\n        \"\"\"Fetch data (implement in subclass).\"\"\"\n        raise NotImplementedError\n\n    def _format_result(self, item: Dict) -&gt; Dict:\n        \"\"\"Format result (implement in subclass).\"\"\"\n        raise NotImplementedError\n\n    def validate_result(self, result: Dict) -&gt; bool:\n        \"\"\"Validate result.\"\"\"\n        return True\n</code></pre>"},{"location":"advanced/custom-collectors/#testing-collectors","title":"Testing Collectors","text":""},{"location":"advanced/custom-collectors/#unit-tests","title":"Unit Tests","text":"<pre><code>import unittest\n\nclass TestCollector(unittest.TestCase):\n    \"\"\"Test suite for collectors.\"\"\"\n\n    def setUp(self):\n        \"\"\"Set up test collector.\"\"\"\n        self.collector = MyCollector(api_key=\"test_key\")\n\n    def test_collect_returns_list(self):\n        \"\"\"Test collect returns list.\"\"\"\n        results = self.collector.collect(\"test query\", max_results=5)\n        self.assertIsInstance(results, list)\n\n    def test_collect_respects_max_results(self):\n        \"\"\"Test max_results parameter.\"\"\"\n        results = self.collector.collect(\"test query\", max_results=5)\n        self.assertLessEqual(len(results), 5)\n\n    def test_result_format(self):\n        \"\"\"Test result has required fields.\"\"\"\n        results = self.collector.collect(\"test query\", max_results=1)\n\n        if results:\n            result = results[0]\n            required_fields = ['id', 'title', 'content_type', 'content']\n\n            for field in required_fields:\n                self.assertIn(field, result)\n\n    def test_validation(self):\n        \"\"\"Test result validation.\"\"\"\n        valid_result = {\n            'id': '123',\n            'title': 'Test',\n            'content_type': 'paper',\n            'content': 'Content'\n        }\n\n        invalid_result = {\n            'id': '123'\n            # Missing required fields\n        }\n\n        self.assertTrue(self.collector.validate_result(valid_result))\n        self.assertFalse(self.collector.validate_result(invalid_result))\n\n    def test_error_handling(self):\n        \"\"\"Test error handling.\"\"\"\n        # Should not raise exception\n        try:\n            results = self.collector.collect(\"\", max_results=-1)\n            self.assertIsInstance(results, list)\n        except Exception as e:\n            self.fail(f\"Collector raised exception: {e}\")\n\nif __name__ == '__main__':\n    unittest.main()\n</code></pre>"},{"location":"advanced/custom-collectors/#best-practices","title":"Best Practices","text":""},{"location":"advanced/custom-collectors/#1-rate-limiting","title":"1. Rate Limiting","text":"<pre><code>import time\nfrom functools import wraps\n\ndef rate_limit(calls_per_second=1):\n    \"\"\"Rate limiting decorator.\"\"\"\n    min_interval = 1.0 / calls_per_second\n    last_called = [0.0]\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            elapsed = time.time() - last_called[0]\n            wait_time = min_interval - elapsed\n\n            if wait_time &gt; 0:\n                time.sleep(wait_time)\n\n            result = func(*args, **kwargs)\n            last_called[0] = time.time()\n            return result\n\n        return wrapper\n    return decorator\n\n# Usage\nclass RateLimitedCollector(BaseCollector):\n    @rate_limit(calls_per_second=2)\n    def _fetch_page(self, query: str):\n        \"\"\"Fetch page with rate limiting.\"\"\"\n        pass\n</code></pre>"},{"location":"advanced/custom-collectors/#2-retry-logic","title":"2. Retry Logic","text":"<pre><code>from functools import wraps\nimport time\n\ndef retry(max_attempts=3, delay=1, backoff=2):\n    \"\"\"Retry decorator with exponential backoff.\"\"\"\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            attempts = 0\n            current_delay = delay\n\n            while attempts &lt; max_attempts:\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    attempts += 1\n                    if attempts &gt;= max_attempts:\n                        raise\n\n                    print(f\"Attempt {attempts} failed: {e}\")\n                    print(f\"Retrying in {current_delay}s...\")\n                    time.sleep(current_delay)\n                    current_delay *= backoff\n\n        return wrapper\n    return decorator\n\n# Usage\n@retry(max_attempts=3, delay=1, backoff=2)\ndef fetch_data(url):\n    \"\"\"Fetch data with retry.\"\"\"\n    response = requests.get(url)\n    response.raise_for_status()\n    return response.json()\n</code></pre>"},{"location":"advanced/custom-collectors/#3-logging","title":"3. Logging","text":"<pre><code>import logging\n\nclass LoggedCollector(BaseCollector):\n    \"\"\"Collector with comprehensive logging.\"\"\"\n\n    def __init__(self):\n        super().__init__()\n        self._setup_logging()\n\n    def _setup_logging(self):\n        \"\"\"Set up logging.\"\"\"\n        logging.basicConfig(\n            level=logging.INFO,\n            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n            handlers=[\n                logging.FileHandler('collector.log'),\n                logging.StreamHandler()\n            ]\n        )\n        self.logger = logging.getLogger(self.__class__.__name__)\n\n    def collect(self, query: str, max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"Collect with logging.\"\"\"\n        self.logger.info(f\"Starting collection: query='{query}', max={max_results}\")\n\n        try:\n            results = self._collect_impl(query, max_results)\n            self.logger.info(f\"Collected {len(results)} results\")\n            return results\n\n        except Exception as e:\n            self.logger.error(f\"Collection failed: {e}\", exc_info=True)\n            return []\n</code></pre>"},{"location":"advanced/custom-collectors/#4-configuration","title":"4. Configuration","text":"<pre><code>from dataclasses import dataclass\nfrom typing import Optional\n\n@dataclass\nclass CollectorConfig:\n    \"\"\"Configuration for collector.\"\"\"\n    api_key: Optional[str] = None\n    base_url: str = \"\"\n    timeout: int = 30\n    max_retries: int = 3\n    rate_limit: float = 1.0  # Requests per second\n    cache_enabled: bool = True\n    cache_ttl: int = 3600\n\nclass ConfigurableCollector(BaseCollector):\n    \"\"\"Collector with configuration.\"\"\"\n\n    def __init__(self, config: CollectorConfig):\n        \"\"\"Initialize with configuration.\"\"\"\n        super().__init__(config.api_key)\n        self.config = config\n\n    def collect(self, query: str, max_results: int = 10) -&gt; List[Dict]:\n        \"\"\"Collect using configuration.\"\"\"\n        # Use config values\n        pass\n\n# Usage\nconfig = CollectorConfig(\n    api_key=\"your_key\",\n    base_url=\"https://api.example.com\",\n    timeout=60,\n    max_retries=5\n)\n\ncollector = ConfigurableCollector(config)\n</code></pre>"},{"location":"advanced/custom-collectors/#integration-with-system","title":"Integration with System","text":""},{"location":"advanced/custom-collectors/#register-collector","title":"Register Collector","text":"<pre><code># In main.py\nfrom multi_modal_rag.data_collectors.custom_collector import CustomCollector\n\n# Register collector\ndata_collectors = {\n    'arxiv': arxiv_collector,\n    'youtube': youtube_collector,\n    'custom': CustomCollector()  # Add your collector\n}\n\n# Use in UI (gradio_app.py)\ncollector_choice = gr.Dropdown(\n    choices=['arxiv', 'youtube', 'custom'],\n    label=\"Data Source\"\n)\n</code></pre>"},{"location":"advanced/custom-collectors/#additional-resources","title":"Additional Resources","text":"<ul> <li>requests Documentation</li> <li>BeautifulSoup Documentation</li> <li>aiohttp Documentation</li> <li>API Best Practices</li> </ul>"},{"location":"advanced/custom-collectors/#summary","title":"Summary","text":"<p>Key Points: 1. Follow standard data format 2. Implement error handling 3. Add rate limiting 4. Include logging 5. Write tests 6. Document your collector 7. Consider caching</p> <p>Quick Start Checklist: - [ ] Create collector class inheriting from BaseCollector - [ ] Implement collect() method - [ ] Implement validate_result() method - [ ] Add error handling - [ ] Test with sample queries - [ ] Document usage - [ ] Register in main.py</p>"},{"location":"advanced/embedding-models/","title":"Embedding Models Deep Dive","text":"<p>Comprehensive guide to understanding and working with embedding models in the Multi-Modal Academic Research System.</p>"},{"location":"advanced/embedding-models/#table-of-contents","title":"Table of Contents","text":"<ul> <li>What Are Embeddings?</li> <li>Current Implementation</li> <li>Choosing an Embedding Model</li> <li>Model Comparison</li> <li>Changing Embedding Models</li> <li>Fine-Tuning Embeddings</li> <li>Optimization Techniques</li> <li>Advanced Topics</li> </ul>"},{"location":"advanced/embedding-models/#what-are-embeddings","title":"What Are Embeddings?","text":""},{"location":"advanced/embedding-models/#definition","title":"Definition","text":"<p>Embeddings are dense vector representations of text that capture semantic meaning. Similar concepts have similar vectors (measured by cosine similarity or other distance metrics).</p> <p>Example: <pre><code>\"machine learning\" \u2192 [0.23, -0.45, 0.67, ..., 0.12]  (384 dimensions)\n\"neural networks\"  \u2192 [0.21, -0.42, 0.69, ..., 0.15]  (similar vector)\n\"pizza recipe\"     \u2192 [-0.67, 0.34, -0.12, ..., 0.89] (different vector)\n</code></pre></p>"},{"location":"advanced/embedding-models/#why-embeddings-matter","title":"Why Embeddings Matter","text":"<p>Traditional keyword search has limitations: - Exact matching only: \"ML\" won't match \"machine learning\" - No semantic understanding: Can't understand synonyms or context - Poor ranking: Simple term frequency doesn't capture relevance</p> <p>Embeddings enable: - Semantic search: Find conceptually similar content - Context awareness: Understand meaning, not just words - Better ranking: Relevance based on meaning</p>"},{"location":"advanced/embedding-models/#current-implementation","title":"Current Implementation","text":""},{"location":"advanced/embedding-models/#model-all-minilm-l6-v2","title":"Model: all-MiniLM-L6-v2","text":"<p>The system uses <code>sentence-transformers/all-MiniLM-L6-v2</code> by default.</p> <p>Specifications: - Parameters: 22.7 million - Embedding dimension: 384 - Max sequence length: 256 tokens - Speed: ~1000 sentences/second (CPU) - Performance: Good balance of speed and quality</p> <p>Location in code: <code>multi_modal_rag/indexing/opensearch_manager.py</code></p> <pre><code>from sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n</code></pre>"},{"location":"advanced/embedding-models/#how-its-used","title":"How It's Used","text":"<ol> <li> <p>During indexing: <pre><code>def generate_embedding(self, text: str) -&gt; List[float]:\n    \"\"\"Generate embedding vector for text.\"\"\"\n    embedding = self.model.encode(\n        text,\n        convert_to_numpy=True,\n        normalize_embeddings=True\n    )\n    return embedding.tolist()\n</code></pre></p> </li> <li> <p>During search: <pre><code>def hybrid_search(self, query_text: str, size: int = 10):\n    \"\"\"Search using both keywords and embeddings.\"\"\"\n    # Generate query embedding\n    query_embedding = self.generate_embedding(query_text)\n\n    # Combine with keyword search\n    query = {\n        \"query\": {\n            \"bool\": {\n                \"should\": [\n                    # Keyword search\n                    {\n                        \"multi_match\": {\n                            \"query\": query_text,\n                            \"fields\": [\"title^2\", \"abstract\", \"content\"]\n                        }\n                    },\n                    # Semantic search\n                    {\n                        \"knn\": {\n                            \"embedding\": {\n                                \"vector\": query_embedding,\n                                \"k\": size\n                            }\n                        }\n                    }\n                ]\n            }\n        }\n    }\n</code></pre></p> </li> </ol>"},{"location":"advanced/embedding-models/#choosing-an-embedding-model","title":"Choosing an Embedding Model","text":""},{"location":"advanced/embedding-models/#factors-to-consider","title":"Factors to Consider","text":"<ol> <li>Embedding dimension</li> <li>Larger = more information, but slower and more memory</li> <li> <p>Smaller = faster, less memory, but less nuanced</p> </li> <li> <p>Model size</p> </li> <li>Larger models: Better quality, slower inference</li> <li> <p>Smaller models: Faster, use less memory</p> </li> <li> <p>Domain specialization</p> </li> <li>General-purpose vs. domain-specific (e.g., scientific text)</li> <li> <p>Pre-trained on similar data = better performance</p> </li> <li> <p>Speed requirements</p> </li> <li>Real-time search needs fast models</li> <li> <p>Batch processing can use slower, higher-quality models</p> </li> <li> <p>Hardware constraints</p> </li> <li>GPU available? Can use larger models</li> <li>CPU only? Need efficient models</li> </ol>"},{"location":"advanced/embedding-models/#decision-tree","title":"Decision Tree","text":"<pre><code>Do you need real-time search?\n\u251c\u2500 Yes \u2192 Use small, fast model (MiniLM, TinyBERT)\n\u2514\u2500 No \u2192 Do you have GPU?\n    \u251c\u2500 Yes \u2192 Use larger model (MPNet, BERT-large)\n    \u2514\u2500 No \u2192 Use medium model (MiniLM, BERT-base)\n\nIs your content domain-specific?\n\u251c\u2500 Scientific \u2192 Use SciBERT, BioBERT\n\u251c\u2500 Legal \u2192 Use Legal-BERT\n\u251c\u2500 Code \u2192 Use CodeBERT\n\u2514\u2500 General \u2192 Use general models (SBERT, MPNet)\n</code></pre>"},{"location":"advanced/embedding-models/#model-comparison","title":"Model Comparison","text":""},{"location":"advanced/embedding-models/#popular-sentence-transformer-models","title":"Popular Sentence Transformer Models","text":"Model Dimensions Size (MB) Speed* Quality** all-MiniLM-L6-v2 384 80 Fast Good all-mpnet-base-v2 768 420 Medium Excellent all-distilroberta-v1 768 290 Medium Very Good paraphrase-MiniLM-L3-v2 384 60 Very Fast Fair msmarco-distilbert-base-v4 768 250 Medium Very Good multi-qa-mpnet-base-dot-v1 768 420 Medium Excellent <p>*Speed: Sentences per second on CPU **Quality: Performance on semantic search benchmarks</p>"},{"location":"advanced/embedding-models/#detailed-comparisons","title":"Detailed Comparisons","text":""},{"location":"advanced/embedding-models/#all-minilm-l6-v2-current","title":"all-MiniLM-L6-v2 (Current)","text":"<pre><code># Pros:\n# - Fast inference (~1000 sentences/sec)\n# - Small memory footprint\n# - Good general-purpose performance\n# - Easy to run on CPU\n\n# Cons:\n# - Lower quality than larger models\n# - 256 token limit (short sequences)\n# - Not domain-specialized\n\n# Best for:\n# - General-purpose applications\n# - CPU-only environments\n# - Real-time search\n</code></pre>"},{"location":"advanced/embedding-models/#all-mpnet-base-v2-recommended-upgrade","title":"all-mpnet-base-v2 (Recommended Upgrade)","text":"<pre><code># Pros:\n# - State-of-the-art quality\n# - 514 token limit (longer sequences)\n# - Excellent on benchmarks\n# - Still reasonably fast\n\n# Cons:\n# - Larger size (420MB vs 80MB)\n# - Slower inference (~500 sentences/sec)\n# - Needs more memory\n\n# Best for:\n# - Quality-focused applications\n# - When you have GPU\n# - Longer documents\n</code></pre>"},{"location":"advanced/embedding-models/#multi-qa-mpnet-base-dot-v1-qa-specialized","title":"multi-qa-mpnet-base-dot-v1 (Q&amp;A Specialized)","text":"<pre><code># Pros:\n# - Optimized for question-answering\n# - Excellent for asymmetric search (query vs document)\n# - High quality results\n# - Uses dot product (faster than cosine)\n\n# Cons:\n# - Larger model size\n# - Slower inference\n# - Needs reindexing with dot product space\n\n# Best for:\n# - Question-answering systems (like this one!)\n# - Asymmetric search scenarios\n# - When GPU is available\n</code></pre>"},{"location":"advanced/embedding-models/#domain-specific-models","title":"Domain-Specific Models","text":""},{"location":"advanced/embedding-models/#scibert-scientific-papers","title":"SciBERT (Scientific Papers)","text":"<pre><code># Model: allenai/scibert_scivocab_uncased\n# Dimensions: 768\n# Trained on: Scientific papers (1.14M papers)\n\n# Best for: Academic/scientific content\n# Use when: Most content is from scientific papers\n\nmodel = SentenceTransformer('sentence-transformers/allenai-specter')\n</code></pre>"},{"location":"advanced/embedding-models/#biobert-biomedical","title":"BioBERT (Biomedical)","text":"<pre><code># Model: dmis-lab/biobert-base-cased-v1.2\n# Trained on: PubMed articles\n\n# Best for: Medical/biological research\nmodel = SentenceTransformer('pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb')\n</code></pre>"},{"location":"advanced/embedding-models/#changing-embedding-models","title":"Changing Embedding Models","text":""},{"location":"advanced/embedding-models/#step-by-step-guide","title":"Step-by-Step Guide","text":""},{"location":"advanced/embedding-models/#1-choose-your-model","title":"1. Choose Your Model","text":"<pre><code># Option 1: Higher quality (recommended)\nnew_model_name = 'sentence-transformers/all-mpnet-base-v2'\nnew_dimension = 768\n\n# Option 2: Faster inference\nnew_model_name = 'sentence-transformers/paraphrase-MiniLM-L3-v2'\nnew_dimension = 384\n\n# Option 3: Scientific content\nnew_model_name = 'sentence-transformers/allenai-specter'\nnew_dimension = 768\n</code></pre>"},{"location":"advanced/embedding-models/#2-update-opensearch_managerpy","title":"2. Update opensearch_manager.py","text":"<pre><code># In __init__ method\nclass OpenSearchManager:\n    def __init__(self, host='localhost', port=9200):\n        # ... existing code ...\n\n        # Load new model\n        self.model = SentenceTransformer('all-mpnet-base-v2')  # Changed!\n\n        # Update dimension\n        self.embedding_dimension = 768  # Changed from 384!\n</code></pre>"},{"location":"advanced/embedding-models/#3-update-index-mapping","title":"3. Update Index Mapping","text":"<pre><code>def create_index(self, index_name='research_assistant'):\n    \"\"\"Create index with updated dimension.\"\"\"\n    index_body = {\n        \"settings\": {\n            \"index\": {\n                \"knn\": True,\n                \"knn.space_type\": \"cosinesimil\"\n            }\n        },\n        \"mappings\": {\n            \"properties\": {\n                \"embedding\": {\n                    \"type\": \"knn_vector\",\n                    \"dimension\": 768  # Updated dimension!\n                },\n                # ... other fields ...\n            }\n        }\n    }\n\n    self.client.indices.create(index=index_name, body=index_body)\n</code></pre>"},{"location":"advanced/embedding-models/#4-reindex-all-documents","title":"4. Reindex All Documents","text":"<pre><code># Delete old index\nclient.indices.delete(index='research_assistant')\n\n# Create new index with updated dimension\nmanager.create_index('research_assistant')\n\n# Reindex all documents\n# Run your data collection and indexing pipeline\n</code></pre>"},{"location":"advanced/embedding-models/#migration-script","title":"Migration Script","text":"<pre><code>#!/usr/bin/env python3\n\"\"\"\nScript to migrate to a new embedding model.\n\"\"\"\n\nfrom multi_modal_rag.indexing.opensearch_manager import OpenSearchManager\nfrom sentence_transformers import SentenceTransformer\nimport json\n\ndef migrate_embeddings(\n    old_index='research_assistant',\n    new_index='research_assistant_v2',\n    new_model_name='all-mpnet-base-v2',\n    new_dimension=768\n):\n    \"\"\"Migrate to new embedding model.\"\"\"\n\n    # Initialize\n    manager = OpenSearchManager()\n    new_model = SentenceTransformer(new_model_name)\n\n    # Create new index\n    print(f\"Creating new index: {new_index}\")\n    # Update index creation with new dimension\n    manager.create_index(new_index)\n\n    # Get all documents from old index\n    print(f\"Fetching documents from {old_index}\")\n    from opensearchpy import helpers\n\n    docs = helpers.scan(\n        manager.client,\n        index=old_index,\n        query={\"query\": {\"match_all\": {}}}\n    )\n\n    # Reindex with new embeddings\n    print(\"Reindexing with new embeddings...\")\n    batch = []\n    for i, doc in enumerate(docs):\n        # Extract text\n        text = doc['_source'].get('content', '')\n\n        # Generate new embedding\n        new_embedding = new_model.encode(text).tolist()\n\n        # Update document\n        doc['_source']['embedding'] = new_embedding\n\n        batch.append({\n            '_index': new_index,\n            '_id': doc['_id'],\n            '_source': doc['_source']\n        })\n\n        # Batch insert\n        if len(batch) &gt;= 100:\n            helpers.bulk(manager.client, batch)\n            print(f\"Processed {i+1} documents...\")\n            batch = []\n\n    # Insert remaining\n    if batch:\n        helpers.bulk(manager.client, batch)\n\n    print(f\"Migration complete! {i+1} documents reindexed.\")\n\n    # Verify\n    count = manager.client.count(index=new_index)\n    print(f\"New index has {count['count']} documents\")\n\n    # Switch alias (optional)\n    print(\"Switching alias...\")\n    manager.client.indices.update_aliases(body={\n        \"actions\": [\n            {\"remove\": {\"index\": old_index, \"alias\": \"research\"}},\n            {\"add\": {\"index\": new_index, \"alias\": \"research\"}}\n        ]\n    })\n\n    print(\"Done! You can now delete the old index:\")\n    print(f\"  curl -X DELETE http://localhost:9200/{old_index}\")\n\nif __name__ == '__main__':\n    migrate_embeddings()\n</code></pre>"},{"location":"advanced/embedding-models/#fine-tuning-embeddings","title":"Fine-Tuning Embeddings","text":""},{"location":"advanced/embedding-models/#when-to-fine-tune","title":"When to Fine-Tune","text":"<p>Fine-tune when: - Your domain is very specialized - You have labeled training data - Pre-trained models perform poorly - You need maximum quality</p>"},{"location":"advanced/embedding-models/#training-data-format","title":"Training Data Format","text":"<pre><code># Triplet format: (anchor, positive, negative)\ntraining_data = [\n    {\n        'anchor': 'What is machine learning?',\n        'positive': 'Machine learning is a subset of AI...',\n        'negative': 'The weather today is sunny...'\n    },\n    # ... more examples\n]\n\n# Or pairs format: (sentence1, sentence2, similarity_score)\ntraining_pairs = [\n    ('deep learning', 'neural networks', 0.9),\n    ('deep learning', 'pizza recipe', 0.1),\n    # ... more pairs\n]\n</code></pre>"},{"location":"advanced/embedding-models/#fine-tuning-script","title":"Fine-Tuning Script","text":"<pre><code>from sentence_transformers import SentenceTransformer, InputExample, losses\nfrom torch.utils.data import DataLoader\n\n# Load base model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Prepare training data\ntrain_examples = [\n    InputExample(texts=[item['anchor'], item['positive'], item['negative']])\n    for item in training_data\n]\n\n# Create dataloader\ntrain_dataloader = DataLoader(\n    train_examples,\n    shuffle=True,\n    batch_size=16\n)\n\n# Define loss\ntrain_loss = losses.TripletLoss(model=model)\n\n# Train\nmodel.fit(\n    train_objectives=[(train_dataloader, train_loss)],\n    epochs=3,\n    warmup_steps=100,\n    output_path='./fine_tuned_model'\n)\n\n# Use fine-tuned model\ncustom_model = SentenceTransformer('./fine_tuned_model')\n</code></pre>"},{"location":"advanced/embedding-models/#optimization-techniques","title":"Optimization Techniques","text":""},{"location":"advanced/embedding-models/#1-gpu-acceleration","title":"1. GPU Acceleration","text":"<pre><code>from sentence_transformers import SentenceTransformer\nimport torch\n\n# Check GPU availability\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\n# Load model on GPU\nmodel = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n\n# Batch encoding (much faster)\ntexts = [\"text 1\", \"text 2\", ..., \"text N\"]\nembeddings = model.encode(\n    texts,\n    batch_size=64,  # Adjust based on GPU memory\n    show_progress_bar=True,\n    convert_to_tensor=True  # Keep on GPU\n)\n</code></pre>"},{"location":"advanced/embedding-models/#2-caching-embeddings","title":"2. Caching Embeddings","text":"<pre><code>import pickle\nfrom functools import lru_cache\n\nclass EmbeddingCache:\n    \"\"\"Cache embeddings to avoid recomputation.\"\"\"\n\n    def __init__(self, cache_file='embeddings_cache.pkl'):\n        self.cache_file = cache_file\n        self.cache = self._load_cache()\n\n    def _load_cache(self):\n        try:\n            with open(self.cache_file, 'rb') as f:\n                return pickle.load(f)\n        except:\n            return {}\n\n    def get_embedding(self, text, model):\n        \"\"\"Get embedding from cache or compute.\"\"\"\n        # Use hash as key\n        text_hash = hash(text)\n\n        if text_hash not in self.cache:\n            self.cache[text_hash] = model.encode(text).tolist()\n            self._save_cache()\n\n        return self.cache[text_hash]\n\n    def _save_cache(self):\n        with open(self.cache_file, 'wb') as f:\n            pickle.dump(self.cache, f)\n\n# Usage\ncache = EmbeddingCache()\nembedding = cache.get_embedding(\"machine learning\", model)\n</code></pre>"},{"location":"advanced/embedding-models/#3-dimensionality-reduction","title":"3. Dimensionality Reduction","text":"<p>Reduce embedding dimension for faster search:</p> <pre><code>from sklearn.decomposition import PCA\nimport numpy as np\n\n# Get original embeddings\nembeddings = model.encode(texts)  # Shape: (N, 384)\n\n# Reduce dimensions\npca = PCA(n_components=128)  # Reduce 384 \u2192 128\nreduced_embeddings = pca.fit_transform(embeddings)\n\n# Quality vs speed tradeoff:\n# 384 \u2192 256: ~99% quality, ~1.5x faster\n# 384 \u2192 128: ~95% quality, ~3x faster\n# 384 \u2192 64:  ~85% quality, ~6x faster\n</code></pre>"},{"location":"advanced/embedding-models/#4-quantization","title":"4. Quantization","text":"<p>Reduce memory and increase speed:</p> <pre><code>import numpy as np\n\ndef quantize_embeddings(embeddings, bits=8):\n    \"\"\"Quantize embeddings to reduce memory.\"\"\"\n    # Normalize to [0, 1]\n    min_val = embeddings.min()\n    max_val = embeddings.max()\n    normalized = (embeddings - min_val) / (max_val - min_val)\n\n    # Quantize\n    scale = (2 ** bits) - 1\n    quantized = (normalized * scale).astype(np.uint8)\n\n    return quantized, min_val, max_val\n\ndef dequantize_embeddings(quantized, min_val, max_val, bits=8):\n    \"\"\"Reconstruct embeddings.\"\"\"\n    scale = (2 ** bits) - 1\n    normalized = quantized.astype(np.float32) / scale\n    return normalized * (max_val - min_val) + min_val\n\n# Usage: 8-bit quantization reduces memory by 4x\nquantized, min_v, max_v = quantize_embeddings(embeddings, bits=8)\n</code></pre>"},{"location":"advanced/embedding-models/#advanced-topics","title":"Advanced Topics","text":""},{"location":"advanced/embedding-models/#multi-vector-embeddings","title":"Multi-Vector Embeddings","text":"<p>For long documents, use multiple embeddings:</p> <pre><code>def chunk_and_embed(text, model, chunk_size=256):\n    \"\"\"Split text into chunks and embed each.\"\"\"\n    # Split text\n    words = text.split()\n    chunks = [\n        ' '.join(words[i:i+chunk_size])\n        for i in range(0, len(words), chunk_size)\n    ]\n\n    # Embed each chunk\n    embeddings = model.encode(chunks)\n\n    return embeddings\n\n# Store in OpenSearch\ndoc = {\n    'content': long_text,\n    'embeddings': chunk_and_embed(long_text, model),  # List of vectors\n    'num_chunks': len(embeddings)\n}\n\n# Search: Compare query to all chunks, take max similarity\n</code></pre>"},{"location":"advanced/embedding-models/#cross-encoder-reranking","title":"Cross-Encoder Reranking","text":"<p>Use cross-encoder for better ranking:</p> <pre><code>from sentence_transformers import CrossEncoder\n\n# Step 1: Fast bi-encoder retrieval (current method)\nbi_encoder = SentenceTransformer('all-MiniLM-L6-v2')\ncandidates = retrieve_top_100(query, bi_encoder)\n\n# Step 2: Slow cross-encoder reranking\ncross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n\n# Create query-document pairs\npairs = [[query, doc['content']] for doc in candidates]\n\n# Score pairs\nscores = cross_encoder.predict(pairs)\n\n# Rerank\nreranked = sorted(\n    zip(candidates, scores),\n    key=lambda x: x[1],\n    reverse=True\n)[:10]  # Top 10 after reranking\n</code></pre>"},{"location":"advanced/embedding-models/#multilingual-embeddings","title":"Multilingual Embeddings","text":"<p>For multilingual support:</p> <pre><code># Use multilingual model\nmodel = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')\n\n# Supports 50+ languages\n# Same embedding space across languages!\n\n# Example: Search in any language\nquery_en = \"machine learning\"\nquery_fr = \"apprentissage automatique\"\nquery_de = \"maschinelles Lernen\"\n\n# All produce similar embeddings\nemb_en = model.encode(query_en)\nemb_fr = model.encode(query_fr)\nemb_de = model.encode(query_de)\n\n# Cosine similarity ~0.9+\n</code></pre>"},{"location":"advanced/embedding-models/#evaluation-and-benchmarking","title":"Evaluation and Benchmarking","text":""},{"location":"advanced/embedding-models/#measuring-embedding-quality","title":"Measuring Embedding Quality","text":"<pre><code>from sklearn.metrics.pairwise import cosine_similarity\nimport numpy as np\n\ndef evaluate_embeddings(model, test_queries, relevant_docs):\n    \"\"\"Evaluate embedding quality.\"\"\"\n\n    # Embed queries and documents\n    query_embeddings = model.encode(test_queries)\n    doc_embeddings = model.encode(relevant_docs)\n\n    # Calculate similarities\n    similarities = cosine_similarity(query_embeddings, doc_embeddings)\n\n    # Calculate metrics\n    # Mean Reciprocal Rank (MRR)\n    reciprocal_ranks = []\n    for i, sim_row in enumerate(similarities):\n        # Get rank of correct document\n        rank = np.where(np.argsort(sim_row)[::-1] == i)[0][0] + 1\n        reciprocal_ranks.append(1.0 / rank)\n\n    mrr = np.mean(reciprocal_ranks)\n\n    # Mean Average Precision (MAP)\n    # ... implement MAP calculation\n\n    return {\n        'mrr': mrr,\n        'map': map_score\n    }\n</code></pre>"},{"location":"advanced/embedding-models/#speed-benchmarking","title":"Speed Benchmarking","text":"<pre><code>import time\n\ndef benchmark_model(model, texts, num_runs=5):\n    \"\"\"Benchmark embedding generation speed.\"\"\"\n\n    # Warmup\n    model.encode(texts[:10])\n\n    # Benchmark\n    times = []\n    for _ in range(num_runs):\n        start = time.time()\n        embeddings = model.encode(texts, batch_size=32)\n        times.append(time.time() - start)\n\n    avg_time = np.mean(times)\n    throughput = len(texts) / avg_time\n\n    print(f\"Average time: {avg_time:.2f}s\")\n    print(f\"Throughput: {throughput:.0f} sentences/sec\")\n\n    return throughput\n</code></pre>"},{"location":"advanced/embedding-models/#additional-resources","title":"Additional Resources","text":"<ul> <li>Sentence Transformers Documentation</li> <li>Hugging Face Model Hub</li> <li>MTEB Leaderboard (Benchmark rankings)</li> <li>Hybrid Search Guide</li> <li>Performance Optimization</li> </ul>"},{"location":"advanced/embedding-models/#best-practices","title":"Best Practices","text":"<ol> <li>Start with general models: all-MiniLM-L6-v2 or all-mpnet-base-v2</li> <li>Use GPU when possible: 10-100x speedup for large batches</li> <li>Cache embeddings: Don't recompute for same text</li> <li>Batch processing: Much faster than one-by-one</li> <li>Monitor quality: Use evaluation metrics</li> <li>Consider domain: Use specialized models when available</li> <li>Test before switching: Compare quality on your data</li> <li>Document your choice: Note why you chose a particular model</li> </ol>"},{"location":"advanced/gemini/","title":"Gemini Integration Deep Dive","text":"<p>Comprehensive guide to Google Gemini integration in the Multi-Modal Academic Research System.</p>"},{"location":"advanced/gemini/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Gemini Models</li> <li>Current Usage</li> <li>API Configuration</li> <li>Advanced Features</li> <li>Optimization Strategies</li> <li>Error Handling</li> <li>Best Practices</li> </ul>"},{"location":"advanced/gemini/#overview","title":"Overview","text":""},{"location":"advanced/gemini/#what-is-gemini","title":"What is Gemini?","text":"<p>Gemini is Google's family of multimodal large language models that can: - Generate text - Understand images - Analyze videos - Process multiple modalities simultaneously</p>"},{"location":"advanced/gemini/#why-gemini-for-this-system","title":"Why Gemini for This System?","text":"<p>Advantages: 1. Multimodal: Can analyze both text and images (for PDF diagrams) 2. Free tier: 60 requests/minute free 3. Quality: State-of-the-art performance 4. Long context: Up to 1M tokens (Gemini 1.5 Pro) 5. No subscription: No monthly costs</p> <p>Current uses: - Generate research answers from retrieved context - Analyze PDF diagrams and figures - Extract key concepts from papers - Summarize video content</p>"},{"location":"advanced/gemini/#gemini-models","title":"Gemini Models","text":""},{"location":"advanced/gemini/#available-models","title":"Available Models","text":""},{"location":"advanced/gemini/#gemini-15-flash-current-default-for-text","title":"Gemini 1.5 Flash (Current Default for Text)","text":"<pre><code>model = genai.GenerativeModel('gemini-1.5-flash')\n</code></pre> <p>Specifications: - Context window: 1M tokens - Speed: Fast (optimized for speed) - Cost: Free tier: 15 RPM, 1M TPM - Best for: Question answering, summarization, chat</p> <p>Characteristics: - Multimodal (text, images, video) - Fast inference - Good quality vs speed tradeoff - Lower cost than Pro</p>"},{"location":"advanced/gemini/#gemini-15-pro","title":"Gemini 1.5 Pro","text":"<pre><code>model = genai.GenerativeModel('gemini-1.5-pro')\n</code></pre> <p>Specifications: - Context window: 2M tokens - Speed: Slower than Flash - Cost: Free tier: 2 RPM - Best for: Complex reasoning, detailed analysis</p> <p>Characteristics: - Highest quality - Better at complex tasks - Larger context window - More expensive (rate-limited on free tier)</p>"},{"location":"advanced/gemini/#gemini-pro-vision-legacy","title":"Gemini Pro Vision (Legacy)","text":"<pre><code>model = genai.GenerativeModel('gemini-pro-vision')\n</code></pre> <p>Note: Being replaced by Gemini 1.5 models which are fully multimodal.</p>"},{"location":"advanced/gemini/#model-comparison","title":"Model Comparison","text":"Feature Flash Pro Pro Vision Text generation Excellent Excellent Good Image understanding Excellent Excellent Excellent Video understanding Yes Yes Yes Speed Fast Medium Medium Context length 1M tokens 2M tokens ~16K tokens Free tier RPM 15 2 2 Best for Production Complex tasks Image-only"},{"location":"advanced/gemini/#current-usage","title":"Current Usage","text":""},{"location":"advanced/gemini/#1-question-answering-research_orchestratorpy","title":"1. Question Answering (research_orchestrator.py)","text":"<pre><code>from langchain_google_genai import ChatGoogleGenerativeAI\n\n# Initialize model\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-1.5-flash\",\n    temperature=0.7,\n    max_tokens=2048\n)\n\n# Create prompt with context\nprompt = f\"\"\"\nYou are a research assistant. Answer the question based on the provided context.\n\nContext:\n{retrieved_documents}\n\nQuestion: {user_question}\n\nProvide a detailed answer with citations [1], [2], etc.\n\"\"\"\n\n# Generate response\nresponse = llm.invoke(prompt)\n</code></pre> <p>Parameters explained: - <code>temperature</code>: Controls randomness (0 = deterministic, 1 = creative)   - Use 0.1-0.3 for factual answers   - Use 0.7-0.9 for creative tasks - <code>max_tokens</code>: Maximum response length - <code>top_p</code>: Nucleus sampling (alternative to temperature) - <code>top_k</code>: Top-k sampling (limits vocabulary)</p>"},{"location":"advanced/gemini/#2-vision-analysis-pdf_processorpy","title":"2. Vision Analysis (pdf_processor.py)","text":"<pre><code>import google.generativeai as genai\nfrom PIL import Image\n\n# Configure API\ngenai.configure(api_key=api_key)\n\n# Initialize vision model\nvision_model = genai.GenerativeModel('gemini-1.5-flash')\n\n# Analyze image\nimage = Image.open(\"diagram.png\")\n\nprompt = \"\"\"\nDescribe this scientific diagram in detail.\nInclude:\n- Main components\n- Relationships shown\n- Key concepts\n- Any labels or annotations\n\"\"\"\n\nresponse = vision_model.generate_content([prompt, image])\ndescription = response.text\n</code></pre> <p>Use cases: - Extract information from diagrams - Describe charts and graphs - Read text from images (OCR alternative) - Analyze experimental setups</p>"},{"location":"advanced/gemini/#3-content-extraction","title":"3. Content Extraction","text":"<pre><code>def extract_key_concepts(text, max_concepts=10):\n    \"\"\"Extract key concepts using Gemini.\"\"\"\n\n    prompt = f\"\"\"\n    Extract the {max_concepts} most important concepts from this text.\n    Return as a comma-separated list.\n\n    Text: {text[:3000]}  # Limit input length\n\n    Concepts:\n    \"\"\"\n\n    response = model.generate_content(prompt)\n\n    # Parse response\n    concepts = [c.strip() for c in response.text.split(',')]\n\n    return concepts[:max_concepts]\n</code></pre>"},{"location":"advanced/gemini/#api-configuration","title":"API Configuration","text":""},{"location":"advanced/gemini/#basic-setup","title":"Basic Setup","text":"<pre><code>import google.generativeai as genai\nimport os\nfrom dotenv import load_dotenv\n\n# Load environment variables\nload_dotenv()\n\n# Configure API\napi_key = os.getenv('GEMINI_API_KEY')\ngenai.configure(api_key=api_key)\n\n# Create model\nmodel = genai.GenerativeModel('gemini-1.5-flash')\n</code></pre>"},{"location":"advanced/gemini/#advanced-configuration","title":"Advanced Configuration","text":"<pre><code>from google.generativeai.types import GenerationConfig, SafetySettings\n\n# Generation configuration\ngeneration_config = GenerationConfig(\n    temperature=0.7,\n    top_p=0.95,\n    top_k=40,\n    max_output_tokens=2048,\n    stop_sequences=[\"\\n\\n\\n\"]  # Stop at triple newline\n)\n\n# Safety settings\nsafety_settings = {\n    \"HARM_CATEGORY_HARASSMENT\": \"BLOCK_MEDIUM_AND_ABOVE\",\n    \"HARM_CATEGORY_HATE_SPEECH\": \"BLOCK_MEDIUM_AND_ABOVE\",\n    \"HARM_CATEGORY_SEXUALLY_EXPLICIT\": \"BLOCK_MEDIUM_AND_ABOVE\",\n    \"HARM_CATEGORY_DANGEROUS_CONTENT\": \"BLOCK_MEDIUM_AND_ABOVE\"\n}\n\n# Create model with config\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    generation_config=generation_config,\n    safety_settings=safety_settings\n)\n</code></pre>"},{"location":"advanced/gemini/#streaming-responses","title":"Streaming Responses","text":"<pre><code>def stream_response(prompt):\n    \"\"\"Stream response token by token.\"\"\"\n\n    response = model.generate_content(\n        prompt,\n        stream=True\n    )\n\n    for chunk in response:\n        if chunk.text:\n            print(chunk.text, end='', flush=True)\n            yield chunk.text\n</code></pre> <p>Benefits: - Lower perceived latency - Better user experience - Can start processing before full response</p> <p>Use in Gradio: <pre><code>def chat_with_streaming(message, history):\n    \"\"\"Gradio chat with streaming.\"\"\"\n\n    prompt = format_prompt(message, history)\n\n    partial_response = \"\"\n    for chunk in stream_response(prompt):\n        partial_response += chunk\n        yield partial_response\n</code></pre></p>"},{"location":"advanced/gemini/#advanced-features","title":"Advanced Features","text":""},{"location":"advanced/gemini/#1-function-calling","title":"1. Function Calling","text":"<p>Gemini can call functions to get real-time data:</p> <pre><code>def search_papers(query: str, max_results: int = 5):\n    \"\"\"Search for papers (will be called by Gemini).\"\"\"\n    # Implementation\n    return search_results\n\n# Define function schema\ntools = [\n    {\n        \"function_declarations\": [\n            {\n                \"name\": \"search_papers\",\n                \"description\": \"Search for academic papers\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"query\": {\n                            \"type\": \"string\",\n                            \"description\": \"Search query\"\n                        },\n                        \"max_results\": {\n                            \"type\": \"integer\",\n                            \"description\": \"Maximum results to return\"\n                        }\n                    },\n                    \"required\": [\"query\"]\n                }\n            }\n        ]\n    }\n]\n\n# Create model with tools\nmodel = genai.GenerativeModel(\n    'gemini-1.5-flash',\n    tools=tools\n)\n\n# Use model\nresponse = model.generate_content(\n    \"Find me papers about transformers in NLP\"\n)\n\n# Model might call search_papers function\nif response.candidates[0].content.parts[0].function_call:\n    function_call = response.candidates[0].content.parts[0].function_call\n    function_name = function_call.name\n    function_args = function_call.args\n\n    # Execute function\n    if function_name == \"search_papers\":\n        results = search_papers(**function_args)\n\n        # Send results back to model\n        response = model.generate_content([\n            response.candidates[0].content,\n            genai.protos.Content(parts=[\n                genai.protos.Part(\n                    function_response=genai.protos.FunctionResponse(\n                        name=function_name,\n                        response={\"results\": results}\n                    )\n                )\n            ])\n        ])\n</code></pre>"},{"location":"advanced/gemini/#2-multimodal-prompts","title":"2. Multimodal Prompts","text":"<p>Combine text and images:</p> <pre><code>def analyze_paper_figure(figure_path, paper_context):\n    \"\"\"Analyze figure in context of paper.\"\"\"\n\n    image = Image.open(figure_path)\n\n    prompt = f\"\"\"\n    Paper context: {paper_context}\n\n    Analyze this figure from the paper:\n    1. What does it show?\n    2. How does it relate to the paper's main findings?\n    3. What are the key takeaways?\n    \"\"\"\n\n    response = model.generate_content([prompt, image])\n    return response.text\n</code></pre>"},{"location":"advanced/gemini/#3-conversation-history","title":"3. Conversation History","text":"<p>Maintain context across turns:</p> <pre><code>class GeminiChat:\n    \"\"\"Chat session with conversation history.\"\"\"\n\n    def __init__(self):\n        self.model = genai.GenerativeModel('gemini-1.5-flash')\n        self.chat = self.model.start_chat(history=[])\n\n    def send_message(self, message):\n        \"\"\"Send message and get response.\"\"\"\n        response = self.chat.send_message(message)\n        return response.text\n\n    def get_history(self):\n        \"\"\"Get conversation history.\"\"\"\n        return self.chat.history\n\n# Usage\nchat = GeminiChat()\nresponse1 = chat.send_message(\"What is machine learning?\")\nresponse2 = chat.send_message(\"How does it differ from deep learning?\")\n# Model remembers previous context\n</code></pre>"},{"location":"advanced/gemini/#4-json-mode","title":"4. JSON Mode","text":"<p>Get structured output:</p> <pre><code>def extract_structured_data(text):\n    \"\"\"Extract structured data from text.\"\"\"\n\n    prompt = f\"\"\"\n    Extract information from this paper and return as JSON:\n\n    {{\n        \"title\": \"paper title\",\n        \"authors\": [\"author1\", \"author2\"],\n        \"year\": 2024,\n        \"key_findings\": [\"finding1\", \"finding2\"],\n        \"methodology\": \"description\"\n    }}\n\n    Text: {text}\n\n    JSON:\n    \"\"\"\n\n    response = model.generate_content(prompt)\n\n    # Parse JSON\n    import json\n    try:\n        data = json.loads(response.text)\n        return data\n    except json.JSONDecodeError:\n        # Handle parsing errors\n        return None\n</code></pre>"},{"location":"advanced/gemini/#optimization-strategies","title":"Optimization Strategies","text":""},{"location":"advanced/gemini/#1-prompt-engineering","title":"1. Prompt Engineering","text":"<p>Be specific: <pre><code># Bad\nprompt = \"Tell me about this paper\"\n\n# Good\nprompt = \"\"\"\nAnalyze this paper and provide:\n1. Main research question (1 sentence)\n2. Methodology (2-3 sentences)\n3. Key findings (3-5 bullet points)\n4. Limitations (2-3 sentences)\n5. Future work suggestions (2-3 bullet points)\n\nFocus on technical details and be concise.\n\"\"\"\n</code></pre></p> <p>Use examples (few-shot): <pre><code>prompt = \"\"\"\nExtract key concepts from papers. Format: concept | definition\n\nExample 1:\nText: \"We propose a transformer architecture...\"\nOutput: Transformer | Neural network architecture using self-attention\n\nExample 2:\nText: \"Our method achieves 95% accuracy using BERT...\"\nOutput: BERT | Bidirectional Encoder Representations from Transformers\n\nNow extract from:\nText: {input_text}\nOutput:\n\"\"\"\n</code></pre></p> <p>Add constraints: <pre><code>prompt = f\"\"\"\nAnswer the question in exactly 3 paragraphs.\nUse only information from the context.\nInclude citations [1], [2], etc.\nEnd with \"Confidence: HIGH/MEDIUM/LOW\"\n\nContext: {context}\nQuestion: {question}\n\"\"\"\n</code></pre></p>"},{"location":"advanced/gemini/#2-context-window-management","title":"2. Context Window Management","text":"<pre><code>def truncate_context(documents, max_tokens=30000):\n    \"\"\"Truncate context to fit in token limit.\"\"\"\n\n    # Rough estimate: 1 token \u2248 4 characters\n    max_chars = max_tokens * 4\n\n    truncated = []\n    total_chars = 0\n\n    for doc in documents:\n        doc_text = doc['content']\n        if total_chars + len(doc_text) &gt; max_chars:\n            # Truncate this document\n            remaining = max_chars - total_chars\n            doc_text = doc_text[:remaining]\n            truncated.append(doc_text)\n            break\n        else:\n            truncated.append(doc_text)\n            total_chars += len(doc_text)\n\n    return \"\\n\\n\".join(truncated)\n</code></pre>"},{"location":"advanced/gemini/#3-caching","title":"3. Caching","text":"<p>Cache responses for common queries:</p> <pre><code>import hashlib\nimport json\nimport os\n\nclass GeminiCache:\n    \"\"\"Cache Gemini responses.\"\"\"\n\n    def __init__(self, cache_dir='cache'):\n        self.cache_dir = cache_dir\n        os.makedirs(cache_dir, exist_ok=True)\n\n    def get_cache_key(self, prompt, model_name):\n        \"\"\"Generate cache key.\"\"\"\n        key_string = f\"{model_name}:{prompt}\"\n        return hashlib.md5(key_string.encode()).hexdigest()\n\n    def get(self, prompt, model_name):\n        \"\"\"Get cached response.\"\"\"\n        key = self.get_cache_key(prompt, model_name)\n        cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n\n        if os.path.exists(cache_file):\n            with open(cache_file, 'r') as f:\n                return json.load(f)['response']\n\n        return None\n\n    def set(self, prompt, model_name, response):\n        \"\"\"Cache response.\"\"\"\n        key = self.get_cache_key(prompt, model_name)\n        cache_file = os.path.join(self.cache_dir, f\"{key}.json\")\n\n        with open(cache_file, 'w') as f:\n            json.dump({\n                'prompt': prompt,\n                'response': response,\n                'model': model_name\n            }, f)\n\n# Usage\ncache = GeminiCache()\n\ndef generate_with_cache(prompt, model):\n    \"\"\"Generate with caching.\"\"\"\n    cached = cache.get(prompt, model.model_name)\n    if cached:\n        return cached\n\n    response = model.generate_content(prompt)\n    cache.set(prompt, model.model_name, response.text)\n    return response.text\n</code></pre>"},{"location":"advanced/gemini/#4-batch-processing","title":"4. Batch Processing","text":"<p>Process multiple requests efficiently:</p> <pre><code>import asyncio\nfrom typing import List\n\nasync def process_batch(prompts: List[str], model, delay=1.0):\n    \"\"\"Process multiple prompts with rate limiting.\"\"\"\n\n    results = []\n\n    for prompt in prompts:\n        response = model.generate_content(prompt)\n        results.append(response.text)\n\n        # Rate limiting\n        await asyncio.sleep(delay)\n\n    return results\n\n# Usage\nprompts = [\n    \"Summarize paper 1\",\n    \"Summarize paper 2\",\n    # ... more prompts\n]\n\nresults = asyncio.run(process_batch(prompts, model, delay=1.0))\n</code></pre>"},{"location":"advanced/gemini/#error-handling","title":"Error Handling","text":""},{"location":"advanced/gemini/#common-errors","title":"Common Errors","text":""},{"location":"advanced/gemini/#1-rate-limit-exceeded","title":"1. Rate Limit Exceeded","text":"<pre><code>from google.api_core import exceptions\nimport time\n\ndef generate_with_retry(prompt, model, max_retries=3):\n    \"\"\"Generate with retry on rate limit.\"\"\"\n\n    for attempt in range(max_retries):\n        try:\n            response = model.generate_content(prompt)\n            return response.text\n\n        except exceptions.ResourceExhausted as e:\n            if attempt &lt; max_retries - 1:\n                wait_time = (2 ** attempt) * 60  # Exponential backoff\n                print(f\"Rate limited. Waiting {wait_time}s...\")\n                time.sleep(wait_time)\n            else:\n                raise\n\n    return None\n</code></pre>"},{"location":"advanced/gemini/#2-safety-filters","title":"2. Safety Filters","text":"<pre><code>def handle_safety_blocking(prompt, model):\n    \"\"\"Handle content blocked by safety filters.\"\"\"\n\n    try:\n        response = model.generate_content(prompt)\n\n        # Check if response was blocked\n        if not response.candidates:\n            print(\"Response blocked by safety filters\")\n            return None\n\n        if response.candidates[0].finish_reason == \"SAFETY\":\n            print(\"Response blocked due to safety\")\n            # Try with more permissive settings\n            return generate_with_permissive_safety(prompt, model)\n\n        return response.text\n\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None\n</code></pre>"},{"location":"advanced/gemini/#3-token-limit-exceeded","title":"3. Token Limit Exceeded","text":"<pre><code>def generate_with_truncation(prompt, context, model, max_tokens=30000):\n    \"\"\"Generate with automatic context truncation.\"\"\"\n\n    # Estimate token count\n    estimated_tokens = len(prompt + context) / 4\n\n    if estimated_tokens &gt; max_tokens:\n        # Truncate context\n        max_context_chars = (max_tokens - len(prompt)/4) * 4\n        context = context[:int(max_context_chars)]\n        print(f\"Context truncated to fit token limit\")\n\n    full_prompt = f\"{prompt}\\n\\nContext: {context}\"\n\n    try:\n        response = model.generate_content(full_prompt)\n        return response.text\n    except Exception as e:\n        print(f\"Error: {e}\")\n        return None\n</code></pre>"},{"location":"advanced/gemini/#best-practices","title":"Best Practices","text":""},{"location":"advanced/gemini/#1-prompt-design","title":"1. Prompt Design","text":"<p>Structure prompts clearly: <pre><code>prompt = f\"\"\"\nRole: You are an expert research assistant specializing in {domain}.\n\nTask: {task_description}\n\nContext:\n{context}\n\nInstructions:\n1. {instruction_1}\n2. {instruction_2}\n3. {instruction_3}\n\nOutput format:\n{format_specification}\n\nQuestion: {question}\n\"\"\"\n</code></pre></p>"},{"location":"advanced/gemini/#2-temperature-settings","title":"2. Temperature Settings","text":"<p>Guidelines: - Factual QA: 0.1 - 0.3 (low randomness) - Summarization: 0.3 - 0.5 (some variation) - Creative tasks: 0.7 - 0.9 (high creativity) - Code generation: 0.2 - 0.4 (mostly deterministic)</p>"},{"location":"advanced/gemini/#3-cost-management","title":"3. Cost Management","text":"<p>Monitor usage: <pre><code>import time\n\nclass UsageTracker:\n    \"\"\"Track API usage.\"\"\"\n\n    def __init__(self):\n        self.requests = []\n\n    def log_request(self, tokens_used):\n        \"\"\"Log a request.\"\"\"\n        self.requests.append({\n            'timestamp': time.time(),\n            'tokens': tokens_used\n        })\n\n    def get_recent_usage(self, minutes=1):\n        \"\"\"Get usage in last N minutes.\"\"\"\n        cutoff = time.time() - (minutes * 60)\n        recent = [r for r in self.requests if r['timestamp'] &gt; cutoff]\n        return {\n            'count': len(recent),\n            'tokens': sum(r['tokens'] for r in recent)\n        }\n\n# Usage\ntracker = UsageTracker()\n\ndef generate_with_tracking(prompt, model):\n    \"\"\"Generate with usage tracking.\"\"\"\n    response = model.generate_content(prompt)\n\n    # Estimate tokens (rough)\n    tokens = len(prompt + response.text) / 4\n    tracker.log_request(tokens)\n\n    # Check if approaching limit\n    recent = tracker.get_recent_usage(minutes=1)\n    if recent['count'] &gt;= 50:  # 60 RPM free tier\n        print(\"Warning: Approaching rate limit\")\n\n    return response.text\n</code></pre></p>"},{"location":"advanced/gemini/#4-testing","title":"4. Testing","text":"<p>Test prompts systematically: <pre><code>def test_prompt_variations(prompt_templates, test_cases):\n    \"\"\"Test different prompt variations.\"\"\"\n\n    results = []\n\n    for template in prompt_templates:\n        for test_case in test_cases:\n            prompt = template.format(**test_case)\n\n            response = model.generate_content(prompt)\n\n            results.append({\n                'template': template,\n                'test_case': test_case,\n                'response': response.text,\n                'quality_score': evaluate_response(response.text)\n            })\n\n    # Analyze results\n    best_template = max(\n        results,\n        key=lambda x: x['quality_score']\n    )['template']\n\n    return best_template, results\n</code></pre></p>"},{"location":"advanced/gemini/#migration-to-other-llms","title":"Migration to Other LLMs","text":"<p>If needed, here's how to switch:</p>"},{"location":"advanced/gemini/#openai-gpt","title":"OpenAI GPT","text":"<pre><code>from langchain_openai import ChatOpenAI\n\n# Replace\nllm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n\n# With\nllm = ChatOpenAI(model=\"gpt-4\", temperature=0.7)\n\n# Rest of code stays the same (LangChain compatibility)\n</code></pre>"},{"location":"advanced/gemini/#anthropic-claude","title":"Anthropic Claude","text":"<pre><code>from langchain_anthropic import ChatAnthropic\n\nllm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n</code></pre>"},{"location":"advanced/gemini/#local-llms-ollama","title":"Local LLMs (Ollama)","text":"<pre><code>from langchain_community.llms import Ollama\n\nllm = Ollama(model=\"llama2\")\n</code></pre>"},{"location":"advanced/gemini/#additional-resources","title":"Additional Resources","text":"<ul> <li>Gemini API Documentation</li> <li>Gemini Prompt Guide</li> <li>Safety Settings</li> <li>LangChain Gemini Integration</li> </ul>"},{"location":"advanced/gemini/#summary","title":"Summary","text":"<p>Key Takeaways: 1. Use Gemini 1.5 Flash for production (fast, efficient) 2. Implement proper error handling and retries 3. Cache responses when possible 4. Structure prompts clearly 5. Monitor rate limits 6. Test prompts systematically 7. Consider cost vs quality tradeoffs</p>"},{"location":"advanced/hybrid-search/","title":"Hybrid Search: Algorithm and Implementation","text":"<p>Deep dive into the hybrid search algorithm that combines keyword and semantic search in the Multi-Modal Academic Research System.</p>"},{"location":"advanced/hybrid-search/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Why Hybrid Search?</li> <li>Algorithm Details</li> <li>Implementation</li> <li>Score Combination Strategies</li> <li>Tuning Parameters</li> <li>Advanced Techniques</li> <li>Performance Optimization</li> </ul>"},{"location":"advanced/hybrid-search/#overview","title":"Overview","text":""},{"location":"advanced/hybrid-search/#what-is-hybrid-search","title":"What is Hybrid Search?","text":"<p>Hybrid search combines two complementary search methods:</p> <ol> <li>Keyword Search (Lexical): Traditional text matching using BM25 algorithm</li> <li>Semantic Search (Vector): Neural embeddings with cosine similarity</li> </ol> <p>By combining both, we get the best of both worlds: - Precision from keyword matching (exact terms) - Recall from semantic matching (related concepts)</p>"},{"location":"advanced/hybrid-search/#simple-example","title":"Simple Example","text":"<p>Query: \"ML algorithms\"</p> <p>Keyword search finds: - \u2713 Documents containing \"ML\" - \u2713 Documents containing \"algorithms\" - \u2717 Documents containing \"machine learning\" (different term) - \u2717 Documents containing \"neural networks\" (related concept)</p> <p>Semantic search finds: - \u2713 Documents about \"machine learning\" (synonym) - \u2713 Documents about \"neural networks\" (related concept) - \u2717 Documents about \"ML\" in different context (e.g., \"Maximum Likelihood\") - \u2717 May miss exact \"ML\" if discussed differently</p> <p>Hybrid search finds: - \u2713 All of the above, properly weighted and ranked</p>"},{"location":"advanced/hybrid-search/#why-hybrid-search","title":"Why Hybrid Search?","text":""},{"location":"advanced/hybrid-search/#limitations-of-keyword-only-search","title":"Limitations of Keyword-Only Search","text":"<pre><code># Query: \"deep learning frameworks\"\n# Keyword search results:\n# 1. Paper with \"deep learning frameworks\" \u2192 Perfect match \u2713\n# 2. Paper with \"DL frameworks\" \u2192 Missed (abbreviation) \u2717\n# 3. Paper with \"neural network libraries\" \u2192 Missed (synonyms) \u2717\n# 4. Paper with \"TensorFlow and PyTorch\" \u2192 Missed (examples) \u2717\n</code></pre> <p>Problems: - Vocabulary mismatch - No understanding of synonyms - Can't handle paraphrases - Misses related concepts</p>"},{"location":"advanced/hybrid-search/#limitations-of-semantic-only-search","title":"Limitations of Semantic-Only Search","text":"<pre><code># Query: \"BERT architecture details\"\n# Semantic search results:\n# 1. Paper about transformers \u2192 Related \u2713\n# 2. Paper about attention mechanism \u2192 Related \u2713\n# 3. Paper mentioning \"BERT\" once \u2192 High ranking \u2717\n# 4. General NLP paper \u2192 Too broad \u2717\n</code></pre> <p>Problems: - May miss exact terminology - Less precise for specific terms - Can be too broad - Slower than keyword search</p>"},{"location":"advanced/hybrid-search/#benefits-of-hybrid-search","title":"Benefits of Hybrid Search","text":"Aspect Keyword Semantic Hybrid Exact matches Excellent Poor Excellent Synonyms Poor Excellent Excellent Related concepts Poor Excellent Excellent Precision High Medium High Recall Low High High Speed Fast Slower Medium"},{"location":"advanced/hybrid-search/#algorithm-details","title":"Algorithm Details","text":""},{"location":"advanced/hybrid-search/#high-level-flow","title":"High-Level Flow","text":"<pre><code>User Query: \"deep learning for NLP\"\n           |\n           v\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Query Parser \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           |\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    |             |\n    v             v\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Keyword \u2502  \u2502 Semantic\u2502\n\u2502 Search  \u2502  \u2502 Search  \u2502\n\u2502 (BM25)  \u2502  \u2502 (kNN)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n    |             |\n    |   Results   |\n    |   +Scores   |\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           v\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Score Fusion \u2502\n    \u2502 (Normalization,\u2502\n    \u2502  Combination) \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           |\n           v\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Final Ranking\u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           |\n           v\n      Top N Results\n</code></pre>"},{"location":"advanced/hybrid-search/#step-by-step-breakdown","title":"Step-by-Step Breakdown","text":""},{"location":"advanced/hybrid-search/#step-1-query-processing","title":"Step 1: Query Processing","text":"<pre><code>def process_query(query_text):\n    \"\"\"Process query for both search methods.\"\"\"\n\n    # For keyword search: Use as-is\n    keyword_query = query_text\n\n    # For semantic search: Generate embedding\n    query_embedding = embedding_model.encode(query_text)\n\n    return keyword_query, query_embedding\n</code></pre>"},{"location":"advanced/hybrid-search/#step-2-keyword-search-bm25","title":"Step 2: Keyword Search (BM25)","text":"<p>BM25 Algorithm: <pre><code>BM25(D, Q) = \u03a3 IDF(qi) \u00d7 (f(qi, D) \u00d7 (k1 + 1)) / (f(qi, D) + k1 \u00d7 (1 - b + b \u00d7 |D| / avgdl))\n\nWhere:\n- D = document\n- Q = query\n- qi = query term i\n- f(qi, D) = frequency of qi in D\n- |D| = length of D\n- avgdl = average document length\n- k1, b = tuning parameters (typically k1=1.5, b=0.75)\n- IDF(qi) = inverse document frequency of qi\n</code></pre></p> <p>Implementation: <pre><code>def keyword_search(query_text, index, size=100):\n    \"\"\"Perform BM25 keyword search.\"\"\"\n\n    query = {\n        \"query\": {\n            \"multi_match\": {\n                \"query\": query_text,\n                \"fields\": [\n                    \"title^3\",      # 3x weight\n                    \"abstract^2\",   # 2x weight\n                    \"content^1\",    # 1x weight\n                    \"key_concepts^2\"\n                ],\n                \"type\": \"best_fields\",\n                \"operator\": \"or\"\n            }\n        },\n        \"size\": size\n    }\n\n    response = client.search(index=index, body=query)\n\n    return [\n        {\n            'id': hit['_id'],\n            'score': hit['_score'],\n            'source': hit['_source']\n        }\n        for hit in response['hits']['hits']\n    ]\n</code></pre></p>"},{"location":"advanced/hybrid-search/#step-3-semantic-search-knn","title":"Step 3: Semantic Search (kNN)","text":"<p>Cosine Similarity: <pre><code>similarity(A, B) = (A \u00b7 B) / (||A|| \u00d7 ||B||)\n\nWhere:\n- A, B = embedding vectors\n- A \u00b7 B = dot product\n- ||A|| = magnitude of A\n</code></pre></p> <p>Implementation: <pre><code>def semantic_search(query_embedding, index, size=100):\n    \"\"\"Perform kNN semantic search.\"\"\"\n\n    query = {\n        \"query\": {\n            \"knn\": {\n                \"embedding\": {\n                    \"vector\": query_embedding,\n                    \"k\": size\n                }\n            }\n        },\n        \"size\": size\n    }\n\n    response = client.search(index=index, body=query)\n\n    return [\n        {\n            'id': hit['_id'],\n            'score': hit['_score'],\n            'source': hit['_source']\n        }\n        for hit in response['hits']['hits']\n    ]\n</code></pre></p>"},{"location":"advanced/hybrid-search/#step-4-score-normalization","title":"Step 4: Score Normalization","text":"<p>Problem: BM25 scores and cosine similarities have different scales.</p> <p>Solution: Normalize to [0, 1] range.</p> <pre><code>def min_max_normalize(scores):\n    \"\"\"Normalize scores to [0, 1] range.\"\"\"\n    if not scores:\n        return []\n\n    min_score = min(scores)\n    max_score = max(scores)\n\n    if max_score == min_score:\n        return [1.0] * len(scores)\n\n    return [\n        (score - min_score) / (max_score - min_score)\n        for score in scores\n    ]\n\ndef z_score_normalize(scores):\n    \"\"\"Normalize using z-score (mean=0, std=1).\"\"\"\n    if not scores:\n        return []\n\n    mean = np.mean(scores)\n    std = np.std(scores)\n\n    if std == 0:\n        return [0.0] * len(scores)\n\n    return [\n        (score - mean) / std\n        for score in scores\n    ]\n</code></pre>"},{"location":"advanced/hybrid-search/#step-5-score-combination","title":"Step 5: Score Combination","text":"<p>Linear Combination: <pre><code>def combine_scores(keyword_score, semantic_score, alpha=0.5):\n    \"\"\"\n    Combine scores using weighted average.\n\n    Args:\n        keyword_score: Normalized BM25 score\n        semantic_score: Normalized cosine similarity\n        alpha: Weight for keyword score (1-alpha for semantic)\n\n    Returns:\n        Combined score\n    \"\"\"\n    return alpha * keyword_score + (1 - alpha) * semantic_score\n</code></pre></p>"},{"location":"advanced/hybrid-search/#step-6-result-merging-and-ranking","title":"Step 6: Result Merging and Ranking","text":"<pre><code>def merge_results(keyword_results, semantic_results, alpha=0.5):\n    \"\"\"Merge and rank results from both searches.\"\"\"\n\n    # Extract scores\n    keyword_scores = [r['score'] for r in keyword_results]\n    semantic_scores = [r['score'] for r in semantic_results]\n\n    # Normalize\n    keyword_scores_norm = min_max_normalize(keyword_scores)\n    semantic_scores_norm = min_max_normalize(semantic_scores)\n\n    # Create score dictionary\n    combined_scores = {}\n\n    # Add keyword results\n    for result, norm_score in zip(keyword_results, keyword_scores_norm):\n        doc_id = result['id']\n        combined_scores[doc_id] = {\n            'keyword_score': norm_score,\n            'semantic_score': 0.0,\n            'source': result['source']\n        }\n\n    # Add semantic results\n    for result, norm_score in zip(semantic_results, semantic_scores_norm):\n        doc_id = result['id']\n        if doc_id in combined_scores:\n            combined_scores[doc_id]['semantic_score'] = norm_score\n        else:\n            combined_scores[doc_id] = {\n                'keyword_score': 0.0,\n                'semantic_score': norm_score,\n                'source': result['source']\n            }\n\n    # Combine scores\n    final_results = []\n    for doc_id, scores in combined_scores.items():\n        combined_score = combine_scores(\n            scores['keyword_score'],\n            scores['semantic_score'],\n            alpha=alpha\n        )\n\n        final_results.append({\n            'id': doc_id,\n            'combined_score': combined_score,\n            'keyword_score': scores['keyword_score'],\n            'semantic_score': scores['semantic_score'],\n            'source': scores['source']\n        })\n\n    # Sort by combined score\n    final_results.sort(key=lambda x: x['combined_score'], reverse=True)\n\n    return final_results\n</code></pre>"},{"location":"advanced/hybrid-search/#implementation","title":"Implementation","text":""},{"location":"advanced/hybrid-search/#complete-hybrid-search-function","title":"Complete Hybrid Search Function","text":"<pre><code>from typing import List, Dict\nimport numpy as np\nfrom opensearchpy import OpenSearch\nfrom sentence_transformers import SentenceTransformer\n\nclass HybridSearch:\n    \"\"\"Hybrid search combining keyword and semantic search.\"\"\"\n\n    def __init__(self, client: OpenSearch, model: SentenceTransformer):\n        self.client = client\n        self.model = model\n\n    def search(\n        self,\n        query: str,\n        index: str = 'research_assistant',\n        size: int = 10,\n        alpha: float = 0.5,\n        keyword_size: int = 100,\n        semantic_size: int = 100\n    ) -&gt; List[Dict]:\n        \"\"\"\n        Perform hybrid search.\n\n        Args:\n            query: Search query\n            index: Index name\n            size: Number of results to return\n            alpha: Weight for keyword score (0-1)\n            keyword_size: Number of keyword results to retrieve\n            semantic_size: Number of semantic results to retrieve\n\n        Returns:\n            List of search results with combined scores\n        \"\"\"\n\n        # 1. Generate query embedding\n        query_embedding = self.model.encode(query).tolist()\n\n        # 2. Keyword search\n        keyword_results = self._keyword_search(\n            query, index, keyword_size\n        )\n\n        # 3. Semantic search\n        semantic_results = self._semantic_search(\n            query_embedding, index, semantic_size\n        )\n\n        # 4. Merge and rank\n        combined_results = self._merge_results(\n            keyword_results,\n            semantic_results,\n            alpha=alpha\n        )\n\n        # 5. Return top N\n        return combined_results[:size]\n\n    def _keyword_search(\n        self,\n        query: str,\n        index: str,\n        size: int\n    ) -&gt; List[Dict]:\n        \"\"\"Perform keyword search.\"\"\"\n\n        query_body = {\n            \"query\": {\n                \"multi_match\": {\n                    \"query\": query,\n                    \"fields\": [\n                        \"title^3\",\n                        \"abstract^2\",\n                        \"content^1\",\n                        \"key_concepts^2\",\n                        \"diagram_descriptions^1.5\"\n                    ],\n                    \"type\": \"best_fields\",\n                    \"operator\": \"or\",\n                    \"fuzziness\": \"AUTO\"\n                }\n            },\n            \"size\": size\n        }\n\n        response = self.client.search(index=index, body=query_body)\n\n        return [\n            {\n                'id': hit['_id'],\n                'score': hit['_score'],\n                'source': hit['_source']\n            }\n            for hit in response['hits']['hits']\n        ]\n\n    def _semantic_search(\n        self,\n        query_embedding: List[float],\n        index: str,\n        size: int\n    ) -&gt; List[Dict]:\n        \"\"\"Perform semantic search.\"\"\"\n\n        query_body = {\n            \"query\": {\n                \"knn\": {\n                    \"embedding\": {\n                        \"vector\": query_embedding,\n                        \"k\": size\n                    }\n                }\n            },\n            \"size\": size\n        }\n\n        response = self.client.search(index=index, body=query_body)\n\n        return [\n            {\n                'id': hit['_id'],\n                'score': hit['_score'],\n                'source': hit['_source']\n            }\n            for hit in response['hits']['hits']\n        ]\n\n    def _merge_results(\n        self,\n        keyword_results: List[Dict],\n        semantic_results: List[Dict],\n        alpha: float\n    ) -&gt; List[Dict]:\n        \"\"\"Merge and rank results.\"\"\"\n\n        # Normalize scores\n        keyword_scores = [r['score'] for r in keyword_results]\n        semantic_scores = [r['score'] for r in semantic_results]\n\n        keyword_norm = self._min_max_normalize(keyword_scores)\n        semantic_norm = self._min_max_normalize(semantic_scores)\n\n        # Combine scores\n        combined = {}\n\n        for result, norm_score in zip(keyword_results, keyword_norm):\n            doc_id = result['id']\n            combined[doc_id] = {\n                'keyword': norm_score,\n                'semantic': 0.0,\n                'source': result['source']\n            }\n\n        for result, norm_score in zip(semantic_results, semantic_norm):\n            doc_id = result['id']\n            if doc_id in combined:\n                combined[doc_id]['semantic'] = norm_score\n            else:\n                combined[doc_id] = {\n                    'keyword': 0.0,\n                    'semantic': norm_score,\n                    'source': result['source']\n                }\n\n        # Calculate final scores\n        final_results = []\n        for doc_id, scores in combined.items():\n            final_score = (\n                alpha * scores['keyword'] +\n                (1 - alpha) * scores['semantic']\n            )\n\n            final_results.append({\n                'id': doc_id,\n                'score': final_score,\n                'keyword_score': scores['keyword'],\n                'semantic_score': scores['semantic'],\n                'source': scores['source']\n            })\n\n        # Sort by score\n        final_results.sort(key=lambda x: x['score'], reverse=True)\n\n        return final_results\n\n    @staticmethod\n    def _min_max_normalize(scores: List[float]) -&gt; List[float]:\n        \"\"\"Normalize scores to [0, 1] range.\"\"\"\n        if not scores:\n            return []\n\n        min_score = min(scores)\n        max_score = max(scores)\n\n        if max_score == min_score:\n            return [1.0] * len(scores)\n\n        return [\n            (score - min_score) / (max_score - min_score)\n            for score in scores\n        ]\n\n# Usage\nsearch = HybridSearch(client, model)\nresults = search.search(\n    query=\"deep learning for natural language processing\",\n    size=10,\n    alpha=0.5  # Equal weight\n)\n\nfor i, result in enumerate(results, 1):\n    print(f\"{i}. {result['source']['title']}\")\n    print(f\"   Combined: {result['score']:.3f}\")\n    print(f\"   Keyword: {result['keyword_score']:.3f}\")\n    print(f\"   Semantic: {result['semantic_score']:.3f}\")\n</code></pre>"},{"location":"advanced/hybrid-search/#score-combination-strategies","title":"Score Combination Strategies","text":""},{"location":"advanced/hybrid-search/#1-linear-combination-current","title":"1. Linear Combination (Current)","text":"<pre><code>score = \u03b1 \u00d7 keyword_score + (1 - \u03b1) \u00d7 semantic_score\n</code></pre> <p>Pros: - Simple and interpretable - Easy to tune with single parameter \u03b1 - Fast computation</p> <p>Cons: - Assumes linear relationship - May not capture complex interactions</p> <p>When to use: Default choice, works well in most cases.</p>"},{"location":"advanced/hybrid-search/#2-reciprocal-rank-fusion-rrf","title":"2. Reciprocal Rank Fusion (RRF)","text":"<pre><code>def reciprocal_rank_fusion(keyword_ranks, semantic_ranks, k=60):\n    \"\"\"\n    Combine using RRF algorithm.\n\n    Args:\n        keyword_ranks: Dict mapping doc_id to rank in keyword results\n        semantic_ranks: Dict mapping doc_id to rank in semantic results\n        k: Constant (typically 60)\n\n    Returns:\n        Combined scores\n    \"\"\"\n    all_docs = set(keyword_ranks.keys()) | set(semantic_ranks.keys())\n\n    scores = {}\n    for doc_id in all_docs:\n        keyword_score = 1 / (k + keyword_ranks.get(doc_id, 1000))\n        semantic_score = 1 / (k + semantic_ranks.get(doc_id, 1000))\n        scores[doc_id] = keyword_score + semantic_score\n\n    return scores\n</code></pre> <p>Pros: - No normalization needed - Robust to score scale differences - Parameter-free (except k)</p> <p>Cons: - Only uses rank information (ignores score magnitude) - May miss nuance in scores</p> <p>When to use: When score scales are very different or unreliable.</p>"},{"location":"advanced/hybrid-search/#3-bayesian-combination","title":"3. Bayesian Combination","text":"<pre><code>def bayesian_combination(keyword_score, semantic_score, prior=0.5):\n    \"\"\"\n    Combine scores using Bayesian approach.\n\n    Assumes scores are probabilities of relevance.\n    \"\"\"\n    # Convert scores to probabilities\n    p_relevant_keyword = keyword_score\n    p_relevant_semantic = semantic_score\n\n    # Bayes' theorem\n    posterior = (\n        (p_relevant_keyword * p_relevant_semantic * prior) /\n        (p_relevant_keyword * p_relevant_semantic * prior +\n         (1 - p_relevant_keyword) * (1 - p_relevant_semantic) * (1 - prior))\n    )\n\n    return posterior\n</code></pre> <p>Pros: - Theoretically grounded - Accounts for uncertainty - Can incorporate prior knowledge</p> <p>Cons: - Assumes independence (often violated) - Requires probability interpretation - More complex</p> <p>When to use: When you have probabilistic scores and independence assumptions hold.</p>"},{"location":"advanced/hybrid-search/#4-harmonic-mean","title":"4. Harmonic Mean","text":"<pre><code>def harmonic_mean(keyword_score, semantic_score, alpha=0.5):\n    \"\"\"\n    Combine using weighted harmonic mean.\n\n    Penalizes imbalanced scores more than arithmetic mean.\n    \"\"\"\n    if keyword_score == 0 or semantic_score == 0:\n        return 0\n\n    return 1 / (alpha / keyword_score + (1 - alpha) / semantic_score)\n</code></pre> <p>Pros: - Penalizes very low scores in one component - Good when both components should be strong</p> <p>Cons: - Sensitive to zero scores - More conservative than arithmetic mean</p> <p>When to use: When you want both keyword and semantic to contribute meaningfully.</p>"},{"location":"advanced/hybrid-search/#tuning-parameters","title":"Tuning Parameters","text":""},{"location":"advanced/hybrid-search/#alpha-keyword-vs-semantic-weight","title":"Alpha (\u03b1) - Keyword vs Semantic Weight","text":"<p>The \u03b1 parameter controls the balance between keyword and semantic search.</p> <p>Values: - <code>\u03b1 = 0.0</code>: Pure semantic search - <code>\u03b1 = 0.5</code>: Equal weight (default) - <code>\u03b1 = 1.0</code>: Pure keyword search</p> <p>Guidelines:</p> Query Type Recommended \u03b1 Reasoning Exact terminology 0.7 - 0.9 Prioritize keyword matching Concept exploration 0.1 - 0.3 Prioritize semantic similarity Technical terms 0.6 - 0.8 Exact terms matter Natural questions 0.3 - 0.5 Semantic understanding helps Short queries 0.4 - 0.6 Balance both Long queries 0.3 - 0.5 More context for semantic <p>Tuning Process:</p> <pre><code>def find_optimal_alpha(queries, ground_truth):\n    \"\"\"Find optimal alpha using validation set.\"\"\"\n\n    alphas = np.arange(0, 1.1, 0.1)\n    best_alpha = 0.5\n    best_score = 0\n\n    for alpha in alphas:\n        scores = []\n        for query, relevant_docs in zip(queries, ground_truth):\n            results = hybrid_search(query, alpha=alpha)\n            score = evaluate_ranking(results, relevant_docs)\n            scores.append(score)\n\n        avg_score = np.mean(scores)\n        if avg_score &gt; best_score:\n            best_score = avg_score\n            best_alpha = alpha\n\n    print(f\"Optimal alpha: {best_alpha} (score: {best_score:.3f})\")\n    return best_alpha\n</code></pre>"},{"location":"advanced/hybrid-search/#field-weights","title":"Field Weights","text":"<p>Control importance of different document fields:</p> <pre><code>fields = [\n    \"title^3\",           # Title most important\n    \"abstract^2\",        # Abstract very important\n    \"key_concepts^2\",    # Key concepts important\n    \"content^1\",         # Content baseline\n    \"diagram_descriptions^1.5\"  # Diagrams somewhat important\n]\n</code></pre> <p>Tuning tips: - Start with <code>title^3</code>, <code>abstract^2</code>, <code>content^1</code> - Increase if field should be more important - Test with queries targeting each field - Monitor impact on overall quality</p>"},{"location":"advanced/hybrid-search/#advanced-techniques","title":"Advanced Techniques","text":""},{"location":"advanced/hybrid-search/#query-expansion","title":"Query Expansion","text":"<p>Expand query before searching:</p> <pre><code>def expand_query(query, model, top_k=5):\n    \"\"\"Expand query with similar terms.\"\"\"\n\n    # Get query embedding\n    query_emb = model.encode(query)\n\n    # Find similar terms (using pre-built term index)\n    similar_terms = find_similar_terms(query_emb, top_k)\n\n    # Combine\n    expanded = f\"{query} {' '.join(similar_terms)}\"\n\n    return expanded\n\n# Usage\nexpanded = expand_query(\"ML algorithms\")\n# Result: \"ML algorithms machine learning classification regression neural networks\"\n</code></pre>"},{"location":"advanced/hybrid-search/#personalization","title":"Personalization","text":"<p>Adapt search based on user history:</p> <pre><code>def personalized_search(query, user_history, alpha=0.5, beta=0.2):\n    \"\"\"\n    Personalized hybrid search.\n\n    Args:\n        query: Search query\n        user_history: List of previously viewed documents\n        alpha: Keyword vs semantic weight\n        beta: Personalization weight\n    \"\"\"\n\n    # Standard hybrid search\n    results = hybrid_search(query, alpha=alpha)\n\n    # Calculate personalization scores\n    for result in results:\n        doc_vector = result['source']['embedding']\n\n        # Similarity to user history\n        history_similarities = [\n            cosine_similarity(doc_vector, hist_doc['embedding'])\n            for hist_doc in user_history\n        ]\n\n        personalization_score = np.mean(history_similarities)\n\n        # Combine with hybrid score\n        result['score'] = (\n            (1 - beta) * result['score'] +\n            beta * personalization_score\n        )\n\n    # Re-sort\n    results.sort(key=lambda x: x['score'], reverse=True)\n\n    return results\n</code></pre>"},{"location":"advanced/hybrid-search/#multi-stage-retrieval","title":"Multi-Stage Retrieval","text":"<p>Retrieve in stages for efficiency:</p> <pre><code>def multi_stage_search(query, size=10):\n    \"\"\"\n    Multi-stage retrieval:\n    1. Fast keyword retrieval (top 1000)\n    2. Semantic reranking (top 100)\n    3. Cross-encoder reranking (top 10)\n    \"\"\"\n\n    # Stage 1: Fast keyword retrieval\n    candidates = keyword_search(query, size=1000)\n\n    # Stage 2: Semantic reranking\n    query_emb = model.encode(query)\n    for candidate in candidates:\n        doc_emb = candidate['source']['embedding']\n        semantic_score = cosine_similarity(query_emb, doc_emb)\n        candidate['score'] = (\n            0.5 * candidate['score'] +\n            0.5 * semantic_score\n        )\n\n    candidates.sort(key=lambda x: x['score'], reverse=True)\n    top_100 = candidates[:100]\n\n    # Stage 3: Cross-encoder reranking (expensive but accurate)\n    cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n    pairs = [[query, c['source']['content'][:512]] for c in top_100]\n    cross_scores = cross_encoder.predict(pairs)\n\n    for candidate, cross_score in zip(top_100, cross_scores):\n        candidate['score'] = cross_score\n\n    top_100.sort(key=lambda x: x['score'], reverse=True)\n\n    return top_100[:size]\n</code></pre>"},{"location":"advanced/hybrid-search/#performance-optimization","title":"Performance Optimization","text":""},{"location":"advanced/hybrid-search/#caching","title":"Caching","text":"<pre><code>from functools import lru_cache\nimport hashlib\n\nclass CachedHybridSearch:\n    \"\"\"Hybrid search with result caching.\"\"\"\n\n    def __init__(self, client, model):\n        self.client = client\n        self.model = model\n        self.cache = {}\n\n    def search(self, query, **kwargs):\n        \"\"\"Search with caching.\"\"\"\n\n        # Create cache key\n        cache_key = self._create_cache_key(query, kwargs)\n\n        # Check cache\n        if cache_key in self.cache:\n            return self.cache[cache_key]\n\n        # Perform search\n        results = self._hybrid_search(query, **kwargs)\n\n        # Cache results\n        self.cache[cache_key] = results\n\n        return results\n\n    def _create_cache_key(self, query, kwargs):\n        \"\"\"Create cache key from query and parameters.\"\"\"\n        key_string = f\"{query}_{str(sorted(kwargs.items()))}\"\n        return hashlib.md5(key_string.encode()).hexdigest()\n</code></pre>"},{"location":"advanced/hybrid-search/#parallel-execution","title":"Parallel Execution","text":"<pre><code>import concurrent.futures\n\ndef parallel_hybrid_search(query, client, model):\n    \"\"\"Execute keyword and semantic search in parallel.\"\"\"\n\n    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n        # Submit both searches\n        keyword_future = executor.submit(keyword_search, query, client)\n        semantic_future = executor.submit(\n            semantic_search,\n            model.encode(query),\n            client\n        )\n\n        # Wait for both to complete\n        keyword_results = keyword_future.result()\n        semantic_results = semantic_future.result()\n\n    # Merge results\n    return merge_results(keyword_results, semantic_results)\n</code></pre>"},{"location":"advanced/hybrid-search/#additional-resources","title":"Additional Resources","text":"<ul> <li>Embedding Models Guide</li> <li>Performance Optimization</li> <li>OpenSearch kNN Documentation</li> <li>BM25 Algorithm</li> </ul>"},{"location":"advanced/hybrid-search/#best-practices","title":"Best Practices","text":"<ol> <li>Start with \u03b1 = 0.5: Equal weight as baseline</li> <li>Use field boosting: Weight title and abstract higher</li> <li>Normalize scores: Always normalize before combining</li> <li>Test on real queries: Use actual user queries for tuning</li> <li>Monitor performance: Track both speed and quality metrics</li> <li>Consider query type: Adapt \u03b1 based on query characteristics</li> <li>Iterate: Continuously evaluate and refine parameters</li> </ol>"},{"location":"advanced/performance/","title":"Performance Optimization Guide","text":"<p>Comprehensive guide to optimizing performance of the Multi-Modal Academic Research System.</p>"},{"location":"advanced/performance/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Performance Overview</li> <li>Profiling and Measurement</li> <li>Indexing Optimization</li> <li>Search Optimization</li> <li>LLM Optimization</li> <li>Database Optimization</li> <li>Application-Level Optimization</li> <li>Infrastructure Optimization</li> </ul>"},{"location":"advanced/performance/#performance-overview","title":"Performance Overview","text":""},{"location":"advanced/performance/#current-performance-characteristics","title":"Current Performance Characteristics","text":"<p>Typical Latencies: - Initial query (cold start): 5-10 seconds - Subsequent queries: 2-4 seconds - Document indexing: 10-30 seconds per document - PDF processing: 5-20 seconds per PDF - Embedding generation: 0.5-2 seconds per document</p> <p>Bottlenecks: 1. Gemini API calls: Rate-limited, network latency 2. Embedding generation: CPU-bound operation 3. PDF processing: I/O and computation intensive 4. OpenSearch queries: Network and index size dependent</p>"},{"location":"advanced/performance/#performance-goals","title":"Performance Goals","text":"Operation Current Target Priority Query response 3-5s &lt;2s High Indexing throughput 3-6 docs/min 20+ docs/min Medium Search latency 200-500ms &lt;100ms High Memory usage 4-6GB &lt;4GB Medium Cold start 5-10s &lt;3s Low"},{"location":"advanced/performance/#profiling-and-measurement","title":"Profiling and Measurement","text":""},{"location":"advanced/performance/#basic-profiling","title":"Basic Profiling","text":"<pre><code>import time\nfrom functools import wraps\n\ndef timeit(func):\n    \"\"\"Decorator to measure function execution time.\"\"\"\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        start = time.time()\n        result = func(*args, **kwargs)\n        elapsed = time.time() - start\n        print(f\"{func.__name__} took {elapsed:.2f}s\")\n        return result\n    return wrapper\n\n# Usage\n@timeit\ndef process_document(doc):\n    # ... processing logic\n    return processed_doc\n</code></pre>"},{"location":"advanced/performance/#detailed-profiling","title":"Detailed Profiling","text":"<pre><code>import cProfile\nimport pstats\nfrom io import StringIO\n\ndef profile_function(func, *args, **kwargs):\n    \"\"\"Profile a function call.\"\"\"\n    profiler = cProfile.Profile()\n    profiler.enable()\n\n    result = func(*args, **kwargs)\n\n    profiler.disable()\n\n    # Print stats\n    stream = StringIO()\n    stats = pstats.Stats(profiler, stream=stream)\n    stats.sort_stats('cumulative')\n    stats.print_stats(20)  # Top 20 functions\n\n    print(stream.getvalue())\n\n    return result\n\n# Usage\nresult = profile_function(process_query, \"machine learning\")\n</code></pre>"},{"location":"advanced/performance/#memory-profiling","title":"Memory Profiling","text":"<pre><code>from memory_profiler import profile\n\n@profile\ndef memory_intensive_function():\n    \"\"\"Function to profile memory usage.\"\"\"\n    large_list = [i for i in range(10000000)]\n    # ... more operations\n    return result\n\n# Run with: python -m memory_profiler script.py\n</code></pre>"},{"location":"advanced/performance/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code>import psutil\nimport time\n\nclass PerformanceMonitor:\n    \"\"\"Monitor system performance metrics.\"\"\"\n\n    def __init__(self):\n        self.metrics = []\n\n    def record_metrics(self):\n        \"\"\"Record current system metrics.\"\"\"\n        process = psutil.Process()\n\n        metrics = {\n            'timestamp': time.time(),\n            'cpu_percent': process.cpu_percent(),\n            'memory_mb': process.memory_info().rss / 1024 / 1024,\n            'threads': process.num_threads(),\n            'open_files': len(process.open_files())\n        }\n\n        self.metrics.append(metrics)\n        return metrics\n\n    def get_summary(self):\n        \"\"\"Get performance summary.\"\"\"\n        if not self.metrics:\n            return {}\n\n        return {\n            'avg_cpu': sum(m['cpu_percent'] for m in self.metrics) / len(self.metrics),\n            'max_memory_mb': max(m['memory_mb'] for m in self.metrics),\n            'avg_memory_mb': sum(m['memory_mb'] for m in self.metrics) / len(self.metrics)\n        }\n\n# Usage\nmonitor = PerformanceMonitor()\n\n# During operation\nfor query in queries:\n    monitor.record_metrics()\n    process_query(query)\n\nprint(monitor.get_summary())\n</code></pre>"},{"location":"advanced/performance/#indexing-optimization","title":"Indexing Optimization","text":""},{"location":"advanced/performance/#1-batch-processing","title":"1. Batch Processing","text":"<p>Problem: Processing documents one-by-one is slow.</p> <p>Solution: Batch processing.</p> <pre><code>def index_documents_batch(documents, batch_size=100):\n    \"\"\"Index documents in batches.\"\"\"\n\n    for i in range(0, len(documents), batch_size):\n        batch = documents[i:i+batch_size]\n\n        # Generate embeddings for batch\n        texts = [doc['content'] for doc in batch]\n        embeddings = model.encode(\n            texts,\n            batch_size=32,\n            show_progress_bar=True\n        )\n\n        # Add embeddings to documents\n        for doc, embedding in zip(batch, embeddings):\n            doc['embedding'] = embedding.tolist()\n\n        # Bulk index\n        from opensearchpy import helpers\n\n        actions = [\n            {\n                '_index': 'research_assistant',\n                '_id': doc['id'],\n                '_source': doc\n            }\n            for doc in batch\n        ]\n\n        helpers.bulk(client, actions)\n\n        print(f\"Indexed batch {i//batch_size + 1}\")\n\n# Result: 5-10x faster than one-by-one\n</code></pre>"},{"location":"advanced/performance/#2-parallel-processing","title":"2. Parallel Processing","text":"<pre><code>from multiprocessing import Pool, cpu_count\n\ndef process_document_wrapper(doc_path):\n    \"\"\"Wrapper for multiprocessing.\"\"\"\n    try:\n        return process_document(doc_path)\n    except Exception as e:\n        return {'error': str(e), 'path': doc_path}\n\ndef process_documents_parallel(doc_paths, num_workers=None):\n    \"\"\"Process documents in parallel.\"\"\"\n\n    if num_workers is None:\n        num_workers = cpu_count() - 1\n\n    with Pool(processes=num_workers) as pool:\n        results = pool.map(process_document_wrapper, doc_paths)\n\n    # Filter out errors\n    successful = [r for r in results if 'error' not in r]\n    errors = [r for r in results if 'error' in r]\n\n    print(f\"Processed: {len(successful)}, Errors: {len(errors)}\")\n\n    return successful, errors\n\n# Result: Near-linear speedup with CPU cores\n</code></pre>"},{"location":"advanced/performance/#3-async-processing","title":"3. Async Processing","text":"<pre><code>import asyncio\nimport aiohttp\n\nasync def process_document_async(doc_path):\n    \"\"\"Process document asynchronously.\"\"\"\n    # I/O operations don't block\n    async with aiofiles.open(doc_path, 'rb') as f:\n        content = await f.read()\n\n    # Process content\n    processed = await process_content_async(content)\n\n    return processed\n\nasync def process_batch_async(doc_paths):\n    \"\"\"Process multiple documents concurrently.\"\"\"\n    tasks = [process_document_async(path) for path in doc_paths]\n    results = await asyncio.gather(*tasks)\n    return results\n\n# Usage\nresults = asyncio.run(process_batch_async(doc_paths))\n\n# Result: Great for I/O-bound operations\n</code></pre>"},{"location":"advanced/performance/#4-disable-refresh-during-bulk-indexing","title":"4. Disable Refresh During Bulk Indexing","text":"<pre><code>def bulk_index_optimized(documents):\n    \"\"\"Optimize bulk indexing performance.\"\"\"\n\n    # Disable refresh during indexing\n    client.indices.put_settings(\n        index='research_assistant',\n        body={'index': {'refresh_interval': '-1'}}\n    )\n\n    try:\n        # Bulk index\n        helpers.bulk(client, prepare_actions(documents))\n\n    finally:\n        # Re-enable refresh\n        client.indices.put_settings(\n            index='research_assistant',\n            body={'index': {'refresh_interval': '1s'}}\n        )\n\n        # Force refresh\n        client.indices.refresh(index='research_assistant')\n\n# Result: 2-3x faster indexing\n</code></pre>"},{"location":"advanced/performance/#search-optimization","title":"Search Optimization","text":""},{"location":"advanced/performance/#1-result-caching","title":"1. Result Caching","text":"<pre><code>from functools import lru_cache\nimport hashlib\n\nclass SearchCache:\n    \"\"\"Cache search results.\"\"\"\n\n    def __init__(self, max_size=1000, ttl=3600):\n        self.cache = {}\n        self.max_size = max_size\n        self.ttl = ttl  # Time to live in seconds\n\n    def get_key(self, query, params):\n        \"\"\"Generate cache key.\"\"\"\n        key_string = f\"{query}:{str(sorted(params.items()))}\"\n        return hashlib.md5(key_string.encode()).hexdigest()\n\n    def get(self, query, params):\n        \"\"\"Get cached results.\"\"\"\n        key = self.get_key(query, params)\n\n        if key in self.cache:\n            entry = self.cache[key]\n\n            # Check if expired\n            if time.time() - entry['timestamp'] &lt; self.ttl:\n                return entry['results']\n            else:\n                del self.cache[key]\n\n        return None\n\n    def set(self, query, params, results):\n        \"\"\"Cache results.\"\"\"\n        key = self.get_key(query, params)\n\n        # Evict oldest if at capacity\n        if len(self.cache) &gt;= self.max_size:\n            oldest = min(self.cache.items(), key=lambda x: x[1]['timestamp'])\n            del self.cache[oldest[0]]\n\n        self.cache[key] = {\n            'results': results,\n            'timestamp': time.time()\n        }\n\n# Usage\ncache = SearchCache()\n\ndef search_with_cache(query, **params):\n    \"\"\"Search with caching.\"\"\"\n    cached = cache.get(query, params)\n    if cached:\n        return cached\n\n    results = perform_search(query, **params)\n    cache.set(query, params, results)\n\n    return results\n\n# Result: Sub-millisecond response for cached queries\n</code></pre>"},{"location":"advanced/performance/#2-query-optimization","title":"2. Query Optimization","text":"<pre><code>def optimized_query(query_text, size=10):\n    \"\"\"Optimized query structure.\"\"\"\n\n    query = {\n        'size': size,\n        'query': {\n            'bool': {\n                # Use filter for exact matches (cached)\n                'filter': [\n                    {'term': {'content_type': 'paper'}}\n                ],\n                # Use must for scoring\n                'must': [\n                    {\n                        'multi_match': {\n                            'query': query_text,\n                            'fields': ['title^3', 'abstract^2', 'content'],\n                            'type': 'best_fields',\n                            'operator': 'or'\n                        }\n                    }\n                ],\n                # Use should for boosting (optional)\n                'should': [\n                    {'match': {'key_concepts': query_text}}\n                ],\n                'minimum_should_match': 0\n            }\n        },\n        # Only return needed fields\n        '_source': ['title', 'abstract', 'authors', 'publication_date'],\n        # Disable expensive features if not needed\n        'track_scores': False\n    }\n\n    return query\n</code></pre>"},{"location":"advanced/performance/#3-pagination-instead-of-large-results","title":"3. Pagination Instead of Large Results","text":"<pre><code>def search_with_pagination(query, page=1, page_size=10):\n    \"\"\"Paginated search.\"\"\"\n\n    query_body = {\n        'query': {...},\n        'from': (page - 1) * page_size,\n        'size': page_size\n    }\n\n    return client.search(index='research_assistant', body=query_body)\n\n# Better than retrieving 1000 results at once\n</code></pre>"},{"location":"advanced/performance/#4-search-after-efficient-deep-pagination","title":"4. Search After (Efficient Deep Pagination)","text":"<pre><code>def deep_pagination(query, search_after=None, size=10):\n    \"\"\"Efficient deep pagination using search_after.\"\"\"\n\n    query_body = {\n        'query': {...},\n        'size': size,\n        'sort': [\n            {'_score': 'desc'},\n            {'_id': 'asc'}  # Tiebreaker\n        ]\n    }\n\n    if search_after:\n        query_body['search_after'] = search_after\n\n    response = client.search(index='research_assistant', body=query_body)\n\n    # Get last hit's sort values for next page\n    hits = response['hits']['hits']\n    if hits:\n        last_sort = hits[-1]['sort']\n        return hits, last_sort\n    else:\n        return hits, None\n\n# Usage\nresults, next_page = deep_pagination(query)\n# Next page\nresults, next_page = deep_pagination(query, search_after=next_page)\n\n# Much faster than using 'from' for deep pagination\n</code></pre>"},{"location":"advanced/performance/#llm-optimization","title":"LLM Optimization","text":""},{"location":"advanced/performance/#1-prompt-optimization","title":"1. Prompt Optimization","text":"<p>Problem: Long prompts increase latency and cost.</p> <p>Solution: Optimize prompt length.</p> <pre><code>def optimize_context(documents, max_length=3000):\n    \"\"\"Select most relevant context.\"\"\"\n\n    # Sort by relevance score\n    documents.sort(key=lambda x: x['score'], reverse=True)\n\n    # Build context up to max length\n    context_parts = []\n    current_length = 0\n\n    for doc in documents:\n        # Use abstract instead of full content for length\n        text = doc['abstract'] if len(doc['content']) &gt; 500 else doc['content']\n\n        if current_length + len(text) &gt; max_length:\n            break\n\n        context_parts.append(text)\n        current_length += len(text)\n\n    return '\\n\\n'.join(context_parts)\n\n# Result: 2-3x faster responses, lower costs\n</code></pre>"},{"location":"advanced/performance/#2-response-streaming","title":"2. Response Streaming","text":"<pre><code>def stream_llm_response(prompt):\n    \"\"\"Stream LLM response for better UX.\"\"\"\n\n    response = model.generate_content(\n        prompt,\n        stream=True\n    )\n\n    full_response = \"\"\n    for chunk in response:\n        if chunk.text:\n            full_response += chunk.text\n            yield chunk.text  # Yield immediately\n\n    return full_response\n\n# In Gradio\ndef chat(message, history):\n    \"\"\"Chat with streaming.\"\"\"\n    prompt = format_prompt(message, history)\n\n    partial = \"\"\n    for chunk in stream_llm_response(prompt):\n        partial += chunk\n        yield partial\n\n# Result: Perceived latency reduced by 50%+\n</code></pre>"},{"location":"advanced/performance/#3-local-llm-for-simple-tasks","title":"3. Local LLM for Simple Tasks","text":"<pre><code># Use Gemini for complex tasks\ndef complex_task(query, context):\n    \"\"\"Use Gemini for complex reasoning.\"\"\"\n    return gemini_model.generate_content(f\"{query}\\n\\n{context}\")\n\n# Use local model for simple tasks\nfrom transformers import pipeline\n\nsummarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n\ndef simple_summarization(text):\n    \"\"\"Use local model for simple summarization.\"\"\"\n    if len(text) &gt; 1024:\n        text = text[:1024]\n\n    summary = summarizer(text, max_length=150, min_length=50)\n    return summary[0]['summary_text']\n\n# Result: No API latency or rate limits for simple tasks\n</code></pre>"},{"location":"advanced/performance/#database-optimization","title":"Database Optimization","text":""},{"location":"advanced/performance/#1-index-settings","title":"1. Index Settings","text":"<pre><code>optimized_settings = {\n    'settings': {\n        'number_of_shards': 1,  # Single node = 1 shard\n        'number_of_replicas': 0,  # No replicas for local dev\n        'refresh_interval': '30s',  # Reduce refresh frequency\n        'index': {\n            'max_result_window': 10000,\n            'knn': True,\n            'knn.algo_param.ef_search': 100  # Balance speed vs quality\n        }\n    },\n    'mappings': {\n        'properties': {\n            'embedding': {\n                'type': 'knn_vector',\n                'dimension': 384,\n                'method': {\n                    'name': 'hnsw',\n                    'space_type': 'cosinesimil',\n                    'engine': 'nmslib',\n                    'parameters': {\n                        'ef_construction': 128,\n                        'm': 16\n                    }\n                }\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"advanced/performance/#2-connection-pooling","title":"2. Connection Pooling","text":"<pre><code>from opensearchpy import OpenSearch\n\n# Optimize connection settings\nclient = OpenSearch(\n    hosts=[{'host': 'localhost', 'port': 9200}],\n    http_compress=True,  # Compress requests/responses\n    use_ssl=False,\n    verify_certs=False,\n    max_retries=3,\n    retry_on_timeout=True,\n    timeout=30,\n    # Connection pooling\n    maxsize=25,  # Connection pool size\n    http_auth=None\n)\n</code></pre>"},{"location":"advanced/performance/#3-bulk-operations","title":"3. Bulk Operations","text":"<pre><code>from opensearchpy import helpers\n\ndef efficient_bulk_index(documents):\n    \"\"\"Efficient bulk indexing.\"\"\"\n\n    # Prepare actions\n    actions = [\n        {\n            '_index': 'research_assistant',\n            '_id': doc['id'],\n            '_source': doc\n        }\n        for doc in documents\n    ]\n\n    # Bulk with optimized settings\n    success, failed = helpers.bulk(\n        client,\n        actions,\n        chunk_size=500,  # Process in chunks\n        request_timeout=60,\n        max_retries=3,\n        raise_on_error=False\n    )\n\n    return success, failed\n</code></pre>"},{"location":"advanced/performance/#application-level-optimization","title":"Application-Level Optimization","text":""},{"location":"advanced/performance/#1-lazy-loading","title":"1. Lazy Loading","text":"<pre><code>class LazyModel:\n    \"\"\"Lazy-load models only when needed.\"\"\"\n\n    def __init__(self):\n        self._model = None\n\n    @property\n    def model(self):\n        if self._model is None:\n            print(\"Loading model...\")\n            from sentence_transformers import SentenceTransformer\n            self._model = SentenceTransformer('all-MiniLM-L6-v2')\n        return self._model\n\n# Usage\nlazy_model = LazyModel()\n# Model not loaded yet\n\nembedding = lazy_model.model.encode(\"text\")\n# Now model is loaded\n</code></pre>"},{"location":"advanced/performance/#2-pre-computation","title":"2. Pre-computation","text":"<pre><code>def precompute_embeddings():\n    \"\"\"Precompute embeddings for common queries.\"\"\"\n\n    common_queries = [\n        \"machine learning\",\n        \"deep learning\",\n        \"neural networks\",\n        # ... more queries\n    ]\n\n    embeddings = {}\n    for query in common_queries:\n        embeddings[query] = model.encode(query).tolist()\n\n    # Save to file\n    import pickle\n    with open('query_embeddings.pkl', 'wb') as f:\n        pickle.dump(embeddings, f)\n\n# Load at startup\nwith open('query_embeddings.pkl', 'rb') as f:\n    precomputed_embeddings = pickle.load(f)\n\n# Use in search\ndef search_optimized(query):\n    \"\"\"Search with precomputed embeddings.\"\"\"\n    if query in precomputed_embeddings:\n        query_embedding = precomputed_embeddings[query]\n    else:\n        query_embedding = model.encode(query).tolist()\n\n    # ... rest of search\n</code></pre>"},{"location":"advanced/performance/#3-background-processing","title":"3. Background Processing","text":"<pre><code>import threading\nimport queue\n\nclass BackgroundProcessor:\n    \"\"\"Process tasks in background.\"\"\"\n\n    def __init__(self):\n        self.queue = queue.Queue()\n        self.thread = threading.Thread(target=self._process_queue, daemon=True)\n        self.thread.start()\n\n    def _process_queue(self):\n        \"\"\"Process tasks from queue.\"\"\"\n        while True:\n            task = self.queue.get()\n            if task is None:\n                break\n\n            func, args, kwargs = task\n            try:\n                func(*args, **kwargs)\n            except Exception as e:\n                print(f\"Background task error: {e}\")\n\n            self.queue.task_done()\n\n    def submit(self, func, *args, **kwargs):\n        \"\"\"Submit task for background processing.\"\"\"\n        self.queue.put((func, args, kwargs))\n\n# Usage\nprocessor = BackgroundProcessor()\n\n# Index documents in background\nprocessor.submit(index_documents, documents)\n\n# Continue with other tasks immediately\n</code></pre>"},{"location":"advanced/performance/#infrastructure-optimization","title":"Infrastructure Optimization","text":""},{"location":"advanced/performance/#1-opensearch-configuration","title":"1. OpenSearch Configuration","text":"<p>Docker settings: <pre><code>docker run -d \\\n  --name opensearch \\\n  -p 9200:9200 -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_JAVA_OPTS=-Xms4g -Xmx4g\" \\\n  -e \"bootstrap.memory_lock=true\" \\\n  -e \"cluster.routing.allocation.disk.threshold_enabled=false\" \\\n  --ulimit memlock=-1:-1 \\\n  --memory=6g \\\n  opensearchproject/opensearch:latest\n</code></pre></p> <p>JVM settings (opensearch.yml): <pre><code># Heap size (50% of available RAM)\n-Xms4g\n-Xmx4g\n\n# GC settings\n-XX:+UseG1GC\n-XX:InitiatingHeapOccupancyPercent=45\n</code></pre></p>"},{"location":"advanced/performance/#2-gpu-acceleration","title":"2. GPU Acceleration","text":"<pre><code>import torch\nfrom sentence_transformers import SentenceTransformer\n\n# Check GPU\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Using device: {device}\")\n\n# Load model on GPU\nmodel = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n\n# Encode with GPU\nembeddings = model.encode(\n    texts,\n    batch_size=128,  # Larger batch for GPU\n    convert_to_tensor=True,\n    show_progress_bar=True\n)\n\n# Result: 10-100x faster on GPU\n</code></pre>"},{"location":"advanced/performance/#3-caching-layer-redis","title":"3. Caching Layer (Redis)","text":"<pre><code>import redis\nimport json\n\n# Connect to Redis\nredis_client = redis.Redis(host='localhost', port=6379, db=0)\n\ndef search_with_redis_cache(query, ttl=3600):\n    \"\"\"Search with Redis caching.\"\"\"\n\n    # Check cache\n    cache_key = f\"search:{query}\"\n    cached = redis_client.get(cache_key)\n\n    if cached:\n        return json.loads(cached)\n\n    # Perform search\n    results = perform_search(query)\n\n    # Cache results\n    redis_client.setex(\n        cache_key,\n        ttl,\n        json.dumps(results)\n    )\n\n    return results\n</code></pre>"},{"location":"advanced/performance/#performance-checklist","title":"Performance Checklist","text":""},{"location":"advanced/performance/#before-optimization","title":"Before Optimization","text":"<ul> <li> Profile to identify bottlenecks</li> <li> Measure baseline performance</li> <li> Set specific performance goals</li> </ul>"},{"location":"advanced/performance/#indexing","title":"Indexing","text":"<ul> <li> Use batch processing</li> <li> Enable parallel processing</li> <li> Disable refresh during bulk indexing</li> <li> Optimize batch sizes</li> <li> Use GPU for embeddings</li> </ul>"},{"location":"advanced/performance/#search","title":"Search","text":"<ul> <li> Implement result caching</li> <li> Optimize query structure</li> <li> Use pagination</li> <li> Limit result size</li> <li> Pre-compute common embeddings</li> </ul>"},{"location":"advanced/performance/#llm","title":"LLM","text":"<ul> <li> Optimize prompt length</li> <li> Implement streaming</li> <li> Cache responses</li> <li> Use appropriate temperature</li> <li> Handle rate limits</li> </ul>"},{"location":"advanced/performance/#database","title":"Database","text":"<ul> <li> Optimize index settings</li> <li> Configure connection pooling</li> <li> Use bulk operations</li> <li> Monitor cluster health</li> <li> Regular maintenance</li> </ul>"},{"location":"advanced/performance/#infrastructure","title":"Infrastructure","text":"<ul> <li> Sufficient memory allocation</li> <li> GPU if available</li> <li> Caching layer (Redis)</li> <li> Monitor resource usage</li> </ul>"},{"location":"advanced/performance/#benchmarking","title":"Benchmarking","text":""},{"location":"advanced/performance/#create-benchmark-suite","title":"Create Benchmark Suite","text":"<pre><code>import time\nimport statistics\n\nclass Benchmark:\n    \"\"\"Benchmark suite for performance testing.\"\"\"\n\n    def __init__(self):\n        self.results = {}\n\n    def run_benchmark(self, name, func, iterations=10):\n        \"\"\"Run benchmark.\"\"\"\n        times = []\n\n        # Warmup\n        func()\n\n        # Benchmark\n        for _ in range(iterations):\n            start = time.time()\n            func()\n            elapsed = time.time() - start\n            times.append(elapsed)\n\n        self.results[name] = {\n            'mean': statistics.mean(times),\n            'median': statistics.median(times),\n            'stdev': statistics.stdev(times) if len(times) &gt; 1 else 0,\n            'min': min(times),\n            'max': max(times)\n        }\n\n    def print_results(self):\n        \"\"\"Print benchmark results.\"\"\"\n        print(\"\\nBenchmark Results:\")\n        print(\"-\" * 60)\n\n        for name, stats in self.results.items():\n            print(f\"\\n{name}:\")\n            print(f\"  Mean:   {stats['mean']:.3f}s\")\n            print(f\"  Median: {stats['median']:.3f}s\")\n            print(f\"  Stdev:  {stats['stdev']:.3f}s\")\n            print(f\"  Min:    {stats['min']:.3f}s\")\n            print(f\"  Max:    {stats['max']:.3f}s\")\n\n# Usage\nbench = Benchmark()\n\nbench.run_benchmark(\n    \"Keyword Search\",\n    lambda: keyword_search(\"machine learning\"),\n    iterations=20\n)\n\nbench.run_benchmark(\n    \"Semantic Search\",\n    lambda: semantic_search(\"machine learning\"),\n    iterations=20\n)\n\nbench.run_benchmark(\n    \"Hybrid Search\",\n    lambda: hybrid_search(\"machine learning\"),\n    iterations=20\n)\n\nbench.print_results()\n</code></pre>"},{"location":"advanced/performance/#additional-resources","title":"Additional Resources","text":"<ul> <li>OpenSearch Performance Tuning</li> <li>Sentence Transformers Performance</li> <li>Python Profiling</li> <li>Gemini API Best Practices</li> </ul>"},{"location":"advanced/performance/#summary","title":"Summary","text":"<p>Quick Wins (implement first): 1. Enable result caching 2. Use batch processing 3. Optimize OpenSearch settings 4. Implement streaming responses 5. Add GPU support for embeddings</p> <p>Major Improvements (larger effort): 1. Parallel processing pipeline 2. Redis caching layer 3. Query optimization 4. Pre-computation strategies 5. Infrastructure upgrades</p> <p>Remember: Measure before and after optimizations to verify improvements!</p>"},{"location":"api/database-api/","title":"Database API Reference","text":""},{"location":"api/database-api/#overview","title":"Overview","text":"<p>The <code>CollectionDatabaseManager</code> class provides a Python API for interacting with the SQLite database that stores all collected research content. This is the primary interface for database operations in the Multi-Modal Academic Research System.</p> <p>Module: <code>multi_modal_rag.database</code> Class: <code>CollectionDatabaseManager</code> File: <code>multi_modal_rag/database/db_manager.py</code></p>"},{"location":"api/database-api/#importing","title":"Importing","text":"<pre><code>from multi_modal_rag.database import CollectionDatabaseManager\n</code></pre>"},{"location":"api/database-api/#class-collectiondatabasemanager","title":"Class: CollectionDatabaseManager","text":""},{"location":"api/database-api/#constructor","title":"Constructor","text":""},{"location":"api/database-api/#__init__db_path-str-datacollectionsdb","title":"<code>__init__(db_path: str = \"data/collections.db\")</code>","text":"<p>Initialize the database manager and create database schema if it doesn't exist.</p> <p>Parameters: - <code>db_path</code> (str, optional): Path to the SQLite database file. Defaults to <code>\"data/collections.db\"</code></p> <p>Returns: <code>CollectionDatabaseManager</code> instance</p> <p>Side Effects: - Creates database directory if it doesn't exist - Initializes all database tables if they don't exist - Logs initialization message</p> <p>Example:</p> <pre><code>from multi_modal_rag.database import CollectionDatabaseManager\n\n# Use default database path\ndb = CollectionDatabaseManager()\n\n# Use custom database path\ndb = CollectionDatabaseManager(db_path=\"custom/path/research.db\")\n</code></pre> <p>Raises: - <code>OSError</code>: If unable to create database directory - <code>sqlite3.Error</code>: If database initialization fails</p>"},{"location":"api/database-api/#collection-management-methods","title":"Collection Management Methods","text":""},{"location":"api/database-api/#add_collection","title":"<code>add_collection()</code>","text":""},{"location":"api/database-api/#add_collectioncontent_type-str-title-str-source-str-url-str-metadata-dict-indexed-bool-false-int","title":"<code>add_collection(content_type: str, title: str, source: str, url: str, metadata: Dict, indexed: bool = False) -&gt; int</code>","text":"<p>Add a new collection item to the database.</p> <p>Parameters: - <code>content_type</code> (str): Type of content - must be <code>'paper'</code>, <code>'video'</code>, or <code>'podcast'</code> - <code>title</code> (str): Title of the content - <code>source</code> (str): Source platform (e.g., <code>'arxiv'</code>, <code>'youtube'</code>, <code>'podcast_rss'</code>) - <code>url</code> (str): Original URL of the content - <code>metadata</code> (Dict): Additional metadata as a dictionary (will be JSON-encoded) - <code>indexed</code> (bool, optional): Whether content is indexed in OpenSearch. Defaults to <code>False</code></p> <p>Returns: <code>int</code> - The auto-generated collection ID</p> <p>Raises: - <code>Exception</code>: If database insertion fails (propagates after rollback)</p> <p>Example:</p> <pre><code>db = CollectionDatabaseManager()\n\n# Add a paper\ncollection_id = db.add_collection(\n    content_type='paper',\n    title='Attention Is All You Need',\n    source='arxiv',\n    url='https://arxiv.org/abs/1706.03762',\n    metadata={\n        'keywords': ['transformers', 'attention'],\n        'language': 'en'\n    },\n    indexed=False\n)\n\nprint(f\"Created collection with ID: {collection_id}\")\n</code></pre> <p>Notes: - The <code>metadata</code> dictionary is automatically JSON-encoded for storage - <code>collection_date</code> is automatically set to current timestamp - <code>status</code> is automatically set to <code>'collected'</code></p>"},{"location":"api/database-api/#get_all_collections","title":"<code>get_all_collections()</code>","text":""},{"location":"api/database-api/#get_all_collectionslimit-int-100-offset-int-0-listdict","title":"<code>get_all_collections(limit: int = 100, offset: int = 0) -&gt; List[Dict]</code>","text":"<p>Retrieve all collections with pagination support.</p> <p>Parameters: - <code>limit</code> (int, optional): Maximum number of results to return. Defaults to <code>100</code> - <code>offset</code> (int, optional): Number of records to skip (for pagination). Defaults to <code>0</code></p> <p>Returns: <code>List[Dict]</code> - List of collection dictionaries, ordered by <code>collection_date</code> DESC</p> <p>Example:</p> <pre><code># Get first 100 collections\ncollections = db.get_all_collections()\n\n# Get next 100 collections (pagination)\ncollections_page2 = db.get_all_collections(limit=100, offset=100)\n\n# Get only 10 collections\nrecent_collections = db.get_all_collections(limit=10)\n\nfor collection in collections:\n    print(f\"{collection['id']}: {collection['title']}\")\n    print(f\"  Type: {collection['content_type']}\")\n    print(f\"  Source: {collection['source']}\")\n    print(f\"  Metadata: {collection['metadata']}\")  # Already parsed from JSON\n</code></pre> <p>Return Format:</p> <pre><code>[\n    {\n        'id': 1,\n        'content_type': 'paper',\n        'title': 'Attention Is All You Need',\n        'source': 'arxiv',\n        'url': 'https://arxiv.org/abs/1706.03762',\n        'collection_date': '2025-10-01 10:30:00',\n        'metadata': {'keywords': ['transformers']},  # Parsed from JSON\n        'status': 'collected',\n        'indexed': 1\n    },\n    ...\n]\n</code></pre> <p>Notes: - The <code>metadata</code> field is automatically parsed from JSON to a Python dictionary - Results are ordered by <code>collection_date</code> in descending order (newest first)</p>"},{"location":"api/database-api/#get_collections_by_type","title":"<code>get_collections_by_type()</code>","text":""},{"location":"api/database-api/#get_collections_by_typecontent_type-str-limit-int-100-listdict","title":"<code>get_collections_by_type(content_type: str, limit: int = 100) -&gt; List[Dict]</code>","text":"<p>Retrieve collections filtered by content type.</p> <p>Parameters: - <code>content_type</code> (str): Type to filter by - must be <code>'paper'</code>, <code>'video'</code>, or <code>'podcast'</code> - <code>limit</code> (int, optional): Maximum number of results. Defaults to <code>100</code></p> <p>Returns: <code>List[Dict]</code> - List of matching collection dictionaries, ordered by <code>collection_date</code> DESC</p> <p>Example:</p> <pre><code># Get all papers\npapers = db.get_collections_by_type('paper', limit=50)\n\n# Get all videos\nvideos = db.get_collections_by_type('video')\n\n# Get all podcasts\npodcasts = db.get_collections_by_type('podcast', limit=20)\n\nprint(f\"Found {len(papers)} papers\")\nfor paper in papers:\n    print(f\"  - {paper['title']}\")\n</code></pre> <p>Return Format: Same as <code>get_all_collections()</code></p>"},{"location":"api/database-api/#get_collection_with_details","title":"<code>get_collection_with_details()</code>","text":""},{"location":"api/database-api/#get_collection_with_detailscollection_id-int-optionaldict","title":"<code>get_collection_with_details(collection_id: int) -&gt; Optional[Dict]</code>","text":"<p>Retrieve full collection details including type-specific data from related tables.</p> <p>Parameters: - <code>collection_id</code> (int): The unique ID of the collection</p> <p>Returns: - <code>Dict</code> - Collection dictionary with additional <code>'details'</code> key containing type-specific data - <code>None</code> - If collection doesn't exist</p> <p>Example:</p> <pre><code># Get paper with details\ncollection = db.get_collection_with_details(1)\n\nif collection:\n    print(f\"Title: {collection['title']}\")\n    print(f\"Type: {collection['content_type']}\")\n\n    # Type-specific details\n    if collection['content_type'] == 'paper':\n        details = collection['details']\n        print(f\"Authors: {', '.join(details['authors'])}\")\n        print(f\"ArXiv ID: {details['arxiv_id']}\")\n        print(f\"Abstract: {details['abstract'][:100]}...\")\n        print(f\"PDF Path: {details['pdf_path']}\")\n\n    elif collection['content_type'] == 'video':\n        details = collection['details']\n        print(f\"Channel: {details['channel']}\")\n        print(f\"Video ID: {details['video_id']}\")\n        print(f\"Duration: {details['duration']} seconds\")\n        print(f\"Views: {details['views']}\")\n\n    elif collection['content_type'] == 'podcast':\n        details = collection['details']\n        print(f\"Podcast: {details['podcast_name']}\")\n        print(f\"Episode ID: {details['episode_id']}\")\n        print(f\"Duration: {details['duration']} seconds\")\nelse:\n    print(\"Collection not found\")\n</code></pre> <p>Return Format for Paper:</p> <pre><code>{\n    'id': 1,\n    'content_type': 'paper',\n    'title': 'Attention Is All You Need',\n    'source': 'arxiv',\n    'url': 'https://arxiv.org/abs/1706.03762',\n    'collection_date': '2025-10-01 10:30:00',\n    'metadata': {},\n    'status': 'collected',\n    'indexed': 1,\n    'details': {\n        'id': 1,\n        'collection_id': 1,\n        'arxiv_id': '1706.03762',\n        'pmc_id': None,\n        'abstract': 'The dominant sequence transduction models...',\n        'authors': ['Ashish Vaswani', 'Noam Shazeer'],  # Parsed from JSON\n        'published_date': '2017-06-12',\n        'categories': ['cs.CL', 'cs.AI'],  # Parsed from JSON\n        'pdf_path': 'data/papers/arxiv_1706.03762.pdf'\n    }\n}\n</code></pre> <p>Notes: - For papers, <code>authors</code> and <code>categories</code> in details are automatically parsed from JSON - If collection exists but has no type-specific record, <code>'details'</code> key will not be present</p>"},{"location":"api/database-api/#search_collections","title":"<code>search_collections()</code>","text":""},{"location":"api/database-api/#search_collectionsquery-str-limit-int-50-listdict","title":"<code>search_collections(query: str, limit: int = 50) -&gt; List[Dict]</code>","text":"<p>Search collections by title or source using substring matching.</p> <p>Parameters: - <code>query</code> (str): Search query string - <code>limit</code> (int, optional): Maximum number of results. Defaults to <code>50</code></p> <p>Returns: <code>List[Dict]</code> - List of matching collection dictionaries, ordered by <code>collection_date</code> DESC</p> <p>Example:</p> <pre><code># Search for \"transformer\"\nresults = db.search_collections('transformer', limit=20)\n\n# Search for \"arxiv\" (searches in source field too)\narxiv_papers = db.search_collections('arxiv')\n\n# Search for \"neural network\"\nnn_results = db.search_collections('neural network')\n\nprint(f\"Found {len(results)} results\")\nfor result in results:\n    print(f\"  {result['content_type']}: {result['title']}\")\n</code></pre> <p>Search Behavior: - Case-insensitive substring matching - Searches both <code>title</code> AND <code>source</code> fields - Uses SQL <code>LIKE '%query%'</code> pattern - Returns results ordered by newest first</p> <p>Return Format: Same as <code>get_all_collections()</code></p>"},{"location":"api/database-api/#type-specific-methods","title":"Type-Specific Methods","text":""},{"location":"api/database-api/#add_paper","title":"<code>add_paper()</code>","text":""},{"location":"api/database-api/#add_papercollection_id-int-paper_data-dict","title":"<code>add_paper(collection_id: int, paper_data: Dict)</code>","text":"<p>Add paper-specific data to the papers table.</p> <p>Parameters: - <code>collection_id</code> (int): ID of the parent collection record - <code>paper_data</code> (Dict): Dictionary containing paper details</p> <p>Paper Data Fields: - <code>arxiv_id</code> (str, optional): ArXiv identifier - <code>pmc_id</code> (str, optional): PubMed Central identifier - <code>abstract</code> (str, optional): Paper abstract - <code>authors</code> (List[str], optional): List of author names - <code>published</code> (str, optional): Publication date - <code>categories</code> (List[str], optional): List of category tags - <code>local_path</code> (str, optional): Path to downloaded PDF</p> <p>Returns: <code>None</code></p> <p>Raises: - <code>Exception</code>: If database insertion fails (propagates after rollback)</p> <p>Example:</p> <pre><code># First, create the collection\ncollection_id = db.add_collection(\n    content_type='paper',\n    title='Attention Is All You Need',\n    source='arxiv',\n    url='https://arxiv.org/abs/1706.03762',\n    metadata={}\n)\n\n# Then add paper-specific details\ndb.add_paper(collection_id, {\n    'arxiv_id': '1706.03762',\n    'pmc_id': None,\n    'abstract': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...',\n    'authors': ['Ashish Vaswani', 'Noam Shazeer', 'Niki Parmar', 'Jakob Uszkoreit'],\n    'published': '2017-06-12',\n    'categories': ['cs.CL', 'cs.AI', 'cs.LG'],\n    'local_path': 'data/papers/arxiv_1706.03762.pdf'\n})\n</code></pre> <p>Notes: - <code>authors</code> and <code>categories</code> lists are automatically JSON-encoded for storage - All fields are optional (nullable in database)</p>"},{"location":"api/database-api/#add_video","title":"<code>add_video()</code>","text":""},{"location":"api/database-api/#add_videocollection_id-int-video_data-dict","title":"<code>add_video(collection_id: int, video_data: Dict)</code>","text":"<p>Add video-specific data to the videos table.</p> <p>Parameters: - <code>collection_id</code> (int): ID of the parent collection record - <code>video_data</code> (Dict): Dictionary containing video details</p> <p>Video Data Fields: - <code>video_id</code> (str, optional): YouTube video ID - <code>author</code> (str, optional): Channel name (mapped to <code>channel</code> field) - <code>length</code> (int, optional): Duration in seconds (mapped to <code>duration</code> field) - <code>views</code> (int, optional): View count - <code>thumbnail_url</code> (str, optional): Thumbnail image URL - <code>transcript</code> (str/bool, optional): Transcript text or boolean indicating availability</p> <p>Returns: <code>None</code></p> <p>Raises: - <code>Exception</code>: If database insertion fails (propagates after rollback)</p> <p>Example:</p> <pre><code># Create collection\ncollection_id = db.add_collection(\n    content_type='video',\n    title='Neural Networks Explained',\n    source='youtube',\n    url='https://youtube.com/watch?v=abc123',\n    metadata={}\n)\n\n# Add video details\ndb.add_video(collection_id, {\n    'video_id': 'abc123',\n    'author': '3Blue1Brown',\n    'length': 1194,\n    'views': 5234891,\n    'thumbnail_url': 'https://i.ytimg.com/vi/abc123/maxresdefault.jpg',\n    'transcript': 'Hello and welcome to this video about neural networks...'\n})\n</code></pre> <p>Notes: - <code>author</code> is mapped to the <code>channel</code> database field - <code>length</code> is mapped to the <code>duration</code> database field - <code>transcript_available</code> is set based on whether <code>transcript</code> field is truthy - All fields are optional (nullable in database)</p>"},{"location":"api/database-api/#add_podcast","title":"<code>add_podcast()</code>","text":""},{"location":"api/database-api/#add_podcastcollection_id-int-podcast_data-dict","title":"<code>add_podcast(collection_id: int, podcast_data: Dict)</code>","text":"<p>Add podcast-specific data to the podcasts table.</p> <p>Parameters: - <code>collection_id</code> (int): ID of the parent collection record - <code>podcast_data</code> (Dict): Dictionary containing podcast details</p> <p>Podcast Data Fields: - <code>episode_id</code> (str, optional): Unique episode identifier - <code>podcast_name</code> (str, optional): Name of the podcast show - <code>audio_url</code> (str, optional): Direct URL to audio file - <code>duration</code> (int, optional): Episode duration in seconds</p> <p>Returns: <code>None</code></p> <p>Raises: - <code>Exception</code>: If database insertion fails (propagates after rollback)</p> <p>Example:</p> <pre><code># Create collection\ncollection_id = db.add_collection(\n    content_type='podcast',\n    title='AI Safety Discussion - Episode 42',\n    source='podcast_rss',\n    url='https://podcast.ai/ep42',\n    metadata={'language': 'en'}\n)\n\n# Add podcast details\ndb.add_podcast(collection_id, {\n    'episode_id': 'ep-42',\n    'podcast_name': 'AI Alignment Podcast',\n    'audio_url': 'https://podcast.ai/audio/ep42.mp3',\n    'duration': 3600\n})\n</code></pre> <p>Notes: - All fields are optional (nullable in database)</p>"},{"location":"api/database-api/#status-management-methods","title":"Status Management Methods","text":""},{"location":"api/database-api/#mark_as_indexed","title":"<code>mark_as_indexed()</code>","text":""},{"location":"api/database-api/#mark_as_indexedcollection_id-int","title":"<code>mark_as_indexed(collection_id: int)</code>","text":"<p>Mark a collection item as indexed in OpenSearch.</p> <p>Parameters: - <code>collection_id</code> (int): The unique ID of the collection</p> <p>Returns: <code>None</code></p> <p>Raises: - <code>Exception</code>: If database update fails (propagates after rollback)</p> <p>Example:</p> <pre><code># After successfully indexing in OpenSearch\ncollection_id = 42\ndb.mark_as_indexed(collection_id)\n\nprint(f\"Collection {collection_id} marked as indexed\")\n</code></pre> <p>SQL Operation: <pre><code>UPDATE collections SET indexed = 1 WHERE id = ?\n</code></pre></p>"},{"location":"api/database-api/#statistics-methods","title":"Statistics Methods","text":""},{"location":"api/database-api/#get_statistics","title":"<code>get_statistics()</code>","text":""},{"location":"api/database-api/#get_statistics-dict","title":"<code>get_statistics() -&gt; Dict</code>","text":"<p>Retrieve comprehensive database statistics.</p> <p>Parameters: None</p> <p>Returns: <code>Dict</code> containing various statistics</p> <p>Return Format:</p> <pre><code>{\n    'by_type': {\n        'paper': 1523,\n        'video': 342,\n        'podcast': 87\n    },\n    'indexed': 1845,\n    'not_indexed': 107,\n    'recent_7_days': 23,\n    'collection_history': [\n        {\n            'type': 'paper',\n            'source': 'arxiv',\n            'total': 1200\n        },\n        {\n            'type': 'paper',\n            'source': 'pubmed',\n            'total': 323\n        },\n        {\n            'type': 'video',\n            'source': 'youtube',\n            'total': 342\n        }\n    ]\n}\n</code></pre> <p>Return Fields: - <code>by_type</code> (Dict[str, int]): Count of collections by content type - <code>indexed</code> (int): Number of indexed collections - <code>not_indexed</code> (int): Number of not-yet-indexed collections - <code>recent_7_days</code> (int): Collections added in the last 7 days - <code>collection_history</code> (List[Dict]): Aggregated collection stats by type and source</p> <p>Example:</p> <pre><code>stats = db.get_statistics()\n\nprint(\"Database Statistics:\")\nprint(f\"  Total Papers: {stats['by_type'].get('paper', 0)}\")\nprint(f\"  Total Videos: {stats['by_type'].get('video', 0)}\")\nprint(f\"  Total Podcasts: {stats['by_type'].get('podcast', 0)}\")\nprint(f\"  Indexed: {stats['indexed']}\")\nprint(f\"  Pending Indexing: {stats['not_indexed']}\")\nprint(f\"  Added Last 7 Days: {stats['recent_7_days']}\")\n\nprint(\"\\nCollection History:\")\nfor item in stats['collection_history']:\n    print(f\"  {item['type']} from {item['source']}: {item['total']} items\")\n</code></pre>"},{"location":"api/database-api/#log_collection_stats","title":"<code>log_collection_stats()</code>","text":""},{"location":"api/database-api/#log_collection_statscontent_type-str-query-str-results_count-int-source_api-str","title":"<code>log_collection_stats(content_type: str, query: str, results_count: int, source_api: str)</code>","text":"<p>Log statistics about a collection operation.</p> <p>Parameters: - <code>content_type</code> (str): Type of content collected - <code>query</code> (str): Search query used - <code>results_count</code> (int): Number of results returned by the API - <code>source_api</code> (str): API source (e.g., <code>'arxiv'</code>, <code>'youtube_api'</code>)</p> <p>Returns: <code>None</code></p> <p>Raises: - <code>Exception</code>: If database insertion fails (propagates after rollback)</p> <p>Example:</p> <pre><code># After collecting papers from ArXiv\ndb.log_collection_stats(\n    content_type='paper',\n    query='machine learning',\n    results_count=25,\n    source_api='arxiv'\n)\n\n# After collecting videos\ndb.log_collection_stats(\n    content_type='video',\n    query='neural networks',\n    results_count=10,\n    source_api='youtube_api'\n)\n</code></pre> <p>Usage: This helps track which queries are being used, how many results are typically returned, and which APIs are most productive.</p>"},{"location":"api/database-api/#complete-usage-example","title":"Complete Usage Example","text":"<pre><code>from multi_modal_rag.database import CollectionDatabaseManager\n\n# Initialize database\ndb = CollectionDatabaseManager()\n\n# === Add a Paper ===\npaper_collection_id = db.add_collection(\n    content_type='paper',\n    title='Attention Is All You Need',\n    source='arxiv',\n    url='https://arxiv.org/abs/1706.03762',\n    metadata={'keywords': ['transformers', 'attention']},\n    indexed=False\n)\n\ndb.add_paper(paper_collection_id, {\n    'arxiv_id': '1706.03762',\n    'abstract': 'The dominant sequence transduction models...',\n    'authors': ['Ashish Vaswani', 'Noam Shazeer'],\n    'published': '2017-06-12',\n    'categories': ['cs.CL', 'cs.AI'],\n    'local_path': 'data/papers/1706.03762.pdf'\n})\n\n# Log the collection\ndb.log_collection_stats('paper', 'transformers', 1, 'arxiv')\n\n# === Add a Video ===\nvideo_collection_id = db.add_collection(\n    content_type='video',\n    title='Neural Networks Explained',\n    source='youtube',\n    url='https://youtube.com/watch?v=abc123',\n    metadata={}\n)\n\ndb.add_video(video_collection_id, {\n    'video_id': 'abc123',\n    'author': '3Blue1Brown',\n    'length': 1194,\n    'views': 5000000,\n    'thumbnail_url': 'https://i.ytimg.com/vi/abc123/maxresdefault.jpg',\n    'transcript': 'Hello and welcome...'\n})\n\n# === Query Collections ===\n\n# Get all papers\npapers = db.get_collections_by_type('paper', limit=10)\nprint(f\"Found {len(papers)} papers\")\n\n# Search\nresults = db.search_collections('transformer')\nprint(f\"Search found {len(results)} results\")\n\n# Get full details\ndetails = db.get_collection_with_details(paper_collection_id)\nprint(f\"Paper title: {details['title']}\")\nprint(f\"Authors: {', '.join(details['details']['authors'])}\")\n\n# === Mark as Indexed ===\ndb.mark_as_indexed(paper_collection_id)\n\n# === Get Statistics ===\nstats = db.get_statistics()\nprint(f\"Total items: {sum(stats['by_type'].values())}\")\nprint(f\"Indexed: {stats['indexed']}, Pending: {stats['not_indexed']}\")\n</code></pre>"},{"location":"api/database-api/#error-handling","title":"Error Handling","text":"<p>All methods that modify the database use try/except blocks with rollback:</p> <pre><code>try:\n    # Database operation\n    conn.commit()\nexcept Exception as e:\n    logger.error(f\"Error: {e}\")\n    conn.rollback()\n    raise  # Re-raise exception\nfinally:\n    conn.close()\n</code></pre> <p>Best Practice:</p> <pre><code>try:\n    collection_id = db.add_collection(...)\n    db.add_paper(collection_id, {...})\nexcept Exception as e:\n    print(f\"Failed to add paper: {e}\")\n    # Handle error appropriately\n</code></pre>"},{"location":"api/database-api/#thread-safety","title":"Thread Safety","text":"<p>Important: SQLite connections are NOT thread-safe by default. Each method creates its own connection and closes it, which is safe for multi-threaded use, but not optimal for performance.</p> <p>For high-concurrency scenarios, consider: 1. Using connection pooling 2. Implementing a connection-per-thread pattern 3. Using a more robust database (PostgreSQL, MySQL)</p>"},{"location":"api/database-api/#performance-considerations","title":"Performance Considerations","text":""},{"location":"api/database-api/#indexing","title":"Indexing","text":"<p>For better performance with large datasets:</p> <pre><code>import sqlite3\n\nconn = sqlite3.connect('data/collections.db')\ncursor = conn.cursor()\n\n# Add indexes\ncursor.execute(\"CREATE INDEX IF NOT EXISTS idx_content_type ON collections(content_type)\")\ncursor.execute(\"CREATE INDEX IF NOT EXISTS idx_indexed ON collections(indexed)\")\ncursor.execute(\"CREATE INDEX IF NOT EXISTS idx_collection_date ON collections(collection_date DESC)\")\n\nconn.commit()\nconn.close()\n</code></pre>"},{"location":"api/database-api/#batch-operations","title":"Batch Operations","text":"<p>For inserting many items, use transactions:</p> <pre><code>import sqlite3\n\nconn = sqlite3.connect('data/collections.db')\ncursor = conn.cursor()\n\ntry:\n    # Disable autocommit for batch insert\n    for paper_data in large_paper_list:\n        cursor.execute(\"INSERT INTO collections ...\")\n        # ... more inserts\n\n    conn.commit()  # Commit all at once\nexcept:\n    conn.rollback()\n    raise\nfinally:\n    conn.close()\n</code></pre>"},{"location":"api/database-api/#query-optimization","title":"Query Optimization","text":"<ul> <li>Use <code>LIMIT</code> to avoid loading too many records</li> <li>Add appropriate indexes on frequently queried fields</li> <li>Use <code>EXPLAIN QUERY PLAN</code> to analyze slow queries</li> </ul>"},{"location":"api/database-api/#backup-and-recovery","title":"Backup and Recovery","text":"<pre><code>import sqlite3\nimport shutil\nfrom datetime import datetime\n\n# Simple file backup\nshutil.copy('data/collections.db', f'data/backup_{datetime.now().strftime(\"%Y%m%d\")}.db')\n\n# SQLite backup API (online backup)\nsource = sqlite3.connect('data/collections.db')\ndest = sqlite3.connect('data/backup.db')\nsource.backup(dest)\ndest.close()\nsource.close()\n</code></pre>"},{"location":"api/rest-api/","title":"REST API Reference","text":""},{"location":"api/rest-api/#overview","title":"Overview","text":"<p>The Multi-Modal Research Data API is a FastAPI-based REST service that provides programmatic access to the collected research data stored in the SQLite database. The API allows querying collections, retrieving detailed information, searching, and viewing statistics.</p> <p>Base URL: <code>http://localhost:8000</code> (default) API Version: 1.0.0 Framework: FastAPI 0.x Documentation: Auto-generated Swagger UI available at <code>/docs</code></p>"},{"location":"api/rest-api/#starting-the-api-server","title":"Starting the API Server","text":"<pre><code># Method 1: Direct execution\npython -m multi_modal_rag.api.api_server\n\n# Method 2: Using uvicorn\nuvicorn multi_modal_rag.api.api_server:app --host 0.0.0.0 --port 8000\n\n# Method 3: With auto-reload for development\nuvicorn multi_modal_rag.api.api_server:app --reload\n</code></pre>"},{"location":"api/rest-api/#interactive-documentation","title":"Interactive Documentation","text":"<p>FastAPI provides automatic interactive API documentation:</p> <ul> <li>Swagger UI: <code>http://localhost:8000/docs</code></li> <li>ReDoc: <code>http://localhost:8000/redoc</code></li> <li>OpenAPI Schema: <code>http://localhost:8000/openapi.json</code></li> </ul>"},{"location":"api/rest-api/#cors-configuration","title":"CORS Configuration","text":"<p>The API is configured with permissive CORS settings to allow frontend access:</p> <pre><code>allow_origins=[\"*\"]\nallow_credentials=True\nallow_methods=[\"*\"]\nallow_headers=[\"*\"]\n</code></pre> <p>Note: In production, restrict <code>allow_origins</code> to specific domains.</p>"},{"location":"api/rest-api/#endpoints","title":"Endpoints","text":""},{"location":"api/rest-api/#1-root-endpoint","title":"1. Root Endpoint","text":"<p>Get API information and available endpoints.</p>"},{"location":"api/rest-api/#request","title":"Request","text":"<pre><code>GET /\n</code></pre>"},{"location":"api/rest-api/#parameters","title":"Parameters","text":"<p>None</p>"},{"location":"api/rest-api/#response","title":"Response","text":"<pre><code>{\n  \"message\": \"Multi-Modal Research Data API\",\n  \"endpoints\": {\n    \"collections\": \"/api/collections\",\n    \"statistics\": \"/api/statistics\",\n    \"search\": \"/api/search\",\n    \"visualization\": \"/viz\"\n  }\n}\n</code></pre>"},{"location":"api/rest-api/#example","title":"Example","text":"<pre><code>curl http://localhost:8000/\n</code></pre>"},{"location":"api/rest-api/#2-get-collections","title":"2. Get Collections","text":"<p>Retrieve all collections with optional filtering and pagination.</p>"},{"location":"api/rest-api/#request_1","title":"Request","text":"<pre><code>GET /api/collections\n</code></pre>"},{"location":"api/rest-api/#query-parameters","title":"Query Parameters","text":"Parameter Type Required Default Description <code>content_type</code> string No None Filter by content type: <code>paper</code>, <code>video</code>, or <code>podcast</code> <code>limit</code> integer No 100 Maximum number of results (1-1000) <code>offset</code> integer No 0 Offset for pagination (\u22650)"},{"location":"api/rest-api/#response_1","title":"Response","text":"<p>Status: 200 OK</p> <pre><code>{\n  \"count\": 25,\n  \"collections\": [\n    {\n      \"id\": 1,\n      \"content_type\": \"paper\",\n      \"title\": \"Attention Is All You Need\",\n      \"source\": \"arxiv\",\n      \"url\": \"https://arxiv.org/abs/1706.03762\",\n      \"collection_date\": \"2025-10-01 10:30:00\",\n      \"metadata\": {\n        \"keywords\": [\"transformers\", \"attention\"]\n      },\n      \"status\": \"collected\",\n      \"indexed\": 1\n    },\n    ...\n  ]\n}\n</code></pre>"},{"location":"api/rest-api/#error-responses","title":"Error Responses","text":"<p>Status: 500 Internal Server Error</p> <pre><code>{\n  \"detail\": \"Error message\"\n}\n</code></pre>"},{"location":"api/rest-api/#examples","title":"Examples","text":"<p>Get all collections (default pagination)</p> <pre><code>curl http://localhost:8000/api/collections\n</code></pre> <p>Get only papers</p> <pre><code>curl \"http://localhost:8000/api/collections?content_type=paper\"\n</code></pre> <p>Get videos with custom pagination</p> <pre><code>curl \"http://localhost:8000/api/collections?content_type=video&amp;limit=50&amp;offset=100\"\n</code></pre> <p>Get podcasts (first 20)</p> <pre><code>curl \"http://localhost:8000/api/collections?content_type=podcast&amp;limit=20\"\n</code></pre>"},{"location":"api/rest-api/#python-example","title":"Python Example","text":"<pre><code>import requests\n\nresponse = requests.get(\n    'http://localhost:8000/api/collections',\n    params={\n        'content_type': 'paper',\n        'limit': 50,\n        'offset': 0\n    }\n)\n\ndata = response.json()\nprint(f\"Found {data['count']} collections\")\nfor collection in data['collections']:\n    print(f\"  - {collection['title']}\")\n</code></pre>"},{"location":"api/rest-api/#3-get-collection-details","title":"3. Get Collection Details","text":"<p>Retrieve detailed information about a specific collection, including type-specific data.</p>"},{"location":"api/rest-api/#request_2","title":"Request","text":"<pre><code>GET /api/collections/{collection_id}\n</code></pre>"},{"location":"api/rest-api/#path-parameters","title":"Path Parameters","text":"Parameter Type Required Description <code>collection_id</code> integer Yes Unique collection ID"},{"location":"api/rest-api/#response_2","title":"Response","text":"<p>Status: 200 OK</p> <p>For a paper:</p> <pre><code>{\n  \"id\": 1,\n  \"content_type\": \"paper\",\n  \"title\": \"Attention Is All You Need\",\n  \"source\": \"arxiv\",\n  \"url\": \"https://arxiv.org/abs/1706.03762\",\n  \"collection_date\": \"2025-10-01 10:30:00\",\n  \"metadata\": {\n    \"keywords\": [\"transformers\"]\n  },\n  \"status\": \"collected\",\n  \"indexed\": 1,\n  \"details\": {\n    \"id\": 1,\n    \"collection_id\": 1,\n    \"arxiv_id\": \"1706.03762\",\n    \"pmc_id\": null,\n    \"abstract\": \"The dominant sequence transduction models...\",\n    \"authors\": [\"Ashish Vaswani\", \"Noam Shazeer\", \"Niki Parmar\"],\n    \"published_date\": \"2017-06-12\",\n    \"categories\": [\"cs.CL\", \"cs.AI\", \"cs.LG\"],\n    \"pdf_path\": \"data/papers/arxiv_1706.03762.pdf\"\n  }\n}\n</code></pre> <p>For a video:</p> <pre><code>{\n  \"id\": 2,\n  \"content_type\": \"video\",\n  \"title\": \"Neural Networks Explained\",\n  \"source\": \"youtube\",\n  \"url\": \"https://youtube.com/watch?v=abc123\",\n  \"collection_date\": \"2025-10-01 11:00:00\",\n  \"metadata\": {},\n  \"status\": \"collected\",\n  \"indexed\": 1,\n  \"details\": {\n    \"id\": 1,\n    \"collection_id\": 2,\n    \"video_id\": \"abc123\",\n    \"channel\": \"3Blue1Brown\",\n    \"duration\": 1194,\n    \"views\": 5234891,\n    \"thumbnail_url\": \"https://i.ytimg.com/vi/abc123/maxresdefault.jpg\",\n    \"transcript_available\": 1\n  }\n}\n</code></pre> <p>For a podcast:</p> <pre><code>{\n  \"id\": 3,\n  \"content_type\": \"podcast\",\n  \"title\": \"AI Safety Discussion\",\n  \"source\": \"podcast_rss\",\n  \"url\": \"https://podcast.ai/ep42\",\n  \"collection_date\": \"2025-10-02 09:15:00\",\n  \"metadata\": {},\n  \"status\": \"collected\",\n  \"indexed\": 0,\n  \"details\": {\n    \"id\": 1,\n    \"collection_id\": 3,\n    \"episode_id\": \"ep-42\",\n    \"podcast_name\": \"AI Alignment Podcast\",\n    \"audio_url\": \"https://podcast.ai/audio/ep42.mp3\",\n    \"duration\": 3600\n  }\n}\n</code></pre>"},{"location":"api/rest-api/#error-responses_1","title":"Error Responses","text":"<p>Status: 404 Not Found</p> <pre><code>{\n  \"detail\": \"Collection not found\"\n}\n</code></pre> <p>Status: 500 Internal Server Error</p> <pre><code>{\n  \"detail\": \"Error message\"\n}\n</code></pre>"},{"location":"api/rest-api/#examples_1","title":"Examples","text":"<pre><code># Get collection with ID 1\ncurl http://localhost:8000/api/collections/1\n\n# Get collection with ID 42\ncurl http://localhost:8000/api/collections/42\n</code></pre>"},{"location":"api/rest-api/#python-example_1","title":"Python Example","text":"<pre><code>import requests\n\ncollection_id = 1\nresponse = requests.get(f'http://localhost:8000/api/collections/{collection_id}')\n\nif response.status_code == 200:\n    collection = response.json()\n    print(f\"Title: {collection['title']}\")\n    print(f\"Type: {collection['content_type']}\")\n\n    if 'details' in collection:\n        if collection['content_type'] == 'paper':\n            print(f\"Authors: {', '.join(collection['details']['authors'])}\")\n        elif collection['content_type'] == 'video':\n            print(f\"Channel: {collection['details']['channel']}\")\nelif response.status_code == 404:\n    print(\"Collection not found\")\n</code></pre>"},{"location":"api/rest-api/#4-get-statistics","title":"4. Get Statistics","text":"<p>Retrieve database statistics including counts by type, indexing status, and collection history.</p>"},{"location":"api/rest-api/#request_3","title":"Request","text":"<pre><code>GET /api/statistics\n</code></pre>"},{"location":"api/rest-api/#parameters_1","title":"Parameters","text":"<p>None</p>"},{"location":"api/rest-api/#response_3","title":"Response","text":"<p>Status: 200 OK</p> <pre><code>{\n  \"by_type\": {\n    \"paper\": 1523,\n    \"video\": 342,\n    \"podcast\": 87\n  },\n  \"indexed\": 1845,\n  \"not_indexed\": 107,\n  \"recent_7_days\": 23,\n  \"collection_history\": [\n    {\n      \"type\": \"paper\",\n      \"source\": \"arxiv\",\n      \"total\": 1200\n    },\n    {\n      \"type\": \"paper\",\n      \"source\": \"pubmed\",\n      \"total\": 323\n    },\n    {\n      \"type\": \"video\",\n      \"source\": \"youtube\",\n      \"total\": 342\n    }\n  ]\n}\n</code></pre>"},{"location":"api/rest-api/#response-fields","title":"Response Fields","text":"Field Type Description <code>by_type</code> object Count of collections by content type <code>indexed</code> integer Number of indexed collections <code>not_indexed</code> integer Number of not-yet-indexed collections <code>recent_7_days</code> integer Collections added in last 7 days <code>collection_history</code> array Breakdown by type and source API"},{"location":"api/rest-api/#error-responses_2","title":"Error Responses","text":"<p>Status: 500 Internal Server Error</p> <pre><code>{\n  \"detail\": \"Error message\"\n}\n</code></pre>"},{"location":"api/rest-api/#examples_2","title":"Examples","text":"<pre><code>curl http://localhost:8000/api/statistics\n</code></pre>"},{"location":"api/rest-api/#python-example_2","title":"Python Example","text":"<pre><code>import requests\n\nresponse = requests.get('http://localhost:8000/api/statistics')\nstats = response.json()\n\nprint(\"Collection Statistics:\")\nprint(f\"  Total Papers: {stats['by_type'].get('paper', 0)}\")\nprint(f\"  Total Videos: {stats['by_type'].get('video', 0)}\")\nprint(f\"  Total Podcasts: {stats['by_type'].get('podcast', 0)}\")\nprint(f\"  Indexed: {stats['indexed']}\")\nprint(f\"  Not Indexed: {stats['not_indexed']}\")\nprint(f\"  Added in Last 7 Days: {stats['recent_7_days']}\")\n</code></pre>"},{"location":"api/rest-api/#5-search-collections","title":"5. Search Collections","text":"<p>Search collections by title or source using substring matching.</p>"},{"location":"api/rest-api/#request_4","title":"Request","text":"<pre><code>GET /api/search\n</code></pre>"},{"location":"api/rest-api/#query-parameters_1","title":"Query Parameters","text":"Parameter Type Required Default Description <code>q</code> string Yes - Search query (minimum 1 character) <code>limit</code> integer No 50 Maximum number of results (1-500)"},{"location":"api/rest-api/#response_4","title":"Response","text":"<p>Status: 200 OK</p> <pre><code>{\n  \"query\": \"machine learning\",\n  \"count\": 12,\n  \"results\": [\n    {\n      \"id\": 5,\n      \"content_type\": \"paper\",\n      \"title\": \"Deep Learning for Machine Translation\",\n      \"source\": \"arxiv\",\n      \"url\": \"https://arxiv.org/abs/...\",\n      \"collection_date\": \"2025-10-01 14:20:00\",\n      \"metadata\": {},\n      \"status\": \"collected\",\n      \"indexed\": 1\n    },\n    ...\n  ]\n}\n</code></pre>"},{"location":"api/rest-api/#response-fields_1","title":"Response Fields","text":"Field Type Description <code>query</code> string The search query that was executed <code>count</code> integer Number of results found <code>results</code> array Array of matching collection objects"},{"location":"api/rest-api/#error-responses_3","title":"Error Responses","text":"<p>Status: 422 Unprocessable Entity</p> <pre><code>{\n  \"detail\": [\n    {\n      \"loc\": [\"query\", \"q\"],\n      \"msg\": \"field required\",\n      \"type\": \"value_error.missing\"\n    }\n  ]\n}\n</code></pre> <p>Status: 500 Internal Server Error</p> <pre><code>{\n  \"detail\": \"Error message\"\n}\n</code></pre>"},{"location":"api/rest-api/#examples_3","title":"Examples","text":"<p>Search for \"transformer\"</p> <pre><code>curl \"http://localhost:8000/api/search?q=transformer\"\n</code></pre> <p>Search for \"neural network\" with limit</p> <pre><code>curl \"http://localhost:8000/api/search?q=neural%20network&amp;limit=20\"\n</code></pre> <p>Search by source</p> <pre><code>curl \"http://localhost:8000/api/search?q=arxiv\"\n</code></pre>"},{"location":"api/rest-api/#python-example_3","title":"Python Example","text":"<pre><code>import requests\n\nresponse = requests.get(\n    'http://localhost:8000/api/search',\n    params={\n        'q': 'machine learning',\n        'limit': 30\n    }\n)\n\ndata = response.json()\nprint(f\"Search: '{data['query']}' - Found {data['count']} results\")\n\nfor result in data['results']:\n    print(f\"  [{result['content_type']}] {result['title']}\")\n</code></pre>"},{"location":"api/rest-api/#search-behavior","title":"Search Behavior","text":"<ul> <li>Case-insensitive substring matching</li> <li>Searches both <code>title</code> and <code>source</code> fields</li> <li>Uses SQL <code>LIKE</code> operator with wildcards: <code>%query%</code></li> <li>Results ordered by <code>collection_date</code> DESC (newest first)</li> </ul>"},{"location":"api/rest-api/#6-visualization-page","title":"6. Visualization Page","text":"<p>Serve the HTML visualization page for browsing collected data.</p>"},{"location":"api/rest-api/#request_5","title":"Request","text":"<pre><code>GET /viz\n</code></pre>"},{"location":"api/rest-api/#parameters_2","title":"Parameters","text":"<p>None</p>"},{"location":"api/rest-api/#response_5","title":"Response","text":"<p>Status: 200 OK</p> <p>Content-Type: <code>text/html</code></p> <p>Returns the HTML content of the visualization page if available, or a fallback message if the file is not found.</p>"},{"location":"api/rest-api/#examples_4","title":"Examples","text":"<pre><code># Open in browser\nopen http://localhost:8000/viz\n\n# Or with curl\ncurl http://localhost:8000/viz\n</code></pre>"},{"location":"api/rest-api/#file-location","title":"File Location","text":"<p>Expected file: <code>multi_modal_rag/api/static/visualization.html</code></p>"},{"location":"api/rest-api/#7-health-check","title":"7. Health Check","text":"<p>Simple health check endpoint to verify API is running.</p>"},{"location":"api/rest-api/#request_6","title":"Request","text":"<pre><code>GET /health\n</code></pre>"},{"location":"api/rest-api/#parameters_3","title":"Parameters","text":"<p>None</p>"},{"location":"api/rest-api/#response_6","title":"Response","text":"<p>Status: 200 OK</p> <pre><code>{\n  \"status\": \"healthy\"\n}\n</code></pre>"},{"location":"api/rest-api/#examples_5","title":"Examples","text":"<pre><code>curl http://localhost:8000/health\n</code></pre>"},{"location":"api/rest-api/#use-cases","title":"Use Cases","text":"<ul> <li>Container orchestration health checks</li> <li>Load balancer status monitoring</li> <li>Automated testing</li> <li>CI/CD pipeline verification</li> </ul>"},{"location":"api/rest-api/#complete-curl-examples","title":"Complete cURL Examples","text":""},{"location":"api/rest-api/#basic-workflow","title":"Basic Workflow","text":"<pre><code># 1. Check API is running\ncurl http://localhost:8000/health\n\n# 2. Get API information\ncurl http://localhost:8000/\n\n# 3. Get statistics\ncurl http://localhost:8000/api/statistics\n\n# 4. Get all collections\ncurl http://localhost:8000/api/collections\n\n# 5. Get only papers\ncurl \"http://localhost:8000/api/collections?content_type=paper&amp;limit=10\"\n\n# 6. Search for specific topic\ncurl \"http://localhost:8000/api/search?q=attention%20mechanism\"\n\n# 7. Get details of specific collection\ncurl http://localhost:8000/api/collections/1\n</code></pre>"},{"location":"api/rest-api/#advanced-examples","title":"Advanced Examples","text":"<p>Pagination through all papers</p> <pre><code># Page 1\ncurl \"http://localhost:8000/api/collections?content_type=paper&amp;limit=100&amp;offset=0\"\n\n# Page 2\ncurl \"http://localhost:8000/api/collections?content_type=paper&amp;limit=100&amp;offset=100\"\n\n# Page 3\ncurl \"http://localhost:8000/api/collections?content_type=paper&amp;limit=100&amp;offset=200\"\n</code></pre> <p>With authentication (if implemented)</p> <pre><code>curl -H \"Authorization: Bearer YOUR_TOKEN\" \\\n     http://localhost:8000/api/collections\n</code></pre> <p>Save response to file</p> <pre><code>curl http://localhost:8000/api/statistics -o statistics.json\n</code></pre> <p>Pretty print JSON output (with jq)</p> <pre><code>curl http://localhost:8000/api/collections | jq .\n</code></pre>"},{"location":"api/rest-api/#python-client-example","title":"Python Client Example","text":"<p>Complete Python client for interacting with the API:</p> <pre><code>import requests\nfrom typing import Optional, List, Dict\n\nclass ResearchDataAPIClient:\n    def __init__(self, base_url: str = \"http://localhost:8000\"):\n        self.base_url = base_url.rstrip('/')\n\n    def health_check(self) -&gt; bool:\n        \"\"\"Check if API is healthy\"\"\"\n        try:\n            response = requests.get(f\"{self.base_url}/health\")\n            return response.status_code == 200\n        except:\n            return False\n\n    def get_collections(\n        self,\n        content_type: Optional[str] = None,\n        limit: int = 100,\n        offset: int = 0\n    ) -&gt; Dict:\n        \"\"\"Get collections with optional filtering\"\"\"\n        params = {'limit': limit, 'offset': offset}\n        if content_type:\n            params['content_type'] = content_type\n\n        response = requests.get(\n            f\"{self.base_url}/api/collections\",\n            params=params\n        )\n        response.raise_for_status()\n        return response.json()\n\n    def get_collection_details(self, collection_id: int) -&gt; Dict:\n        \"\"\"Get detailed information about a collection\"\"\"\n        response = requests.get(\n            f\"{self.base_url}/api/collections/{collection_id}\"\n        )\n        response.raise_for_status()\n        return response.json()\n\n    def get_statistics(self) -&gt; Dict:\n        \"\"\"Get database statistics\"\"\"\n        response = requests.get(f\"{self.base_url}/api/statistics\")\n        response.raise_for_status()\n        return response.json()\n\n    def search(self, query: str, limit: int = 50) -&gt; Dict:\n        \"\"\"Search collections by title or source\"\"\"\n        response = requests.get(\n            f\"{self.base_url}/api/search\",\n            params={'q': query, 'limit': limit}\n        )\n        response.raise_for_status()\n        return response.json()\n\n# Usage\nclient = ResearchDataAPIClient()\n\n# Check health\nif client.health_check():\n    print(\"API is healthy\")\n\n    # Get statistics\n    stats = client.get_statistics()\n    print(f\"Total papers: {stats['by_type'].get('paper', 0)}\")\n\n    # Search\n    results = client.search(\"transformers\", limit=10)\n    print(f\"Found {results['count']} results\")\n\n    # Get details\n    if results['count'] &gt; 0:\n        first_id = results['results'][0]['id']\n        details = client.get_collection_details(first_id)\n        print(f\"Title: {details['title']}\")\n</code></pre>"},{"location":"api/rest-api/#error-handling","title":"Error Handling","text":""},{"location":"api/rest-api/#http-status-codes","title":"HTTP Status Codes","text":"Code Meaning When It Occurs 200 OK Successful request 404 Not Found Collection ID doesn't exist 422 Unprocessable Entity Invalid query parameters 500 Internal Server Error Database or server error"},{"location":"api/rest-api/#error-response-format","title":"Error Response Format","text":"<p>All errors return JSON with a <code>detail</code> field:</p> <pre><code>{\n  \"detail\": \"Human-readable error message\"\n}\n</code></pre> <p>For validation errors (422), the detail is an array:</p> <pre><code>{\n  \"detail\": [\n    {\n      \"loc\": [\"query\", \"limit\"],\n      \"msg\": \"ensure this value is less than or equal to 1000\",\n      \"type\": \"value_error.number.not_le\"\n    }\n  ]\n}\n</code></pre>"},{"location":"api/rest-api/#rate-limiting","title":"Rate Limiting","text":"<p>Currently, the API has no rate limiting implemented. For production use, consider:</p> <ul> <li>Adding rate limiting middleware (e.g., <code>slowapi</code>)</li> <li>Implementing per-IP request limits</li> <li>Adding authentication and per-user quotas</li> </ul>"},{"location":"api/rest-api/#security-considerations","title":"Security Considerations","text":""},{"location":"api/rest-api/#current-state","title":"Current State","text":"<ul> <li>No authentication required</li> <li>CORS allows all origins</li> <li>No rate limiting</li> <li>Suitable for local/development use only</li> </ul>"},{"location":"api/rest-api/#production-recommendations","title":"Production Recommendations","text":"<ol> <li> <p>Add Authentication <pre><code>from fastapi.security import HTTPBearer\nsecurity = HTTPBearer()\n</code></pre></p> </li> <li> <p>Restrict CORS <pre><code>allow_origins=[\"https://yourdomain.com\"]\n</code></pre></p> </li> <li> <p>Add Rate Limiting <pre><code>from slowapi import Limiter\nlimiter = Limiter(key_func=get_remote_address)\n</code></pre></p> </li> <li> <p>Use HTTPS</p> </li> <li>Deploy behind reverse proxy (nginx, Caddy)</li> <li> <p>Use SSL certificates</p> </li> <li> <p>Input Validation</p> </li> <li>Already implemented via FastAPI/Pydantic</li> <li>Additional sanitization for search queries</li> </ol>"},{"location":"api/rest-api/#deployment","title":"Deployment","text":""},{"location":"api/rest-api/#development","title":"Development","text":"<pre><code>uvicorn multi_modal_rag.api.api_server:app --reload --host 127.0.0.1 --port 8000\n</code></pre>"},{"location":"api/rest-api/#production-with-gunicorn","title":"Production (with Gunicorn)","text":"<pre><code>gunicorn multi_modal_rag.api.api_server:app \\\n  --workers 4 \\\n  --worker-class uvicorn.workers.UvicornWorker \\\n  --bind 0.0.0.0:8000\n</code></pre>"},{"location":"api/rest-api/#docker","title":"Docker","text":"<pre><code>FROM python:3.9\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY . .\nCMD [\"uvicorn\", \"multi_modal_rag.api.api_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"api/rest-api/#environment-variables","title":"Environment Variables","text":"<pre><code># Database path\nexport DB_PATH=/path/to/collections.db\n\n# API host and port\nexport API_HOST=0.0.0.0\nexport API_PORT=8000\n</code></pre>"},{"location":"api/rest-api/#monitoring-and-logging","title":"Monitoring and Logging","text":"<p>The API uses the application's logging configuration from <code>multi_modal_rag.logging_config</code>.</p> <p>Log Locations: Check <code>logs/</code> directory or console output</p> <p>Log Levels: - INFO: Normal operations - ERROR: Database errors, exceptions</p> <p>Example Log Output: <pre><code>2025-10-02 10:30:00 - INFO - CollectionDatabaseManager initialized\n2025-10-02 10:30:05 - INFO - Starting FastAPI server...\n2025-10-02 10:30:15 - ERROR - Error fetching collections: database is locked\n</code></pre></p>"},{"location":"api/rest-api/#testing","title":"Testing","text":""},{"location":"api/rest-api/#manual-testing","title":"Manual Testing","text":"<p>Use the interactive Swagger UI: <code>http://localhost:8000/docs</code></p>"},{"location":"api/rest-api/#automated-testing","title":"Automated Testing","text":"<pre><code>import pytest\nfrom fastapi.testclient import TestClient\nfrom multi_modal_rag.api.api_server import app\n\nclient = TestClient(app)\n\ndef test_health_check():\n    response = client.get(\"/health\")\n    assert response.status_code == 200\n    assert response.json() == {\"status\": \"healthy\"}\n\ndef test_get_collections():\n    response = client.get(\"/api/collections\")\n    assert response.status_code == 200\n    assert \"count\" in response.json()\n    assert \"collections\" in response.json()\n\ndef test_search():\n    response = client.get(\"/api/search?q=test\")\n    assert response.status_code == 200\n    assert \"query\" in response.json()\n    assert response.json()[\"query\"] == \"test\"\n</code></pre> <p>Run tests: <pre><code>pytest tests/test_api.py\n</code></pre></p>"},{"location":"architecture/data-flow/","title":"Data Flow Architecture","text":""},{"location":"architecture/data-flow/#overview","title":"Overview","text":"<p>This document details how data flows through the Multi-Modal Academic Research System, from initial collection to final query response.</p>"},{"location":"architecture/data-flow/#complete-system-data-flow","title":"Complete System Data Flow","text":"<pre><code>External Sources (ArXiv, YouTube, Podcasts)\n             \u2502\n             \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Data Collectors\u2502  \u2190 User initiates via Gradio UI\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502 Raw metadata + files\n             \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n             \u25bc          \u25bc              \u25bc\n      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n      \u2502 File      \u2502 \u2502 Database \u2502 \u2502Processors\u2502\n      \u2502 Storage   \u2502 \u2502 (SQLite) \u2502 \u2502          \u2502\n      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n                                      \u2502 Structured documents\n                                      \u25bc\n                               \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                               \u2502  OpenSearch  \u2502\n                               \u2502   Indexing   \u2502\n                               \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                      \u2502\n                                      \u25bc\n                         Indexed + Searchable Content\n                                      \u2502\n                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                  \u25bc                                    \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502  Query/Search   \u2502                  \u2502Visualization \u2502\n         \u2502  (Orchestrator) \u2502                  \u2502     API      \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518                  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502\n                  \u25bc\n         Response with Citations\n</code></pre>"},{"location":"architecture/data-flow/#1-data-collection-flow","title":"1. Data Collection Flow","text":""},{"location":"architecture/data-flow/#step-by-step-process","title":"Step-by-Step Process","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    USER ACTION                               \u2502\n\u2502  User clicks \"Collect Data\" in Gradio UI                    \u2502\n\u2502  Selects: Source Type | Query | Max Results                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502               GRADIO UI (gradio_app.py)                      \u2502\n\u2502  handle_data_collection()                                    \u2502\n\u2502  - Validates input                                           \u2502\n\u2502  - Routes to appropriate collector                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          DATA COLLECTOR (paper_collector.py, etc)            \u2502\n\u2502                                                              \u2502\n\u2502  ArXiv Papers:                                               \u2502\n\u2502   1. arxiv.Search(query, max_results)                       \u2502\n\u2502   2. For each result:                                        \u2502\n\u2502      - Extract metadata (title, authors, abstract, etc)     \u2502\n\u2502      - Download PDF to data/papers/                         \u2502\n\u2502      - Return metadata dict                                  \u2502\n\u2502                                                              \u2502\n\u2502  YouTube Videos:                                             \u2502\n\u2502   1. yt_dlp.YoutubeDL.extract_info(search_query)           \u2502\n\u2502   2. For each video:                                        \u2502\n\u2502      - Extract metadata (title, channel, views, etc)        \u2502\n\u2502      - Fetch transcript via YouTubeTranscriptApi            \u2502\n\u2502      - Save metadata to data/videos/                        \u2502\n\u2502      - Return metadata dict                                  \u2502\n\u2502                                                              \u2502\n\u2502  Podcasts:                                                   \u2502\n\u2502   1. feedparser.parse(rss_url)                             \u2502\n\u2502   2. For each episode:                                      \u2502\n\u2502      - Extract metadata (title, description, audio_url)     \u2502\n\u2502      - Optionally transcribe with Whisper                   \u2502\n\u2502      - Save metadata to data/podcasts/                      \u2502\n\u2502      - Return metadata dict                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          DATABASE TRACKING (db_manager.py)                   \u2502\n\u2502                                                              \u2502\n\u2502  For each collected item:                                    \u2502\n\u2502   1. db_manager.add_collection()                            \u2502\n\u2502      - INSERT INTO collections (type, title, source, url...)\u2502\n\u2502      - Returns collection_id                                 \u2502\n\u2502                                                              \u2502\n\u2502   2. db_manager.add_paper/video/podcast(collection_id, data)\u2502\n\u2502      - INSERT INTO papers/videos/podcasts (type-specific)   \u2502\n\u2502                                                              \u2502\n\u2502   3. db_manager.log_collection_stats()                      \u2502\n\u2502      - INSERT INTO collection_stats (query, count, source)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          DATA PROCESSING (pdf_processor.py, etc)             \u2502\n\u2502                                                              \u2502\n\u2502  Paper Processing:                                           \u2502\n\u2502   1. PDFProcessor.extract_text(pdf_path)                   \u2502\n\u2502      - Use PyMuPDF to extract full text                    \u2502\n\u2502   2. PDFProcessor.extract_diagrams(pdf_path)               \u2502\n\u2502      - Extract images from PDF                             \u2502\n\u2502      - Send to Gemini Vision for description               \u2502\n\u2502   3. Return structured document                             \u2502\n\u2502                                                              \u2502\n\u2502  Video Processing:                                           \u2502\n\u2502   1. VideoProcessor.analyze_transcript(transcript)         \u2502\n\u2502      - Send to Gemini for analysis                         \u2502\n\u2502      - Extract key concepts                                 \u2502\n\u2502   2. Return structured document                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          OPENSEARCH INDEXING (opensearch_manager.py)         \u2502\n\u2502                                                              \u2502\n\u2502  For each document:                                          \u2502\n\u2502   1. Format document for indexing:                          \u2502\n\u2502      {                                                       \u2502\n\u2502        content_type: 'paper'/'video'/'podcast',            \u2502\n\u2502        title, abstract, content, authors,                   \u2502\n\u2502        publication_date, url, metadata                      \u2502\n\u2502      }                                                       \u2502\n\u2502                                                              \u2502\n\u2502   2. Generate embedding:                                     \u2502\n\u2502      text = title + abstract + content[:1000]              \u2502\n\u2502      embedding = SentenceTransformer.encode(text)          \u2502\n\u2502      \u2192 384-dimensional vector                               \u2502\n\u2502                                                              \u2502\n\u2502   3. Bulk index to OpenSearch:                              \u2502\n\u2502      - Index with kNN vector + text fields                  \u2502\n\u2502      - Indexed count returned                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          MARK AS INDEXED (db_manager.py)                     \u2502\n\u2502                                                              \u2502\n\u2502  For each collection_id:                                     \u2502\n\u2502   - UPDATE collections SET indexed = 1 WHERE id = ?         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n           \u2705 Collection Complete!\n           Data is now searchable\n</code></pre>"},{"location":"architecture/data-flow/#collection-flow-diagram","title":"Collection Flow Diagram","text":"<pre><code>User Input\n    \u2502\n    \u251c\u2500\u2192 Query: \"machine learning\"\n    \u251c\u2500\u2192 Source: ArXiv Papers\n    \u2514\u2500\u2192 Max: 20 results\n         \u2502\n         \u25bc\nArXiv API Call \u2500\u2192 20 Papers Retrieved\n         \u2502\n         \u251c\u2500\u2192 Paper 1 \u2192 [PDF Download] \u2192 data/papers/2304.05133v2.pdf\n         \u2502                \u2502\n         \u2502                \u2514\u2500\u2192 [DB Insert] \u2192 collections.id=1, papers.id=1\n         \u2502                         \u2502\n         \u2502                         \u2514\u2500\u2192 [Process] \u2192 Extract text + diagrams\n         \u2502                                  \u2502\n         \u2502                                  \u2514\u2500\u2192 [Index] \u2192 OpenSearch doc_1\n         \u2502                                           \u2502\n         \u2502                                           \u2514\u2500\u2192 [Mark] \u2192 indexed=True\n         \u2502\n         \u251c\u2500\u2192 Paper 2 \u2192 ... (repeat process)\n         \u2502\n         \u2514\u2500\u2192 Paper 20 \u2192 ... (repeat process)\n              \u2502\n              \u25bc\n         Statistics Updated\n         Database: 20 new papers\n         OpenSearch: 20 new documents\n</code></pre>"},{"location":"architecture/data-flow/#2-querysearch-flow","title":"2. Query/Search Flow","text":""},{"location":"architecture/data-flow/#step-by-step-process_1","title":"Step-by-Step Process","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    USER ACTION                               \u2502\n\u2502  User enters query: \"What is RAG?\"                          \u2502\n\u2502  Clicks \"Search\" in Gradio UI                               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          RESEARCH ORCHESTRATOR (research_orchestrator.py)    \u2502\n\u2502                                                              \u2502\n\u2502  process_query(query, index_name):                          \u2502\n\u2502   1. Clean and normalize query                              \u2502\n\u2502   2. Call OpenSearchManager.hybrid_search(query, k=10)     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          OPENSEARCH HYBRID SEARCH (opensearch_manager.py)    \u2502\n\u2502                                                              \u2502\n\u2502  hybrid_search(query, k=10):                                \u2502\n\u2502   1. Text Search (BM25):                                    \u2502\n\u2502      - Multi-match query on:                                \u2502\n\u2502        * title^3 (3x weight)                                \u2502\n\u2502        * abstract^2 (2x weight)                             \u2502\n\u2502        * content (1x weight)                                \u2502\n\u2502        * transcript (1x weight)                             \u2502\n\u2502        * key_concepts^2 (2x weight)                         \u2502\n\u2502      - Fuzzy matching enabled                               \u2502\n\u2502                                                              \u2502\n\u2502   2. Execute search on OpenSearch index                     \u2502\n\u2502                                                              \u2502\n\u2502   3. Return top-k results with scores:                      \u2502\n\u2502      [{score: 8.5, source: {...}}, ...]                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          CONTEXT FORMATION (research_orchestrator.py)        \u2502\n\u2502                                                              \u2502\n\u2502  Format retrieved documents as context:                      \u2502\n\u2502                                                              \u2502\n\u2502  \"You are a research assistant. Use these sources:          \u2502\n\u2502                                                              \u2502\n\u2502   Source 1 [paper]:                                         \u2502\n\u2502   Title: Attention Is All You Need                          \u2502\n\u2502   Content: Transformers are neural network...               \u2502\n\u2502                                                              \u2502\n\u2502   Source 2 [video]:                                         \u2502\n\u2502   Title: Understanding Transformers                          \u2502\n\u2502   Transcript: In this lecture we discuss...                 \u2502\n\u2502                                                              \u2502\n\u2502   ...                                                        \u2502\n\u2502                                                              \u2502\n\u2502   Answer the question: {query}                              \u2502\n\u2502   Provide citations using [Source N] format.\"               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          GEMINI LLM PROCESSING (via LangChain)               \u2502\n\u2502                                                              \u2502\n\u2502  Input: Context + Query                                      \u2502\n\u2502  Model: Gemini Pro                                           \u2502\n\u2502                                                              \u2502\n\u2502  LLM generates response:                                     \u2502\n\u2502   \"RAG (Retrieval-Augmented Generation) is a technique     \u2502\n\u2502    that combines information retrieval with text generation \u2502\n\u2502    [Source 1]. It works by first retrieving relevant        \u2502\n\u2502    documents from a knowledge base, then using those        \u2502\n\u2502    documents as context for an LLM to generate accurate     \u2502\n\u2502    responses [Source 3]...\"                                 \u2502\n\u2502                                                              \u2502\n\u2502  Output: Generated text with citation markers               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          CITATION EXTRACTION (citation_tracker.py)           \u2502\n\u2502                                                              \u2502\n\u2502  extract_citations(response_text):                          \u2502\n\u2502   1. Regex pattern: \\[Source (\\d+)\\]                       \u2502\n\u2502   2. Find all matches \u2192 [1, 1, 3]                          \u2502\n\u2502   3. Map to actual source documents                         \u2502\n\u2502   4. Create citation objects:                               \u2502\n\u2502      [{                                                      \u2502\n\u2502        text: \"Source 1\",                                    \u2502\n\u2502        title: \"Attention Is All You Need\",                 \u2502\n\u2502        authors: [\"Vaswani, A.\", ...],                      \u2502\n\u2502        url: \"https://arxiv.org/abs/...\"                    \u2502\n\u2502      }, ...]                                                \u2502\n\u2502                                                              \u2502\n\u2502  track_citations(citations):                                \u2502\n\u2502   - Increment citation count for each source                \u2502\n\u2502   - Store in citation database                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          RESPONSE FORMATTING (gradio_app.py)                 \u2502\n\u2502                                                              \u2502\n\u2502  Format for display:                                         \u2502\n\u2502                                                              \u2502\n\u2502  ## Answer                                                   \u2502\n\u2502  RAG (Retrieval-Augmented Generation) is a technique...    \u2502\n\u2502                                                              \u2502\n\u2502  ---                                                         \u2502\n\u2502  **Sources Used:** 3                                         \u2502\n\u2502                                                              \u2502\n\u2502  Citations (JSON):                                           \u2502\n\u2502  [                                                           \u2502\n\u2502    {title: \"...\", authors: [...], url: \"...\"},            \u2502\n\u2502    ...                                                       \u2502\n\u2502  ]                                                           \u2502\n\u2502                                                              \u2502\n\u2502  Related Queries:                                            \u2502\n\u2502  1. What are transformers in deep learning?                 \u2502\n\u2502  2. How does attention mechanism work?                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n           Display to User in Gradio UI\n</code></pre>"},{"location":"architecture/data-flow/#query-flow-diagram","title":"Query Flow Diagram","text":"<pre><code>\"What is RAG?\"\n      \u2502\n      \u25bc\nHybrid Search \u2500\u2500\u2192 OpenSearch Query\n      \u2502              \u2502\n      \u2502              \u251c\u2500\u2192 BM25 Text Match: title^3, abstract^2, content\n      \u2502              \u2502\n      \u2502              \u2514\u2500\u2192 Results: Top 10 documents by relevance score\n      \u2502\n      \u25bc\nContext Assembly\n      \u2502\n      \u251c\u2500\u2192 Source 1: [paper] \"RAG Paper\" (score: 9.2)\n      \u251c\u2500\u2192 Source 2: [video] \"RAG Explained\" (score: 8.5)\n      \u2514\u2500\u2192 Source 3: [paper] \"LLM Survey\" (score: 7.8)\n      \u2502\n      \u25bc\nLLM Processing (Gemini)\n      \u2502\n      \u251c\u2500\u2192 Prompt: Context + Sources + Query\n      \u2502\n      \u2514\u2500\u2192 Response: \"RAG is... [Source 1] ... [Source 3]\"\n           \u2502\n           \u25bc\nCitation Extraction\n      \u2502\n      \u2514\u2500\u2192 Extracted: [Source 1, Source 3]\n           \u2502\n           \u25bc\nResponse Display\n</code></pre>"},{"location":"architecture/data-flow/#3-visualization-flow","title":"3. Visualization Flow","text":""},{"location":"architecture/data-flow/#dashboard-data-flow","title":"Dashboard Data Flow","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    USER ACTION                               \u2502\n\u2502  User opens http://localhost:8000/viz                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          FASTAPI SERVER (api_server.py)                      \u2502\n\u2502                                                              \u2502\n\u2502  GET /viz:                                                   \u2502\n\u2502   - Serve static HTML file                                   \u2502\n\u2502   - visualization.html loaded in browser                     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          BROWSER JAVASCRIPT (visualization.html)             \u2502\n\u2502                                                              \u2502\n\u2502  On page load:                                               \u2502\n\u2502   1. fetch('http://localhost:8000/api/statistics')         \u2502\n\u2502   2. fetch('http://localhost:8000/api/collections?limit=50')\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          API ENDPOINTS (api_server.py)                       \u2502\n\u2502                                                              \u2502\n\u2502  GET /api/statistics:                                        \u2502\n\u2502   1. db_manager.get_statistics()                            \u2502\n\u2502   2. Query aggregations:                                     \u2502\n\u2502      - SELECT content_type, COUNT(*) ... GROUP BY ...       \u2502\n\u2502      - SELECT indexed, COUNT(*) ... GROUP BY ...            \u2502\n\u2502      - SELECT ... WHERE date &gt; NOW() - 7 days               \u2502\n\u2502   3. Return JSON:                                            \u2502\n\u2502      {                                                       \u2502\n\u2502        by_type: {paper: 120, video: 45, podcast: 30},      \u2502\n\u2502        indexed: 150,                                         \u2502\n\u2502        not_indexed: 45,                                      \u2502\n\u2502        recent_7_days: 25                                     \u2502\n\u2502      }                                                       \u2502\n\u2502                                                              \u2502\n\u2502  GET /api/collections:                                       \u2502\n\u2502   1. db_manager.get_all_collections(limit, offset)         \u2502\n\u2502   2. Query:                                                  \u2502\n\u2502      SELECT * FROM collections                              \u2502\n\u2502      ORDER BY collection_date DESC                          \u2502\n\u2502      LIMIT ? OFFSET ?                                        \u2502\n\u2502   3. Return JSON array:                                      \u2502\n\u2502      {                                                       \u2502\n\u2502        count: 50,                                            \u2502\n\u2502        collections: [{id, type, title, ...}, ...]          \u2502\n\u2502      }                                                       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          JAVASCRIPT RENDERING (visualization.html)           \u2502\n\u2502                                                              \u2502\n\u2502  Update Statistics Cards:                                    \u2502\n\u2502   document.getElementById('total-count').textContent = 195  \u2502\n\u2502   document.getElementById('paper-count').textContent = 120  \u2502\n\u2502   ...                                                        \u2502\n\u2502                                                              \u2502\n\u2502  Populate Data Table:                                        \u2502\n\u2502   &lt;table&gt;                                                    \u2502\n\u2502     &lt;tr&gt;                                                     \u2502\n\u2502       &lt;td&gt;1&lt;/td&gt;                                            \u2502\n\u2502       &lt;td&gt;&lt;badge&gt;paper&lt;/badge&gt;&lt;/td&gt;                         \u2502\n\u2502       &lt;td&gt;Attention Is All You Need&lt;/td&gt;                    \u2502\n\u2502       &lt;td&gt;arxiv&lt;/td&gt;                                        \u2502\n\u2502       &lt;td&gt;&lt;badge green&gt;Indexed&lt;/badge&gt;&lt;/td&gt;                 \u2502\n\u2502       &lt;td&gt;2025-10-02&lt;/td&gt;                                   \u2502\n\u2502       &lt;td&gt;&lt;a href=\"...\"&gt;View&lt;/a&gt;&lt;/td&gt;                       \u2502\n\u2502     &lt;/tr&gt;                                                    \u2502\n\u2502     ...                                                      \u2502\n\u2502   &lt;/table&gt;                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/data-flow/#4-file-system-data-flow","title":"4. File System Data Flow","text":""},{"location":"architecture/data-flow/#directory-structure-and-data-storage","title":"Directory Structure and Data Storage","text":"<pre><code>project_root/\n\u2502\n\u251c\u2500\u2500 data/\n\u2502   \u251c\u2500\u2500 papers/               \u2190 PDF files downloaded\n\u2502   \u2502   \u251c\u2500\u2500 2304.05133v2.pdf\n\u2502   \u2502   \u2514\u2500\u2500 ...\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 videos/               \u2190 Video metadata JSON\n\u2502   \u2502   \u2514\u2500\u2500 (future: video files)\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 podcasts/             \u2190 Podcast audio + transcripts\n\u2502   \u2502   \u2514\u2500\u2500 (future: audio files)\n\u2502   \u2502\n\u2502   \u251c\u2500\u2500 processed/            \u2190 Processed documents\n\u2502   \u2502   \u2514\u2500\u2500 (extracted text, structured data)\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 collections.db        \u2190 SQLite tracking database\n\u2502\n\u2514\u2500\u2500 logs/                     \u2190 Application logs\n    \u2514\u2500\u2500 research_system_YYYYMMDD_HHMMSS.log\n</code></pre>"},{"location":"architecture/data-flow/#file-operations-flow","title":"File Operations Flow","text":"<ol> <li> <p>Paper Collection:    <pre><code>ArXiv API \u2192 Download PDF \u2192 data/papers/[arxiv_id].pdf\n                          \u2193\n                Record path in database\n</code></pre></p> </li> <li> <p>Processing:    <pre><code>data/papers/[id].pdf \u2192 PDFProcessor \u2192 Extracted text\n                                     \u2193\n                           data/processed/[id].json\n</code></pre></p> </li> <li> <p>Database Recording:    <pre><code>All metadata \u2192 SQLite \u2192 data/collections.db\n                       \u2193\n              Permanent record with references to files\n</code></pre></p> </li> </ol>"},{"location":"architecture/data-flow/#inter-module-communication","title":"Inter-Module Communication","text":""},{"location":"architecture/data-flow/#module-dependencies","title":"Module Dependencies","text":"<pre><code>UI Layer (Gradio)\n    \u2193 calls\nOrchestrator\n    \u2193 calls\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            \u2502             \u2502              \u2502\n\u25bc            \u25bc             \u25bc              \u25bc\nOpenSearch   Database   Collectors   Processors\n\u2502            \u2502             \u2502              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             All modules use\n          Logging System (logging_config.py)\n</code></pre>"},{"location":"architecture/data-flow/#function-call-flow","title":"Function Call Flow","text":"<pre><code>main.py\n  \u2502\n  \u251c\u2500\u2192 Initializes all components\n  \u2502   \u251c\u2500\u2192 DataCollectors (paper, video, podcast)\n  \u2502   \u251c\u2500\u2192 DataProcessors (pdf, video)\n  \u2502   \u251c\u2500\u2192 OpenSearchManager\n  \u2502   \u251c\u2500\u2192 DatabaseManager\n  \u2502   \u251c\u2500\u2192 ResearchOrchestrator\n  \u2502   \u251c\u2500\u2192 CitationTracker\n  \u2502   \u2514\u2500\u2192 ResearchAssistantUI\n  \u2502\n  \u2514\u2500\u2192 Launches Gradio UI\n       \u2502\n       \u2514\u2500\u2192 User interactions trigger:\n            \u251c\u2500\u2192 handle_data_collection() \u2192 Collectors \u2192 DB \u2192 Indexing\n            \u251c\u2500\u2192 handle_search() \u2192 Orchestrator \u2192 OpenSearch \u2192 LLM\n            \u251c\u2500\u2192 get_database_statistics() \u2192 DatabaseManager\n            \u2514\u2500\u2192 export_citations() \u2192 CitationTracker\n</code></pre>"},{"location":"architecture/data-flow/#data-transformation-pipeline","title":"Data Transformation Pipeline","text":""},{"location":"architecture/data-flow/#raw-data-indexed-document","title":"Raw Data \u2192 Indexed Document","text":"<pre><code>1. Raw Source Data\n   {arxiv_id, title, authors[], abstract, pdf_url, published, categories[]}\n\n2. Downloaded File\n   data/papers/2304.05133v2.pdf\n\n3. Processed Document\n   {\n     extracted_text: \"Full paper text...\",\n     diagrams: [{description: \"Architecture diagram showing...\"}],\n     key_concepts: [\"transformers\", \"attention\", \"NLP\"]\n   }\n\n4. Indexed Document\n   {\n     content_type: \"paper\",\n     title: \"...\",\n     abstract: \"...\",\n     content: \"...\",\n     authors: [...],\n     publication_date: \"2023-04-12\",\n     url: \"https://arxiv.org/abs/2304.05133\",\n     embedding: [0.123, -0.456, ...],  // 384 dimensions\n     metadata: {arxiv_id: \"2304.05133\", categories: [...]}\n   }\n\n5. Database Record\n   collections: {id: 1, content_type: \"paper\", title: \"...\", indexed: true}\n   papers: {id: 1, collection_id: 1, arxiv_id: \"2304.05133\", ...}\n</code></pre>"},{"location":"architecture/data-flow/#error-handling-flow","title":"Error Handling Flow","text":"<pre><code>Operation Attempt\n      \u2502\n      \u251c\u2500\u2192 Try: Execute operation\n      \u2502        \u2502\n      \u2502        \u251c\u2500\u2192 Success \u2192 Log info \u2192 Continue\n      \u2502        \u2502\n      \u2502        \u2514\u2500\u2192 Exception \u2192 Catch\n      \u2502                       \u2502\n      \u2502                       \u251c\u2500\u2192 Log error (with stack trace)\n      \u2502                       \u2502\n      \u2502                       \u251c\u2500\u2192 Update UI with error message\n      \u2502                       \u2502\n      \u2502                       \u251c\u2500\u2192 Graceful degradation\n      \u2502                       \u2502   (e.g., continue with partial results)\n      \u2502                       \u2502\n      \u2502                       \u2514\u2500\u2192 Return error response\n      \u2502\n      \u2514\u2500\u2192 Finally: Cleanup resources\n</code></pre>"},{"location":"architecture/data-flow/#related-documentation","title":"Related Documentation","text":"<ul> <li>System Architecture Overview</li> <li>Module Dependencies</li> <li>Database Schema</li> </ul>"},{"location":"architecture/overview/","title":"System Architecture Overview","text":""},{"location":"architecture/overview/#introduction","title":"Introduction","text":"<p>The Multi-Modal Academic Research System is designed as a modular, scalable platform for collecting, processing, indexing, and querying academic content from multiple sources. The system leverages RAG (Retrieval-Augmented Generation) to provide intelligent responses with citations.</p>"},{"location":"architecture/overview/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                         User Interfaces                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502   Gradio Web UI     \u2502         \u2502  FastAPI Visualization   \u2502  \u2502\n\u2502  \u2502  (Port 7860)        \u2502         \u2502  Dashboard (Port 8000)   \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502                              \u2502\n              \u25bc                              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      Orchestration Layer                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502  Research Orchestrator   \u2502   \u2502   Citation Tracker       \u2502   \u2502\n\u2502  \u2502  (LangChain + Gemini)    \u2502   \u2502   (Bibliography Export)  \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u25bc                       \u25bc                 \u25bc              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 OpenSearch\u2502          \u2502 Database \u2502      \u2502Collectors\u2502   \u2502Processors\u2502\n\u2502  Index   \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502 SQLite   \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2502  Layer   \u2502\u25c4\u2500\u2500\u2502  Layer   \u2502\n\u2502  (Vector \u2502          \u2502 (Tracking)\u2502      \u2502          \u2502   \u2502          \u2502\n\u2502  Search) \u2502          \u2502          \u2502      \u2502          \u2502   \u2502          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                             \u2502\n                          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                          \u25bc                  \u25bc                  \u25bc\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502  ArXiv   \u2502      \u2502 YouTube  \u2502      \u2502 Podcasts \u2502\n                    \u2502   API    \u2502      \u2502   API    \u2502      \u2502   RSS    \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/overview/#core-components","title":"Core Components","text":""},{"location":"architecture/overview/#1-data-collection-layer-multi_modal_ragdata_collectors","title":"1. Data Collection Layer (<code>multi_modal_rag/data_collectors/</code>)","text":"<p>Purpose: Fetch raw academic content from external sources</p> <p>Components: - <code>AcademicPaperCollector</code>: Collects papers from ArXiv, PubMed Central, Semantic Scholar - <code>YouTubeLectureCollector</code>: Collects educational videos with transcripts using yt-dlp - <code>PodcastCollector</code>: Collects podcast episodes via RSS feeds</p> <p>Key Features: - Rate limiting to respect API quotas - Automatic retry logic - Metadata extraction - Local file storage</p> <p>Dependencies: - External APIs (ArXiv, YouTube, RSS) - File system for storage - Database for tracking</p>"},{"location":"architecture/overview/#2-data-processing-layer-multi_modal_ragdata_processors","title":"2. Data Processing Layer (<code>multi_modal_rag/data_processors/</code>)","text":"<p>Purpose: Transform raw content into indexed, searchable format</p> <p>Components: - <code>PDFProcessor</code>: Extracts text and images from PDFs   - Uses PyMuPDF for text extraction   - Gemini Vision API for diagram analysis - <code>VideoProcessor</code>: Analyzes video content   - Uses Gemini for content analysis   - Processes transcripts</p> <p>Key Features: - Multi-modal content extraction (text + visual) - AI-powered diagram description - Structured data output</p> <p>Dependencies: - Google Gemini API - PyMuPDF, PyPDF libraries - Sentence transformers</p>"},{"location":"architecture/overview/#3-indexing-layer-multi_modal_ragindexing","title":"3. Indexing Layer (<code>multi_modal_rag/indexing/</code>)","text":"<p>Purpose: Store and retrieve content efficiently</p> <p>Component: <code>OpenSearchManager</code></p> <p>Key Features: - Hybrid Search: Combines keyword (BM25) + semantic (kNN vector) search - Embedding Generation: Uses SentenceTransformer (all-MiniLM-L6-v2, 384 dimensions) - Schema Management: Creates and manages indices - Bulk Operations: Efficient batch indexing</p> <p>Search Strategy: 1. Convert query to embedding vector 2. Perform multi-match text search with field boosting 3. Combine scores for ranking 4. Return top-k results</p> <p>Dependencies: - OpenSearch (Docker or local instance) - sentence-transformers library</p>"},{"location":"architecture/overview/#4-database-layer-multi_modal_ragdatabase","title":"4. Database Layer (<code>multi_modal_rag/database/</code>)","text":"<p>Purpose: Track all collected data with metadata</p> <p>Component: <code>CollectionDatabaseManager</code></p> <p>Schema: - <code>collections</code>: Main table (id, type, title, source, url, status, indexed) - <code>papers</code>: Paper-specific details (arxiv_id, abstract, authors, categories) - <code>videos</code>: Video-specific details (video_id, channel, views, duration) - <code>podcasts</code>: Podcast-specific details (episode_id, audio_url) - <code>collection_stats</code>: Collection operation statistics</p> <p>Key Features: - Automatic tracking on collection - Indexing status management - Query history and statistics - Metadata preservation</p> <p>Dependencies: - SQLite3 (built-in Python)</p>"},{"location":"architecture/overview/#5-orchestration-layer-multi_modal_ragorchestration","title":"5. Orchestration Layer (<code>multi_modal_rag/orchestration/</code>)","text":"<p>Purpose: Coordinate research queries and generate responses</p> <p>Components:</p> <p>a) <code>ResearchOrchestrator</code>: - Processes user queries - Retrieves relevant documents from OpenSearch - Uses LangChain + Gemini to generate responses - Maintains conversation memory - Provides source citations</p> <p>Query Flow: <pre><code>User Query \u2192 Hybrid Search \u2192 Document Retrieval \u2192 Context Formation\n    \u2193\nGemini LLM Processing \u2192 Response Generation \u2192 Citation Extraction\n    \u2193\nFormatted Response + Sources\n</code></pre></p> <p>b) <code>CitationTracker</code>: - Extracts citations from LLM responses - Matches citations to source documents - Tracks citation usage statistics - Exports bibliographies (BibTeX, APA, JSON)</p> <p>Dependencies: - LangChain framework - Google Gemini API - OpenSearchManager</p>"},{"location":"architecture/overview/#6-api-layer-multi_modal_ragapi","title":"6. API Layer (<code>multi_modal_rag/api/</code>)","text":"<p>Purpose: Provide REST API and visualization interface</p> <p>Component: <code>FastAPI Server</code></p> <p>Endpoints: - <code>GET /api/collections</code>: List all collections - <code>GET /api/collections/{id}</code>: Get collection details - <code>GET /api/statistics</code>: Database statistics - <code>GET /api/search</code>: Search collections - <code>GET /viz</code>: Interactive visualization dashboard - <code>GET /docs</code>: Auto-generated API docs</p> <p>Key Features: - CORS-enabled for web access - Pagination support - Real-time statistics - Interactive HTML dashboard</p> <p>Dependencies: - FastAPI framework - Uvicorn ASGI server - Database layer</p>"},{"location":"architecture/overview/#7-user-interface-layer-multi_modal_ragui","title":"7. User Interface Layer (<code>multi_modal_rag/ui/</code>)","text":"<p>Purpose: Provide user-friendly web interface</p> <p>Component: <code>ResearchAssistantUI</code> (Gradio)</p> <p>Tabs: 1. Research: Query system, view answers with citations 2. Data Collection: Collect papers/videos/podcasts 3. Citation Manager: View and export citations 4. Settings: Configure OpenSearch, API keys 5. Data Visualization: View collection statistics</p> <p>Key Features: - Real-time collection status - Citation formatting - Statistics dashboard - Index management</p> <p>Dependencies: - Gradio framework - All backend modules</p>"},{"location":"architecture/overview/#data-flow","title":"Data Flow","text":""},{"location":"architecture/overview/#collection-flow","title":"Collection Flow","text":"<pre><code>1. User initiates collection (via Gradio UI)\n   \u2193\n2. Collector fetches data from external API\n   \u2193\n3. Raw data saved to local storage (data/papers, data/videos, data/podcasts)\n   \u2193\n4. Metadata recorded in SQLite database\n   \u2193\n5. Processor extracts and structures content\n   \u2193\n6. Document indexed in OpenSearch with embeddings\n   \u2193\n7. Collection marked as \"indexed\" in database\n</code></pre>"},{"location":"architecture/overview/#query-flow","title":"Query Flow","text":"<pre><code>1. User submits research query (via Gradio UI)\n   \u2193\n2. ResearchOrchestrator receives query\n   \u2193\n3. Hybrid search performed on OpenSearch\n   \u2193\n4. Top-k relevant documents retrieved\n   \u2193\n5. Documents formatted as context for LLM\n   \u2193\n6. Gemini generates response with citations\n   \u2193\n7. Citations extracted and tracked\n   \u2193\n8. Response displayed to user with sources\n</code></pre>"},{"location":"architecture/overview/#visualization-flow","title":"Visualization Flow","text":"<pre><code>1. User accesses visualization dashboard\n   \u2193\n2. FastAPI endpoint queries SQLite database\n   \u2193\n3. Statistics aggregated and formatted\n   \u2193\n4. JSON response sent to frontend\n   \u2193\n5. JavaScript renders interactive charts/tables\n</code></pre>"},{"location":"architecture/overview/#design-principles","title":"Design Principles","text":""},{"location":"architecture/overview/#1-modularity","title":"1. Modularity","text":"<p>Each component has a single, well-defined responsibility and can operate independently.</p>"},{"location":"architecture/overview/#2-separation-of-concerns","title":"2. Separation of Concerns","text":"<ul> <li>Collection \u2260 Processing \u2260 Indexing</li> <li>Each layer has distinct interfaces</li> </ul>"},{"location":"architecture/overview/#3-scalability","title":"3. Scalability","text":"<ul> <li>Bulk operations for efficiency</li> <li>Stateless API design</li> <li>Database-backed persistence</li> </ul>"},{"location":"architecture/overview/#4-extensibility","title":"4. Extensibility","text":"<ul> <li>Plugin architecture for new collectors</li> <li>Configurable search strategies</li> <li>Customizable UI tabs</li> </ul>"},{"location":"architecture/overview/#5-resilience","title":"5. Resilience","text":"<ul> <li>Graceful degradation (e.g., works without OpenSearch)</li> <li>Comprehensive error handling</li> <li>Detailed logging</li> </ul>"},{"location":"architecture/overview/#6-freeopen-technologies","title":"6. Free/Open Technologies","text":"<ul> <li>Local OpenSearch (Docker)</li> <li>SQLite (built-in)</li> <li>Free APIs (ArXiv, YouTube)</li> <li>Open-source libraries</li> </ul>"},{"location":"architecture/overview/#technology-choices","title":"Technology Choices","text":"Component Technology Rationale Search Engine OpenSearch Open-source, supports vector search, BM25 Vector Embeddings SentenceTransformers Fast, local, no API costs LLM Google Gemini Free tier, multimodal, good quality Database SQLite Zero-config, serverless, embedded API Framework FastAPI Fast, auto-docs, type hints UI Framework Gradio Rapid prototyping, Python-native PDF Processing PyMuPDF Fast, accurate text extraction Video Metadata yt-dlp Robust, actively maintained"},{"location":"architecture/overview/#security-considerations","title":"Security Considerations","text":"<ol> <li>API Keys: Stored in <code>.env</code> file, never committed to git</li> <li>OpenSearch: Local-only deployment by default</li> <li>CORS: Configured for localhost only in production</li> <li>Input Validation: All API endpoints validate inputs</li> <li>SQL Injection: Prevented via parameterized queries</li> </ol>"},{"location":"architecture/overview/#performance-characteristics","title":"Performance Characteristics","text":"<ul> <li>Indexing Speed: ~10-50 documents/second (bulk)</li> <li>Query Latency: ~1-3 seconds (including LLM)</li> <li>Embedding Generation: ~50ms per document</li> <li>Database Queries: &lt;10ms for most operations</li> <li>Storage: ~1MB per paper (PDF + metadata + embeddings)</li> </ul>"},{"location":"architecture/overview/#future-enhancements","title":"Future Enhancements","text":"<ol> <li>Distributed Search: Multi-node OpenSearch cluster</li> <li>Caching Layer: Redis for frequently accessed data</li> <li>Background Workers: Celery for async processing</li> <li>Advanced Analytics: Time-series analysis of collection trends</li> <li>Collaborative Features: Shared collections, annotations</li> <li>Mobile Interface: Responsive UI for mobile devices</li> </ol>"},{"location":"architecture/overview/#related-documentation","title":"Related Documentation","text":"<ul> <li>Data Flow Diagram</li> <li>Module Dependencies</li> <li>Technology Stack Details</li> </ul>"},{"location":"architecture/technology-stack/","title":"Technology Stack","text":"<p>Comprehensive documentation of all technologies, libraries, and frameworks used in the Multi-Modal Academic Research System.</p>"},{"location":"architecture/technology-stack/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Overview</li> <li>Core Technologies</li> <li>AI and Machine Learning</li> <li>Search and Vector Database</li> <li>Data Collection and Processing</li> <li>Web Framework and UI</li> <li>Supporting Libraries</li> <li>Development Tools</li> <li>Version Compatibility</li> <li>Architecture Decisions</li> <li>Alternative Technologies Considered</li> </ul>"},{"location":"architecture/technology-stack/#overview","title":"Overview","text":"<p>The Multi-Modal Academic Research System is built on a modern Python stack, leveraging state-of-the-art AI models, vector search capabilities, and a user-friendly web interface. The technology choices prioritize:</p> <ul> <li>Free and Open Source: Minimize costs, maximize accessibility</li> <li>Local-First: Data and processing remain on your machine</li> <li>Modern AI: Latest language models and embedding techniques</li> <li>Scalability: Capable of handling thousands of documents</li> <li>Ease of Use: Simple installation and intuitive interface</li> </ul>"},{"location":"architecture/technology-stack/#core-technologies","title":"Core Technologies","text":""},{"location":"architecture/technology-stack/#python-39","title":"Python 3.9+","text":"<p>Version: 3.9+ (3.11 recommended)</p> <p>Why Python: - Rich ecosystem for AI/ML and data processing - Extensive libraries for academic data collection - Strong community support - Easy integration with modern AI APIs - Excellent for rapid prototyping and development</p> <p>Why Python 3.9+: - Type hints support (PEP 585, 604) - Dictionary merge operators - String methods improvements - Required for modern dependency versions</p> <p>Official: https://www.python.org/</p>"},{"location":"architecture/technology-stack/#ai-and-machine-learning","title":"AI and Machine Learning","text":""},{"location":"architecture/technology-stack/#1-google-gemini-google-generativeai-072","title":"1. Google Gemini (google-generativeai 0.7.2)","text":"<p>Purpose: AI-powered text generation and vision analysis</p> <p>Why Gemini: - Free tier available (no credit card required) - State-of-the-art multimodal capabilities - Excellent for academic content analysis - Vision API for diagram understanding - Competitive with GPT-4 in many tasks - Lower latency than other commercial APIs</p> <p>Models Used: - Gemini 1.5 Pro (<code>gemini-1.5-pro-latest</code>):   - Research query responses   - Text synthesis and analysis   - Citation generation   - Context window: 1M tokens</p> <ul> <li>Gemini 1.5 Flash (<code>gemini-1.5-flash</code>):</li> <li>PDF diagram analysis</li> <li>Image description</li> <li>Faster, lower cost for vision tasks</li> </ul> <p>Alternatives Considered: - OpenAI GPT-4: Higher cost, requires payment - Anthropic Claude: Limited free tier - Local models (LLaMA): Higher compute requirements</p> <p>Official: https://ai.google.dev/</p>"},{"location":"architecture/technology-stack/#2-langchain-0216","title":"2. LangChain (0.2.16)","text":"<p>Purpose: AI orchestration and prompt management framework</p> <p>Why LangChain: - Industry-standard for LLM applications - Built-in memory management for conversations - Excellent prompt templating - Easy integration with multiple LLM providers - Strong community and documentation - Modular architecture for extensibility</p> <p>Key Features Used: - <code>ChatGoogleGenerativeAI</code>: Gemini integration - <code>ConversationBufferWindowMemory</code>: Conversation tracking - <code>PromptTemplate</code>: Structured prompts for research queries - Chain composition for multi-step reasoning</p> <p>LangChain Google GenAI (1.0.10): - Official LangChain integration for Google's AI - Seamless Gemini model support - Streaming responses - Function calling support</p> <p>Alternatives Considered: - Direct API calls: More work, less abstraction - LlamaIndex: Different focus (more on indexing) - Haystack: Less mature Gemini integration</p> <p>Official: https://python.langchain.com/</p>"},{"location":"architecture/technology-stack/#3-sentence-transformers-270","title":"3. Sentence Transformers (2.7.0)","text":"<p>Purpose: Generate semantic embeddings for vector search</p> <p>Why Sentence Transformers: - State-of-the-art semantic similarity models - Fast inference on CPU - Excellent for retrieval tasks - Easy to use and well-documented - Large collection of pre-trained models - Active development and updates</p> <p>Model Used: <code>all-MiniLM-L6-v2</code> - Dimensions: 384 - Speed: ~14,000 sentences/second (CPU) - Performance: Excellent quality/speed tradeoff - Size: ~90MB download - Best for: Semantic search in medium-large corpora</p> <p>Why all-MiniLM-L6-v2: - Optimal balance of speed and quality - Small embedding size (384d) = lower storage - Fast retrieval with k-NN search - Good performance on academic text - Widely used and battle-tested</p> <p>Alternative Models Available: - <code>all-mpnet-base-v2</code>: Higher quality (768d), slower - <code>all-MiniLM-L12-v2</code>: Similar size, slightly better quality - <code>multi-qa-mpnet-base-dot-v1</code>: Optimized for Q&amp;A tasks</p> <p>Official: https://www.sbert.net/</p>"},{"location":"architecture/technology-stack/#search-and-vector-database","title":"Search and Vector Database","text":""},{"location":"architecture/technology-stack/#opensearch-opensearch-py-240","title":"OpenSearch (opensearch-py 2.4.0)","text":"<p>Purpose: Vector database, full-text search, and document indexing</p> <p>Why OpenSearch: - Open source: Fork of Elasticsearch, Apache 2.0 license - Free to use: No licensing costs - Hybrid search: Combines keyword (BM25) and vector (k-NN) search - Scalable: Handles millions of documents - Feature-rich: Aggregations, filtering, faceting - Local deployment: Runs on your machine, full control - Active development: AWS-backed, regular updates</p> <p>Key Features Used:</p> <ol> <li>k-NN Vector Search:</li> <li>384-dimensional embeddings</li> <li>Cosine similarity for semantic matching</li> <li> <p>Fast approximate nearest neighbors</p> </li> <li> <p>Full-Text Search:</p> </li> <li>BM25 ranking algorithm</li> <li>Multi-field queries</li> <li> <p>Field boosting (title^2)</p> </li> <li> <p>Hybrid Search:</p> </li> <li>Combines keyword and vector results</li> <li>Best of both worlds: precise and semantic</li> <li> <p>Configurable weighting</p> </li> <li> <p>Index Management:</p> </li> <li>Custom mappings for multi-modal content</li> <li>Nested objects for citations</li> <li>Keyword arrays for metadata</li> </ol> <p>Schema Design: <pre><code>{\n    'content_type': 'keyword',      # paper/video/podcast\n    'title': 'text',                # Searchable title\n    'abstract': 'text',             # Paper abstract\n    'content': 'text',              # Main content\n    'authors': 'keyword',           # Author list\n    'publication_date': 'date',     # Temporal filtering\n    'embedding': 'knn_vector',      # 384-dim semantic vector\n    'diagram_descriptions': 'text', # From Gemini Vision\n    'key_concepts': 'keyword',      # Extracted concepts\n    'citations': 'nested'           # Citation tracking\n}\n</code></pre></p> <p>Deployment: Docker container for local development <pre><code>docker run -p 9200:9200 -e \"discovery.type=single-node\" \\\n  opensearchproject/opensearch:latest\n</code></pre></p> <p>Alternatives Considered: - Elasticsearch: Proprietary license, OpenSearch is the open fork - Pinecone: Cloud-only, costs money, less control - Weaviate: Good but more complex setup - Qdrant: Excellent but newer, smaller ecosystem - ChromaDB: Included but not primary (simpler use cases) - FAISS: No full-text search, just vectors - Milvus: More complex, higher overhead</p> <p>Why Not ChromaDB: - Included in dependencies (<code>chromadb==0.4.20</code>) - Could be used for simpler deployments - OpenSearch chosen for hybrid search capabilities - ChromaDB better for pure vector search</p> <p>Official: https://opensearch.org/</p>"},{"location":"architecture/technology-stack/#data-collection-and-processing","title":"Data Collection and Processing","text":""},{"location":"architecture/technology-stack/#academic-data-sources","title":"Academic Data Sources","text":""},{"location":"architecture/technology-stack/#1-arxiv-arxiv-200","title":"1. ArXiv (arxiv 2.0.0)","text":"<p>Purpose: Collect papers from ArXiv preprint server</p> <p>Why ArXiv: - Largest open-access preprint repository - Covers CS, physics, math, and more - Free API, no authentication required - Rich metadata (authors, abstract, categories) - Direct PDF download links</p> <p>Usage: <pre><code>from arxiv import Search, Client\nclient.search(query=\"machine learning\", max_results=10)\n</code></pre></p> <p>Official: https://arxiv.org/</p>"},{"location":"architecture/technology-stack/#2-scholarly-1711","title":"2. Scholarly (1.7.11)","text":"<p>Purpose: Collect papers from Google Scholar and Semantic Scholar</p> <p>Why Scholarly: - Access to Google Scholar's vast database - Semantic Scholar integration - Citation information - No API key required (uses scraping) - Author profiles and metrics</p> <p>Limitations: - Rate limiting required (avoid IP bans) - May need proxies for heavy use - Less reliable than official APIs</p> <p>Usage: <pre><code>from scholarly import scholarly\nsearch = scholarly.search_pubs('deep learning')\n</code></pre></p> <p>Official: https://github.com/scholarly-python-package/scholarly</p>"},{"location":"architecture/technology-stack/#3-youtube-transcript-api-youtube-transcript-api-061","title":"3. YouTube Transcript API (youtube-transcript-api 0.6.1)","text":"<p>Purpose: Extract transcripts from educational YouTube videos</p> <p>Why YouTube Transcript API: - Free and no API key required - Accesses official YouTube transcripts - Supports multiple languages - Auto-generated and manual captions - Timestamp information</p> <p>Usage: <pre><code>from youtube_transcript_api import YouTubeTranscriptApi\ntranscript = YouTubeTranscriptApi.get_transcript(video_id)\n</code></pre></p> <p>Alternatives: - YouTube Data API v3: Requires API key, quota limits - pytube (0.15.0): Video metadata extraction - yt-dlp (2024.3.10): Alternative downloader</p> <p>Official: https://github.com/jdepoix/youtube-transcript-api</p>"},{"location":"architecture/technology-stack/#4-feedparser-6010","title":"4. Feedparser (6.0.10)","text":"<p>Purpose: Parse RSS/Atom feeds for podcast collection</p> <p>Why Feedparser: - Universal feed parser (RSS, Atom, RDF) - Robust and battle-tested - Handles malformed feeds gracefully - Extract episode metadata - Widely used and maintained</p> <p>Usage: <pre><code>import feedparser\nfeed = feedparser.parse('https://podcast.rss.url')\n</code></pre></p> <p>Official: https://feedparser.readthedocs.io/</p>"},{"location":"architecture/technology-stack/#document-processing","title":"Document Processing","text":""},{"location":"architecture/technology-stack/#1-pypdf-pypdf-3170","title":"1. PyPDF (pypdf 3.17.0)","text":"<p>Purpose: Extract text and metadata from PDF files</p> <p>Why PyPDF: - Pure Python, no external dependencies - Actively maintained (formerly PyPDF2) - Good text extraction - PDF metadata parsing - Page-by-page processing</p> <p>Limitations: - May struggle with complex layouts - Scanned PDFs need OCR</p> <p>Official: https://pypdf.readthedocs.io/</p>"},{"location":"architecture/technology-stack/#2-pymupdf-1238","title":"2. PyMuPDF (1.23.8)","text":"<p>Purpose: Advanced PDF processing and image extraction</p> <p>Why PyMuPDF (fitz): - Fast C-based implementation - Excellent image extraction - Better handling of complex PDFs - Page rendering capabilities - Extract diagrams and figures</p> <p>Why Both PyPDF and PyMuPDF: - Fallback mechanism: Try PyMuPDF first, fallback to PyPDF - Different PDFs work better with different libraries - Maximize successful text extraction</p> <p>Usage: <pre><code>import fitz  # PyMuPDF\ndoc = fitz.open(\"paper.pdf\")\nimages = doc[page_num].get_images()\n</code></pre></p> <p>Official: https://pymupdf.readthedocs.io/</p>"},{"location":"architecture/technology-stack/#3-whisper-1110","title":"3. Whisper (1.1.10)","text":"<p>Purpose: Audio transcription for videos and podcasts</p> <p>Why Whisper: - State-of-the-art speech recognition - Multilingual support (99 languages) - Open source from OpenAI - Works offline (local processing) - High accuracy on academic content</p> <p>Models: - <code>tiny</code>, <code>base</code>: Fast, lower accuracy - <code>small</code>, <code>medium</code>: Balanced - <code>large</code>: Best accuracy, slower</p> <p>Note: Currently included but not fully integrated. YouTube uses existing transcripts.</p> <p>Official: https://github.com/openai/whisper</p>"},{"location":"architecture/technology-stack/#web-framework-and-ui","title":"Web Framework and UI","text":""},{"location":"architecture/technology-stack/#gradio-480","title":"Gradio (4.8.0)","text":"<p>Purpose: Web-based user interface</p> <p>Why Gradio: - Rapid development: Build UIs in minutes - Beautiful defaults: Professional look out of the box - Multi-tab support: Organize complex applications - Real-time updates: Live feedback during processing - Share functionality: Create public URLs instantly - Python-native: No JavaScript required - FastAPI integration: Built on modern async framework</p> <p>Key Features Used: - Tabbed interface (Research, Data Collection, Citations, Settings) - Text input/output components - Buttons and interactive elements - Real-time status updates - File upload capabilities - Markdown rendering for responses</p> <p>UI Structure: <pre><code>with gr.Blocks() as app:\n    with gr.Tab(\"Research\"):\n        # Query interface\n    with gr.Tab(\"Data Collection\"):\n        # Collection controls\n    with gr.Tab(\"Citation Manager\"):\n        # Citation export\n    with gr.Tab(\"Settings\"):\n        # System configuration\n</code></pre></p> <p>Why Gradio over alternatives: - Streamlit: Less flexible layout, page reloads - Dash: More complex, steeper learning curve - Flask/FastAPI: Would require frontend development - Jupyter: Not ideal for production deployment</p> <p>FastAPI (0.109.0) + Uvicorn (0.27.0): - Gradio runs on FastAPI (modern async framework) - Uvicorn is the ASGI server - High performance, async support - Easy to extend with custom API endpoints</p> <p>Official: https://gradio.app/</p>"},{"location":"architecture/technology-stack/#supporting-libraries","title":"Supporting Libraries","text":""},{"location":"architecture/technology-stack/#1-python-dotenv-100","title":"1. Python-dotenv (1.0.0)","text":"<p>Purpose: Environment variable management</p> <p>Why python-dotenv: - Load <code>.env</code> files automatically - Keep secrets out of code - Easy configuration management - Development/production separation</p> <p>Usage: <pre><code>from dotenv import load_dotenv\nload_dotenv()\napi_key = os.getenv('GEMINI_API_KEY')\n</code></pre></p>"},{"location":"architecture/technology-stack/#2-requests-2310","title":"2. Requests (2.31.0)","text":"<p>Purpose: HTTP client for API calls</p> <p>Why Requests: - De facto standard for HTTP in Python - Simple, elegant API - Robust error handling - Session management - Wide adoption and support</p>"},{"location":"architecture/technology-stack/#3-beautifulsoup4-4122","title":"3. BeautifulSoup4 (4.12.2)","text":"<p>Purpose: HTML and XML parsing</p> <p>Why BeautifulSoup: - Intuitive API for parsing HTML - Robust handling of malformed HTML - Multiple parser backends - Used for web scraping when APIs unavailable</p>"},{"location":"architecture/technology-stack/#4-pandas-213","title":"4. Pandas (2.1.3)","text":"<p>Purpose: Data manipulation and analysis</p> <p>Why Pandas: - DataFrame structure for tabular data - Easy data transformation - CSV export capabilities - Integration with other tools - Citation export and management</p>"},{"location":"architecture/technology-stack/#5-numpy-1252-20","title":"5. NumPy (&gt;=1.25.2, &lt;2.0)","text":"<p>Purpose: Numerical computing foundation</p> <p>Why NumPy: - Dependency for many libraries (Pandas, Sentence Transformers) - Array operations for embeddings - Mathematical computations - Version &lt;2.0 for compatibility</p>"},{"location":"architecture/technology-stack/#6-tqdm-4661","title":"6. tqdm (4.66.1)","text":"<p>Purpose: Progress bars for long operations</p> <p>Why tqdm: - Visual feedback during collection/processing - Works in terminal and notebooks - Minimal overhead - Easy integration</p>"},{"location":"architecture/technology-stack/#7-pydub-0251","title":"7. Pydub (0.25.1)","text":"<p>Purpose: Audio processing and manipulation</p> <p>Why Pydub: - Simple API for audio operations - Format conversion - Audio segmentation - Required for Whisper integration</p>"},{"location":"architecture/technology-stack/#8-yt-dlp-2024310","title":"8. yt-dlp (2024.3.10)","text":"<p>Purpose: YouTube video metadata extraction</p> <p>Why yt-dlp: - Active fork of youtube-dl - Regular updates for YouTube changes - Robust error handling - Alternative to pytube - More reliable than pytube</p>"},{"location":"architecture/technology-stack/#development-tools","title":"Development Tools","text":""},{"location":"architecture/technology-stack/#version-control","title":"Version Control","text":"<ul> <li>Git: Source control and collaboration</li> <li>.gitignore: Excludes venv, .env, data, logs</li> </ul>"},{"location":"architecture/technology-stack/#virtual-environment","title":"Virtual Environment","text":"<ul> <li>venv: Isolate project dependencies</li> <li>Platform-independent</li> <li>Built into Python 3.3+</li> </ul>"},{"location":"architecture/technology-stack/#package-management","title":"Package Management","text":"<ul> <li>pip: Python package installer</li> <li>requirements.txt: Dependency specification</li> </ul>"},{"location":"architecture/technology-stack/#version-compatibility","title":"Version Compatibility","text":""},{"location":"architecture/technology-stack/#python-version-requirements","title":"Python Version Requirements","text":"<p>Minimum: Python 3.9 Recommended: Python 3.11</p> <p>Why 3.9+: - Type hint improvements (PEP 585, 604) - Dictionary merge operators (|) - String methods (removeprefix, removesuffix) - Required for modern packages</p> <p>Why 3.11 recommended: - 10-60% faster than 3.10 - Better error messages - Improved typing features - Current stable release</p>"},{"location":"architecture/technology-stack/#critical-dependencies","title":"Critical Dependencies","text":"<p>Must be compatible: 1. <code>opensearch-py</code> with OpenSearch server version 2. <code>langchain</code> with <code>langchain-google-genai</code> 3. <code>numpy &lt;2.0</code> (compatibility constraint) 4. <code>sentence-transformers</code> with PyTorch (auto-installed)</p>"},{"location":"architecture/technology-stack/#breaking-changes-to-watch","title":"Breaking Changes to Watch","text":"<p>NumPy 2.0: - Many libraries not yet compatible - Pinned to &lt;2.0 in requirements - Will update when ecosystem catches up</p> <p>LangChain: - Rapid development, frequent updates - Pin to 0.2.x for stability - Check migration guides for major versions</p> <p>OpenSearch: - Compatible with 1.x and 2.x servers - Client version should match server major version</p>"},{"location":"architecture/technology-stack/#architecture-decisions","title":"Architecture Decisions","text":""},{"location":"architecture/technology-stack/#why-hybrid-search","title":"Why Hybrid Search?","text":"<p>Decision: Combine BM25 keyword search with k-NN vector search</p> <p>Rationale: - Keyword search (BM25): Precise matching, handles specific terms - Vector search (k-NN): Semantic similarity, understands meaning - Together: Best of both worlds</p> <p>Example: - Query: \"neural network training\" - BM25 finds: Papers with exact phrase - k-NN finds: Papers about \"model optimization\", \"gradient descent\" - Hybrid: Comprehensive results covering all aspects</p>"},{"location":"architecture/technology-stack/#why-local-first","title":"Why Local-First?","text":"<p>Decision: Run everything locally (OpenSearch, embeddings, processing)</p> <p>Rationale: - Privacy: Your data stays on your machine - Cost: No cloud fees, only API costs for Gemini - Control: Full control over infrastructure - Offline: Works without constant internet - Speed: No network latency for search</p> <p>Cloud usage limited to: - Gemini API calls (can be minimized) - Public Gradio link (optional)</p>"},{"location":"architecture/technology-stack/#why-gemini-over-gpt","title":"Why Gemini over GPT?","text":"<p>Decision: Use Google Gemini as primary LLM</p> <p>Rationale: - Free tier: No credit card, generous limits - Multimodal: Native vision support - Quality: Competitive with GPT-4 - Context: 1M token window - Speed: Fast response times - API: Simple, well-documented</p> <p>Trade-offs: - GPT-4 may be slightly better for some tasks - OpenAI ecosystem is more mature - But cost and accessibility favor Gemini</p>"},{"location":"architecture/technology-stack/#why-gradio-over-custom-frontend","title":"Why Gradio over Custom Frontend?","text":"<p>Decision: Use Gradio for UI instead of React/Vue</p> <p>Rationale: - Speed: Build in hours, not days - Python-only: No JavaScript needed - Good enough: Professional appearance - Share feature: Instant public URLs - Maintenance: Less code to maintain</p> <p>Trade-offs: - Less customization than custom frontend - Tied to Gradio's update cycle - Limited styling options - But: Faster development and deployment</p>"},{"location":"architecture/technology-stack/#alternative-technologies-considered","title":"Alternative Technologies Considered","text":""},{"location":"architecture/technology-stack/#vector-databases","title":"Vector Databases","text":"<p>Evaluated: 1. Pinecone: Cloud-only, paid service 2. Weaviate: More setup complexity 3. Qdrant: Excellent but newer 4. Milvus: Higher operational overhead 5. FAISS: No full-text search 6. ChromaDB: Simpler but less features</p> <p>Chosen: OpenSearch (hybrid search, open source, free)</p>"},{"location":"architecture/technology-stack/#llm-providers","title":"LLM Providers","text":"<p>Evaluated: 1. OpenAI GPT-4: Better quality, higher cost, requires payment 2. Anthropic Claude: Good quality, limited free tier 3. Cohere: Commercial focus, pricing model 4. Local models (LLaMA, Mistral): No API costs, high compute requirements</p> <p>Chosen: Google Gemini (free, multimodal, good quality)</p>"},{"location":"architecture/technology-stack/#orchestration-frameworks","title":"Orchestration Frameworks","text":"<p>Evaluated: 1. Direct API calls: More control, more work 2. LlamaIndex: Better for pure indexing 3. Haystack: Less mature Gemini support</p> <p>Chosen: LangChain (mature, flexible, good Gemini integration)</p>"},{"location":"architecture/technology-stack/#ui-frameworks","title":"UI Frameworks","text":"<p>Evaluated: 1. Streamlit: Popular but less flexible 2. Dash: Plotly-based, more complex 3. Flask + React: Full control, more development 4. Jupyter: Not production-ready</p> <p>Chosen: Gradio (fast development, good features)</p>"},{"location":"architecture/technology-stack/#technology-roadmap","title":"Technology Roadmap","text":""},{"location":"architecture/technology-stack/#potential-future-additions","title":"Potential Future Additions","text":"<p>Enhanced Search: - Reranking models (e.g., cross-encoders) - Query expansion techniques - Multi-vector search</p> <p>More Data Sources: - PubMed Central integration - Springer/Nature APIs (if available) - Podcast platforms (Spotify, Apple)</p> <p>Advanced AI: - Local LLM support (LLaMA, Mistral) - Fine-tuned models for academic text - Multi-agent systems</p> <p>Performance: - GPU acceleration for embeddings - Distributed OpenSearch - Caching layer (Redis)</p> <p>Features: - Document summarization - Automatic concept extraction - Knowledge graph generation - Collaborative features</p>"},{"location":"architecture/technology-stack/#dependency-tree","title":"Dependency Tree","text":"<pre><code>Multi-Modal Academic Research System\n\u2502\n\u251c\u2500\u2500 AI &amp; ML\n\u2502   \u251c\u2500\u2500 google-generativeai (Gemini API)\n\u2502   \u251c\u2500\u2500 google-genai (newer SDK)\n\u2502   \u251c\u2500\u2500 langchain (orchestration)\n\u2502   \u251c\u2500\u2500 langchain-google-genai (integration)\n\u2502   \u2514\u2500\u2500 sentence-transformers (embeddings)\n\u2502       \u2514\u2500\u2500 PyTorch (auto-installed)\n\u2502\n\u251c\u2500\u2500 Search &amp; Database\n\u2502   \u251c\u2500\u2500 opensearch-py (vector DB)\n\u2502   \u2514\u2500\u2500 chromadb (alternative)\n\u2502\n\u251c\u2500\u2500 Data Collection\n\u2502   \u251c\u2500\u2500 arxiv (papers)\n\u2502   \u251c\u2500\u2500 scholarly (Google Scholar)\n\u2502   \u251c\u2500\u2500 youtube-transcript-api (YouTube)\n\u2502   \u251c\u2500\u2500 pytube (video metadata)\n\u2502   \u251c\u2500\u2500 yt-dlp (alternative downloader)\n\u2502   \u2514\u2500\u2500 feedparser (podcasts)\n\u2502\n\u251c\u2500\u2500 Document Processing\n\u2502   \u251c\u2500\u2500 pypdf (PDF text)\n\u2502   \u251c\u2500\u2500 PyMuPDF (PDF images)\n\u2502   \u251c\u2500\u2500 whisper (audio transcription)\n\u2502   \u2514\u2500\u2500 pydub (audio processing)\n\u2502\n\u251c\u2500\u2500 Web &amp; UI\n\u2502   \u251c\u2500\u2500 gradio (UI framework)\n\u2502   \u251c\u2500\u2500 fastapi (backend)\n\u2502   \u2514\u2500\u2500 uvicorn (ASGI server)\n\u2502\n\u2514\u2500\u2500 Supporting\n    \u251c\u2500\u2500 python-dotenv (config)\n    \u251c\u2500\u2500 requests (HTTP)\n    \u251c\u2500\u2500 beautifulsoup4 (parsing)\n    \u251c\u2500\u2500 pandas (data manipulation)\n    \u251c\u2500\u2500 numpy (numerical computing)\n    \u2514\u2500\u2500 tqdm (progress bars)\n</code></pre>"},{"location":"architecture/technology-stack/#installation-impact","title":"Installation Impact","text":""},{"location":"architecture/technology-stack/#download-sizes-approximate","title":"Download Sizes (Approximate)","text":"<p>Python Packages: ~2GB total - PyTorch (sentence-transformers dependency): ~800MB - Gradio + FastAPI: ~200MB - OpenSearch client: ~50MB - Other packages: ~950MB combined</p> <p>Models (downloaded on first use): - all-MiniLM-L6-v2 embeddings: ~90MB - Whisper models (optional):   - tiny: ~75MB   - base: ~150MB   - small: ~500MB   - medium: ~1.5GB   - large: ~3GB</p> <p>Docker Images: - OpenSearch: ~1.2GB</p> <p>Total First Install: ~3-4GB (without Whisper models)</p>"},{"location":"architecture/technology-stack/#installation-time","title":"Installation Time","text":"<p>On typical broadband (50 Mbps): - Python packages: 5-10 minutes - Embedding model: 1-2 minutes - OpenSearch Docker: 2-3 minutes - Total: 10-15 minutes</p>"},{"location":"architecture/technology-stack/#summary","title":"Summary","text":"<p>The Multi-Modal Academic Research System leverages a modern, open-source technology stack designed for:</p> <ol> <li>Accessibility: Free tools, no paywalls</li> <li>Quality: State-of-the-art AI and search</li> <li>Privacy: Local-first architecture</li> <li>Flexibility: Modular, extensible design</li> <li>Usability: Simple installation, intuitive interface</li> </ol> <p>Core Stack: - Python 3.11: Modern language features - Google Gemini: Free, powerful AI - OpenSearch: Hybrid search capabilities - LangChain: AI orchestration - Gradio: Rapid UI development - Sentence Transformers: Semantic embeddings</p> <p>This technology combination enables sophisticated academic research workflows while maintaining simplicity and cost-effectiveness.</p> <p>For more information: - Installation Guide - Quick Start - Configuration - Main Documentation</p>"},{"location":"database/collections-table/","title":"Collections Table Reference","text":""},{"location":"database/collections-table/#overview","title":"Overview","text":"<p>The <code>collections</code> table is the core table in the Multi-Modal Academic Research System database. It serves as the central registry for all collected research content, regardless of type (papers, videos, or podcasts).</p>"},{"location":"database/collections-table/#table-definition","title":"Table Definition","text":"<pre><code>CREATE TABLE IF NOT EXISTS collections (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    content_type TEXT NOT NULL,\n    title TEXT NOT NULL,\n    source TEXT,\n    url TEXT,\n    collection_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    metadata TEXT,\n    status TEXT DEFAULT 'collected',\n    indexed BOOLEAN DEFAULT 0\n)\n</code></pre>"},{"location":"database/collections-table/#field-specifications","title":"Field Specifications","text":""},{"location":"database/collections-table/#id","title":"id","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: <code>PRIMARY KEY AUTOINCREMENT</code></li> <li>Description: Auto-incrementing unique identifier for each collection item</li> <li>Usage: Used as foreign key in type-specific tables (papers, videos, podcasts)</li> <li>Example: <code>1</code>, <code>2</code>, <code>3</code>, ...</li> </ul>"},{"location":"database/collections-table/#content_type","title":"content_type","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: <code>NOT NULL</code></li> <li>Description: Identifies the type of content</li> <li>Valid Values:</li> <li><code>'paper'</code> - Academic papers (ArXiv, PubMed, etc.)</li> <li><code>'video'</code> - YouTube videos</li> <li><code>'podcast'</code> - Podcast episodes</li> <li>Usage: Determines which type-specific table contains additional data</li> <li>Example: <code>'paper'</code></li> </ul>"},{"location":"database/collections-table/#title","title":"title","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: <code>NOT NULL</code></li> <li>Description: The title of the research content</li> <li>Usage: Primary display name, searchable field</li> <li>Example: <code>'Attention Is All You Need'</code></li> </ul>"},{"location":"database/collections-table/#source","title":"source","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: The platform or API from which content was collected</li> <li>Common Values:</li> <li><code>'arxiv'</code> - ArXiv repository</li> <li><code>'pubmed'</code> - PubMed Central</li> <li><code>'semantic_scholar'</code> - Semantic Scholar API</li> <li><code>'youtube'</code> - YouTube platform</li> <li><code>'podcast_rss'</code> - Podcast RSS feed</li> <li>Example: <code>'arxiv'</code></li> </ul>"},{"location":"database/collections-table/#url","title":"url","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: Original URL of the content</li> <li>Usage: Link back to source, can be used for re-fetching or citation</li> <li>Examples:</li> <li><code>'https://arxiv.org/abs/1706.03762'</code></li> <li><code>'https://www.youtube.com/watch?v=dQw4w9WgXcQ'</code></li> <li><code>'https://podcast.example.com/episode/123'</code></li> </ul>"},{"location":"database/collections-table/#collection_date","title":"collection_date","text":"<ul> <li>Type: <code>TIMESTAMP</code></li> <li>Constraints: <code>DEFAULT CURRENT_TIMESTAMP</code></li> <li>Description: Timestamp when the item was collected</li> <li>Format: <code>YYYY-MM-DD HH:MM:SS</code></li> <li>Usage: Sorting, filtering recent collections, analytics</li> <li>Example: <code>'2025-10-02 14:30:45'</code></li> </ul>"},{"location":"database/collections-table/#metadata","title":"metadata","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: JSON-encoded dictionary containing arbitrary metadata</li> <li>Usage: Flexible storage for additional information not captured in structured fields</li> <li>Structure: JSON string, automatically parsed to dict by database manager</li> <li>Example: <pre><code>{\n  \"collector_version\": \"1.0.0\",\n  \"keywords\": [\"machine learning\", \"transformers\"],\n  \"language\": \"en\",\n  \"download_time_ms\": 1234\n}\n</code></pre></li> </ul>"},{"location":"database/collections-table/#status","title":"status","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: <code>DEFAULT 'collected'</code></li> <li>Description: Processing status of the collection item</li> <li>Common Values:</li> <li><code>'collected'</code> - Successfully collected, not yet processed</li> <li><code>'processing'</code> - Currently being processed</li> <li><code>'processed'</code> - Processing complete</li> <li><code>'failed'</code> - Processing failed</li> <li><code>'indexed'</code> - Successfully indexed (though <code>indexed</code> field is preferred)</li> <li>Usage: Track processing workflow, identify items needing attention</li> <li>Example: <code>'collected'</code></li> </ul>"},{"location":"database/collections-table/#indexed","title":"indexed","text":"<ul> <li>Type: <code>BOOLEAN</code> (stored as INTEGER)</li> <li>Constraints: <code>DEFAULT 0</code></li> <li>Description: Whether the item has been indexed in OpenSearch</li> <li>Valid Values:</li> <li><code>0</code> - Not indexed (False)</li> <li><code>1</code> - Indexed (True)</li> <li>Usage: Track which items are searchable in the RAG system</li> <li>Example: <code>1</code></li> </ul>"},{"location":"database/collections-table/#relationships","title":"Relationships","text":""},{"location":"database/collections-table/#one-to-one-with-type-specific-tables","title":"One-to-One with Type-Specific Tables","text":"<p>Each collection has exactly zero or one corresponding entry in a type-specific table:</p> <ul> <li>If <code>content_type = 'paper'</code> \u2192 One record in <code>papers</code> table</li> <li>If <code>content_type = 'video'</code> \u2192 One record in <code>videos</code> table</li> <li>If <code>content_type = 'podcast'</code> \u2192 One record in <code>podcasts</code> table</li> </ul> <p>Foreign Key: <code>papers.collection_id</code>, <code>videos.collection_id</code>, <code>podcasts.collection_id</code> all reference <code>collections.id</code></p>"},{"location":"database/collections-table/#relationship-diagram","title":"Relationship Diagram","text":"<pre><code>collections (1) \u2190\u2192 (0..1) papers\ncollections (1) \u2190\u2192 (0..1) videos\ncollections (1) \u2190\u2192 (0..1) podcasts\n</code></pre>"},{"location":"database/collections-table/#common-query-patterns","title":"Common Query Patterns","text":""},{"location":"database/collections-table/#insert-new-collection","title":"Insert New Collection","text":"<pre><code>INSERT INTO collections (content_type, title, source, url, metadata, indexed)\nVALUES ('paper', 'Attention Is All You Need', 'arxiv',\n        'https://arxiv.org/abs/1706.03762',\n        '{\"keywords\": [\"transformers\", \"attention\"]}',\n        0);\n</code></pre>"},{"location":"database/collections-table/#get-all-collections","title":"Get All Collections","text":"<pre><code>SELECT * FROM collections\nORDER BY collection_date DESC\nLIMIT 100;\n</code></pre>"},{"location":"database/collections-table/#filter-by-content-type","title":"Filter by Content Type","text":"<pre><code>SELECT * FROM collections\nWHERE content_type = 'paper'\nORDER BY collection_date DESC;\n</code></pre>"},{"location":"database/collections-table/#get-unindexed-items","title":"Get Unindexed Items","text":"<pre><code>SELECT id, title, content_type\nFROM collections\nWHERE indexed = 0\nORDER BY collection_date ASC;\n</code></pre>"},{"location":"database/collections-table/#search-by-title","title":"Search by Title","text":"<pre><code>SELECT * FROM collections\nWHERE title LIKE '%machine learning%'\nORDER BY collection_date DESC\nLIMIT 50;\n</code></pre>"},{"location":"database/collections-table/#count-by-type","title":"Count by Type","text":"<pre><code>SELECT content_type, COUNT(*) as count\nFROM collections\nGROUP BY content_type;\n</code></pre>"},{"location":"database/collections-table/#recent-collections-last-7-days","title":"Recent Collections (Last 7 Days)","text":"<pre><code>SELECT * FROM collections\nWHERE collection_date &gt;= datetime('now', '-7 days')\nORDER BY collection_date DESC;\n</code></pre>"},{"location":"database/collections-table/#update-indexed-status","title":"Update Indexed Status","text":"<pre><code>UPDATE collections\nSET indexed = 1\nWHERE id = ?;\n</code></pre>"},{"location":"database/collections-table/#delete-collection","title":"Delete Collection","text":"<pre><code>-- First delete from type-specific table\nDELETE FROM papers WHERE collection_id = ?;\n\n-- Then delete from collections\nDELETE FROM collections WHERE id = ?;\n</code></pre>"},{"location":"database/collections-table/#example-data","title":"Example Data","text":"id content_type title source url collection_date metadata status indexed 1 paper Attention Is All You Need arxiv https://arxiv.org/abs/1706.03762 2025-10-01 10:30:00 {\"keywords\": [\"transformers\"]} collected 1 2 video Introduction to Neural Networks youtube https://youtube.com/watch?v=abc123 2025-10-01 11:00:00 {\"duration\": 1800} collected 1 3 podcast AI Podcast Episode 42 podcast_rss https://podcast.ai/ep42 2025-10-02 09:15:00 {\"language\": \"en\"} collected 0"},{"location":"database/collections-table/#indexing-recommendations","title":"Indexing Recommendations","text":"<p>For optimal query performance on the collections table:</p> <pre><code>-- Content type filtering (frequently used)\nCREATE INDEX idx_content_type ON collections(content_type);\n\n-- Indexed status filtering (find unindexed items)\nCREATE INDEX idx_indexed ON collections(indexed);\n\n-- Collection date sorting (most common sort)\nCREATE INDEX idx_collection_date ON collections(collection_date DESC);\n\n-- Composite index for type + indexed queries\nCREATE INDEX idx_type_indexed ON collections(content_type, indexed);\n\n-- Full-text search on title (optional, requires FTS5)\nCREATE VIRTUAL TABLE collections_fts USING fts5(title, content='collections', content_rowid='id');\n</code></pre>"},{"location":"database/collections-table/#data-validation","title":"Data Validation","text":"<p>When inserting data, ensure:</p> <ol> <li>content_type is one of: <code>'paper'</code>, <code>'video'</code>, <code>'podcast'</code></li> <li>title is not empty</li> <li>metadata is valid JSON (if provided)</li> <li>indexed is 0 or 1 (not NULL)</li> <li>url is a valid URL format (if provided)</li> </ol>"},{"location":"database/collections-table/#python-database-manager-usage","title":"Python Database Manager Usage","text":"<p>The <code>CollectionDatabaseManager</code> class provides methods to interact with this table:</p> <pre><code>from multi_modal_rag.database import CollectionDatabaseManager\n\ndb = CollectionDatabaseManager()\n\n# Add a new collection\ncollection_id = db.add_collection(\n    content_type='paper',\n    title='Attention Is All You Need',\n    source='arxiv',\n    url='https://arxiv.org/abs/1706.03762',\n    metadata={'keywords': ['transformers', 'attention']},\n    indexed=False\n)\n\n# Get all collections with pagination\ncollections = db.get_all_collections(limit=100, offset=0)\n\n# Get collections by type\npapers = db.get_collections_by_type('paper', limit=50)\n\n# Mark as indexed\ndb.mark_as_indexed(collection_id)\n\n# Search collections\nresults = db.search_collections('transformer', limit=50)\n\n# Get full details (includes type-specific data)\ndetails = db.get_collection_with_details(collection_id)\n</code></pre>"},{"location":"database/collections-table/#storage-considerations","title":"Storage Considerations","text":""},{"location":"database/collections-table/#size-estimates","title":"Size Estimates","text":"<p>Approximate storage per collection record: - Base record: ~500 bytes - With small metadata: ~1 KB - With large metadata (long arrays): up to 10 KB</p> <p>Example: 10,000 collections \u2248 10-100 MB</p>"},{"location":"database/collections-table/#metadata-json-best-practices","title":"Metadata JSON Best Practices","text":"<ul> <li>Keep metadata JSON compact</li> <li>Don't store large text blobs (use separate fields or files)</li> <li>Use consistent key naming conventions</li> <li>Store only non-searchable auxiliary data (searchable data should go in proper fields)</li> </ul> <p>Good metadata examples: <pre><code>{\n  \"collector_version\": \"1.0.0\",\n  \"language\": \"en\",\n  \"download_timestamp\": 1696234567\n}\n</code></pre></p> <p>Bad metadata examples (too large): <pre><code>{\n  \"full_text\": \"...[thousands of lines]...\",\n  \"raw_html\": \"...[complete HTML dump]...\"\n}\n</code></pre></p>"},{"location":"database/collections-table/#migration-path","title":"Migration Path","text":"<p>If adding new fields to the collections table:</p> <pre><code>-- Add new column (SQLite limited ALTER TABLE support)\nALTER TABLE collections ADD COLUMN new_field TEXT DEFAULT NULL;\n\n-- For complex changes, create new table and migrate:\nCREATE TABLE collections_new (...);\nINSERT INTO collections_new SELECT ..., DEFAULT_VALUE FROM collections;\nDROP TABLE collections;\nALTER TABLE collections_new RENAME TO collections;\n</code></pre>"},{"location":"database/collections-table/#troubleshooting","title":"Troubleshooting","text":""},{"location":"database/collections-table/#issue-foreign-key-constraint-failed","title":"Issue: Foreign Key Constraint Failed","text":"<p>Cause: Trying to delete a collection that has type-specific records</p> <p>Solution: Delete type-specific records first <pre><code>DELETE FROM papers WHERE collection_id = 123;\nDELETE FROM collections WHERE id = 123;\n</code></pre></p>"},{"location":"database/collections-table/#issue-invalid-json-in-metadata","title":"Issue: Invalid JSON in metadata","text":"<p>Cause: Manually inserted invalid JSON string</p> <p>Solution: Validate JSON before insert <pre><code>import json\nmetadata_str = json.dumps(metadata_dict)  # Always use json.dumps()\n</code></pre></p>"},{"location":"database/collections-table/#issue-duplicate-collections","title":"Issue: Duplicate collections","text":"<p>Cause: No UNIQUE constraint on url or title</p> <p>Solution: Add application-level deduplication or: <pre><code>CREATE UNIQUE INDEX idx_unique_url ON collections(url) WHERE url IS NOT NULL;\n</code></pre></p>"},{"location":"database/schema/","title":"Database Schema Documentation","text":""},{"location":"database/schema/#overview","title":"Overview","text":"<p>The Multi-Modal Academic Research System uses SQLite as its database backend to track all collected research content. The database is located at <code>data/collections.db</code> by default and consists of 5 main tables that work together to store papers, videos, podcasts, and collection statistics.</p>"},{"location":"database/schema/#database-manager","title":"Database Manager","text":"<p>Class: <code>CollectionDatabaseManager</code> Location: <code>multi_modal_rag/database/db_manager.py</code> Default Path: <code>data/collections.db</code></p>"},{"location":"database/schema/#entity-relationship-diagram","title":"Entity Relationship Diagram","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502     collections         \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 id (PK)                 \u2502\n\u2502 content_type            \u2502\n\u2502 title                   \u2502\n\u2502 source                  \u2502\n\u2502 url                     \u2502\n\u2502 collection_date         \u2502\n\u2502 metadata                \u2502\n\u2502 status                  \u2502\n\u2502 indexed                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502\n            \u2502 1:1 (content_type dependent)\n            \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502             \u2502              \u2502              \u2502\n     \u25bc             \u25bc              \u25bc              \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 papers  \u2502  \u2502  videos  \u2502  \u2502 podcasts  \u2502  \u2502 collection_stats \u2502\n\u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2502\n\u2502 id (PK) \u2502  \u2502 id (PK)  \u2502  \u2502 id (PK)   \u2502  \u2502 id (PK)          \u2502\n\u2502 coll_id \u2502  \u2502 coll_id  \u2502  \u2502 coll_id   \u2502  \u2502 content_type     \u2502\n\u2502 (FK)    \u2502  \u2502 (FK)     \u2502  \u2502 (FK)      \u2502  \u2502 query            \u2502\n\u2502 ...     \u2502  \u2502 ...      \u2502  \u2502 ...       \u2502  \u2502 results_count    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502 collection_date  \u2502\n                                           \u2502 source_api       \u2502\n                                           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"database/schema/#tables","title":"Tables","text":""},{"location":"database/schema/#1-collections-main-table","title":"1. collections (Main Table)","text":"<p>The primary table that stores all collected research content regardless of type.</p> Field Type Constraints Description <code>id</code> INTEGER PRIMARY KEY AUTOINCREMENT Unique identifier for each collection item <code>content_type</code> TEXT NOT NULL Type of content: 'paper', 'video', or 'podcast' <code>title</code> TEXT NOT NULL Title of the research content <code>source</code> TEXT - Source platform (e.g., 'arxiv', 'youtube', 'podcast_rss') <code>url</code> TEXT - Original URL of the content <code>collection_date</code> TIMESTAMP DEFAULT CURRENT_TIMESTAMP When the item was collected <code>metadata</code> TEXT - JSON-encoded additional metadata <code>status</code> TEXT DEFAULT 'collected' Processing status <code>indexed</code> BOOLEAN DEFAULT 0 Whether item is indexed in OpenSearch (0=false, 1=true) <p>Indexes: - Primary key on <code>id</code> - Implicit index on <code>content_type</code> (for filtering) - Implicit index on <code>collection_date</code> (for ordering)</p>"},{"location":"database/schema/#2-papers","title":"2. papers","text":"<p>Stores paper-specific data with a foreign key reference to <code>collections</code>.</p> Field Type Constraints Description <code>id</code> INTEGER PRIMARY KEY AUTOINCREMENT Unique identifier <code>collection_id</code> INTEGER FOREIGN KEY \u2192 collections(id) Reference to parent collection <code>arxiv_id</code> TEXT - ArXiv identifier (if from ArXiv) <code>pmc_id</code> TEXT - PubMed Central identifier (if from PMC) <code>abstract</code> TEXT - Paper abstract text <code>authors</code> TEXT - JSON array of author names <code>published_date</code> TEXT - Publication date <code>categories</code> TEXT - JSON array of research categories/tags <code>pdf_path</code> TEXT - Local filesystem path to downloaded PDF <p>Relationships: - <code>collection_id</code> FOREIGN KEY references <code>collections(id)</code></p>"},{"location":"database/schema/#3-videos","title":"3. videos","text":"<p>Stores YouTube video-specific data.</p> Field Type Constraints Description <code>id</code> INTEGER PRIMARY KEY AUTOINCREMENT Unique identifier <code>collection_id</code> INTEGER FOREIGN KEY \u2192 collections(id) Reference to parent collection <code>video_id</code> TEXT - YouTube video ID <code>channel</code> TEXT - YouTube channel name <code>duration</code> INTEGER - Video duration in seconds <code>views</code> INTEGER - View count <code>thumbnail_url</code> TEXT - URL to video thumbnail <code>transcript_available</code> BOOLEAN DEFAULT 0 Whether transcript was successfully retrieved <p>Relationships: - <code>collection_id</code> FOREIGN KEY references <code>collections(id)</code></p>"},{"location":"database/schema/#4-podcasts","title":"4. podcasts","text":"<p>Stores podcast episode-specific data.</p> Field Type Constraints Description <code>id</code> INTEGER PRIMARY KEY AUTOINCREMENT Unique identifier <code>collection_id</code> INTEGER FOREIGN KEY \u2192 collections(id) Reference to parent collection <code>episode_id</code> TEXT - Unique episode identifier <code>podcast_name</code> TEXT - Name of the podcast show <code>audio_url</code> TEXT - Direct URL to audio file <code>duration</code> INTEGER - Episode duration in seconds <p>Relationships: - <code>collection_id</code> FOREIGN KEY references <code>collections(id)</code></p>"},{"location":"database/schema/#5-collection_stats","title":"5. collection_stats","text":"<p>Tracks statistics about collection operations for analytics.</p> Field Type Constraints Description <code>id</code> INTEGER PRIMARY KEY AUTOINCREMENT Unique identifier <code>content_type</code> TEXT - Type of content collected <code>query</code> TEXT - Search query used <code>results_count</code> INTEGER - Number of results returned <code>collection_date</code> TIMESTAMP DEFAULT CURRENT_TIMESTAMP When the collection occurred <code>source_api</code> TEXT - Which API was used (e.g., 'arxiv', 'youtube_api') <p>Note: This table is independent and does not reference <code>collections</code>.</p>"},{"location":"database/schema/#data-types-and-storage","title":"Data Types and Storage","text":""},{"location":"database/schema/#json-fields","title":"JSON Fields","text":"<p>Several fields store JSON-encoded data for flexibility:</p> <ul> <li><code>collections.metadata</code>: Arbitrary metadata dictionary</li> <li><code>papers.authors</code>: Array of author names, e.g., <code>[\"John Doe\", \"Jane Smith\"]</code></li> <li><code>papers.categories</code>: Array of category tags, e.g., <code>[\"cs.AI\", \"cs.LG\"]</code></li> </ul> <p>When retrieved via the database manager, these JSON fields are automatically parsed back into Python dictionaries/lists.</p>"},{"location":"database/schema/#boolean-fields","title":"Boolean Fields","text":"<p>SQLite doesn't have a native BOOLEAN type. Boolean fields use INTEGER: - <code>0</code> = False - <code>1</code> = True</p> <p>Fields using this convention: - <code>collections.indexed</code> - <code>videos.transcript_available</code></p>"},{"location":"database/schema/#timestamps","title":"Timestamps","text":"<p>Timestamp fields use SQLite's <code>CURRENT_TIMESTAMP</code> which stores in format: <code>YYYY-MM-DD HH:MM:SS</code></p>"},{"location":"database/schema/#constraints-and-relationships","title":"Constraints and Relationships","text":""},{"location":"database/schema/#foreign-keys","title":"Foreign Keys","text":"<p>Foreign keys maintain referential integrity between tables:</p> <ol> <li><code>papers.collection_id</code> \u2192 <code>collections.id</code></li> <li><code>videos.collection_id</code> \u2192 <code>collections.id</code></li> <li><code>podcasts.collection_id</code> \u2192 <code>collections.id</code></li> </ol> <p>Cascade Behavior: SQLite foreign keys are enforced if <code>PRAGMA foreign_keys = ON</code>. By default, no CASCADE DELETE is configured, so collections should be deleted manually after removing type-specific records.</p>"},{"location":"database/schema/#example-queries","title":"Example Queries","text":""},{"location":"database/schema/#get-all-papers-with-full-details","title":"Get All Papers with Full Details","text":"<pre><code>SELECT\n    c.*,\n    p.arxiv_id,\n    p.abstract,\n    p.authors,\n    p.published_date,\n    p.pdf_path\nFROM collections c\nINNER JOIN papers p ON c.id = p.collection_id\nWHERE c.content_type = 'paper'\nORDER BY c.collection_date DESC;\n</code></pre>"},{"location":"database/schema/#count-collections-by-type","title":"Count Collections by Type","text":"<pre><code>SELECT\n    content_type,\n    COUNT(*) as count\nFROM collections\nGROUP BY content_type;\n</code></pre>"},{"location":"database/schema/#find-unindexed-items","title":"Find Unindexed Items","text":"<pre><code>SELECT\n    id,\n    content_type,\n    title,\n    collection_date\nFROM collections\nWHERE indexed = 0\nORDER BY collection_date ASC;\n</code></pre>"},{"location":"database/schema/#get-videos-with-transcripts","title":"Get Videos with Transcripts","text":"<pre><code>SELECT\n    c.title,\n    c.url,\n    v.video_id,\n    v.channel,\n    v.duration\nFROM collections c\nINNER JOIN videos v ON c.id = v.collection_id\nWHERE v.transcript_available = 1;\n</code></pre>"},{"location":"database/schema/#recent-collections-last-7-days","title":"Recent Collections (Last 7 Days)","text":"<pre><code>SELECT *\nFROM collections\nWHERE collection_date &gt;= datetime('now', '-7 days')\nORDER BY collection_date DESC;\n</code></pre>"},{"location":"database/schema/#search-by-title-or-source","title":"Search by Title or Source","text":"<pre><code>SELECT *\nFROM collections\nWHERE title LIKE '%machine learning%'\n   OR source LIKE '%arxiv%'\nORDER BY collection_date DESC\nLIMIT 50;\n</code></pre>"},{"location":"database/schema/#collection-statistics-by-api","title":"Collection Statistics by API","text":"<pre><code>SELECT\n    content_type,\n    source_api,\n    SUM(results_count) as total_results,\n    COUNT(*) as query_count\nFROM collection_stats\nGROUP BY content_type, source_api\nORDER BY total_results DESC;\n</code></pre>"},{"location":"database/schema/#papers-with-authors-and-categories","title":"Papers with Authors and Categories","text":"<pre><code>SELECT\n    c.title,\n    p.authors,\n    p.categories,\n    p.published_date,\n    p.arxiv_id\nFROM collections c\nINNER JOIN papers p ON c.id = p.collection_id\nWHERE c.content_type = 'paper'\n  AND p.authors LIKE '%LeCun%';\n</code></pre>"},{"location":"database/schema/#indexes","title":"Indexes","text":""},{"location":"database/schema/#implicit-indexes","title":"Implicit Indexes","text":"<p>SQLite automatically creates indexes for: - All PRIMARY KEY columns - All UNIQUE columns</p>"},{"location":"database/schema/#recommended-additional-indexes","title":"Recommended Additional Indexes","text":"<p>For better query performance, consider adding:</p> <pre><code>-- Index for content type filtering\nCREATE INDEX idx_content_type ON collections(content_type);\n\n-- Index for indexed status\nCREATE INDEX idx_indexed ON collections(indexed);\n\n-- Index for collection date sorting\nCREATE INDEX idx_collection_date ON collections(collection_date DESC);\n\n-- Index for paper ArXiv IDs\nCREATE INDEX idx_arxiv_id ON papers(arxiv_id);\n\n-- Index for video IDs\nCREATE INDEX idx_video_id ON videos(video_id);\n\n-- Composite index for type-specific lookups\nCREATE INDEX idx_type_indexed ON collections(content_type, indexed);\n</code></pre>"},{"location":"database/schema/#database-initialization","title":"Database Initialization","text":"<p>The database schema is automatically created when <code>CollectionDatabaseManager</code> is instantiated:</p> <pre><code>from multi_modal_rag.database import CollectionDatabaseManager\n\n# Automatically creates database and all tables if they don't exist\ndb_manager = CollectionDatabaseManager(db_path=\"data/collections.db\")\n</code></pre>"},{"location":"database/schema/#migration-considerations","title":"Migration Considerations","text":"<p>The current schema does NOT include migration management. If schema changes are needed:</p> <ol> <li>Backup the existing database: <code>cp data/collections.db data/collections.db.backup</code></li> <li>Update schema in <code>db_manager.py</code></li> <li>Manually migrate data using SQL commands or Python scripts</li> <li>Consider adding a migration framework like Alembic for production use</li> </ol>"},{"location":"database/schema/#performance-notes","title":"Performance Notes","text":"<ul> <li>Pagination: Use LIMIT and OFFSET for large result sets</li> <li>JSON Parsing: JSON fields are parsed in Python, not at the database level</li> <li>Full-Text Search: For advanced search, consider SQLite FTS5 extension</li> <li>Concurrent Access: SQLite supports concurrent reads but serializes writes</li> <li>Database Size: Monitor <code>data/collections.db</code> size; SQLite handles databases up to terabytes but performance degrades with very large datasets</li> </ul>"},{"location":"database/schema/#backup-and-maintenance","title":"Backup and Maintenance","text":""},{"location":"database/schema/#backup","title":"Backup","text":"<pre><code># Simple file copy (stop application first)\ncp data/collections.db data/collections.db.backup\n\n# SQLite backup command (online backup)\nsqlite3 data/collections.db \".backup data/collections.db.backup\"\n</code></pre>"},{"location":"database/schema/#vacuum-optimize","title":"Vacuum (Optimize)","text":"<pre><code>-- Reclaim unused space and optimize\nVACUUM;\n</code></pre>"},{"location":"database/schema/#integrity-check","title":"Integrity Check","text":"<pre><code>-- Check database integrity\nPRAGMA integrity_check;\n</code></pre>"},{"location":"database/type-tables/","title":"Type-Specific Tables Reference","text":""},{"location":"database/type-tables/#overview","title":"Overview","text":"<p>The Multi-Modal Academic Research System uses type-specific tables to store detailed information that is unique to each content type. Each type-specific table has a foreign key relationship with the main <code>collections</code> table.</p>"},{"location":"database/type-tables/#table-relationships","title":"Table Relationships","text":"<pre><code>collections (parent)\n    \u251c\u2500\u2500 papers (child)\n    \u251c\u2500\u2500 videos (child)\n    \u2514\u2500\u2500 podcasts (child)\n</code></pre> <p>Each collection record (in <code>collections</code> table) has exactly zero or one corresponding record in one of these type-specific tables, depending on its <code>content_type</code> field.</p>"},{"location":"database/type-tables/#papers-table","title":"Papers Table","text":""},{"location":"database/type-tables/#overview_1","title":"Overview","text":"<p>Stores detailed metadata for academic papers collected from sources like ArXiv, PubMed Central, and Semantic Scholar.</p>"},{"location":"database/type-tables/#table-definition","title":"Table Definition","text":"<pre><code>CREATE TABLE IF NOT EXISTS papers (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    collection_id INTEGER,\n    arxiv_id TEXT,\n    pmc_id TEXT,\n    abstract TEXT,\n    authors TEXT,\n    published_date TEXT,\n    categories TEXT,\n    pdf_path TEXT,\n    FOREIGN KEY (collection_id) REFERENCES collections(id)\n)\n</code></pre>"},{"location":"database/type-tables/#fields","title":"Fields","text":""},{"location":"database/type-tables/#id","title":"id","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: <code>PRIMARY KEY AUTOINCREMENT</code></li> <li>Description: Unique identifier for the paper record</li> <li>Example: <code>1</code></li> </ul>"},{"location":"database/type-tables/#collection_id","title":"collection_id","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: <code>FOREIGN KEY \u2192 collections(id)</code></li> <li>Description: References the parent collection record</li> <li>Usage: Join key to get full collection details</li> <li>Example: <code>42</code></li> </ul>"},{"location":"database/type-tables/#arxiv_id","title":"arxiv_id","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: ArXiv identifier if paper is from ArXiv</li> <li>Format: Typically <code>YYMM.NNNNN</code> or <code>archive/YYMMNNN</code></li> <li>Example: <code>'1706.03762'</code>, <code>'2103.14030'</code></li> </ul>"},{"location":"database/type-tables/#pmc_id","title":"pmc_id","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: PubMed Central identifier if paper is from PMC</li> <li>Format: <code>PMC</code> followed by numbers</li> <li>Example: <code>'PMC1234567'</code></li> </ul>"},{"location":"database/type-tables/#abstract","title":"abstract","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: Full text of the paper's abstract</li> <li>Usage: Searchable, used for initial indexing and display</li> <li>Example: <code>'We propose a new architecture for neural machine translation...'</code></li> </ul>"},{"location":"database/type-tables/#authors","title":"authors","text":"<ul> <li>Type: <code>TEXT</code> (JSON array)</li> <li>Constraints: None (nullable)</li> <li>Description: JSON-encoded array of author names</li> <li>Format: Stored as JSON string, parsed to list by database manager</li> <li>Example: <code>'[\"Ashish Vaswani\", \"Noam Shazeer\", \"Niki Parmar\"]'</code></li> </ul>"},{"location":"database/type-tables/#published_date","title":"published_date","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: Publication date of the paper</li> <li>Format: Flexible text format (ISO 8601 recommended: <code>YYYY-MM-DD</code>)</li> <li>Examples: <code>'2017-06-12'</code>, <code>'2021-03-15'</code></li> </ul>"},{"location":"database/type-tables/#categories","title":"categories","text":"<ul> <li>Type: <code>TEXT</code> (JSON array)</li> <li>Constraints: None (nullable)</li> <li>Description: JSON-encoded array of research categories/tags</li> <li>Format: Stored as JSON string, parsed to list by database manager</li> <li>Examples: <code>'[\"cs.CL\", \"cs.AI\", \"cs.LG\"]'</code></li> </ul>"},{"location":"database/type-tables/#pdf_path","title":"pdf_path","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: Local filesystem path to the downloaded PDF file</li> <li>Format: Absolute or relative path</li> <li>Example: <code>'data/papers/1706.03762.pdf'</code></li> </ul>"},{"location":"database/type-tables/#example-data","title":"Example Data","text":"<pre><code>{\n  \"id\": 1,\n  \"collection_id\": 42,\n  \"arxiv_id\": \"1706.03762\",\n  \"pmc_id\": null,\n  \"abstract\": \"The dominant sequence transduction models are based on complex recurrent or convolutional neural networks...\",\n  \"authors\": \"[\\\"Ashish Vaswani\\\", \\\"Noam Shazeer\\\", \\\"Niki Parmar\\\", \\\"Jakob Uszkoreit\\\", \\\"Llion Jones\\\", \\\"Aidan N. Gomez\\\", \\\"Lukasz Kaiser\\\", \\\"Illia Polosukhin\\\"]\",\n  \"published_date\": \"2017-06-12\",\n  \"categories\": \"[\\\"cs.CL\\\", \\\"cs.AI\\\", \\\"cs.LG\\\"]\",\n  \"pdf_path\": \"data/papers/arxiv_1706.03762.pdf\"\n}\n</code></pre>"},{"location":"database/type-tables/#common-queries","title":"Common Queries","text":"<pre><code>-- Get all papers with collection details\nSELECT c.*, p.*\nFROM collections c\nJOIN papers p ON c.id = p.collection_id\nORDER BY p.published_date DESC;\n\n-- Find papers by author\nSELECT c.title, p.authors, p.published_date\nFROM collections c\nJOIN papers p ON c.id = p.collection_id\nWHERE p.authors LIKE '%Vaswani%';\n\n-- Get papers from ArXiv only\nSELECT c.title, p.arxiv_id, p.pdf_path\nFROM collections c\nJOIN papers p ON c.id = p.collection_id\nWHERE p.arxiv_id IS NOT NULL;\n\n-- Papers by category\nSELECT c.title, p.categories\nFROM collections c\nJOIN papers p ON c.id = p.collection_id\nWHERE p.categories LIKE '%cs.AI%';\n</code></pre>"},{"location":"database/type-tables/#videos-table","title":"Videos Table","text":""},{"location":"database/type-tables/#overview_2","title":"Overview","text":"<p>Stores metadata for educational videos collected from YouTube.</p>"},{"location":"database/type-tables/#table-definition_1","title":"Table Definition","text":"<pre><code>CREATE TABLE IF NOT EXISTS videos (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    collection_id INTEGER,\n    video_id TEXT,\n    channel TEXT,\n    duration INTEGER,\n    views INTEGER,\n    thumbnail_url TEXT,\n    transcript_available BOOLEAN DEFAULT 0,\n    FOREIGN KEY (collection_id) REFERENCES collections(id)\n)\n</code></pre>"},{"location":"database/type-tables/#fields_1","title":"Fields","text":""},{"location":"database/type-tables/#id_1","title":"id","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: <code>PRIMARY KEY AUTOINCREMENT</code></li> <li>Description: Unique identifier for the video record</li> <li>Example: <code>1</code></li> </ul>"},{"location":"database/type-tables/#collection_id_1","title":"collection_id","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: <code>FOREIGN KEY \u2192 collections(id)</code></li> <li>Description: References the parent collection record</li> <li>Example: <code>43</code></li> </ul>"},{"location":"database/type-tables/#video_id","title":"video_id","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: YouTube video ID</li> <li>Format: 11-character alphanumeric string</li> <li>Example: <code>'dQw4w9WgXcQ'</code></li> <li>Usage: Construct YouTube URL: <code>https://www.youtube.com/watch?v={video_id}</code></li> </ul>"},{"location":"database/type-tables/#channel","title":"channel","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: YouTube channel name</li> <li>Example: <code>'3Blue1Brown'</code>, <code>'Two Minute Papers'</code></li> </ul>"},{"location":"database/type-tables/#duration","title":"duration","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: None (nullable)</li> <li>Description: Video duration in seconds</li> <li>Example: <code>1800</code> (30 minutes), <code>600</code> (10 minutes)</li> <li>Display: Convert to <code>HH:MM:SS</code> format in UI</li> </ul>"},{"location":"database/type-tables/#views","title":"views","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: None (nullable)</li> <li>Description: Video view count at time of collection</li> <li>Example: <code>1000000</code></li> <li>Note: This is a snapshot; actual views may have changed</li> </ul>"},{"location":"database/type-tables/#thumbnail_url","title":"thumbnail_url","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: URL to video thumbnail image</li> <li>Example: <code>'https://i.ytimg.com/vi/dQw4w9WgXcQ/maxresdefault.jpg'</code></li> <li>Common Formats:</li> <li><code>default.jpg</code> - 120x90</li> <li><code>mqdefault.jpg</code> - 320x180</li> <li><code>hqdefault.jpg</code> - 480x360</li> <li><code>maxresdefault.jpg</code> - 1280x720</li> </ul>"},{"location":"database/type-tables/#transcript_available","title":"transcript_available","text":"<ul> <li>Type: <code>BOOLEAN</code> (stored as INTEGER)</li> <li>Constraints: <code>DEFAULT 0</code></li> <li>Description: Whether a transcript was successfully retrieved</li> <li>Values:</li> <li><code>0</code> - No transcript available</li> <li><code>1</code> - Transcript successfully retrieved</li> <li>Example: <code>1</code></li> </ul>"},{"location":"database/type-tables/#example-data_1","title":"Example Data","text":"<pre><code>{\n  \"id\": 1,\n  \"collection_id\": 43,\n  \"video_id\": \"aircAruvnKk\",\n  \"channel\": \"3Blue1Brown\",\n  \"duration\": 1194,\n  \"views\": 5234891,\n  \"thumbnail_url\": \"https://i.ytimg.com/vi/aircAruvnKk/maxresdefault.jpg\",\n  \"transcript_available\": 1\n}\n</code></pre>"},{"location":"database/type-tables/#common-queries_1","title":"Common Queries","text":"<pre><code>-- Get all videos with transcripts\nSELECT c.title, v.channel, v.duration, v.video_id\nFROM collections c\nJOIN videos v ON c.id = v.collection_id\nWHERE v.transcript_available = 1;\n\n-- Videos by channel\nSELECT c.title, v.video_id, v.views\nFROM collections c\nJOIN videos v ON c.id = v.collection_id\nWHERE v.channel = '3Blue1Brown'\nORDER BY v.views DESC;\n\n-- Long videos (&gt;30 minutes)\nSELECT c.title, v.duration/60 as duration_minutes\nFROM collections c\nJOIN videos v ON c.id = v.collection_id\nWHERE v.duration &gt; 1800\nORDER BY v.duration DESC;\n\n-- Most viewed videos\nSELECT c.title, v.channel, v.views\nFROM collections c\nJOIN videos v ON c.id = v.collection_id\nORDER BY v.views DESC\nLIMIT 10;\n</code></pre>"},{"location":"database/type-tables/#podcasts-table","title":"Podcasts Table","text":""},{"location":"database/type-tables/#overview_3","title":"Overview","text":"<p>Stores metadata for podcast episodes collected from RSS feeds.</p>"},{"location":"database/type-tables/#table-definition_2","title":"Table Definition","text":"<pre><code>CREATE TABLE IF NOT EXISTS podcasts (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    collection_id INTEGER,\n    episode_id TEXT,\n    podcast_name TEXT,\n    audio_url TEXT,\n    duration INTEGER,\n    FOREIGN KEY (collection_id) REFERENCES collections(id)\n)\n</code></pre>"},{"location":"database/type-tables/#fields_2","title":"Fields","text":""},{"location":"database/type-tables/#id_2","title":"id","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: <code>PRIMARY KEY AUTOINCREMENT</code></li> <li>Description: Unique identifier for the podcast record</li> <li>Example: <code>1</code></li> </ul>"},{"location":"database/type-tables/#collection_id_2","title":"collection_id","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: <code>FOREIGN KEY \u2192 collections(id)</code></li> <li>Description: References the parent collection record</li> <li>Example: <code>44</code></li> </ul>"},{"location":"database/type-tables/#episode_id","title":"episode_id","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: Unique identifier for the podcast episode</li> <li>Format: Varies by podcast platform (GUID from RSS feed)</li> <li>Example: <code>'ep-123-ai-safety'</code>, <code>'https://podcast.example.com/episode/456'</code></li> </ul>"},{"location":"database/type-tables/#podcast_name","title":"podcast_name","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: Name of the podcast show</li> <li>Example: <code>'The AI Podcast'</code>, <code>'Lex Fridman Podcast'</code></li> </ul>"},{"location":"database/type-tables/#audio_url","title":"audio_url","text":"<ul> <li>Type: <code>TEXT</code></li> <li>Constraints: None (nullable)</li> <li>Description: Direct URL to the audio file (MP3, M4A, etc.)</li> <li>Example: <code>'https://podcast.example.com/audio/episode-123.mp3'</code></li> <li>Usage: For downloading or streaming the episode</li> </ul>"},{"location":"database/type-tables/#duration_1","title":"duration","text":"<ul> <li>Type: <code>INTEGER</code></li> <li>Constraints: None (nullable)</li> <li>Description: Episode duration in seconds</li> <li>Example: <code>3600</code> (1 hour), <code>5400</code> (1.5 hours)</li> <li>Display: Convert to <code>HH:MM:SS</code> format in UI</li> </ul>"},{"location":"database/type-tables/#example-data_2","title":"Example Data","text":"<pre><code>{\n  \"id\": 1,\n  \"collection_id\": 44,\n  \"episode_id\": \"ep-312-yann-lecun\",\n  \"podcast_name\": \"Lex Fridman Podcast\",\n  \"audio_url\": \"https://lexfridman.com/audio/312-yann-lecun.mp3\",\n  \"duration\": 7200\n}\n</code></pre>"},{"location":"database/type-tables/#common-queries_2","title":"Common Queries","text":"<pre><code>-- Get all podcasts with collection details\nSELECT c.title, p.podcast_name, p.duration, p.audio_url\nFROM collections c\nJOIN podcasts p ON c.id = p.collection_id\nORDER BY c.collection_date DESC;\n\n-- Episodes by podcast name\nSELECT c.title, p.episode_id, p.duration\nFROM collections c\nJOIN podcasts p ON c.id = p.collection_id\nWHERE p.podcast_name = 'Lex Fridman Podcast'\nORDER BY c.collection_date DESC;\n\n-- Long episodes (&gt;2 hours)\nSELECT c.title, p.podcast_name, p.duration/3600.0 as duration_hours\nFROM collections c\nJOIN podcasts p ON c.id = p.collection_id\nWHERE p.duration &gt; 7200\nORDER BY p.duration DESC;\n\n-- Total podcast duration by show\nSELECT p.podcast_name,\n       COUNT(*) as episode_count,\n       SUM(p.duration)/3600.0 as total_hours\nFROM collections c\nJOIN podcasts p ON c.id = p.collection_id\nGROUP BY p.podcast_name\nORDER BY total_hours DESC;\n</code></pre>"},{"location":"database/type-tables/#python-database-manager-usage","title":"Python Database Manager Usage","text":""},{"location":"database/type-tables/#adding-type-specific-records","title":"Adding Type-Specific Records","text":"<pre><code>from multi_modal_rag.database import CollectionDatabaseManager\n\ndb = CollectionDatabaseManager()\n\n# 1. Add paper\ncollection_id = db.add_collection(\n    content_type='paper',\n    title='Attention Is All You Need',\n    source='arxiv',\n    url='https://arxiv.org/abs/1706.03762',\n    metadata={}\n)\n\ndb.add_paper(collection_id, {\n    'arxiv_id': '1706.03762',\n    'abstract': 'The dominant sequence transduction models...',\n    'authors': ['Ashish Vaswani', 'Noam Shazeer'],\n    'published': '2017-06-12',\n    'categories': ['cs.CL', 'cs.AI'],\n    'local_path': 'data/papers/1706.03762.pdf'\n})\n\n# 2. Add video\ncollection_id = db.add_collection(\n    content_type='video',\n    title='Neural Networks Explained',\n    source='youtube',\n    url='https://youtube.com/watch?v=abc123',\n    metadata={}\n)\n\ndb.add_video(collection_id, {\n    'video_id': 'abc123',\n    'author': '3Blue1Brown',  # Maps to 'channel' field\n    'length': 1194,            # Maps to 'duration' field\n    'views': 1000000,\n    'thumbnail_url': 'https://i.ytimg.com/vi/abc123/maxresdefault.jpg',\n    'transcript': 'Full transcript text...'  # Boolean check for transcript_available\n})\n\n# 3. Add podcast\ncollection_id = db.add_collection(\n    content_type='podcast',\n    title='AI Safety Episode',\n    source='podcast_rss',\n    url='https://podcast.ai/ep42',\n    metadata={}\n)\n\ndb.add_podcast(collection_id, {\n    'episode_id': 'ep-42',\n    'podcast_name': 'AI Alignment Podcast',\n    'audio_url': 'https://podcast.ai/audio/ep42.mp3',\n    'duration': 3600\n})\n</code></pre>"},{"location":"database/type-tables/#retrieving-type-specific-data","title":"Retrieving Type-Specific Data","text":"<pre><code># Get full collection details with type-specific data\ndetails = db.get_collection_with_details(collection_id)\n\n# For a paper, details will include:\n# {\n#   'id': 42,\n#   'content_type': 'paper',\n#   'title': '...',\n#   'details': {\n#     'id': 1,\n#     'collection_id': 42,\n#     'arxiv_id': '1706.03762',\n#     'authors': ['Ashish Vaswani', ...],  # Parsed from JSON\n#     'categories': ['cs.CL', ...],         # Parsed from JSON\n#     ...\n#   }\n# }\n</code></pre>"},{"location":"database/type-tables/#indexing-recommendations","title":"Indexing Recommendations","text":"<pre><code>-- Papers\nCREATE INDEX idx_papers_collection_id ON papers(collection_id);\nCREATE INDEX idx_papers_arxiv_id ON papers(arxiv_id);\nCREATE INDEX idx_papers_pmc_id ON papers(pmc_id);\nCREATE INDEX idx_papers_published_date ON papers(published_date);\n\n-- Videos\nCREATE INDEX idx_videos_collection_id ON videos(collection_id);\nCREATE INDEX idx_videos_video_id ON videos(video_id);\nCREATE INDEX idx_videos_channel ON videos(channel);\nCREATE INDEX idx_videos_transcript_available ON videos(transcript_available);\n\n-- Podcasts\nCREATE INDEX idx_podcasts_collection_id ON podcasts(collection_id);\nCREATE INDEX idx_podcasts_episode_id ON podcasts(episode_id);\nCREATE INDEX idx_podcasts_podcast_name ON podcasts(podcast_name);\n</code></pre>"},{"location":"database/type-tables/#data-validation","title":"Data Validation","text":""},{"location":"database/type-tables/#papers","title":"Papers","text":"<ul> <li>At least one of <code>arxiv_id</code> or <code>pmc_id</code> should be present</li> <li><code>authors</code> must be valid JSON array</li> <li><code>categories</code> must be valid JSON array</li> <li><code>published_date</code> should be in ISO format (YYYY-MM-DD)</li> </ul>"},{"location":"database/type-tables/#videos","title":"Videos","text":"<ul> <li><code>video_id</code> should be 11 characters</li> <li><code>duration</code> and <code>views</code> should be non-negative integers</li> <li><code>thumbnail_url</code> should be valid URL</li> <li><code>transcript_available</code> should be 0 or 1</li> </ul>"},{"location":"database/type-tables/#podcasts","title":"Podcasts","text":"<ul> <li><code>episode_id</code> should be unique within a podcast</li> <li><code>audio_url</code> should be valid URL</li> <li><code>duration</code> should be non-negative integer</li> </ul>"},{"location":"database/type-tables/#troubleshooting","title":"Troubleshooting","text":""},{"location":"database/type-tables/#issue-json-parse-errors","title":"Issue: JSON Parse Errors","text":"<p>Cause: Invalid JSON in <code>authors</code> or <code>categories</code> fields</p> <p>Solution: Always use <code>json.dumps()</code> when inserting: <pre><code>import json\nauthors_json = json.dumps(['Author 1', 'Author 2'])\n</code></pre></p>"},{"location":"database/type-tables/#issue-orphaned-type-records","title":"Issue: Orphaned Type Records","text":"<p>Cause: Deleting from <code>collections</code> without deleting from type tables</p> <p>Solution: Delete in correct order: <pre><code># First delete type-specific record\ncursor.execute(\"DELETE FROM papers WHERE collection_id = ?\", (id,))\n# Then delete collection\ncursor.execute(\"DELETE FROM collections WHERE id = ?\", (id,))\n</code></pre></p>"},{"location":"database/type-tables/#issue-duplicate-video-ids","title":"Issue: Duplicate Video IDs","text":"<p>Cause: Same video collected multiple times</p> <p>Solution: Check before inserting: <pre><code>SELECT COUNT(*) FROM videos WHERE video_id = ?;\n</code></pre></p> <p>Or add UNIQUE constraint: <pre><code>CREATE UNIQUE INDEX idx_unique_video_id ON videos(video_id);\n</code></pre></p>"},{"location":"deployment/","title":"Deployment Documentation","text":"<p>Comprehensive deployment guides for the Multi-Modal Academic Research System.</p>"},{"location":"deployment/#quick-links","title":"Quick Links","text":"<ul> <li>Local Deployment - Development environment setup</li> <li>Docker Deployment - Containerized deployment</li> <li>OpenSearch Setup - Search engine configuration</li> <li>Production Considerations - Production deployment</li> </ul>"},{"location":"deployment/#documentation-overview","title":"Documentation Overview","text":""},{"location":"deployment/#1-local-deployment-guide-localmd","title":"1. Local Deployment Guide (<code>local.md</code>)","text":"<p>Complete guide for setting up and running the application on your local machine.</p> <p>Contents: - Prerequisites and system requirements - Virtual environment setup - Environment configuration - Running the application - Running multiple instances - Port configuration - Development workflow - Comprehensive troubleshooting (10+ common issues)</p> <p>Best for: - Local development - Testing and debugging - Learning the system - Quick prototyping</p> <p>File size: ~800 lines | 15KB</p>"},{"location":"deployment/#2-docker-deployment-dockermd","title":"2. Docker Deployment (<code>docker.md</code>)","text":"<p>Containerization guide using Docker and Docker Compose.</p> <p>Contents: - Dockerfile creation with best practices - Multi-service Docker Compose setup - Volume management and data persistence - Container orchestration and lifecycle - Networking configuration - Health checks and monitoring - Performance optimization - Troubleshooting containerized deployments</p> <p>Best for: - Consistent environments - CI/CD pipelines - Easy deployment across teams - Isolated testing</p> <p>File size: ~850 lines | 18KB</p>"},{"location":"deployment/#3-opensearch-setup-opensearchmd","title":"3. OpenSearch Setup (<code>opensearch.md</code>)","text":"<p>Deep dive into OpenSearch installation, configuration, and optimization.</p> <p>Contents: - Installation methods (Docker, native, Homebrew) - Configuration for development and production - Index management and optimization - Security configuration (SSL/TLS, authentication) - Performance tuning - Single-node and multi-node cluster setup - Backup and restore strategies - Monitoring and maintenance - Troubleshooting and debugging</p> <p>Best for: - Understanding search infrastructure - Optimizing search performance - Setting up production search clusters - Data backup and recovery</p> <p>File size: ~1,250 lines | 28KB</p>"},{"location":"deployment/#4-production-considerations-productionmd","title":"4. Production Considerations (<code>production.md</code>)","text":"<p>Production-ready deployment strategies and best practices.</p> <p>Contents: - Production architecture (multi-tier, multi-region) - Scaling strategies (vertical and horizontal) - Performance optimization (caching, connection pooling, async) - Security hardening (authentication, network security, secrets management) - Comprehensive monitoring and logging (ELK, Prometheus, Grafana) - Backup strategies and disaster recovery - High availability setup - Load balancing (Nginx, HAProxy) - Cost optimization - Complete deployment checklist</p> <p>Best for: - Production deployments - High-traffic applications - Enterprise environments - Mission-critical systems</p> <p>File size: ~1,300 lines | 30KB</p>"},{"location":"deployment/#deployment-path-recommendations","title":"Deployment Path Recommendations","text":""},{"location":"deployment/#for-developers","title":"For Developers","text":"<ol> <li>Start with Local Deployment to understand the system</li> <li>Move to Docker Deployment for consistent environments</li> <li>Review OpenSearch Setup for search optimization</li> </ol>"},{"location":"deployment/#for-devops-engineers","title":"For DevOps Engineers","text":"<ol> <li>Review Docker Deployment for containerization</li> <li>Study OpenSearch Setup for infrastructure</li> <li>Implement Production Considerations for deployment</li> </ol>"},{"location":"deployment/#for-system-architects","title":"For System Architects","text":"<ol> <li>Read Production Considerations for architecture</li> <li>Reference OpenSearch Setup for cluster design</li> <li>Use Docker Deployment for orchestration</li> </ol>"},{"location":"deployment/#for-quick-start","title":"For Quick Start","text":"<ol> <li>Follow Local Deployment to get running in 10 minutes</li> <li>Use Docker commands from Docker Deployment for single-command deployment</li> </ol>"},{"location":"deployment/#key-features-across-documentation","title":"Key Features Across Documentation","text":""},{"location":"deployment/#configuration-examples","title":"Configuration Examples","text":"<p>All guides include: - Complete configuration files - Environment variable setups - Command-line examples - Code snippets</p>"},{"location":"deployment/#troubleshooting","title":"Troubleshooting","text":"<p>Comprehensive troubleshooting sections with: - Common issues and solutions - Debug commands - Error explanations - Performance tips</p>"},{"location":"deployment/#security","title":"Security","text":"<p>Security guidance including: - SSL/TLS configuration - Authentication and authorization - Network security - Secrets management - Best practices</p>"},{"location":"deployment/#monitoring","title":"Monitoring","text":"<p>Monitoring setup with: - Health checks - Metrics collection - Logging configuration - Alerting setup</p>"},{"location":"deployment/#quick-start-commands","title":"Quick Start Commands","text":""},{"location":"deployment/#local-development","title":"Local Development","text":"<pre><code># Setup\npython -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\ncp .env.example .env\n# Edit .env with your GEMINI_API_KEY\n\n# Start OpenSearch\ndocker run -d -p 9200:9200 -e \"discovery.type=single-node\" opensearchproject/opensearch:latest\n\n# Run application\npython main.py\n</code></pre>"},{"location":"deployment/#docker-deployment","title":"Docker Deployment","text":"<pre><code># Start everything with Docker Compose\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f\n\n# Stop services\ndocker-compose down\n</code></pre>"},{"location":"deployment/#production-deployment","title":"Production Deployment","text":"<p>See Production Considerations for complete production setup.</p>"},{"location":"deployment/#system-requirements","title":"System Requirements","text":""},{"location":"deployment/#minimum-development","title":"Minimum (Development)","text":"<ul> <li>CPU: 2 cores</li> <li>RAM: 4GB</li> <li>Disk: 10GB</li> <li>OS: macOS, Linux, or Windows</li> </ul>"},{"location":"deployment/#recommended-production","title":"Recommended (Production)","text":"<ul> <li>CPU: 4+ cores</li> <li>RAM: 8GB+</li> <li>Disk: 50GB+ SSD</li> <li>OS: Linux (Ubuntu/CentOS)</li> </ul>"},{"location":"deployment/#additional-resources","title":"Additional Resources","text":""},{"location":"deployment/#external-documentation","title":"External Documentation","text":"<ul> <li>OpenSearch Documentation</li> <li>Docker Documentation</li> <li>Gradio Documentation</li> <li>Google Gemini API</li> </ul>"},{"location":"deployment/#project-documentation","title":"Project Documentation","text":"<ul> <li>Main README: <code>../../README.md</code></li> <li>Project Guidelines: <code>../../CLAUDE.md</code></li> <li>API Documentation: Coming soon</li> <li>Architecture Diagrams: Coming soon</li> </ul>"},{"location":"deployment/#support-and-contribution","title":"Support and Contribution","text":""},{"location":"deployment/#getting-help","title":"Getting Help","text":"<ol> <li>Check the relevant guide's troubleshooting section</li> <li>Review logs: <code>logs/research_assistant.log</code></li> <li>Search GitHub issues</li> <li>Create a new issue with:</li> <li>Deployment method (local/docker/production)</li> <li>Error messages</li> <li>Configuration details</li> <li>Steps to reproduce</li> </ol>"},{"location":"deployment/#contributing","title":"Contributing","text":"<p>Contributions to improve deployment documentation are welcome:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Submit a pull request</li> </ol>"},{"location":"deployment/#documentation-updates","title":"Documentation Updates","text":"<p>If you find: - Missing information - Outdated commands - Errors or typos - Opportunities for improvement</p> <p>Please create an issue or submit a PR.</p>"},{"location":"deployment/#version-history","title":"Version History","text":"<ul> <li>v1.0.0 (2025-10-02) - Initial comprehensive deployment documentation</li> <li>Local deployment guide</li> <li>Docker deployment guide</li> <li>OpenSearch setup guide</li> <li>Production considerations guide</li> </ul>"},{"location":"deployment/#license","title":"License","text":"<p>This documentation is part of the Multi-Modal Academic Research System project.</p>"},{"location":"deployment/#summary","title":"Summary","text":"<p>Total documentation: 4,185 lines across 4 comprehensive guides covering every aspect of deploying the Multi-Modal Academic Research System from local development to enterprise-scale production.</p>"},{"location":"deployment/docker/","title":"Docker Deployment Guide","text":"<p>This guide covers containerizing the Multi-Modal Academic Research System using Docker and Docker Compose for easy deployment and management.</p>"},{"location":"deployment/docker/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Prerequisites</li> <li>Docker Setup</li> <li>Docker Compose Setup</li> <li>Building and Running</li> <li>Volume Management</li> <li>Container Orchestration</li> <li>Networking</li> <li>Troubleshooting</li> </ol>"},{"location":"deployment/docker/#overview","title":"Overview","text":""},{"location":"deployment/docker/#benefits-of-docker-deployment","title":"Benefits of Docker Deployment","text":"<ul> <li>Consistency: Same environment across development, testing, and production</li> <li>Isolation: Dependencies contained within containers</li> <li>Portability: Deploy anywhere Docker runs</li> <li>Scalability: Easy to scale services independently</li> <li>Version Control: Infrastructure as code</li> </ul>"},{"location":"deployment/docker/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Docker Compose Stack              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                             \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502                  \u2502  \u2502                  \u2502\u2502\n\u2502  \u2502   Research App   \u2502\u2190\u2192\u2502   OpenSearch    \u2502\u2502\n\u2502  \u2502   (Port 7860)    \u2502  \u2502   (Port 9200)   \u2502\u2502\n\u2502  \u2502                  \u2502  \u2502                  \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502           \u2193                      \u2193          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u2502\n\u2502  \u2502  App Data Volume \u2502  \u2502  OS Data Volume  \u2502\u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\u2502\n\u2502                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"deployment/docker/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/docker/#required-software","title":"Required Software","text":"<ol> <li> <p>Docker Engine (version 20.10+)    <pre><code>docker --version\n# Docker version 20.10.x or higher\n</code></pre></p> </li> <li> <p>Docker Compose (version 2.0+)    <pre><code>docker-compose --version\n# Docker Compose version 2.x.x or higher\n</code></pre></p> </li> </ol>"},{"location":"deployment/docker/#installation","title":"Installation","text":"<p>macOS: <pre><code># Install Docker Desktop\nbrew install --cask docker\n\n# Or download from: https://www.docker.com/products/docker-desktop\n</code></pre></p> <p>Linux (Ubuntu/Debian): <pre><code># Update package index\nsudo apt-get update\n\n# Install dependencies\nsudo apt-get install ca-certificates curl gnupg lsb-release\n\n# Add Docker's official GPG key\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\n# Set up repository\necho \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\n# Install Docker Engine\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\n# Add user to docker group\nsudo usermod -aG docker $USER\nnewgrp docker\n</code></pre></p> <p>Windows: <pre><code># Download and install Docker Desktop from:\n# https://www.docker.com/products/docker-desktop\n</code></pre></p>"},{"location":"deployment/docker/#docker-setup","title":"Docker Setup","text":""},{"location":"deployment/docker/#1-create-dockerfile-for-application","title":"1. Create Dockerfile for Application","text":"<p>Create <code>Dockerfile</code> in project root:</p> <pre><code># Use official Python runtime as base image\nFROM python:3.11-slim\n\n# Set working directory\nWORKDIR /app\n\n# Set environment variables\nENV PYTHONUNBUFFERED=1 \\\n    PYTHONDONTWRITEBYTECODE=1 \\\n    PIP_NO_CACHE_DIR=1 \\\n    PIP_DISABLE_PIP_VERSION_CHECK=1\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    build-essential \\\n    curl \\\n    git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# Copy requirements first (for layer caching)\nCOPY requirements.txt .\n\n# Install Python dependencies\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy application code\nCOPY . .\n\n# Create necessary directories\nRUN mkdir -p data/papers data/videos data/podcasts data/processed logs configs\n\n# Set permissions\nRUN chmod -R 755 data logs configs\n\n# Expose Gradio port\nEXPOSE 7860\n\n# Health check\nHEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \\\n    CMD curl -f http://localhost:7860/ || exit 1\n\n# Run application\nCMD [\"python\", \"main.py\"]\n</code></pre>"},{"location":"deployment/docker/#2-create-dockerignore","title":"2. Create .dockerignore","text":"<p>Create <code>.dockerignore</code> to exclude unnecessary files:</p> <pre><code># Virtual environments\nvenv/\nenv/\nENV/\n*.pyc\n__pycache__/\n\n# IDE files\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# Git\n.git/\n.gitignore\n\n# Data directories (will use volumes)\ndata/\nlogs/\n\n# Environment files with secrets\n.env\n\n# Documentation\ndocs/\n*.md\n!README.md\n\n# Test files\ntests/\n*.pytest_cache/\n\n# OS files\n.DS_Store\nThumbs.db\n\n# Build artifacts\nbuild/\ndist/\n*.egg-info/\n</code></pre>"},{"location":"deployment/docker/#3-build-docker-image","title":"3. Build Docker Image","text":"<pre><code># Build image with tag\ndocker build -t research-assistant:latest .\n\n# Build with specific version\ndocker build -t research-assistant:v1.0.0 .\n\n# Build with no cache (clean build)\ndocker build --no-cache -t research-assistant:latest .\n\n# Verify image\ndocker images | grep research-assistant\n</code></pre>"},{"location":"deployment/docker/#4-run-single-container","title":"4. Run Single Container","text":"<pre><code># Run with environment variables\ndocker run -d \\\n  --name research-assistant \\\n  -p 7860:7860 \\\n  -e GEMINI_API_KEY=your_api_key_here \\\n  -e OPENSEARCH_HOST=opensearch \\\n  -e OPENSEARCH_PORT=9200 \\\n  -v $(pwd)/data:/app/data \\\n  -v $(pwd)/logs:/app/logs \\\n  research-assistant:latest\n\n# Check logs\ndocker logs -f research-assistant\n\n# Stop container\ndocker stop research-assistant\n\n# Remove container\ndocker rm research-assistant\n</code></pre>"},{"location":"deployment/docker/#docker-compose-setup","title":"Docker Compose Setup","text":""},{"location":"deployment/docker/#1-create-docker-composeyml","title":"1. Create docker-compose.yml","text":"<p>Create <code>docker-compose.yml</code> in project root:</p> <pre><code>version: '3.8'\n\nservices:\n  # OpenSearch service\n  opensearch:\n    image: opensearchproject/opensearch:2.11.0\n    container_name: opensearch-node\n    environment:\n      - discovery.type=single-node\n      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword123!\n      - bootstrap.memory_lock=true\n      - \"OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g\"\n      - cluster.name=research-cluster\n      - node.name=opensearch-node\n      - plugins.security.disabled=true  # Disable for development\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n      nofile:\n        soft: 65536\n        hard: 65536\n    volumes:\n      - opensearch-data:/usr/share/opensearch/data\n    ports:\n      - \"9200:9200\"\n      - \"9600:9600\"\n    networks:\n      - research-network\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:9200/_cluster/health || exit 1\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n      start_period: 60s\n\n  # Research Assistant application\n  research-app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    container_name: research-assistant-app\n    depends_on:\n      opensearch:\n        condition: service_healthy\n    environment:\n      - GEMINI_API_KEY=${GEMINI_API_KEY}\n      - OPENSEARCH_HOST=opensearch\n      - OPENSEARCH_PORT=9200\n      - OPENSEARCH_USER=admin\n      - OPENSEARCH_PASSWORD=MyStrongPassword123!\n      - OPENSEARCH_USE_SSL=false\n      - OPENSEARCH_VERIFY_CERTS=false\n      - GRADIO_SERVER_NAME=0.0.0.0\n      - GRADIO_SERVER_PORT=7860\n      - GRADIO_SHARE=true\n    volumes:\n      - ./data:/app/data\n      - ./logs:/app/logs\n      - ./configs:/app/configs\n    ports:\n      - \"7860:7860\"\n    networks:\n      - research-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD-SHELL\", \"curl -f http://localhost:7860/ || exit 1\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 60s\n\nnetworks:\n  research-network:\n    driver: bridge\n\nvolumes:\n  opensearch-data:\n    driver: local\n</code></pre>"},{"location":"deployment/docker/#2-create-docker-composeoverrideyml-optional","title":"2. Create docker-compose.override.yml (Optional)","text":"<p>For development-specific settings:</p> <pre><code>version: '3.8'\n\nservices:\n  research-app:\n    environment:\n      - LOG_LEVEL=DEBUG\n      - GRADIO_SHARE=false\n    volumes:\n      - .:/app  # Mount entire directory for live code updates\n    command: python main.py --debug\n</code></pre>"},{"location":"deployment/docker/#3-create-production-docker-composeprodyml","title":"3. Create Production docker-compose.prod.yml","text":"<pre><code>version: '3.8'\n\nservices:\n  opensearch:\n    environment:\n      - \"OPENSEARCH_JAVA_OPTS=-Xms4g -Xmx4g\"  # More memory\n      - plugins.security.disabled=false  # Enable security\n      - plugins.security.ssl.http.enabled=true\n    deploy:\n      resources:\n        limits:\n          cpus: '2'\n          memory: 4G\n        reservations:\n          memory: 2G\n\n  research-app:\n    environment:\n      - LOG_LEVEL=INFO\n      - GRADIO_SHARE=false\n    deploy:\n      replicas: 2  # Run 2 instances\n      resources:\n        limits:\n          cpus: '1'\n          memory: 2G\n        reservations:\n          memory: 1G\n    restart: always\n</code></pre>"},{"location":"deployment/docker/#building-and-running","title":"Building and Running","text":""},{"location":"deployment/docker/#development-environment","title":"Development Environment","text":"<pre><code># Start all services\ndocker-compose up -d\n\n# View logs\ndocker-compose logs -f\n\n# View specific service logs\ndocker-compose logs -f research-app\ndocker-compose logs -f opensearch\n\n# Stop services\ndocker-compose stop\n\n# Start stopped services\ndocker-compose start\n\n# Restart services\ndocker-compose restart\n\n# Stop and remove containers\ndocker-compose down\n\n# Stop and remove containers, networks, volumes\ndocker-compose down -v\n</code></pre>"},{"location":"deployment/docker/#production-environment","title":"Production Environment","text":"<pre><code># Build and start with production config\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n\n# Scale application\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --scale research-app=3\n\n# View status\ndocker-compose ps\n\n# Stop production\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml down\n</code></pre>"},{"location":"deployment/docker/#rebuild-after-code-changes","title":"Rebuild After Code Changes","text":"<pre><code># Rebuild and restart\ndocker-compose up -d --build\n\n# Rebuild specific service\ndocker-compose build research-app\ndocker-compose up -d research-app\n\n# Force rebuild (no cache)\ndocker-compose build --no-cache\ndocker-compose up -d\n</code></pre>"},{"location":"deployment/docker/#volume-management","title":"Volume Management","text":""},{"location":"deployment/docker/#understanding-volumes","title":"Understanding Volumes","text":"<p>Volumes persist data outside containers:</p> <ol> <li>opensearch-data: OpenSearch indices and data</li> <li>./data: Application data (papers, videos, podcasts)</li> <li>./logs: Application logs</li> <li>./configs: Configuration files</li> </ol>"},{"location":"deployment/docker/#volume-operations","title":"Volume Operations","text":"<pre><code># List volumes\ndocker volume ls\n\n# Inspect volume\ndocker volume inspect multi-modal-academic-research-system_opensearch-data\n\n# Backup volume\ndocker run --rm \\\n  -v multi-modal-academic-research-system_opensearch-data:/data \\\n  -v $(pwd)/backups:/backup \\\n  alpine tar czf /backup/opensearch-backup-$(date +%Y%m%d).tar.gz -C /data .\n\n# Restore volume\ndocker run --rm \\\n  -v multi-modal-academic-research-system_opensearch-data:/data \\\n  -v $(pwd)/backups:/backup \\\n  alpine tar xzf /backup/opensearch-backup-20240101.tar.gz -C /data\n\n# Remove unused volumes\ndocker volume prune\n\n# Remove specific volume (WARNING: deletes data)\ndocker volume rm multi-modal-academic-research-system_opensearch-data\n</code></pre>"},{"location":"deployment/docker/#bind-mounts-vs-named-volumes","title":"Bind Mounts vs Named Volumes","text":"<p>Bind Mounts (./data:/app/data): - Direct mapping to host directory - Easy access from host - Good for development and logs</p> <p>Named Volumes (opensearch-data): - Managed by Docker - Better performance - Good for databases</p>"},{"location":"deployment/docker/#container-orchestration","title":"Container Orchestration","text":""},{"location":"deployment/docker/#managing-container-lifecycle","title":"Managing Container Lifecycle","text":"<pre><code># Start containers\ndocker-compose start\n\n# Stop containers (preserves containers)\ndocker-compose stop\n\n# Pause containers (freeze processes)\ndocker-compose pause\n\n# Unpause containers\ndocker-compose unpause\n\n# Restart containers\ndocker-compose restart\n\n# Remove stopped containers\ndocker-compose rm\n\n# Stop and remove containers, networks\ndocker-compose down\n</code></pre>"},{"location":"deployment/docker/#scaling-services","title":"Scaling Services","text":"<pre><code># Scale to 3 instances\ndocker-compose up -d --scale research-app=3\n\n# Scale with load balancer (requires nginx)\ndocker-compose up -d --scale research-app=3 nginx\n</code></pre>"},{"location":"deployment/docker/#health-checks","title":"Health Checks","text":"<pre><code># Check container health\ndocker ps --format \"table {{.Names}}\\t{{.Status}}\"\n\n# Inspect health check\ndocker inspect --format='{{json .State.Health}}' research-assistant-app | jq\n\n# View health check logs\ndocker inspect research-assistant-app | jq '.[0].State.Health.Log'\n</code></pre>"},{"location":"deployment/docker/#resource-management","title":"Resource Management","text":"<p>Limit CPU and Memory:</p> <pre><code>services:\n  research-app:\n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 2G\n        reservations:\n          cpus: '0.5'\n          memory: 1G\n</code></pre> <p>Monitor Resource Usage:</p> <pre><code># Real-time stats\ndocker stats\n\n# Specific container\ndocker stats research-assistant-app\n\n# Export stats to file\ndocker stats --no-stream &gt; stats.txt\n</code></pre>"},{"location":"deployment/docker/#networking","title":"Networking","text":""},{"location":"deployment/docker/#network-configuration","title":"Network Configuration","text":"<pre><code># List networks\ndocker network ls\n\n# Inspect network\ndocker network inspect multi-modal-academic-research-system_research-network\n\n# Test connectivity between containers\ndocker exec research-assistant-app ping opensearch\n\n# Check DNS resolution\ndocker exec research-assistant-app nslookup opensearch\n</code></pre>"},{"location":"deployment/docker/#expose-additional-ports","title":"Expose Additional Ports","text":"<pre><code>services:\n  research-app:\n    ports:\n      - \"7860:7860\"  # Main app\n      - \"7861:7861\"  # Admin interface (if added)\n      - \"8080:8080\"  # Health check endpoint\n</code></pre>"},{"location":"deployment/docker/#use-host-network-not-recommended","title":"Use Host Network (Not Recommended)","text":"<pre><code>services:\n  research-app:\n    network_mode: \"host\"\n</code></pre>"},{"location":"deployment/docker/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/docker/#common-issues","title":"Common Issues","text":""},{"location":"deployment/docker/#1-container-wont-start","title":"1. Container Won't Start","text":"<pre><code># Check logs\ndocker-compose logs research-app\n\n# Check last 100 lines\ndocker-compose logs --tail=100 research-app\n\n# Follow logs in real-time\ndocker-compose logs -f research-app\n\n# Check container status\ndocker-compose ps\n</code></pre>"},{"location":"deployment/docker/#2-opensearch-unhealthy","title":"2. OpenSearch Unhealthy","text":"<pre><code># Check OpenSearch logs\ndocker-compose logs opensearch\n\n# Check cluster health\ndocker exec opensearch-node curl http://localhost:9200/_cluster/health?pretty\n\n# Increase memory\n# Edit docker-compose.yml:\nenvironment:\n  - \"OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g\"\n\n# Restart\ndocker-compose restart opensearch\n</code></pre>"},{"location":"deployment/docker/#3-permission-denied-errors","title":"3. Permission Denied Errors","text":"<pre><code># Fix host directory permissions\nsudo chown -R $USER:$USER data/ logs/ configs/\nchmod -R 755 data/ logs/ configs/\n\n# Fix container permissions\ndocker exec -u root research-assistant-app chown -R nobody:nogroup /app/data\n</code></pre>"},{"location":"deployment/docker/#4-port-already-in-use","title":"4. Port Already in Use","text":"<pre><code># Find process using port\nlsof -i :7860\n\n# Change port in docker-compose.yml\nports:\n  - \"7861:7860\"  # Host:Container\n\n# Or stop conflicting service\ndocker stop &lt;container_name&gt;\n</code></pre>"},{"location":"deployment/docker/#5-cannot-connect-to-opensearch","title":"5. Cannot Connect to OpenSearch","text":"<pre><code># Test from host\ncurl http://localhost:9200\n\n# Test from container\ndocker exec research-assistant-app curl http://opensearch:9200\n\n# Check network connectivity\ndocker network inspect multi-modal-academic-research-system_research-network\n\n# Verify service names in docker-compose.yml match environment variables\n</code></pre>"},{"location":"deployment/docker/#6-out-of-disk-space","title":"6. Out of Disk Space","text":"<pre><code># Check disk usage\ndocker system df\n\n# Remove unused data\ndocker system prune\n\n# Remove all unused images, containers, volumes\ndocker system prune -a --volumes\n\n# Remove specific items\ndocker image prune\ndocker container prune\ndocker volume prune\n</code></pre>"},{"location":"deployment/docker/#7-build-fails","title":"7. Build Fails","text":"<pre><code># Clean build\ndocker-compose build --no-cache\n\n# Check Docker logs\ndocker-compose logs --tail=50\n\n# Verify Dockerfile syntax\ndocker build --dry-run -t test .\n\n# Build with verbose output\ndocker-compose build --progress=plain\n</code></pre>"},{"location":"deployment/docker/#8-container-exits-immediately","title":"8. Container Exits Immediately","text":"<pre><code># Check exit code\ndocker-compose ps\n\n# View last container logs\ndocker logs $(docker ps -lq)\n\n# Run interactive shell to debug\ndocker run -it --rm research-assistant:latest /bin/bash\n\n# Override entrypoint\ndocker run -it --rm --entrypoint /bin/bash research-assistant:latest\n</code></pre>"},{"location":"deployment/docker/#9-volume-mount-issues","title":"9. Volume Mount Issues","text":"<pre><code># Verify volume exists\ndocker volume ls | grep opensearch-data\n\n# Check mount points\ndocker inspect research-assistant-app | jq '.[0].Mounts'\n\n# Test volume permissions\ndocker run --rm -v $(pwd)/data:/test alpine ls -la /test\n</code></pre>"},{"location":"deployment/docker/#10-network-issues","title":"10. Network Issues","text":"<pre><code># Recreate network\ndocker-compose down\ndocker network prune\ndocker-compose up -d\n\n# Check DNS resolution\ndocker exec research-assistant-app cat /etc/hosts\ndocker exec research-assistant-app nslookup opensearch\n\n# Test connectivity\ndocker exec research-assistant-app telnet opensearch 9200\n</code></pre>"},{"location":"deployment/docker/#debug-commands","title":"Debug Commands","text":"<pre><code># Shell into container\ndocker exec -it research-assistant-app /bin/bash\n\n# Run as root\ndocker exec -u root -it research-assistant-app /bin/bash\n\n# Copy files from container\ndocker cp research-assistant-app:/app/logs/research_assistant.log ./\n\n# Copy files to container\ndocker cp config.json research-assistant-app:/app/configs/\n\n# View container processes\ndocker top research-assistant-app\n\n# View container resource usage\ndocker stats research-assistant-app --no-stream\n\n# Inspect container details\ndocker inspect research-assistant-app\n\n# View container environment variables\ndocker exec research-assistant-app env\n</code></pre>"},{"location":"deployment/docker/#performance-optimization","title":"Performance Optimization","text":"<pre><code># Optimize Docker Desktop (macOS)\n# Increase resources in Docker Desktop settings:\n# - CPUs: 4+\n# - Memory: 8GB+\n# - Swap: 2GB+\n\n# Enable BuildKit for faster builds\nexport DOCKER_BUILDKIT=1\ndocker-compose build\n\n# Use multi-stage builds\n# Add to Dockerfile:\n# FROM python:3.11-slim as builder\n# ... build steps ...\n# FROM python:3.11-slim\n# COPY --from=builder ...\n\n# Layer caching optimization\n# Order Dockerfile commands from least to most frequently changing\n</code></pre>"},{"location":"deployment/docker/#logging-best-practices","title":"Logging Best Practices","text":"<pre><code># Configure log rotation in docker-compose.yml\nservices:\n  research-app:\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\n# View logs with timestamps\ndocker-compose logs -f -t research-app\n\n# Export logs\ndocker-compose logs research-app &gt; app-logs.txt\n</code></pre>"},{"location":"deployment/docker/#next-steps","title":"Next Steps","text":"<ul> <li>Review OpenSearch Setup for advanced OpenSearch configuration</li> <li>See Production Considerations for production deployment</li> <li>Check Local Deployment for development workflow</li> </ul>"},{"location":"deployment/local/","title":"Local Deployment Guide","text":"<p>This guide covers setting up and running the Multi-Modal Academic Research System on your local development machine.</p>"},{"location":"deployment/local/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisites</li> <li>Initial Setup</li> <li>Environment Configuration</li> <li>Running the Application</li> <li>Running Multiple Instances</li> <li>Port Configuration</li> <li>Local Development Workflow</li> <li>Troubleshooting</li> </ol>"},{"location":"deployment/local/#prerequisites","title":"Prerequisites","text":""},{"location":"deployment/local/#system-requirements","title":"System Requirements","text":"<ul> <li>Operating System: macOS, Linux, or Windows 10/11</li> <li>Python: Version 3.9 or higher</li> <li>RAM: Minimum 4GB, recommended 8GB+</li> <li>Disk Space: Minimum 5GB for application and data</li> <li>Docker: For running OpenSearch (or install OpenSearch natively)</li> </ul>"},{"location":"deployment/local/#required-software","title":"Required Software","text":"<ol> <li> <p>Python 3.9+ <pre><code># Check Python version\npython --version\n# or\npython3 --version\n</code></pre></p> </li> <li> <p>pip (Python package manager)    <pre><code># Check pip version\npip --version\n</code></pre></p> </li> <li> <p>Docker Desktop (recommended for OpenSearch)</p> </li> <li>Download from: https://www.docker.com/products/docker-desktop</li> <li> <p>Verify installation:      <pre><code>docker --version\ndocker-compose --version\n</code></pre></p> </li> <li> <p>Git (for cloning repository)    <pre><code>git --version\n</code></pre></p> </li> </ol>"},{"location":"deployment/local/#initial-setup","title":"Initial Setup","text":""},{"location":"deployment/local/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code># Clone the repository\ngit clone &lt;repository-url&gt;\ncd multi-modal-academic-research-system\n\n# Verify repository structure\nls -la\n</code></pre>"},{"location":"deployment/local/#2-create-virtual-environment","title":"2. Create Virtual Environment","text":"<p>Using a virtual environment isolates project dependencies from your system Python.</p> <p>macOS/Linux: <pre><code># Create virtual environment\npython3 -m venv venv\n\n# Activate virtual environment\nsource venv/bin/activate\n\n# Verify activation (should show venv in path)\nwhich python\n</code></pre></p> <p>Windows: <pre><code># Create virtual environment\npython -m venv venv\n\n# Activate virtual environment\nvenv\\Scripts\\activate\n\n# Verify activation\nwhere python\n</code></pre></p>"},{"location":"deployment/local/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code># Upgrade pip to latest version\npip install --upgrade pip\n\n# Install all required packages\npip install -r requirements.txt\n\n# Verify installation\npip list\n</code></pre> <p>Expected Key Packages: - opensearch-py==2.4.0 - langchain==0.2.16 - google-generativeai==0.7.2 - gradio==4.8.0 - sentence-transformers==2.7.0</p>"},{"location":"deployment/local/#4-create-data-directories","title":"4. Create Data Directories","text":"<p>The application stores data in various directories:</p> <pre><code># Create all necessary directories\nmkdir -p data/papers\nmkdir -p data/videos\nmkdir -p data/podcasts\nmkdir -p data/processed\nmkdir -p configs\nmkdir -p logs\n\n# Verify directory structure\ntree -d -L 2\n</code></pre>"},{"location":"deployment/local/#environment-configuration","title":"Environment Configuration","text":""},{"location":"deployment/local/#1-create-environment-file","title":"1. Create Environment File","text":"<pre><code># Copy example environment file\ncp .env.example .env\n\n# Edit the file with your preferred editor\nnano .env\n# or\nvim .env\n# or\ncode .env  # VS Code\n</code></pre>"},{"location":"deployment/local/#2-configure-environment-variables","title":"2. Configure Environment Variables","text":"<p>Edit <code>.env</code> file with the following configuration:</p> <pre><code># ============================================\n# API Keys (Required)\n# ============================================\n# Get your Gemini API key from: https://makersuite.google.com/app/apikey\nGEMINI_API_KEY=your_actual_api_key_here\n\n# ============================================\n# OpenSearch Configuration\n# ============================================\nOPENSEARCH_HOST=localhost\nOPENSEARCH_PORT=9200\nOPENSEARCH_USER=admin\nOPENSEARCH_PASSWORD=admin\nOPENSEARCH_USE_SSL=false\nOPENSEARCH_VERIFY_CERTS=false\n\n# ============================================\n# Application Configuration\n# ============================================\n# Gradio server settings\nGRADIO_SERVER_NAME=0.0.0.0\nGRADIO_SERVER_PORT=7860\nGRADIO_SHARE=true\n\n# Index name for OpenSearch\nOPENSEARCH_INDEX_NAME=research_assistant\n\n# Embedding model\nEMBEDDING_MODEL=all-MiniLM-L6-v2\nEMBEDDING_DIMENSION=384\n\n# ============================================\n# Data Collection Settings\n# ============================================\n# Maximum papers to collect per query\nMAX_PAPERS_PER_QUERY=10\n\n# Maximum videos to collect per query\nMAX_VIDEOS_PER_QUERY=10\n\n# Rate limiting (requests per minute)\nAPI_RATE_LIMIT=60\n\n# ============================================\n# Logging Configuration\n# ============================================\nLOG_LEVEL=INFO\nLOG_FILE=logs/research_assistant.log\n</code></pre>"},{"location":"deployment/local/#3-obtain-gemini-api-key","title":"3. Obtain Gemini API Key","text":"<p>The Gemini API key is required for the application to function:</p> <ol> <li>Visit: https://makersuite.google.com/app/apikey</li> <li>Sign in with your Google account</li> <li>Click \"Create API Key\"</li> <li>Copy the generated key</li> <li>Paste it into your <code>.env</code> file</li> </ol> <p>Security Note: Never commit your <code>.env</code> file with real API keys to version control.</p>"},{"location":"deployment/local/#running-the-application","title":"Running the Application","text":""},{"location":"deployment/local/#1-start-opensearch","title":"1. Start OpenSearch","text":"<p>Using Docker (Recommended):</p> <pre><code># Start OpenSearch in background\ndocker run -d \\\n  --name opensearch-node1 \\\n  -p 9200:9200 \\\n  -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword123!\" \\\n  opensearchproject/opensearch:latest\n\n# Verify OpenSearch is running\ncurl -X GET \"http://localhost:9200\" -u admin:MyStrongPassword123!\n\n# Check container logs\ndocker logs opensearch-node1\n</code></pre> <p>Expected Response: <pre><code>{\n  \"name\" : \"opensearch-node1\",\n  \"cluster_name\" : \"docker-cluster\",\n  \"version\" : {\n    \"number\" : \"2.11.0\",\n    ...\n  },\n  \"tagline\" : \"The OpenSearch Project: https://opensearch.org/\"\n}\n</code></pre></p> <p>Stop OpenSearch: <pre><code>docker stop opensearch-node1\ndocker rm opensearch-node1\n</code></pre></p>"},{"location":"deployment/local/#2-start-the-application","title":"2. Start the Application","text":"<pre><code># Ensure virtual environment is activated\nsource venv/bin/activate  # macOS/Linux\n# or\nvenv\\Scripts\\activate  # Windows\n\n# Run the application\npython main.py\n</code></pre> <p>Expected Output: <pre><code>\ud83d\ude80 Initializing Multi-Modal Research Assistant...\n\u2705 Research Assistant ready!\n\ud83c\udf10 Opening web interface...\n\ud83d\udcdd Logs are being written to: logs/research_assistant.log\n\nRunning on local URL:  http://0.0.0.0:7860\nRunning on public URL: https://xxxxx.gradio.live\n\nThis share link expires in 72 hours.\n</code></pre></p>"},{"location":"deployment/local/#3-access-the-application","title":"3. Access the Application","text":"<ul> <li>Local URL: http://localhost:7860</li> <li>Public URL: Provided in console output (valid for 72 hours)</li> <li>Local Network: http://:7860"},{"location":"deployment/local/#running-multiple-instances","title":"Running Multiple Instances","text":"<p>You may want to run multiple instances for different use cases or testing.</p>"},{"location":"deployment/local/#method-1-different-ports","title":"Method 1: Different Ports","text":"<pre><code># Terminal 1 - Instance 1 on port 7860\nexport GRADIO_SERVER_PORT=7860\npython main.py\n\n# Terminal 2 - Instance 2 on port 7861\nexport GRADIO_SERVER_PORT=7861\npython main.py\n\n# Terminal 3 - Instance 3 on port 7862\nexport GRADIO_SERVER_PORT=7862\npython main.py\n</code></pre>"},{"location":"deployment/local/#method-2-different-virtual-environments","title":"Method 2: Different Virtual Environments","text":"<pre><code># Create separate environments for each instance\npython3 -m venv venv1\npython3 -m venv venv2\n\n# Setup instance 1\nsource venv1/bin/activate\npip install -r requirements.txt\ncp .env .env1\n# Edit .env1 with different GRADIO_SERVER_PORT\npython main.py\n\n# Setup instance 2 (new terminal)\nsource venv2/bin/activate\npip install -r requirements.txt\ncp .env .env2\n# Edit .env2 with different GRADIO_SERVER_PORT and INDEX_NAME\npython main.py\n</code></pre>"},{"location":"deployment/local/#method-3-different-opensearch-indices","title":"Method 3: Different OpenSearch Indices","text":"<p>To avoid data conflicts, use separate indices:</p> <pre><code># Instance 1 - .env file\nOPENSEARCH_INDEX_NAME=research_assistant_dev\nGRADIO_SERVER_PORT=7860\n\n# Instance 2 - .env.test file\nOPENSEARCH_INDEX_NAME=research_assistant_test\nGRADIO_SERVER_PORT=7861\n\n# Run instances\npython main.py  # Uses .env\npython main.py --env-file .env.test  # Custom env file (if supported)\n</code></pre>"},{"location":"deployment/local/#port-configuration","title":"Port Configuration","text":""},{"location":"deployment/local/#understanding-port-usage","title":"Understanding Port Usage","text":"<p>The application uses the following ports:</p> <ol> <li>7860 - Gradio web interface (default)</li> <li>9200 - OpenSearch HTTP API</li> <li>9600 - OpenSearch Performance Analyzer (optional)</li> </ol>"},{"location":"deployment/local/#changing-the-gradio-port","title":"Changing the Gradio Port","text":"<p>Method 1: Environment Variable <pre><code># In .env file\nGRADIO_SERVER_PORT=8080\n\n# Or set temporarily\nexport GRADIO_SERVER_PORT=8080\npython main.py\n</code></pre></p> <p>Method 2: Modify main.py <pre><code># In main.py, find:\napp.launch(\n    server_name=\"0.0.0.0\",\n    server_port=7860,  # Change this\n    share=True\n)\n</code></pre></p>"},{"location":"deployment/local/#checking-port-availability","title":"Checking Port Availability","text":"<pre><code># macOS/Linux\nlsof -i :7860\nnetstat -an | grep 7860\n\n# Windows\nnetstat -ano | findstr :7860\n</code></pre>"},{"location":"deployment/local/#freeing-up-ports","title":"Freeing Up Ports","text":"<pre><code># Find process using port\nlsof -ti:7860\n\n# Kill process\nkill -9 $(lsof -ti:7860)\n\n# Or on Windows\n# Find PID\nnetstat -ano | findstr :7860\n# Kill using Task Manager or:\ntaskkill /PID &lt;pid&gt; /F\n</code></pre>"},{"location":"deployment/local/#local-development-workflow","title":"Local Development Workflow","text":""},{"location":"deployment/local/#daily-development-routine","title":"Daily Development Routine","text":"<ol> <li> <p>Start Development Session <pre><code># Navigate to project\ncd /path/to/multi-modal-academic-research-system\n\n# Activate virtual environment\nsource venv/bin/activate\n\n# Start OpenSearch (if not running)\ndocker start opensearch-node1\n\n# Verify OpenSearch\ncurl -X GET \"http://localhost:9200/_cluster/health\"\n\n# Start application\npython main.py\n</code></pre></p> </li> <li> <p>Make Changes</p> </li> <li>Edit code in your preferred IDE</li> <li>Save changes</li> <li> <p>Restart application to see changes</p> </li> <li> <p>View Logs <pre><code># Tail application logs\ntail -f logs/research_assistant.log\n\n# View OpenSearch logs\ndocker logs -f opensearch-node1\n</code></pre></p> </li> <li> <p>End Development Session <pre><code># Stop application (Ctrl+C)\n\n# Optionally stop OpenSearch\ndocker stop opensearch-node1\n\n# Deactivate virtual environment\ndeactivate\n</code></pre></p> </li> </ol>"},{"location":"deployment/local/#development-tips","title":"Development Tips","text":"<ol> <li>Auto-Reload During Development</li> </ol> <p>Use a file watcher to restart on changes:    <pre><code># Install watchdog\npip install watchdog\n\n# Create restart script\necho '#!/bin/bash\nwhile true; do\n  python main.py\n  sleep 2\ndone' &gt; run_dev.sh\n\nchmod +x run_dev.sh\n./run_dev.sh\n</code></pre></p> <ol> <li>Debugging</li> </ol> <p>Enable debug logging in <code>.env</code>:    <pre><code>LOG_LEVEL=DEBUG\n</code></pre></p> <p>Or use Python debugger:    <pre><code># Add to code\nimport pdb; pdb.set_trace()\n</code></pre></p> <ol> <li>Testing Changes</li> </ol> <pre><code># Run with test index\nexport OPENSEARCH_INDEX_NAME=test_index\npython main.py\n</code></pre>"},{"location":"deployment/local/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/local/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"deployment/local/#1-port-already-in-use","title":"1. Port Already in Use","text":"<p>Error: <pre><code>OSError: [Errno 48] Address already in use\n</code></pre></p> <p>Solution: <pre><code># Find and kill process on port 7860\nlsof -ti:7860 | xargs kill -9\n\n# Or change port\nexport GRADIO_SERVER_PORT=7861\npython main.py\n</code></pre></p>"},{"location":"deployment/local/#2-opensearch-connection-failed","title":"2. OpenSearch Connection Failed","text":"<p>Error: <pre><code>ConnectionRefusedError: [Errno 61] Connection refused\n</code></pre></p> <p>Solutions:</p> <p>a) Check if OpenSearch is running: <pre><code>docker ps | grep opensearch\ncurl http://localhost:9200\n</code></pre></p> <p>b) Start OpenSearch: <pre><code>docker start opensearch-node1\n# or\ndocker run -d --name opensearch-node1 -p 9200:9200 -e \"discovery.type=single-node\" opensearchproject/opensearch:latest\n</code></pre></p> <p>c) Check firewall settings: <pre><code># macOS\nsudo /usr/libexec/ApplicationFirewall/socketfilterfw --add python3\nsudo /usr/libexec/ApplicationFirewall/socketfilterfw --unblock python3\n\n# Linux (UFW)\nsudo ufw allow 9200\n</code></pre></p> <p>d) Verify .env configuration: <pre><code># Check OPENSEARCH_HOST and OPENSEARCH_PORT\ncat .env | grep OPENSEARCH\n</code></pre></p>"},{"location":"deployment/local/#3-missing-gemini_api_key","title":"3. Missing GEMINI_API_KEY","text":"<p>Error: <pre><code>\u26a0\ufe0f  Please set GEMINI_API_KEY in your .env file\n</code></pre></p> <p>Solution: 1. Get API key from: https://makersuite.google.com/app/apikey 2. Add to <code>.env</code>:    <pre><code>GEMINI_API_KEY=your_actual_key_here\n</code></pre> 3. Restart application</p>"},{"location":"deployment/local/#4-module-not-found-errors","title":"4. Module Not Found Errors","text":"<p>Error: <pre><code>ModuleNotFoundError: No module named 'opensearch'\n</code></pre></p> <p>Solution: <pre><code># Verify virtual environment is activated\nwhich python\n# Should show path inside venv/\n\n# Reinstall dependencies\npip install -r requirements.txt\n\n# Check installed packages\npip list | grep opensearch\n</code></pre></p>"},{"location":"deployment/local/#5-permission-denied-errors","title":"5. Permission Denied Errors","text":"<p>Error: <pre><code>PermissionError: [Errno 13] Permission denied: 'data/papers'\n</code></pre></p> <p>Solution: <pre><code># Fix directory permissions\nchmod -R 755 data/\nchmod -R 755 logs/\n\n# Or recreate directories\nrm -rf data/ logs/\nmkdir -p data/{papers,videos,podcasts,processed} logs/\n</code></pre></p>"},{"location":"deployment/local/#6-out-of-memory-errors","title":"6. Out of Memory Errors","text":"<p>Error: <pre><code>MemoryError: Unable to allocate array\n</code></pre></p> <p>Solutions:</p> <p>a) Reduce batch size in configuration b) Use smaller embedding model c) Increase system swap space d) Process fewer documents at once</p>"},{"location":"deployment/local/#7-gradio-not-accessible","title":"7. Gradio Not Accessible","text":"<p>Error: Cannot access http://localhost:7860</p> <p>Solutions:</p> <p>a) Check if application is running: <pre><code>ps aux | grep python\n</code></pre></p> <p>b) Check if port is listening: <pre><code>netstat -an | grep 7860\nlsof -i :7860\n</code></pre></p> <p>c) Try different server name: <pre><code># In main.py\napp.launch(\n    server_name=\"127.0.0.1\",  # Instead of 0.0.0.0\n    server_port=7860,\n    share=False\n)\n</code></pre></p> <p>d) Check firewall: <pre><code># macOS\nsudo pfctl -d  # Disable firewall temporarily\n\n# Linux\nsudo ufw status\nsudo ufw allow 7860\n</code></pre></p>"},{"location":"deployment/local/#8-slow-performance","title":"8. Slow Performance","text":"<p>Symptoms: - Slow search queries - UI freezing - Long processing times</p> <p>Solutions:</p> <p>a) Check OpenSearch health: <pre><code>curl http://localhost:9200/_cluster/health?pretty\n</code></pre></p> <p>b) Monitor resource usage: <pre><code># CPU and memory\ntop\nhtop\n\n# Docker resources\ndocker stats opensearch-node1\n</code></pre></p> <p>c) Optimize OpenSearch: <pre><code># Increase heap size\ndocker run -d \\\n  --name opensearch-node1 \\\n  -p 9200:9200 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g\" \\\n  opensearchproject/opensearch:latest\n</code></pre></p> <p>d) Clear old data: <pre><code># Delete old indices\ncurl -X DELETE \"http://localhost:9200/old_index_name\"\n\n# Clear cache\ncurl -X POST \"http://localhost:9200/_cache/clear\"\n</code></pre></p>"},{"location":"deployment/local/#9-ssl-certificate-errors","title":"9. SSL Certificate Errors","text":"<p>Error: <pre><code>SSLError: certificate verify failed\n</code></pre></p> <p>Solution: <pre><code># In .env file\nOPENSEARCH_USE_SSL=false\nOPENSEARCH_VERIFY_CERTS=false\n</code></pre></p>"},{"location":"deployment/local/#10-application-crashes-on-startup","title":"10. Application Crashes on Startup","text":"<p>Solutions:</p> <p>a) Check logs: <pre><code>tail -100 logs/research_assistant.log\n</code></pre></p> <p>b) Verify Python version: <pre><code>python --version  # Should be 3.9+\n</code></pre></p> <p>c) Clean reinstall: <pre><code># Remove virtual environment\nrm -rf venv/\n\n# Recreate\npython3 -m venv venv\nsource venv/bin/activate\npip install --upgrade pip\npip install -r requirements.txt\n</code></pre></p> <p>d) Check for conflicting processes: <pre><code># Kill all python processes\npkill -f python\n\n# Restart clean\npython main.py\n</code></pre></p>"},{"location":"deployment/local/#getting-help","title":"Getting Help","text":"<p>If issues persist:</p> <ol> <li>Check logs: <code>logs/research_assistant.log</code></li> <li>Enable debug logging: Set <code>LOG_LEVEL=DEBUG</code> in <code>.env</code></li> <li>Check GitHub issues: Search for similar problems</li> <li>Stack traces: Include full error messages when reporting issues</li> </ol>"},{"location":"deployment/local/#useful-commands-reference","title":"Useful Commands Reference","text":"<pre><code># Check application status\nps aux | grep \"python main.py\"\n\n# Monitor logs in real-time\ntail -f logs/research_assistant.log\n\n# Check OpenSearch status\ncurl http://localhost:9200/_cat/health?v\n\n# List all indices\ncurl http://localhost:9200/_cat/indices?v\n\n# Check index document count\ncurl http://localhost:9200/research_assistant/_count\n\n# Monitor system resources\ntop -o cpu  # Sort by CPU\ntop -o mem  # Sort by memory\n\n# Test Gemini API connection\ncurl -H \"Content-Type: application/json\" \\\n  -d '{\"contents\":[{\"parts\":[{\"text\":\"Hello\"}]}]}' \\\n  \"https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=YOUR_API_KEY\"\n</code></pre>"},{"location":"deployment/local/#next-steps","title":"Next Steps","text":"<ul> <li>Review Docker Deployment for containerized setup</li> <li>See OpenSearch Setup for advanced configuration</li> <li>Check Production Considerations before deploying to production</li> </ul>"},{"location":"deployment/opensearch/","title":"OpenSearch Setup Guide","text":"<p>This comprehensive guide covers OpenSearch installation, configuration, optimization, and maintenance for the Multi-Modal Academic Research System.</p>"},{"location":"deployment/opensearch/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Installation Methods</li> <li>Configuration</li> <li>Index Management</li> <li>Security Configuration</li> <li>Performance Optimization</li> <li>Cluster Setup</li> <li>Backup and Restore</li> <li>Monitoring and Maintenance</li> <li>Troubleshooting</li> </ol>"},{"location":"deployment/opensearch/#overview","title":"Overview","text":""},{"location":"deployment/opensearch/#what-is-opensearch","title":"What is OpenSearch?","text":"<p>OpenSearch is an open-source search and analytics engine derived from Elasticsearch. It provides:</p> <ul> <li>Full-text search with BM25 ranking</li> <li>Vector search with k-NN capabilities</li> <li>Hybrid search combining keyword and semantic search</li> <li>Real-time indexing and querying</li> <li>Scalability from single node to large clusters</li> </ul>"},{"location":"deployment/opensearch/#system-requirements","title":"System Requirements","text":"<p>Minimum (Development): - CPU: 2 cores - RAM: 2GB - Disk: 10GB</p> <p>Recommended (Production): - CPU: 4+ cores - RAM: 8GB+ (16GB optimal) - Disk: 50GB+ SSD - Java: OpenJDK 11 or 17</p>"},{"location":"deployment/opensearch/#installation-methods","title":"Installation Methods","text":""},{"location":"deployment/opensearch/#method-1-docker-recommended-for-development","title":"Method 1: Docker (Recommended for Development)","text":"<p>Single Node Setup:</p> <pre><code># Pull latest OpenSearch image\ndocker pull opensearchproject/opensearch:latest\n\n# Run single node with security disabled (development)\ndocker run -d \\\n  --name opensearch-dev \\\n  -p 9200:9200 \\\n  -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword123!\" \\\n  -e \"plugins.security.disabled=true\" \\\n  -e \"OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n  opensearchproject/opensearch:latest\n\n# Verify installation\ncurl http://localhost:9200\n\n# Expected response:\n{\n  \"name\" : \"opensearch-dev\",\n  \"cluster_name\" : \"docker-cluster\",\n  \"cluster_uuid\" : \"...\",\n  \"version\" : {\n    \"number\" : \"2.11.0\",\n    ...\n  }\n}\n</code></pre> <p>With Persistence:</p> <pre><code># Create volume for data persistence\ndocker volume create opensearch-data\n\n# Run with persistent storage\ndocker run -d \\\n  --name opensearch-dev \\\n  -p 9200:9200 \\\n  -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword123!\" \\\n  -e \"OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g\" \\\n  -v opensearch-data:/usr/share/opensearch/data \\\n  opensearchproject/opensearch:latest\n</code></pre>"},{"location":"deployment/opensearch/#method-2-docker-compose","title":"Method 2: Docker Compose","text":"<p>Create <code>opensearch-docker-compose.yml</code>:</p> <pre><code>version: '3.8'\n\nservices:\n  opensearch-node1:\n    image: opensearchproject/opensearch:2.11.0\n    container_name: opensearch-node1\n    environment:\n      - cluster.name=opensearch-cluster\n      - node.name=opensearch-node1\n      - discovery.type=single-node\n      - bootstrap.memory_lock=true\n      - \"OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g\"\n      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword123!\n    ulimits:\n      memlock:\n        soft: -1\n        hard: -1\n      nofile:\n        soft: 65536\n        hard: 65536\n    volumes:\n      - opensearch-data1:/usr/share/opensearch/data\n    ports:\n      - 9200:9200\n      - 9600:9600\n    networks:\n      - opensearch-net\n\n  opensearch-dashboards:\n    image: opensearchproject/opensearch-dashboards:2.11.0\n    container_name: opensearch-dashboards\n    ports:\n      - 5601:5601\n    expose:\n      - \"5601\"\n    environment:\n      OPENSEARCH_HOSTS: '[\"http://opensearch-node1:9200\"]'\n    networks:\n      - opensearch-net\n    depends_on:\n      - opensearch-node1\n\nvolumes:\n  opensearch-data1:\n\nnetworks:\n  opensearch-net:\n</code></pre> <p>Start services:</p> <pre><code>docker-compose -f opensearch-docker-compose.yml up -d\n\n# Access OpenSearch: http://localhost:9200\n# Access Dashboards: http://localhost:5601\n</code></pre>"},{"location":"deployment/opensearch/#method-3-native-installation-linux","title":"Method 3: Native Installation (Linux)","text":"<p>Ubuntu/Debian:</p> <pre><code># Import OpenSearch GPG key\nwget -qO - https://artifacts.opensearch.org/publickeys/opensearch.pgp | sudo gpg --dearmor -o /usr/share/keyrings/opensearch-keyring.gpg\n\n# Add repository\necho \"deb [signed-by=/usr/share/keyrings/opensearch-keyring.gpg] https://artifacts.opensearch.org/releases/bundle/opensearch/2.x/apt stable main\" | sudo tee /etc/apt/sources.list.d/opensearch-2.x.list\n\n# Update and install\nsudo apt-get update\nsudo apt-get install opensearch\n\n# Configure\nsudo nano /etc/opensearch/opensearch.yml\n\n# Start service\nsudo systemctl start opensearch\nsudo systemctl enable opensearch\n\n# Verify\ncurl http://localhost:9200\n</code></pre> <p>CentOS/RHEL:</p> <pre><code># Create repo file\nsudo tee /etc/yum.repos.d/opensearch-2.x.repo &lt;&lt;EOF\n[opensearch-2.x]\nname=OpenSearch 2.x\nbaseurl=https://artifacts.opensearch.org/releases/bundle/opensearch/2.x/yum\nenabled=1\ngpgcheck=1\ngpgkey=https://artifacts.opensearch.org/publickeys/opensearch.pgp\nEOF\n\n# Install\nsudo yum install opensearch\n\n# Configure and start\nsudo systemctl start opensearch\nsudo systemctl enable opensearch\n</code></pre>"},{"location":"deployment/opensearch/#method-4-macos-homebrew","title":"Method 4: macOS (Homebrew)","text":"<pre><code># Tap OpenSearch\nbrew tap opensearch-project/opensearch\n\n# Install OpenSearch\nbrew install opensearch\n\n# Start service\nbrew services start opensearch\n\n# Or start manually\nopensearch\n</code></pre>"},{"location":"deployment/opensearch/#configuration","title":"Configuration","text":""},{"location":"deployment/opensearch/#basic-configuration-opensearchyml","title":"Basic Configuration (opensearch.yml)","text":"<p>Development Configuration:</p> <pre><code># /etc/opensearch/opensearch.yml or config/opensearch.yml\n\n# ======================== Cluster ========================\ncluster.name: research-cluster\nnode.name: node-1\n\n# ======================== Network ========================\nnetwork.host: 0.0.0.0\nhttp.port: 9200\n\n# ======================== Discovery ========================\ndiscovery.type: single-node\n\n# ======================== Memory ========================\nbootstrap.memory_lock: true\n\n# ======================== Paths ========================\npath.data: /var/lib/opensearch\npath.logs: /var/log/opensearch\n\n# ======================== Security ========================\n# Disable security for development\nplugins.security.disabled: true\n\n# ======================== Performance ========================\n# Thread pools\nthread_pool.search.size: 4\nthread_pool.search.queue_size: 1000\nthread_pool.write.size: 4\nthread_pool.write.queue_size: 500\n</code></pre> <p>Production Configuration:</p> <pre><code># ======================== Cluster ========================\ncluster.name: research-production-cluster\nnode.name: node-1\nnode.roles: [ master, data, ingest ]\n\n# ======================== Network ========================\nnetwork.host: _site_\nhttp.port: 9200\ntransport.port: 9300\n\n# ======================== Discovery ========================\ndiscovery.seed_hosts: [\"node-1.example.com:9300\", \"node-2.example.com:9300\"]\ncluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"]\n\n# ======================== Memory ========================\nbootstrap.memory_lock: true\n\n# ======================== Security ========================\nplugins.security.ssl.http.enabled: true\nplugins.security.ssl.http.pemcert_filepath: certificates/node1.pem\nplugins.security.ssl.http.pemkey_filepath: certificates/node1-key.pem\nplugins.security.ssl.http.pemtrustedcas_filepath: certificates/root-ca.pem\n\n# ======================== Performance ========================\nindices.memory.index_buffer_size: 30%\nindices.queries.cache.size: 10%\nindices.fielddata.cache.size: 30%\n\n# ======================== Circuit Breakers ========================\nindices.breaker.total.limit: 70%\nindices.breaker.request.limit: 40%\nindices.breaker.fielddata.limit: 40%\n</code></pre>"},{"location":"deployment/opensearch/#jvm-configuration-jvmoptions","title":"JVM Configuration (jvm.options)","text":"<pre><code># /etc/opensearch/jvm.options\n\n# Heap size (set to 50% of available RAM, max 32GB)\n-Xms4g\n-Xmx4g\n\n# GC configuration\n-XX:+UseG1GC\n-XX:G1ReservePercent=25\n-XX:InitiatingHeapOccupancyPercent=30\n\n# GC logging\n-Xlog:gc*,gc+age=trace,safepoint:file=/var/log/opensearch/gc.log:utctime,pid,tags:filecount=32,filesize=64m\n\n# Heap dumps on OOM\n-XX:+HeapDumpOnOutOfMemoryError\n-XX:HeapDumpPath=/var/log/opensearch/\n\n# Performance\n-XX:+AlwaysPreTouch\n-Djava.io.tmpdir=/tmp\n</code></pre>"},{"location":"deployment/opensearch/#environment-variables","title":"Environment Variables","text":"<pre><code># Set in .env or environment\n\n# Connection\nexport OPENSEARCH_HOST=localhost\nexport OPENSEARCH_PORT=9200\nexport OPENSEARCH_USER=admin\nexport OPENSEARCH_PASSWORD=admin\n\n# SSL/TLS\nexport OPENSEARCH_USE_SSL=false\nexport OPENSEARCH_VERIFY_CERTS=false\n\n# Timeouts\nexport OPENSEARCH_TIMEOUT=30\nexport OPENSEARCH_RETRY_ON_TIMEOUT=true\nexport OPENSEARCH_MAX_RETRIES=3\n</code></pre>"},{"location":"deployment/opensearch/#index-management","title":"Index Management","text":""},{"location":"deployment/opensearch/#create-research-index","title":"Create Research Index","text":"<p>Python Code:</p> <pre><code>from opensearchpy import OpenSearch\n\n# Connect to OpenSearch\nclient = OpenSearch(\n    hosts=[{'host': 'localhost', 'port': 9200}],\n    http_auth=('admin', 'admin'),\n    use_ssl=False,\n    verify_certs=False\n)\n\n# Define index mapping\nindex_mapping = {\n    \"settings\": {\n        \"number_of_shards\": 2,\n        \"number_of_replicas\": 1,\n        \"refresh_interval\": \"1s\",\n        \"index.knn\": True,\n        \"index.knn.space_type\": \"cosinesimil\",\n        \"analysis\": {\n            \"analyzer\": {\n                \"custom_analyzer\": {\n                    \"type\": \"custom\",\n                    \"tokenizer\": \"standard\",\n                    \"filter\": [\"lowercase\", \"stop\", \"snowball\"]\n                }\n            }\n        }\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"content_type\": {\n                \"type\": \"keyword\"\n            },\n            \"title\": {\n                \"type\": \"text\",\n                \"analyzer\": \"custom_analyzer\",\n                \"fields\": {\n                    \"keyword\": {\"type\": \"keyword\"}\n                }\n            },\n            \"abstract\": {\n                \"type\": \"text\",\n                \"analyzer\": \"custom_analyzer\"\n            },\n            \"content\": {\n                \"type\": \"text\",\n                \"analyzer\": \"custom_analyzer\"\n            },\n            \"authors\": {\n                \"type\": \"keyword\"\n            },\n            \"publication_date\": {\n                \"type\": \"date\"\n            },\n            \"embedding\": {\n                \"type\": \"knn_vector\",\n                \"dimension\": 384,\n                \"method\": {\n                    \"name\": \"hnsw\",\n                    \"space_type\": \"cosinesimil\",\n                    \"engine\": \"nmslib\",\n                    \"parameters\": {\n                        \"ef_construction\": 128,\n                        \"m\": 16\n                    }\n                }\n            },\n            \"diagram_descriptions\": {\n                \"type\": \"text\"\n            },\n            \"key_concepts\": {\n                \"type\": \"keyword\"\n            },\n            \"citations\": {\n                \"type\": \"nested\",\n                \"properties\": {\n                    \"text\": {\"type\": \"text\"},\n                    \"source\": {\"type\": \"keyword\"}\n                }\n            }\n        }\n    }\n}\n\n# Create index\nclient.indices.create(index='research_assistant', body=index_mapping)\nprint(\"Index created successfully!\")\n</code></pre>"},{"location":"deployment/opensearch/#index-operations","title":"Index Operations","text":"<pre><code># Using curl\n\n# Create index\ncurl -X PUT \"http://localhost:9200/research_assistant\" -H 'Content-Type: application/json' -d @index_mapping.json\n\n# Get index info\ncurl -X GET \"http://localhost:9200/research_assistant\"\n\n# Get index settings\ncurl -X GET \"http://localhost:9200/research_assistant/_settings\"\n\n# Get index mappings\ncurl -X GET \"http://localhost:9200/research_assistant/_mapping\"\n\n# Update index settings (requires close/open)\ncurl -X POST \"http://localhost:9200/research_assistant/_close\"\ncurl -X PUT \"http://localhost:9200/research_assistant/_settings\" -H 'Content-Type: application/json' -d'\n{\n  \"index\": {\n    \"number_of_replicas\": 2\n  }\n}'\ncurl -X POST \"http://localhost:9200/research_assistant/_open\"\n\n# Delete index (WARNING: destroys data)\ncurl -X DELETE \"http://localhost:9200/research_assistant\"\n\n# Reindex to new index\ncurl -X POST \"http://localhost:9200/_reindex\" -H 'Content-Type: application/json' -d'\n{\n  \"source\": {\n    \"index\": \"research_assistant\"\n  },\n  \"dest\": {\n    \"index\": \"research_assistant_v2\"\n  }\n}'\n</code></pre>"},{"location":"deployment/opensearch/#index-templates","title":"Index Templates","text":"<p>Create templates for automatic index configuration:</p> <pre><code>{\n  \"index_patterns\": [\"research_*\"],\n  \"template\": {\n    \"settings\": {\n      \"number_of_shards\": 2,\n      \"number_of_replicas\": 1,\n      \"index.knn\": true\n    },\n    \"mappings\": {\n      \"properties\": {\n        \"timestamp\": {\n          \"type\": \"date\"\n        },\n        \"embedding\": {\n          \"type\": \"knn_vector\",\n          \"dimension\": 384\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>Apply template:</p> <pre><code>curl -X PUT \"http://localhost:9200/_index_template/research_template\" \\\n  -H 'Content-Type: application/json' \\\n  -d @template.json\n</code></pre>"},{"location":"deployment/opensearch/#security-configuration","title":"Security Configuration","text":""},{"location":"deployment/opensearch/#enable-security-plugin","title":"Enable Security Plugin","text":"<p>1. Generate Certificates:</p> <pre><code># Create certificate directory\nmkdir -p /etc/opensearch/certificates\ncd /etc/opensearch/certificates\n\n# Generate root CA\nopenssl genrsa -out root-ca-key.pem 2048\nopenssl req -new -x509 -sha256 -key root-ca-key.pem -out root-ca.pem -days 730 \\\n  -subj \"/C=US/ST=State/L=City/O=Organization/CN=root-ca\"\n\n# Generate node certificate\nopenssl genrsa -out node1-key.pem 2048\nopenssl req -new -key node1-key.pem -out node1.csr \\\n  -subj \"/C=US/ST=State/L=City/O=Organization/CN=node1.example.com\"\n\n# Sign node certificate\nopenssl x509 -req -in node1.csr -CA root-ca.pem -CAkey root-ca-key.pem \\\n  -CAcreateserial -sha256 -out node1.pem -days 365\n\n# Set permissions\nchmod 600 *-key.pem\nchown opensearch:opensearch *\n</code></pre> <p>2. Configure Security in opensearch.yml:</p> <pre><code># Security\nplugins.security.disabled: false\n\n# SSL for HTTP\nplugins.security.ssl.http.enabled: true\nplugins.security.ssl.http.pemcert_filepath: certificates/node1.pem\nplugins.security.ssl.http.pemkey_filepath: certificates/node1-key.pem\nplugins.security.ssl.http.pemtrustedcas_filepath: certificates/root-ca.pem\n\n# SSL for transport\nplugins.security.ssl.transport.pemcert_filepath: certificates/node1.pem\nplugins.security.ssl.transport.pemkey_filepath: certificates/node1-key.pem\nplugins.security.ssl.transport.pemtrustedcas_filepath: certificates/root-ca.pem\nplugins.security.ssl.transport.enforce_hostname_verification: false\n\n# Authentication\nplugins.security.authcz.admin_dn:\n  - 'CN=admin,OU=SSL,O=Organization,L=City,ST=State,C=US'\n</code></pre> <p>3. Configure Users:</p> <pre><code># Run security initialization\n/usr/share/opensearch/plugins/opensearch-security/tools/securityadmin.sh \\\n  -cd /etc/opensearch/opensearch-security/ \\\n  -icl -nhnv \\\n  -cacert /etc/opensearch/certificates/root-ca.pem \\\n  -cert /etc/opensearch/certificates/admin.pem \\\n  -key /etc/opensearch/certificates/admin-key.pem\n</code></pre> <p>4. Create Application User:</p> <pre><code># Create internal_users.yml\ncat &gt; /etc/opensearch/opensearch-security/internal_users.yml &lt;&lt;EOF\nresearch_app_user:\n  hash: \"$2y$12$...\"  # Generate with tools/hash.sh\n  reserved: false\n  backend_roles:\n    - \"research_app_role\"\n  description: \"Research application user\"\nEOF\n\n# Create roles_mapping.yml\ncat &gt; /etc/opensearch/opensearch-security/roles_mapping.yml &lt;&lt;EOF\nresearch_app_role:\n  reserved: false\n  backend_roles:\n    - \"research_app_role\"\n  users:\n    - \"research_app_user\"\nEOF\n</code></pre>"},{"location":"deployment/opensearch/#authentication-methods","title":"Authentication Methods","text":"<p>1. Basic Authentication:</p> <pre><code>from opensearchpy import OpenSearch\n\nclient = OpenSearch(\n    hosts=[{'host': 'localhost', 'port': 9200}],\n    http_auth=('research_app_user', 'password'),\n    use_ssl=True,\n    verify_certs=True,\n    ca_certs='/path/to/root-ca.pem'\n)\n</code></pre> <p>2. API Key Authentication:</p> <pre><code># Create API key\ncurl -X POST \"https://localhost:9200/_plugins/_security/api/apikeys\" \\\n  -u admin:admin \\\n  -H 'Content-Type: application/json' -d'\n{\n  \"name\": \"research_app_key\",\n  \"permissions\": [\"indices:data/read/*\", \"indices:data/write/*\"]\n}'\n\n# Use in application\nheaders = {\n    'Authorization': f'ApiKey {api_key_id}:{api_key}'\n}\n</code></pre>"},{"location":"deployment/opensearch/#performance-optimization","title":"Performance Optimization","text":""},{"location":"deployment/opensearch/#index-optimization","title":"Index Optimization","text":"<p>1. Shard Configuration:</p> <pre><code># Optimal shard size: 10-50GB\n# Formula: number_of_shards = total_data_size / 30GB\n\nsettings = {\n    \"number_of_shards\": 2,  # For dataset &lt; 60GB\n    \"number_of_replicas\": 1,  # 1 replica for HA\n    \"refresh_interval\": \"30s\",  # Reduce refresh frequency\n    \"translog.durability\": \"async\",  # Better indexing performance\n    \"translog.sync_interval\": \"30s\"\n}\n</code></pre> <p>2. Merge Policy:</p> <pre><code>{\n  \"settings\": {\n    \"index.merge.policy.max_merged_segment\": \"5gb\",\n    \"index.merge.policy.segments_per_tier\": 10,\n    \"index.merge.scheduler.max_thread_count\": 1\n  }\n}\n</code></pre> <p>3. Codec Optimization:</p> <pre><code>{\n  \"settings\": {\n    \"index.codec\": \"best_compression\"\n  }\n}\n</code></pre>"},{"location":"deployment/opensearch/#query-optimization","title":"Query Optimization","text":"<p>1. Use Filters Instead of Queries:</p> <pre><code># Less optimal\nquery = {\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\"match\": {\"content\": \"machine learning\"}},\n                {\"match\": {\"content_type\": \"paper\"}}\n            ]\n        }\n    }\n}\n\n# Better - filter is cached\nquery = {\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\"match\": {\"content\": \"machine learning\"}}\n            ],\n            \"filter\": [\n                {\"term\": {\"content_type\": \"paper\"}}\n            ]\n        }\n    }\n}\n</code></pre> <p>2. Optimize Field Data:</p> <pre><code>{\n  \"mappings\": {\n    \"properties\": {\n      \"title\": {\n        \"type\": \"text\",\n        \"fields\": {\n          \"keyword\": {\n            \"type\": \"keyword\"\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>3. Use Source Filtering:</p> <pre><code># Only return necessary fields\nsearch_body = {\n    \"_source\": [\"title\", \"abstract\", \"authors\"],\n    \"query\": {...}\n}\n</code></pre>"},{"location":"deployment/opensearch/#hardware-optimization","title":"Hardware Optimization","text":"<p>1. Disk: - Use SSD for best performance - Separate OS, data, and log disks - RAID 0 for data (if replicated)</p> <p>2. Memory: - Heap: 50% of RAM, max 32GB - File system cache: remaining 50%</p> <p>3. CPU: - Modern CPU with good single-thread performance - At least 4 cores</p> <p>4. Network: - 10Gb network for cluster communication - Low latency between nodes</p>"},{"location":"deployment/opensearch/#cache-configuration","title":"Cache Configuration","text":"<pre><code># opensearch.yml\nindices.queries.cache.size: 10%\nindices.fielddata.cache.size: 30%\nindices.requests.cache.size: 2%\n</code></pre>"},{"location":"deployment/opensearch/#cluster-setup","title":"Cluster Setup","text":""},{"location":"deployment/opensearch/#single-node-cluster-development","title":"Single-Node Cluster (Development)","text":"<pre><code>cluster.name: dev-cluster\nnode.name: node-1\ndiscovery.type: single-node\n</code></pre>"},{"location":"deployment/opensearch/#multi-node-cluster-production","title":"Multi-Node Cluster (Production)","text":"<p>Node 1 Configuration:</p> <pre><code># opensearch.yml\ncluster.name: production-cluster\nnode.name: node-1\nnode.roles: [ master, data, ingest ]\n\nnetwork.host: 192.168.1.10\nhttp.port: 9200\ntransport.port: 9300\n\ndiscovery.seed_hosts: [\"192.168.1.10:9300\", \"192.168.1.11:9300\", \"192.168.1.12:9300\"]\ncluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"]\n</code></pre> <p>Node 2 Configuration:</p> <pre><code>cluster.name: production-cluster\nnode.name: node-2\nnode.roles: [ master, data, ingest ]\n\nnetwork.host: 192.168.1.11\nhttp.port: 9200\ntransport.port: 9300\n\ndiscovery.seed_hosts: [\"192.168.1.10:9300\", \"192.168.1.11:9300\", \"192.168.1.12:9300\"]\ncluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"]\n</code></pre> <p>Node 3 Configuration:</p> <pre><code>cluster.name: production-cluster\nnode.name: node-3\nnode.roles: [ master, data, ingest ]\n\nnetwork.host: 192.168.1.12\nhttp.port: 9200\ntransport.port: 9300\n\ndiscovery.seed_hosts: [\"192.168.1.10:9300\", \"192.168.1.11:9300\", \"192.168.1.12:9300\"]\ncluster.initial_master_nodes: [\"node-1\", \"node-2\", \"node-3\"]\n</code></pre>"},{"location":"deployment/opensearch/#dedicated-node-roles","title":"Dedicated Node Roles","text":"<p>Master-eligible nodes:</p> <pre><code>node.roles: [ master ]\n</code></pre> <p>Data nodes:</p> <pre><code>node.roles: [ data ]\n</code></pre> <p>Coordinating nodes:</p> <pre><code>node.roles: []\n</code></pre>"},{"location":"deployment/opensearch/#cluster-health-monitoring","title":"Cluster Health Monitoring","text":"<pre><code># Cluster health\ncurl http://localhost:9200/_cluster/health?pretty\n\n# Node stats\ncurl http://localhost:9200/_nodes/stats?pretty\n\n# Cluster stats\ncurl http://localhost:9200/_cluster/stats?pretty\n\n# Pending tasks\ncurl http://localhost:9200/_cluster/pending_tasks?pretty\n</code></pre>"},{"location":"deployment/opensearch/#backup-and-restore","title":"Backup and Restore","text":""},{"location":"deployment/opensearch/#snapshot-repository-setup","title":"Snapshot Repository Setup","text":"<p>1. Create Repository Directory:</p> <pre><code># Create backup directory\nsudo mkdir -p /mnt/backups/opensearch\nsudo chown opensearch:opensearch /mnt/backups/opensearch\n</code></pre> <p>2. Configure Repository Path:</p> <pre><code># opensearch.yml\npath.repo: [\"/mnt/backups/opensearch\"]\n</code></pre> <p>3. Register Repository:</p> <pre><code>curl -X PUT \"http://localhost:9200/_snapshot/backup_repo\" -H 'Content-Type: application/json' -d'\n{\n  \"type\": \"fs\",\n  \"settings\": {\n    \"location\": \"/mnt/backups/opensearch\",\n    \"compress\": true\n  }\n}'\n</code></pre>"},{"location":"deployment/opensearch/#create-snapshots","title":"Create Snapshots","text":"<p>Manual Snapshot:</p> <pre><code># Create snapshot\ncurl -X PUT \"http://localhost:9200/_snapshot/backup_repo/snapshot_1?wait_for_completion=true\" -H 'Content-Type: application/json' -d'\n{\n  \"indices\": \"research_assistant\",\n  \"ignore_unavailable\": true,\n  \"include_global_state\": false\n}'\n\n# List snapshots\ncurl -X GET \"http://localhost:9200/_snapshot/backup_repo/_all?pretty\"\n\n# Get snapshot status\ncurl -X GET \"http://localhost:9200/_snapshot/backup_repo/snapshot_1/_status?pretty\"\n</code></pre> <p>Automated Snapshots (Using Snapshot Management):</p> <pre><code># Create snapshot policy\ncurl -X PUT \"http://localhost:9200/_plugins/_sm/policies/daily_snapshot\" -H 'Content-Type: application/json' -d'\n{\n  \"description\": \"Daily snapshot policy\",\n  \"enabled\": true,\n  \"snapshot_config\": {\n    \"date_format\": \"yyyy-MM-dd-HH:mm\",\n    \"timezone\": \"America/Los_Angeles\",\n    \"indices\": \"*\",\n    \"repository\": \"backup_repo\",\n    \"ignore_unavailable\": true,\n    \"include_global_state\": false,\n    \"partial\": false\n  },\n  \"creation\": {\n    \"schedule\": {\n      \"cron\": {\n        \"expression\": \"0 0 * * *\",\n        \"timezone\": \"America/Los_Angeles\"\n      }\n    }\n  },\n  \"deletion\": {\n    \"schedule\": {\n      \"cron\": {\n        \"expression\": \"0 1 * * *\",\n        \"timezone\": \"America/Los_Angeles\"\n      }\n    },\n    \"condition\": {\n      \"max_age\": \"30d\",\n      \"max_count\": 30\n    }\n  }\n}'\n</code></pre>"},{"location":"deployment/opensearch/#restore-from-snapshot","title":"Restore from Snapshot","text":"<pre><code># Close index before restore\ncurl -X POST \"http://localhost:9200/research_assistant/_close\"\n\n# Restore snapshot\ncurl -X POST \"http://localhost:9200/_snapshot/backup_repo/snapshot_1/_restore\" -H 'Content-Type: application/json' -d'\n{\n  \"indices\": \"research_assistant\",\n  \"ignore_unavailable\": true,\n  \"include_global_state\": false,\n  \"rename_pattern\": \"(.+)\",\n  \"rename_replacement\": \"restored_$1\"\n}'\n\n# Monitor restore progress\ncurl -X GET \"http://localhost:9200/_recovery?pretty\"\n\n# Open index after restore\ncurl -X POST \"http://localhost:9200/research_assistant/_open\"\n</code></pre>"},{"location":"deployment/opensearch/#s3-repository-cloud-backup","title":"S3 Repository (Cloud Backup)","text":"<p>1. Install S3 Plugin:</p> <pre><code>/usr/share/opensearch/bin/opensearch-plugin install repository-s3\n</code></pre> <p>2. Configure AWS Credentials:</p> <pre><code># Add credentials to keystore\n/usr/share/opensearch/bin/opensearch-keystore add s3.client.default.access_key\n/usr/share/opensearch/bin/opensearch-keystore add s3.client.default.secret_key\n</code></pre> <p>3. Create S3 Repository:</p> <pre><code>curl -X PUT \"http://localhost:9200/_snapshot/s3_backup\" -H 'Content-Type: application/json' -d'\n{\n  \"type\": \"s3\",\n  \"settings\": {\n    \"bucket\": \"my-opensearch-backups\",\n    \"region\": \"us-east-1\",\n    \"base_path\": \"snapshots\",\n    \"compress\": true\n  }\n}'\n</code></pre>"},{"location":"deployment/opensearch/#monitoring-and-maintenance","title":"Monitoring and Maintenance","text":""},{"location":"deployment/opensearch/#health-checks","title":"Health Checks","text":"<pre><code># Cluster health\ncurl http://localhost:9200/_cluster/health?pretty\n\n# Index health\ncurl http://localhost:9200/_cat/indices?v&amp;health=yellow\n\n# Shard allocation\ncurl http://localhost:9200/_cat/shards?v\n\n# Node information\ncurl http://localhost:9200/_cat/nodes?v&amp;h=name,node.role,heap.percent,ram.percent,cpu,load_1m,disk.used_percent\n</code></pre>"},{"location":"deployment/opensearch/#performance-metrics","title":"Performance Metrics","text":"<pre><code># Index stats\ncurl http://localhost:9200/research_assistant/_stats?pretty\n\n# Node stats\ncurl http://localhost:9200/_nodes/stats/indices,os,process,jvm,thread_pool?pretty\n\n# Task management\ncurl http://localhost:9200/_tasks?detailed=true&amp;actions=*search*&amp;pretty\n\n# Hot threads\ncurl http://localhost:9200/_nodes/hot_threads\n</code></pre>"},{"location":"deployment/opensearch/#monitoring-tools","title":"Monitoring Tools","text":"<p>1. OpenSearch Dashboards:</p> <p>Access at http://localhost:5601</p> <ul> <li>Stack Management \u2192 Index Patterns</li> <li>Visualize \u2192 Create visualizations</li> <li>Dashboard \u2192 Monitor cluster</li> </ul> <p>2. Prometheus Exporter:</p> <pre><code># Install prometheus exporter\ndocker run -d \\\n  --name opensearch-exporter \\\n  -p 9114:9114 \\\n  -e OPENSEARCH_URI=http://opensearch:9200 \\\n  prometheuscommunity/opensearch-exporter:latest\n\n# Scrape endpoint\ncurl http://localhost:9114/metrics\n</code></pre> <p>3. Custom Monitoring Script:</p> <pre><code>import requests\nfrom datetime import datetime\n\ndef monitor_cluster():\n    base_url = \"http://localhost:9200\"\n\n    # Cluster health\n    health = requests.get(f\"{base_url}/_cluster/health\").json()\n    print(f\"Cluster Status: {health['status']}\")\n    print(f\"Active Shards: {health['active_shards']}\")\n\n    # Index stats\n    stats = requests.get(f\"{base_url}/research_assistant/_stats\").json()\n    index_stats = stats['indices']['research_assistant']['total']\n    print(f\"Document Count: {index_stats['docs']['count']}\")\n    print(f\"Store Size: {index_stats['store']['size_in_bytes'] / 1024 / 1024:.2f} MB\")\n\n    # Node stats\n    nodes = requests.get(f\"{base_url}/_nodes/stats\").json()\n    for node_id, node in nodes['nodes'].items():\n        print(f\"\\nNode: {node['name']}\")\n        print(f\"  Heap Used: {node['jvm']['mem']['heap_used_percent']}%\")\n        print(f\"  CPU: {node['os']['cpu']['percent']}%\")\n\nif __name__ == \"__main__\":\n    monitor_cluster()\n</code></pre>"},{"location":"deployment/opensearch/#maintenance-tasks","title":"Maintenance Tasks","text":"<p>1. Force Merge:</p> <pre><code># Force merge to reduce segments (run during low traffic)\ncurl -X POST \"http://localhost:9200/research_assistant/_forcemerge?max_num_segments=1\"\n</code></pre> <p>2. Clear Cache:</p> <pre><code># Clear all caches\ncurl -X POST \"http://localhost:9200/_cache/clear\"\n\n# Clear specific cache\ncurl -X POST \"http://localhost:9200/research_assistant/_cache/clear?fielddata=true\"\n</code></pre> <p>3. Reindex:</p> <pre><code># Reindex for mapping changes\ncurl -X POST \"http://localhost:9200/_reindex\" -H 'Content-Type: application/json' -d'\n{\n  \"source\": {\n    \"index\": \"research_assistant\"\n  },\n  \"dest\": {\n    \"index\": \"research_assistant_v2\"\n  }\n}'\n</code></pre> <p>4. Update Settings:</p> <pre><code># Update replica count\ncurl -X PUT \"http://localhost:9200/research_assistant/_settings\" -H 'Content-Type: application/json' -d'\n{\n  \"index\": {\n    \"number_of_replicas\": 2\n  }\n}'\n</code></pre>"},{"location":"deployment/opensearch/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/opensearch/#common-issues","title":"Common Issues","text":"<p>1. Cluster Yellow/Red Status</p> <pre><code># Check shard allocation\ncurl http://localhost:9200/_cat/shards?v\n\n# Explain unassigned shards\ncurl http://localhost:9200/_cluster/allocation/explain?pretty\n\n# Force allocation\ncurl -X POST \"http://localhost:9200/_cluster/reroute\" -H 'Content-Type: application/json' -d'\n{\n  \"commands\": [\n    {\n      \"allocate_replica\": {\n        \"index\": \"research_assistant\",\n        \"shard\": 0,\n        \"node\": \"node-1\"\n      }\n    }\n  ]\n}'\n</code></pre> <p>2. Out of Memory Errors</p> <pre><code># Check heap usage\ncurl http://localhost:9200/_nodes/stats/jvm?pretty\n\n# Increase heap size in jvm.options\n-Xms4g\n-Xmx4g\n\n# Clear field data cache\ncurl -X POST \"http://localhost:9200/_cache/clear?fielddata=true\"\n</code></pre> <p>3. Slow Queries</p> <pre><code># Enable slow log\ncurl -X PUT \"http://localhost:9200/research_assistant/_settings\" -H 'Content-Type: application/json' -d'\n{\n  \"index.search.slowlog.threshold.query.warn\": \"10s\",\n  \"index.search.slowlog.threshold.query.info\": \"5s\",\n  \"index.search.slowlog.threshold.fetch.warn\": \"1s\"\n}'\n\n# View slow log\ntail -f /var/log/opensearch/research-cluster_index_search_slowlog.log\n</code></pre> <p>4. Disk Space Issues</p> <pre><code># Check disk usage\ncurl http://localhost:9200/_cat/allocation?v\n\n# Delete old indices\ncurl -X DELETE \"http://localhost:9200/old_index\"\n\n# Set disk watermarks\ncurl -X PUT \"http://localhost:9200/_cluster/settings\" -H 'Content-Type: application/json' -d'\n{\n  \"persistent\": {\n    \"cluster.routing.allocation.disk.watermark.low\": \"85%\",\n    \"cluster.routing.allocation.disk.watermark.high\": \"90%\",\n    \"cluster.routing.allocation.disk.watermark.flood_stage\": \"95%\"\n  }\n}'\n</code></pre>"},{"location":"deployment/opensearch/#debug-commands","title":"Debug Commands","text":"<pre><code># Detailed cluster state\ncurl http://localhost:9200/_cluster/state?pretty\n\n# Thread pool stats\ncurl http://localhost:9200/_nodes/stats/thread_pool?pretty\n\n# Circuit breaker stats\ncurl http://localhost:9200/_nodes/stats/breaker?pretty\n\n# Segment stats\ncurl http://localhost:9200/_cat/segments/research_assistant?v\n\n# Recovery status\ncurl http://localhost:9200/_cat/recovery?v&amp;active_only=true\n</code></pre>"},{"location":"deployment/opensearch/#next-steps","title":"Next Steps","text":"<ul> <li>Review Production Considerations for deployment best practices</li> <li>See Docker Deployment for containerized OpenSearch</li> <li>Check Local Deployment for development setup</li> </ul>"},{"location":"deployment/production/","title":"Production Deployment Guide","text":"<p>This comprehensive guide covers production deployment considerations, best practices, and optimization strategies for the Multi-Modal Academic Research System.</p>"},{"location":"deployment/production/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Production Architecture</li> <li>Scaling Strategies</li> <li>Performance Optimization</li> <li>Security Hardening</li> <li>Monitoring and Logging</li> <li>Backup Strategies</li> <li>High Availability Setup</li> <li>Load Balancing</li> <li>Cost Optimization</li> <li>Deployment Checklist</li> </ol>"},{"location":"deployment/production/#production-architecture","title":"Production Architecture","text":""},{"location":"deployment/production/#reference-architecture","title":"Reference Architecture","text":"<pre><code>                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                        \u2502   Load Balancer  \u2502\n                        \u2502   (Nginx/HAProxy)\u2502\n                        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502                \u2502                \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  App Server 1 \u2502 \u2502 App Server 2\u2502 \u2502 App Server 3\u2502\n        \u2502  (Gradio)     \u2502 \u2502  (Gradio)   \u2502 \u2502  (Gradio)   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502                \u2502                \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   OpenSearch Cluster    \u2502\n                    \u2502  \u250c\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2510\u2502\n                    \u2502  \u2502 N1 \u2502  \u2502 N2 \u2502  \u2502 N3 \u2502\u2502\n                    \u2502  \u2514\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2518\u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                 \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   Shared File Storage   \u2502\n                    \u2502  (NFS/S3/EFS/GCS)      \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"deployment/production/#infrastructure-components","title":"Infrastructure Components","text":"<p>1. Application Tier: - Multiple application instances (3+ for HA) - Containerized deployment (Docker/Kubernetes) - Auto-scaling based on load - Health checks and automatic recovery</p> <p>2. Search Tier: - OpenSearch cluster (minimum 3 nodes) - Dedicated master nodes - Hot/warm architecture for data - Automated snapshots</p> <p>3. Storage Tier: - Shared file storage (NFS, S3, EFS) - Separate storage for papers, videos, podcasts - CDN for static assets - Object storage for processed data</p> <p>4. Load Balancing: - Layer 7 load balancer - SSL/TLS termination - Health checks - Session affinity (if needed)</p> <p>5. Monitoring: - Centralized logging (ELK, Splunk) - Metrics collection (Prometheus) - Alerting (PagerDuty, Opsgenie) - APM (Application Performance Monitoring)</p>"},{"location":"deployment/production/#scaling-strategies","title":"Scaling Strategies","text":""},{"location":"deployment/production/#vertical-scaling","title":"Vertical Scaling","text":"<p>Application Servers:</p> <pre><code># docker-compose.prod.yml\nservices:\n  research-app:\n    deploy:\n      resources:\n        limits:\n          cpus: '4'\n          memory: 8G\n        reservations:\n          cpus: '2'\n          memory: 4G\n</code></pre> <p>OpenSearch Nodes:</p> <pre><code># Increase heap size\nenvironment:\n  - \"OPENSEARCH_JAVA_OPTS=-Xms8g -Xmx8g\"\n\n# Add more resources\ndeploy:\n  resources:\n    limits:\n      cpus: '8'\n      memory: 16G\n</code></pre>"},{"location":"deployment/production/#horizontal-scaling","title":"Horizontal Scaling","text":"<p>Application Scaling:</p> <pre><code># Docker Swarm\ndocker service scale research-app=5\n\n# Kubernetes\nkubectl scale deployment research-app --replicas=5\n\n# Docker Compose\ndocker-compose up -d --scale research-app=5\n</code></pre> <p>OpenSearch Scaling:</p> <p>Add more data nodes to the cluster:</p> <pre><code># Add node-4 to docker-compose\nopensearch-node4:\n  image: opensearchproject/opensearch:2.11.0\n  environment:\n    - cluster.name=opensearch-cluster\n    - node.name=opensearch-node4\n    - discovery.seed_hosts=opensearch-node1,opensearch-node2,opensearch-node3\n    - cluster.initial_master_nodes=opensearch-node1,opensearch-node2,opensearch-node3\n    - node.roles=[data]\n</code></pre>"},{"location":"deployment/production/#auto-scaling-configuration","title":"Auto-Scaling Configuration","text":"<p>Kubernetes HPA (Horizontal Pod Autoscaler):</p> <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: research-app-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: research-app\n  minReplicas: 3\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n  behavior:\n    scaleDown:\n      stabilizationWindowSeconds: 300\n      policies:\n      - type: Percent\n        value: 50\n        periodSeconds: 60\n    scaleUp:\n      stabilizationWindowSeconds: 60\n      policies:\n      - type: Percent\n        value: 100\n        periodSeconds: 30\n</code></pre> <p>AWS Auto Scaling:</p> <pre><code>{\n  \"AutoScalingGroupName\": \"research-app-asg\",\n  \"MinSize\": 3,\n  \"MaxSize\": 10,\n  \"DesiredCapacity\": 3,\n  \"HealthCheckType\": \"ELB\",\n  \"HealthCheckGracePeriod\": 300,\n  \"TargetGroupARNs\": [\"arn:aws:elasticloadbalancing:...\"],\n  \"Tags\": [\n    {\n      \"Key\": \"Name\",\n      \"Value\": \"research-app\"\n    }\n  ]\n}\n</code></pre>"},{"location":"deployment/production/#performance-optimization","title":"Performance Optimization","text":""},{"location":"deployment/production/#application-optimization","title":"Application Optimization","text":"<p>1. Caching Strategy:</p> <pre><code># Implement Redis caching\nimport redis\nfrom functools import wraps\n\nredis_client = redis.Redis(\n    host='redis',\n    port=6379,\n    decode_responses=True\n)\n\ndef cache_result(ttl=3600):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            cache_key = f\"{func.__name__}:{str(args)}:{str(kwargs)}\"\n            cached = redis_client.get(cache_key)\n            if cached:\n                return json.loads(cached)\n            result = func(*args, **kwargs)\n            redis_client.setex(cache_key, ttl, json.dumps(result))\n            return result\n        return wrapper\n    return decorator\n\n@cache_result(ttl=1800)\ndef search_papers(query):\n    # Expensive search operation\n    pass\n</code></pre> <p>2. Connection Pooling:</p> <pre><code># OpenSearch connection pool\nfrom opensearchpy import OpenSearch, ConnectionPool\n\nopensearch_client = OpenSearch(\n    hosts=[\n        {'host': 'opensearch-1', 'port': 9200},\n        {'host': 'opensearch-2', 'port': 9200},\n        {'host': 'opensearch-3', 'port': 9200}\n    ],\n    connection_class=ConnectionPool,\n    maxsize=25,  # Connection pool size\n    timeout=30,\n    max_retries=3,\n    retry_on_timeout=True\n)\n</code></pre> <p>3. Async Processing:</p> <pre><code># Use async for I/O operations\nimport asyncio\nimport aiohttp\n\nasync def fetch_multiple_papers(paper_ids):\n    async with aiohttp.ClientSession() as session:\n        tasks = [fetch_paper(session, pid) for pid in paper_ids]\n        return await asyncio.gather(*tasks)\n\nasync def fetch_paper(session, paper_id):\n    async with session.get(f'/api/papers/{paper_id}') as response:\n        return await response.json()\n</code></pre> <p>4. Background Tasks:</p> <pre><code># Use Celery for background processing\nfrom celery import Celery\n\ncelery_app = Celery('research_assistant',\n                    broker='redis://redis:6379/0',\n                    backend='redis://redis:6379/0')\n\n@celery_app.task\ndef process_pdf_async(pdf_path):\n    processor = PDFProcessor()\n    return processor.process(pdf_path)\n\n# Queue task\ntask = process_pdf_async.delay('/path/to/paper.pdf')\nresult = task.get(timeout=300)\n</code></pre> <p>5. Optimize Gradio:</p> <pre><code># Production Gradio configuration\napp.queue(\n    concurrency_count=10,  # Number of concurrent workers\n    max_size=100,  # Max queue size\n    api_open=False  # Disable API for security\n)\n\napp.launch(\n    server_name=\"0.0.0.0\",\n    server_port=7860,\n    share=False,  # Disable public sharing in production\n    enable_queue=True,\n    show_error=False,  # Don't show errors to users\n    ssl_certfile=\"/path/to/cert.pem\",\n    ssl_keyfile=\"/path/to/key.pem\"\n)\n</code></pre>"},{"location":"deployment/production/#database-optimization","title":"Database Optimization","text":"<p>OpenSearch Performance Tuning:</p> <pre><code># Production opensearch.yml\nindices.memory.index_buffer_size: 30%\nindices.queries.cache.size: 15%\nindices.fielddata.cache.size: 25%\n\n# Thread pools\nthread_pool.search.size: 16\nthread_pool.search.queue_size: 2000\nthread_pool.write.size: 8\nthread_pool.write.queue_size: 1000\n\n# Bulk settings\nbulk.queue_size: 500\n\n# Circuit breakers\nindices.breaker.total.limit: 70%\nindices.breaker.request.limit: 45%\nindices.breaker.fielddata.limit: 40%\n</code></pre> <p>Index Optimization:</p> <pre><code># Optimize index settings for production\nproduction_settings = {\n    \"number_of_shards\": 4,\n    \"number_of_replicas\": 2,\n    \"refresh_interval\": \"30s\",\n    \"codec\": \"best_compression\",\n    \"max_result_window\": 10000,\n    \"translog\": {\n        \"durability\": \"async\",\n        \"sync_interval\": \"30s\",\n        \"flush_threshold_size\": \"1gb\"\n    },\n    \"merge\": {\n        \"policy\": {\n            \"max_merged_segment\": \"5gb\",\n            \"segments_per_tier\": 10\n        }\n    }\n}\n</code></pre>"},{"location":"deployment/production/#cdn-integration","title":"CDN Integration","text":"<p>Cloudflare Configuration:</p> <pre><code># Cache static assets via CDN\nlocation ~* \\.(jpg|jpeg|png|gif|ico|css|js)$ {\n    expires 1y;\n    add_header Cache-Control \"public, immutable\";\n    add_header X-Content-Type-Options nosniff;\n}\n\n# Cache API responses (short TTL)\nlocation /api/papers {\n    proxy_pass http://backend;\n    proxy_cache api_cache;\n    proxy_cache_valid 200 5m;\n    proxy_cache_key \"$request_uri\";\n    add_header X-Cache-Status $upstream_cache_status;\n}\n</code></pre>"},{"location":"deployment/production/#security-hardening","title":"Security Hardening","text":""},{"location":"deployment/production/#application-security","title":"Application Security","text":"<p>1. Environment Variables:</p> <pre><code># Use secrets management (AWS Secrets Manager, Vault)\nexport GEMINI_API_KEY=$(aws secretsmanager get-secret-value \\\n    --secret-id research-app/gemini-key \\\n    --query SecretString \\\n    --output text)\n</code></pre> <p>2. Input Validation:</p> <pre><code>from pydantic import BaseModel, validator, Field\n\nclass SearchQuery(BaseModel):\n    query: str = Field(..., min_length=3, max_length=500)\n    filters: dict = Field(default_factory=dict)\n    page: int = Field(default=1, ge=1, le=100)\n\n    @validator('query')\n    def validate_query(cls, v):\n        # Prevent injection attacks\n        if any(char in v for char in ['&lt;', '&gt;', ';', '--']):\n            raise ValueError('Invalid characters in query')\n        return v.strip()\n</code></pre> <p>3. Rate Limiting:</p> <pre><code>from slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\n\nlimiter = Limiter(key_func=get_remote_address)\n\n@app.route(\"/api/search\")\n@limiter.limit(\"100/hour\")\ndef search():\n    # API endpoint with rate limiting\n    pass\n</code></pre> <p>4. Authentication &amp; Authorization:</p> <pre><code># Implement JWT authentication\nfrom jose import JWTError, jwt\nfrom datetime import datetime, timedelta\n\nSECRET_KEY = os.getenv(\"JWT_SECRET_KEY\")\nALGORITHM = \"HS256\"\n\ndef create_access_token(data: dict):\n    to_encode = data.copy()\n    expire = datetime.utcnow() + timedelta(hours=24)\n    to_encode.update({\"exp\": expire})\n    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)\n\ndef verify_token(token: str):\n    try:\n        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])\n        return payload\n    except JWTError:\n        return None\n</code></pre>"},{"location":"deployment/production/#network-security","title":"Network Security","text":"<p>1. Firewall Rules:</p> <pre><code># UFW configuration\nsudo ufw default deny incoming\nsudo ufw default allow outgoing\nsudo ufw allow 22/tcp    # SSH\nsudo ufw allow 80/tcp    # HTTP\nsudo ufw allow 443/tcp   # HTTPS\nsudo ufw allow from 10.0.0.0/8 to any port 9200  # OpenSearch (internal)\nsudo ufw enable\n</code></pre> <p>2. SSL/TLS Configuration:</p> <pre><code># nginx.conf\nserver {\n    listen 443 ssl http2;\n    server_name research.example.com;\n\n    ssl_certificate /etc/ssl/certs/fullchain.pem;\n    ssl_certificate_key /etc/ssl/private/privkey.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384';\n    ssl_prefer_server_ciphers on;\n    ssl_session_cache shared:SSL:10m;\n    ssl_session_timeout 10m;\n    ssl_stapling on;\n    ssl_stapling_verify on;\n\n    # Security headers\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\n    add_header X-Frame-Options \"SAMEORIGIN\" always;\n    add_header X-Content-Type-Options \"nosniff\" always;\n    add_header X-XSS-Protection \"1; mode=block\" always;\n\n    location / {\n        proxy_pass http://research-app:7860;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre> <p>3. VPC/Network Isolation:</p> <pre><code># AWS VPC setup\nVPC:\n  CIDR: 10.0.0.0/16\n  Subnets:\n    Public:\n      - 10.0.1.0/24  # Load balancer\n      - 10.0.2.0/24  # Bastion host\n    Private:\n      - 10.0.10.0/24  # Application servers\n      - 10.0.11.0/24  # Application servers\n      - 10.0.20.0/24  # OpenSearch\n      - 10.0.21.0/24  # OpenSearch\n  SecurityGroups:\n    LoadBalancer:\n      Ingress: [80, 443] from 0.0.0.0/0\n      Egress: [7860] to AppServers\n    AppServers:\n      Ingress: [7860] from LoadBalancer\n      Egress: [9200] to OpenSearch\n    OpenSearch:\n      Ingress: [9200, 9300] from AppServers\n</code></pre>"},{"location":"deployment/production/#secrets-management","title":"Secrets Management","text":"<p>AWS Secrets Manager:</p> <pre><code>import boto3\nimport json\n\ndef get_secret(secret_name):\n    session = boto3.session.Session()\n    client = session.client(service_name='secretsmanager')\n\n    try:\n        response = client.get_secret_value(SecretId=secret_name)\n        return json.loads(response['SecretString'])\n    except Exception as e:\n        print(f\"Error retrieving secret: {e}\")\n        raise\n\n# Usage\nsecrets = get_secret('research-app/production')\nGEMINI_API_KEY = secrets['gemini_api_key']\nOPENSEARCH_PASSWORD = secrets['opensearch_password']\n</code></pre> <p>HashiCorp Vault:</p> <pre><code>import hvac\n\nclient = hvac.Client(url='https://vault.example.com:8200')\nclient.token = os.getenv('VAULT_TOKEN')\n\nsecret = client.secrets.kv.v2.read_secret_version(\n    path='research-app/production'\n)\n\nGEMINI_API_KEY = secret['data']['data']['gemini_api_key']\n</code></pre>"},{"location":"deployment/production/#monitoring-and-logging","title":"Monitoring and Logging","text":""},{"location":"deployment/production/#centralized-logging","title":"Centralized Logging","text":"<p>1. ELK Stack Setup:</p> <pre><code># docker-compose.logging.yml\nversion: '3.8'\n\nservices:\n  elasticsearch:\n    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0\n    environment:\n      - discovery.type=single-node\n      - xpack.security.enabled=false\n    volumes:\n      - elasticsearch-data:/usr/share/elasticsearch/data\n    ports:\n      - \"9200:9200\"\n\n  logstash:\n    image: docker.elastic.co/logstash/logstash:8.10.0\n    volumes:\n      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf\n    ports:\n      - \"5000:5000\"\n    depends_on:\n      - elasticsearch\n\n  kibana:\n    image: docker.elastic.co/kibana/kibana:8.10.0\n    ports:\n      - \"5601:5601\"\n    environment:\n      ELASTICSEARCH_HOSTS: http://elasticsearch:9200\n    depends_on:\n      - elasticsearch\n</code></pre> <p>2. Logstash Configuration:</p> <pre><code># logstash.conf\ninput {\n  tcp {\n    port =&gt; 5000\n    codec =&gt; json\n  }\n  file {\n    path =&gt; \"/var/log/research-assistant/*.log\"\n    start_position =&gt; \"beginning\"\n    sincedb_path =&gt; \"/dev/null\"\n  }\n}\n\nfilter {\n  if [type] == \"research-app\" {\n    grok {\n      match =&gt; { \"message\" =&gt; \"%{TIMESTAMP_ISO8601:timestamp} - %{LOGLEVEL:loglevel} - %{GREEDYDATA:message}\" }\n    }\n    date {\n      match =&gt; [\"timestamp\", \"ISO8601\"]\n      target =&gt; \"@timestamp\"\n    }\n  }\n}\n\noutput {\n  elasticsearch {\n    hosts =&gt; [\"elasticsearch:9200\"]\n    index =&gt; \"research-app-%{+YYYY.MM.dd}\"\n  }\n  stdout { codec =&gt; rubydebug }\n}\n</code></pre> <p>3. Application Logging:</p> <pre><code>import logging\nimport logging.handlers\nimport json\nfrom pythonjsonlogger import jsonlogger\n\n# Configure structured logging\nlogHandler = logging.handlers.RotatingFileHandler(\n    'logs/research_assistant.log',\n    maxBytes=50*1024*1024,  # 50MB\n    backupCount=10\n)\n\nformatter = jsonlogger.JsonFormatter(\n    '%(timestamp)s %(name)s %(levelname)s %(message)s',\n    timestamp=True\n)\n\nlogHandler.setFormatter(formatter)\nlogger = logging.getLogger()\nlogger.addHandler(logHandler)\nlogger.setLevel(logging.INFO)\n\n# Usage\nlogger.info('Search performed', extra={\n    'query': query,\n    'results_count': len(results),\n    'duration_ms': duration,\n    'user_id': user_id\n})\n</code></pre>"},{"location":"deployment/production/#metrics-collection","title":"Metrics Collection","text":"<p>1. Prometheus Setup:</p> <pre><code># prometheus.yml\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n\nscrape_configs:\n  - job_name: 'research-app'\n    static_configs:\n      - targets: ['research-app:8000']\n\n  - job_name: 'opensearch'\n    static_configs:\n      - targets: ['opensearch-exporter:9114']\n\n  - job_name: 'node-exporter'\n    static_configs:\n      - targets: ['node-exporter:9100']\n</code></pre> <p>2. Application Metrics:</p> <pre><code>from prometheus_client import Counter, Histogram, Gauge, start_http_server\n\n# Define metrics\nsearch_requests = Counter('search_requests_total', 'Total search requests')\nsearch_duration = Histogram('search_duration_seconds', 'Search duration')\nactive_users = Gauge('active_users', 'Number of active users')\napi_errors = Counter('api_errors_total', 'Total API errors', ['endpoint'])\n\n# Instrument code\n@search_duration.time()\ndef perform_search(query):\n    search_requests.inc()\n    try:\n        results = opensearch_manager.search(query)\n        return results\n    except Exception as e:\n        api_errors.labels(endpoint='search').inc()\n        raise\n\n# Start metrics server\nstart_http_server(8000)\n</code></pre> <p>3. Grafana Dashboards:</p> <pre><code>{\n  \"dashboard\": {\n    \"title\": \"Research Assistant Monitoring\",\n    \"panels\": [\n      {\n        \"title\": \"Request Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(search_requests_total[5m])\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Search Latency (p95)\",\n        \"targets\": [\n          {\n            \"expr\": \"histogram_quantile(0.95, search_duration_seconds_bucket)\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Error Rate\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(api_errors_total[5m])\"\n          }\n        ]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"deployment/production/#alerting","title":"Alerting","text":"<p>1. Prometheus Alerts:</p> <pre><code># alerts.yml\ngroups:\n  - name: research-app-alerts\n    interval: 30s\n    rules:\n      - alert: HighErrorRate\n        expr: rate(api_errors_total[5m]) &gt; 0.05\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"High error rate detected\"\n          description: \"Error rate is {{ $value }} errors/second\"\n\n      - alert: HighMemoryUsage\n        expr: container_memory_usage_bytes / container_spec_memory_limit_bytes &gt; 0.9\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High memory usage on {{ $labels.container_name }}\"\n\n      - alert: OpenSearchClusterRed\n        expr: opensearch_cluster_health_status{color=\"red\"} == 1\n        for: 1m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"OpenSearch cluster is in RED state\"\n</code></pre> <p>2. PagerDuty Integration:</p> <pre><code>import pypd\n\npypd.api_key = os.getenv('PAGERDUTY_API_KEY')\n\ndef trigger_alert(title, description, severity='error'):\n    pypd.EventV2.create(data={\n        'routing_key': os.getenv('PAGERDUTY_ROUTING_KEY'),\n        'event_action': 'trigger',\n        'payload': {\n            'summary': title,\n            'severity': severity,\n            'source': 'research-assistant',\n            'custom_details': {\n                'description': description\n            }\n        }\n    })\n</code></pre>"},{"location":"deployment/production/#backup-strategies","title":"Backup Strategies","text":""},{"location":"deployment/production/#automated-backup-system","title":"Automated Backup System","text":"<p>1. Backup Script:</p> <pre><code>#!/bin/bash\n# backup.sh\n\nTIMESTAMP=$(date +%Y%m%d_%H%M%S)\nBACKUP_DIR=\"/mnt/backups\"\nS3_BUCKET=\"s3://research-app-backups\"\n\n# OpenSearch snapshot\ncurl -X PUT \"localhost:9200/_snapshot/backup_repo/snapshot_$TIMESTAMP?wait_for_completion=true\"\n\n# Application data\ntar -czf \"$BACKUP_DIR/app_data_$TIMESTAMP.tar.gz\" /app/data/\n\n# Logs\ntar -czf \"$BACKUP_DIR/logs_$TIMESTAMP.tar.gz\" /app/logs/\n\n# Upload to S3\naws s3 sync \"$BACKUP_DIR/\" \"$S3_BUCKET/\" --storage-class GLACIER\n\n# Cleanup old backups (keep 30 days)\nfind \"$BACKUP_DIR/\" -name \"*.tar.gz\" -mtime +30 -delete\n\n# Verify backups\naws s3 ls \"$S3_BUCKET/\" | tail -5\n</code></pre> <p>2. Cron Schedule:</p> <pre><code># /etc/cron.d/research-app-backup\n# Daily backup at 2 AM\n0 2 * * * /opt/research-app/backup.sh &gt;&gt; /var/log/backup.log 2&gt;&amp;1\n\n# Weekly full backup on Sunday\n0 1 * * 0 /opt/research-app/full_backup.sh &gt;&gt; /var/log/backup.log 2&gt;&amp;1\n</code></pre> <p>3. Backup Verification:</p> <pre><code>import subprocess\nimport hashlib\n\ndef verify_backup(backup_file):\n    # Calculate checksum\n    with open(backup_file, 'rb') as f:\n        checksum = hashlib.sha256(f.read()).hexdigest()\n\n    # Test extraction\n    try:\n        subprocess.run(\n            ['tar', '-tzf', backup_file],\n            check=True,\n            capture_output=True\n        )\n        return True, checksum\n    except subprocess.CalledProcessError:\n        return False, None\n\ndef restore_backup(backup_file, destination):\n    subprocess.run(\n        ['tar', '-xzf', backup_file, '-C', destination],\n        check=True\n    )\n</code></pre>"},{"location":"deployment/production/#disaster-recovery-plan","title":"Disaster Recovery Plan","text":"<p>RTO (Recovery Time Objective): 1 hour RPO (Recovery Point Objective): 24 hours</p> <p>Recovery Procedure:</p> <pre><code># 1. Provision new infrastructure\nterraform apply -var-file=production.tfvars\n\n# 2. Restore OpenSearch snapshots\ncurl -X POST \"localhost:9200/_snapshot/backup_repo/latest/_restore\"\n\n# 3. Restore application data\naws s3 sync s3://research-app-backups/latest/ /app/data/\n\n# 4. Verify services\ncurl http://localhost:9200/_cluster/health\ncurl http://localhost:7860/health\n\n# 5. Switch DNS/Load balancer\n# Manual or automated DNS update\n</code></pre>"},{"location":"deployment/production/#high-availability-setup","title":"High Availability Setup","text":""},{"location":"deployment/production/#multi-region-deployment","title":"Multi-Region Deployment","text":"<p>Architecture:</p> <pre><code>Region 1 (Primary)          Region 2 (Secondary)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Load Balancer   \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 Load Balancer   \u2502\n\u2502 App Servers (3) \u2502         \u2502 App Servers (3) \u2502\n\u2502 OpenSearch (3)  \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524 OpenSearch (3)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                           \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                    \u2502\n              Global DNS\n           (Route 53/CloudFlare)\n</code></pre> <p>Cross-Region Replication:</p> <pre><code># OpenSearch cross-cluster replication\ncurl -X PUT \"https://region1-opensearch:9200/_cluster/settings\" -d'\n{\n  \"persistent\": {\n    \"cluster\": {\n      \"remote\": {\n        \"region2\": {\n          \"seeds\": [\"region2-opensearch:9300\"]\n        }\n      }\n    }\n  }\n}'\n\n# Start replication\ncurl -X PUT \"https://region1-opensearch:9200/research_assistant/_ccr/follow\" -d'\n{\n  \"remote_cluster\": \"region2\",\n  \"leader_index\": \"research_assistant\"\n}'\n</code></pre>"},{"location":"deployment/production/#health-checks","title":"Health Checks","text":"<pre><code>from fastapi import FastAPI, Response\nfrom fastapi.responses import JSONResponse\n\napp = FastAPI()\n\n@app.get(\"/health\")\nasync def health_check():\n    checks = {\n        \"opensearch\": check_opensearch(),\n        \"redis\": check_redis(),\n        \"disk_space\": check_disk_space(),\n        \"memory\": check_memory()\n    }\n\n    all_healthy = all(checks.values())\n    status_code = 200 if all_healthy else 503\n\n    return JSONResponse(\n        content={\"status\": \"healthy\" if all_healthy else \"unhealthy\", \"checks\": checks},\n        status_code=status_code\n    )\n\ndef check_opensearch():\n    try:\n        health = opensearch_client.cluster.health()\n        return health['status'] in ['green', 'yellow']\n    except:\n        return False\n\n@app.get(\"/ready\")\nasync def readiness_check():\n    # Check if app is ready to serve traffic\n    return {\"status\": \"ready\"}\n\n@app.get(\"/live\")\nasync def liveness_check():\n    # Check if app is alive\n    return {\"status\": \"alive\"}\n</code></pre>"},{"location":"deployment/production/#load-balancing","title":"Load Balancing","text":""},{"location":"deployment/production/#nginx-configuration","title":"Nginx Configuration","text":"<pre><code># /etc/nginx/nginx.conf\n\nupstream research_app {\n    least_conn;  # Load balancing method\n\n    server app1.example.com:7860 max_fails=3 fail_timeout=30s;\n    server app2.example.com:7860 max_fails=3 fail_timeout=30s;\n    server app3.example.com:7860 max_fails=3 fail_timeout=30s;\n\n    keepalive 32;\n}\n\nserver {\n    listen 80;\n    server_name research.example.com;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name research.example.com;\n\n    ssl_certificate /etc/ssl/certs/fullchain.pem;\n    ssl_certificate_key /etc/ssl/private/privkey.pem;\n\n    # Rate limiting\n    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;\n    limit_req zone=api_limit burst=20 nodelay;\n\n    # Connection limiting\n    limit_conn_zone $binary_remote_addr zone=conn_limit:10m;\n    limit_conn conn_limit 10;\n\n    # Timeouts\n    proxy_connect_timeout 60s;\n    proxy_send_timeout 60s;\n    proxy_read_timeout 60s;\n\n    # Buffer settings\n    proxy_buffering on;\n    proxy_buffer_size 4k;\n    proxy_buffers 8 4k;\n    proxy_busy_buffers_size 8k;\n\n    location / {\n        proxy_pass http://research_app;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # Health check\n        proxy_next_upstream error timeout http_502 http_503 http_504;\n        proxy_next_upstream_tries 3;\n    }\n\n    location /health {\n        access_log off;\n        proxy_pass http://research_app/health;\n    }\n\n    # Static files\n    location /static {\n        alias /var/www/static;\n        expires 1y;\n        add_header Cache-Control \"public, immutable\";\n    }\n}\n</code></pre>"},{"location":"deployment/production/#haproxy-configuration","title":"HAProxy Configuration","text":"<pre><code># /etc/haproxy/haproxy.cfg\n\nglobal\n    log /dev/log local0\n    log /dev/log local1 notice\n    maxconn 4096\n    user haproxy\n    group haproxy\n    daemon\n\ndefaults\n    log     global\n    mode    http\n    option  httplog\n    option  dontlognull\n    timeout connect 5000\n    timeout client  50000\n    timeout server  50000\n\nfrontend http_front\n    bind *:80\n    redirect scheme https code 301 if !{ ssl_fc }\n\nfrontend https_front\n    bind *:443 ssl crt /etc/ssl/certs/research.pem\n    default_backend research_backend\n\nbackend research_backend\n    balance roundrobin\n    option httpchk GET /health\n    http-check expect status 200\n\n    server app1 app1.example.com:7860 check inter 5s fall 3 rise 2\n    server app2 app2.example.com:7860 check inter 5s fall 3 rise 2\n    server app3 app3.example.com:7860 check inter 5s fall 3 rise 2\n\nlisten stats\n    bind *:8404\n    stats enable\n    stats uri /stats\n    stats refresh 30s\n</code></pre>"},{"location":"deployment/production/#cost-optimization","title":"Cost Optimization","text":""},{"location":"deployment/production/#resource-right-sizing","title":"Resource Right-Sizing","text":"<p>1. Monitor Usage:</p> <pre><code># Track resource utilization\nimport psutil\n\ndef log_resource_usage():\n    metrics = {\n        'cpu_percent': psutil.cpu_percent(interval=1),\n        'memory_percent': psutil.virtual_memory().percent,\n        'disk_usage': psutil.disk_usage('/').percent,\n        'network_io': psutil.net_io_counters()._asdict()\n    }\n    logger.info('Resource usage', extra=metrics)\n</code></pre> <p>2. Auto-Scaling Policies:</p> <pre><code># Scale down during low traffic\nscaleDown:\n  - schedule: \"0 22 * * *\"  # 10 PM\n    minReplicas: 1\n    maxReplicas: 3\n\n# Scale up during peak hours\nscaleUp:\n  - schedule: \"0 8 * * *\"  # 8 AM\n    minReplicas: 3\n    maxReplicas: 10\n</code></pre>"},{"location":"deployment/production/#storage-optimization","title":"Storage Optimization","text":"<p>1. Data Lifecycle:</p> <pre><code># Implement data retention policies\nfrom datetime import datetime, timedelta\n\ndef cleanup_old_data():\n    cutoff_date = datetime.now() - timedelta(days=90)\n\n    # Delete old documents\n    opensearch_client.delete_by_query(\n        index='research_assistant',\n        body={\n            'query': {\n                'range': {\n                    'indexed_date': {'lt': cutoff_date.isoformat()}\n                }\n            }\n        }\n    )\n\n    # Move to cold storage\n    archive_to_s3(cutoff_date)\n</code></pre> <p>2. Compression:</p> <pre><code># Compress stored files\nfind /app/data/papers -name \"*.pdf\" -exec gzip {} \\;\n\n# Use compressed index codec\ncurl -X PUT \"localhost:9200/research_assistant/_settings\" -d'\n{\n  \"index\": {\n    \"codec\": \"best_compression\"\n  }\n}'\n</code></pre>"},{"location":"deployment/production/#compute-optimization","title":"Compute Optimization","text":"<p>1. Spot Instances (AWS):</p> <pre><code>resource \"aws_autoscaling_group\" \"research_app\" {\n  mixed_instances_policy {\n    instances_distribution {\n      on_demand_base_capacity                  = 2\n      on_demand_percentage_above_base_capacity = 30\n      spot_allocation_strategy                 = \"capacity-optimized\"\n    }\n\n    launch_template {\n      launch_template_specification {\n        launch_template_id = aws_launch_template.app.id\n        version           = \"$Latest\"\n      }\n\n      override {\n        instance_type = \"c5.xlarge\"\n      }\n      override {\n        instance_type = \"c5a.xlarge\"\n      }\n    }\n  }\n}\n</code></pre> <p>2. Reserved Instances:</p> <p>Purchase reserved instances for baseline capacity.</p>"},{"location":"deployment/production/#deployment-checklist","title":"Deployment Checklist","text":""},{"location":"deployment/production/#pre-deployment","title":"Pre-Deployment","text":"<ul> <li> Security audit completed</li> <li> Load testing performed</li> <li> Backup and recovery tested</li> <li> Monitoring and alerting configured</li> <li> SSL certificates installed and verified</li> <li> DNS configuration updated</li> <li> Firewall rules configured</li> <li> Secrets migrated to secrets manager</li> <li> Documentation updated</li> <li> Runbook created</li> </ul>"},{"location":"deployment/production/#deployment","title":"Deployment","text":"<ul> <li> Create deployment snapshot/backup</li> <li> Deploy to staging environment first</li> <li> Run smoke tests</li> <li> Deploy to production with canary/blue-green</li> <li> Verify health checks</li> <li> Monitor error rates and latency</li> <li> Check logs for anomalies</li> <li> Verify all integrations working</li> <li> Test rollback procedure</li> </ul>"},{"location":"deployment/production/#post-deployment","title":"Post-Deployment","text":"<ul> <li> Monitor performance metrics</li> <li> Review error logs</li> <li> Check backup completion</li> <li> Verify alerting system</li> <li> Update documentation</li> <li> Communicate to stakeholders</li> <li> Schedule post-mortem if needed</li> </ul>"},{"location":"deployment/production/#next-steps","title":"Next Steps","text":"<ul> <li>Review Local Deployment for development setup</li> <li>See Docker Deployment for containerization</li> <li>Check OpenSearch Setup for search configuration</li> </ul>"},{"location":"modules/api/","title":"API Module","text":""},{"location":"modules/api/#overview","title":"Overview","text":"<p>The API module provides a FastAPI-based REST API for visualizing and accessing collected research data. It includes endpoints for retrieving collections, viewing statistics, searching content, and serving a visualization dashboard.</p>"},{"location":"modules/api/#module-architecture","title":"Module Architecture","text":"<pre><code>multi_modal_rag/api/\n\u251c\u2500\u2500 api_server.py         # FastAPI application\n\u2514\u2500\u2500 static/\n    \u2514\u2500\u2500 visualization.html # Frontend dashboard (optional)\n</code></pre>"},{"location":"modules/api/#fastapi-application","title":"FastAPI Application","text":"<p>File: <code>multi_modal_rag/api/api_server.py</code></p>"},{"location":"modules/api/#application-setup","title":"Application Setup","text":"<pre><code>from fastapi import FastAPI\nfrom fastapi.middleware.cors import CORSMiddleware\n\napp = FastAPI(\n    title=\"Multi-Modal Research Data API\",\n    description=\"API for visualizing collected research data\",\n    version=\"1.0.0\"\n)\n</code></pre> <p>Features: - CORS enabled for frontend access - Automatic OpenAPI/Swagger documentation - Integrated database manager - RESTful endpoints</p>"},{"location":"modules/api/#starting-the-server","title":"Starting the Server","text":"<p>Method 1: Direct Execution</p> <pre><code>python -m multi_modal_rag.api.api_server\n</code></pre> <p>Method 2: Using uvicorn</p> <pre><code>uvicorn multi_modal_rag.api.api_server:app --host 0.0.0.0 --port 8000\n</code></pre> <p>Method 3: Using start script</p> <pre><code>python start_api_server.py\n</code></pre> <p>Access Points: - API: http://localhost:8000 - Swagger Docs: http://localhost:8000/docs - ReDoc: http://localhost:8000/redoc</p>"},{"location":"modules/api/#api-endpoints","title":"API Endpoints","text":""},{"location":"modules/api/#root-endpoint","title":"Root Endpoint","text":""},{"location":"modules/api/#get","title":"<code>GET /</code>","text":"<p>Returns API information and available endpoints.</p> <p>Response:</p> <pre><code>{\n    \"message\": \"Multi-Modal Research Data API\",\n    \"endpoints\": {\n        \"collections\": \"/api/collections\",\n        \"statistics\": \"/api/statistics\",\n        \"search\": \"/api/search\",\n        \"visualization\": \"/viz\"\n    }\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/\n</code></pre>"},{"location":"modules/api/#collections-endpoints","title":"Collections Endpoints","text":""},{"location":"modules/api/#get-apicollections","title":"<code>GET /api/collections</code>","text":"<p>Retrieves all collections with optional filtering and pagination.</p> <p>Query Parameters: - <code>content_type</code> (str, optional): Filter by type ('paper', 'video', 'podcast') - <code>limit</code> (int, optional): Max results (1-1000). Default: 100 - <code>offset</code> (int, optional): Offset for pagination. Default: 0</p> <p>Response:</p> <pre><code>{\n    \"count\": 25,\n    \"collections\": [\n        {\n            \"id\": 1,\n            \"content_type\": \"paper\",\n            \"title\": \"Attention Is All You Need\",\n            \"source\": \"arxiv\",\n            \"url\": \"https://arxiv.org/abs/1706.03762\",\n            \"collection_date\": \"2024-10-02T14:30:00\",\n            \"metadata\": {\n                \"query\": \"transformer models\",\n                \"categories\": [\"cs.CL\", \"cs.LG\"]\n            },\n            \"status\": \"collected\",\n            \"indexed\": true\n        },\n        // ... more collections\n    ]\n}\n</code></pre> <p>Examples:</p> <pre><code># Get all collections\ncurl http://localhost:8000/api/collections\n\n# Get only papers\ncurl http://localhost:8000/api/collections?content_type=paper\n\n# Get videos with pagination\ncurl http://localhost:8000/api/collections?content_type=video&amp;limit=20&amp;offset=0\n\n# Get second page\ncurl http://localhost:8000/api/collections?limit=50&amp;offset=50\n</code></pre> <p>Python Client:</p> <pre><code>import requests\n\n# Get all collections\nresponse = requests.get(\"http://localhost:8000/api/collections\")\ndata = response.json()\n\nprint(f\"Total collections: {data['count']}\")\nfor item in data['collections']:\n    print(f\"  - {item['title']} ({item['content_type']})\")\n\n# Filter by type\nresponse = requests.get(\n    \"http://localhost:8000/api/collections\",\n    params={\"content_type\": \"paper\", \"limit\": 50}\n)\npapers = response.json()['collections']\n</code></pre>"},{"location":"modules/api/#get-apicollectionscollection_id","title":"<code>GET /api/collections/{collection_id}</code>","text":"<p>Retrieves detailed information for a specific collection.</p> <p>Path Parameters: - <code>collection_id</code> (int): Collection ID</p> <p>Response:</p> <pre><code>{\n    \"id\": 1,\n    \"content_type\": \"paper\",\n    \"title\": \"Attention Is All You Need\",\n    \"source\": \"arxiv\",\n    \"url\": \"https://arxiv.org/abs/1706.03762\",\n    \"collection_date\": \"2024-10-02T14:30:00\",\n    \"metadata\": {\n        \"query\": \"transformer models\",\n        \"categories\": [\"cs.CL\", \"cs.LG\"]\n    },\n    \"status\": \"collected\",\n    \"indexed\": true,\n    \"details\": {\n        \"id\": 1,\n        \"collection_id\": 1,\n        \"arxiv_id\": \"1706.03762\",\n        \"pmc_id\": null,\n        \"abstract\": \"The dominant sequence transduction models...\",\n        \"authors\": [\"Ashish Vaswani\", \"Noam Shazeer\", \"Niki Parmar\"],\n        \"published_date\": \"2017-06-12\",\n        \"categories\": [\"cs.CL\", \"cs.LG\"],\n        \"pdf_path\": \"data/papers/1706.03762.pdf\"\n    }\n}\n</code></pre> <p>Error Responses:</p> <pre><code>// 404 Not Found\n{\n    \"detail\": \"Collection not found\"\n}\n\n// 500 Internal Server Error\n{\n    \"detail\": \"Error message here\"\n}\n</code></pre> <p>Examples:</p> <pre><code># Get collection details\ncurl http://localhost:8000/api/collections/1\n\n# Handle errors\ncurl http://localhost:8000/api/collections/99999\n# Returns 404 with \"Collection not found\"\n</code></pre> <p>Python Client:</p> <pre><code>import requests\n\ndef get_collection_details(collection_id: int):\n    response = requests.get(\n        f\"http://localhost:8000/api/collections/{collection_id}\"\n    )\n\n    if response.status_code == 200:\n        data = response.json()\n        print(f\"Title: {data['title']}\")\n        print(f\"Type: {data['content_type']}\")\n\n        if 'details' in data:\n            if data['content_type'] == 'paper':\n                details = data['details']\n                print(f\"Authors: {', '.join(details['authors'])}\")\n                print(f\"Abstract: {details['abstract'][:200]}...\")\n    else:\n        print(f\"Error: {response.status_code}\")\n\nget_collection_details(1)\n</code></pre>"},{"location":"modules/api/#statistics-endpoint","title":"Statistics Endpoint","text":""},{"location":"modules/api/#get-apistatistics","title":"<code>GET /api/statistics</code>","text":"<p>Retrieves database statistics.</p> <p>Response:</p> <pre><code>{\n    \"by_type\": {\n        \"paper\": 150,\n        \"video\": 75,\n        \"podcast\": 30\n    },\n    \"indexed\": 200,\n    \"not_indexed\": 55,\n    \"recent_7_days\": 25,\n    \"collection_history\": [\n        {\n            \"type\": \"paper\",\n            \"source\": \"arxiv\",\n            \"total\": 150\n        },\n        {\n            \"type\": \"video\",\n            \"source\": \"youtube\",\n            \"total\": 75\n        },\n        {\n            \"type\": \"podcast\",\n            \"source\": \"rss\",\n            \"total\": 30\n        }\n    ]\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/api/statistics\n</code></pre> <p>Python Client:</p> <pre><code>import requests\n\nresponse = requests.get(\"http://localhost:8000/api/statistics\")\nstats = response.json()\n\nprint(\"=== Database Statistics ===\")\nprint(f\"\\nContent by Type:\")\nfor content_type, count in stats['by_type'].items():\n    print(f\"  {content_type}: {count}\")\n\nprint(f\"\\nIndexing Status:\")\nprint(f\"  Indexed: {stats['indexed']}\")\nprint(f\"  Not Indexed: {stats['not_indexed']}\")\n\ntotal = stats['indexed'] + stats['not_indexed']\npercentage = (stats['indexed'] / total * 100) if total &gt; 0 else 0\nprint(f\"  Completion: {percentage:.1f}%\")\n\nprint(f\"\\nRecent Activity:\")\nprint(f\"  Last 7 days: {stats['recent_7_days']} new items\")\n</code></pre> <p>Visualization Example:</p> <pre><code>import matplotlib.pyplot as plt\n\n# Pie chart of content types\nresponse = requests.get(\"http://localhost:8000/api/statistics\")\nstats = response.json()\n\nlabels = list(stats['by_type'].keys())\nsizes = list(stats['by_type'].values())\n\nplt.pie(sizes, labels=labels, autopct='%1.1f%%')\nplt.title('Collection Distribution by Type')\nplt.show()\n</code></pre>"},{"location":"modules/api/#search-endpoint","title":"Search Endpoint","text":""},{"location":"modules/api/#get-apisearch","title":"<code>GET /api/search</code>","text":"<p>Searches collections by title or source.</p> <p>Query Parameters: - <code>q</code> (str, required): Search query (min 1 character) - <code>limit</code> (int, optional): Max results (1-500). Default: 50</p> <p>Response:</p> <pre><code>{\n    \"query\": \"transformer\",\n    \"count\": 12,\n    \"results\": [\n        {\n            \"id\": 1,\n            \"content_type\": \"paper\",\n            \"title\": \"Attention Is All You Need\",\n            \"source\": \"arxiv\",\n            \"url\": \"https://arxiv.org/abs/1706.03762\",\n            \"collection_date\": \"2024-10-02T14:30:00\",\n            \"metadata\": {...},\n            \"status\": \"collected\",\n            \"indexed\": true\n        },\n        // ... more results\n    ]\n}\n</code></pre> <p>Examples:</p> <pre><code># Search by title keyword\ncurl \"http://localhost:8000/api/search?q=transformer\"\n\n# Search by source\ncurl \"http://localhost:8000/api/search?q=arxiv&amp;limit=100\"\n\n# Search with special characters (URL encoded)\ncurl \"http://localhost:8000/api/search?q=neural%20networks\"\n</code></pre> <p>Python Client:</p> <pre><code>import requests\n\ndef search_collections(query: str, limit: int = 50):\n    response = requests.get(\n        \"http://localhost:8000/api/search\",\n        params={\"q\": query, \"limit\": limit}\n    )\n\n    data = response.json()\n    print(f\"Query: '{data['query']}'\")\n    print(f\"Found {data['count']} results\\n\")\n\n    for item in data['results']:\n        print(f\"  {item['id']}: {item['title']}\")\n        print(f\"     Type: {item['content_type']}, Source: {item['source']}\")\n        print()\n\n# Search for papers about attention\nsearch_collections(\"attention\", limit=10)\n\n# Search for specific source\nsearch_collections(\"youtube\")\n</code></pre>"},{"location":"modules/api/#visualization-dashboard","title":"Visualization Dashboard","text":""},{"location":"modules/api/#get-viz","title":"<code>GET /viz</code>","text":"<p>Serves the HTML visualization dashboard.</p> <p>Response: HTML page with interactive visualizations</p> <p>Features: - Charts showing collection distribution - Filter by content type - Search functionality - Recent activity timeline - Statistics cards</p> <p>Access:</p> <pre><code># Open in browser\nopen http://localhost:8000/viz\n</code></pre> <p>Fallback Response (if visualization.html not found):</p> <pre><code>&lt;html&gt;\n    &lt;body&gt;\n        &lt;h1&gt;Visualization page not found&lt;/h1&gt;\n        &lt;p&gt;Please ensure visualization.html exists in the static directory&lt;/p&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Dashboard Implementation:</p> <p>The visualization page should be located at: <pre><code>multi_modal_rag/api/static/visualization.html\n</code></pre></p> <p>Example Dashboard HTML:</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Research Collection Dashboard&lt;/title&gt;\n    &lt;script src=\"https://cdn.jsdelivr.net/npm/chart.js\"&gt;&lt;/script&gt;\n    &lt;style&gt;\n        body { font-family: Arial, sans-serif; margin: 20px; }\n        .stats-card {\n            display: inline-block;\n            padding: 20px;\n            margin: 10px;\n            background: #f0f0f0;\n            border-radius: 8px;\n        }\n        .chart-container {\n            width: 400px;\n            height: 400px;\n            display: inline-block;\n        }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Research Collection Dashboard&lt;/h1&gt;\n\n    &lt;div id=\"stats\"&gt;&lt;/div&gt;\n    &lt;div id=\"charts\"&gt;&lt;/div&gt;\n\n    &lt;script&gt;\n        // Fetch statistics\n        fetch('/api/statistics')\n            .then(response =&gt; response.json())\n            .then(stats =&gt; {\n                // Display stats cards\n                document.getElementById('stats').innerHTML = `\n                    &lt;div class=\"stats-card\"&gt;\n                        &lt;h3&gt;Total Papers&lt;/h3&gt;\n                        &lt;p&gt;${stats.by_type.paper || 0}&lt;/p&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"stats-card\"&gt;\n                        &lt;h3&gt;Total Videos&lt;/h3&gt;\n                        &lt;p&gt;${stats.by_type.video || 0}&lt;/p&gt;\n                    &lt;/div&gt;\n                    &lt;div class=\"stats-card\"&gt;\n                        &lt;h3&gt;Indexed&lt;/h3&gt;\n                        &lt;p&gt;${stats.indexed}&lt;/p&gt;\n                    &lt;/div&gt;\n                `;\n\n                // Create pie chart\n                const ctx = document.createElement('canvas');\n                document.getElementById('charts').appendChild(ctx);\n\n                new Chart(ctx, {\n                    type: 'pie',\n                    data: {\n                        labels: Object.keys(stats.by_type),\n                        datasets: [{\n                            data: Object.values(stats.by_type),\n                            backgroundColor: ['#FF6384', '#36A2EB', '#FFCE56']\n                        }]\n                    }\n                });\n            });\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"modules/api/#health-check-endpoint","title":"Health Check Endpoint","text":""},{"location":"modules/api/#get-health","title":"<code>GET /health</code>","text":"<p>Health check endpoint for monitoring.</p> <p>Response:</p> <pre><code>{\n    \"status\": \"healthy\"\n}\n</code></pre> <p>Example:</p> <pre><code>curl http://localhost:8000/health\n</code></pre> <p>Use Cases: - Load balancer health checks - Container orchestration (Kubernetes) - Monitoring systems - CI/CD pipelines</p>"},{"location":"modules/api/#cors-configuration","title":"CORS Configuration","text":"<p>The API is configured to allow cross-origin requests:</p> <pre><code>app.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],          # Allow all origins\n    allow_credentials=True,\n    allow_methods=[\"*\"],          # Allow all HTTP methods\n    allow_headers=[\"*\"],          # Allow all headers\n)\n</code></pre> <p>Security Note: For production, restrict <code>allow_origins</code> to specific domains:</p> <pre><code>allow_origins=[\n    \"https://yourdomain.com\",\n    \"http://localhost:3000\"\n]\n</code></pre>"},{"location":"modules/api/#error-handling","title":"Error Handling","text":""},{"location":"modules/api/#http-status-codes","title":"HTTP Status Codes","text":"Code Description When Used 200 OK Successful request 404 Not Found Collection ID doesn't exist 422 Unprocessable Entity Invalid parameters 500 Internal Server Error Database or server error"},{"location":"modules/api/#error-response-format","title":"Error Response Format","text":"<pre><code>{\n    \"detail\": \"Error message describing what went wrong\"\n}\n</code></pre> <p>Examples:</p> <pre><code>from fastapi import HTTPException\n\n# Collection not found\nraise HTTPException(status_code=404, detail=\"Collection not found\")\n\n# Invalid parameters (handled by FastAPI automatically)\n# Query parameter validation fails \u2192 422\n\n# Database error\nraise HTTPException(status_code=500, detail=str(e))\n</code></pre>"},{"location":"modules/api/#integration-examples","title":"Integration Examples","text":""},{"location":"modules/api/#frontend-integration-react","title":"Frontend Integration (React)","text":"<pre><code>import React, { useState, useEffect } from 'react';\n\nfunction CollectionsList() {\n    const [collections, setCollections] = useState([]);\n    const [loading, setLoading] = useState(true);\n\n    useEffect(() =&gt; {\n        fetch('http://localhost:8000/api/collections?limit=50')\n            .then(response =&gt; response.json())\n            .then(data =&gt; {\n                setCollections(data.collections);\n                setLoading(false);\n            });\n    }, []);\n\n    if (loading) return &lt;div&gt;Loading...&lt;/div&gt;;\n\n    return (\n        &lt;div&gt;\n            &lt;h1&gt;Collections ({collections.length})&lt;/h1&gt;\n            {collections.map(item =&gt; (\n                &lt;div key={item.id}&gt;\n                    &lt;h3&gt;{item.title}&lt;/h3&gt;\n                    &lt;p&gt;Type: {item.content_type}&lt;/p&gt;\n                    &lt;p&gt;Source: {item.source}&lt;/p&gt;\n                &lt;/div&gt;\n            ))}\n        &lt;/div&gt;\n    );\n}\n</code></pre>"},{"location":"modules/api/#python-data-analysis","title":"Python Data Analysis","text":"<pre><code>import requests\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Fetch all collections\nresponse = requests.get(\"http://localhost:8000/api/collections?limit=1000\")\ncollections = response.json()['collections']\n\n# Convert to DataFrame\ndf = pd.DataFrame(collections)\n\n# Analysis\nprint(\"Collections by Type:\")\nprint(df['content_type'].value_counts())\n\nprint(\"\\nCollections by Source:\")\nprint(df['source'].value_counts())\n\n# Visualization\ndf['content_type'].value_counts().plot(kind='bar')\nplt.title('Collections by Type')\nplt.xlabel('Content Type')\nplt.ylabel('Count')\nplt.show()\n\n# Time series analysis\ndf['collection_date'] = pd.to_datetime(df['collection_date'])\ndf.set_index('collection_date', inplace=True)\ndf.resample('D').size().plot()\nplt.title('Collections Over Time')\nplt.show()\n</code></pre>"},{"location":"modules/api/#cli-tool","title":"CLI Tool","text":"<pre><code>import click\nimport requests\n\n@click.group()\ndef cli():\n    \"\"\"Research Collection CLI\"\"\"\n    pass\n\n@cli.command()\n@click.option('--type', help='Filter by content type')\n@click.option('--limit', default=10, help='Number of results')\ndef list_collections(type, limit):\n    \"\"\"List collections\"\"\"\n    params = {'limit': limit}\n    if type:\n        params['content_type'] = type\n\n    response = requests.get('http://localhost:8000/api/collections', params=params)\n    data = response.json()\n\n    click.echo(f\"Found {data['count']} collections\\n\")\n    for item in data['collections']:\n        click.echo(f\"[{item['id']}] {item['title']}\")\n        click.echo(f\"    Type: {item['content_type']}, Source: {item['source']}\")\n        click.echo()\n\n@cli.command()\n@click.argument('query')\ndef search(query):\n    \"\"\"Search collections\"\"\"\n    response = requests.get('http://localhost:8000/api/search', params={'q': query})\n    data = response.json()\n\n    click.echo(f\"Query: '{data['query']}' - {data['count']} results\\n\")\n    for item in data['results']:\n        click.echo(f\"\u2022 {item['title']} ({item['content_type']})\")\n\n@cli.command()\ndef stats():\n    \"\"\"Show statistics\"\"\"\n    response = requests.get('http://localhost:8000/api/statistics')\n    data = response.json()\n\n    click.echo(\"=== Statistics ===\\n\")\n    click.echo(\"By Type:\")\n    for t, count in data['by_type'].items():\n        click.echo(f\"  {t}: {count}\")\n\n    click.echo(f\"\\nIndexed: {data['indexed']}\")\n    click.echo(f\"Not Indexed: {data['not_indexed']}\")\n\nif __name__ == '__main__':\n    cli()\n</code></pre> <p>Usage:</p> <pre><code>python cli_tool.py list-collections --type paper --limit 5\npython cli_tool.py search \"neural networks\"\npython cli_tool.py stats\n</code></pre>"},{"location":"modules/api/#performance-considerations","title":"Performance Considerations","text":""},{"location":"modules/api/#response-times","title":"Response Times","text":"<p>Typical Response Times: - <code>GET /</code>: &lt;5ms - <code>GET /api/collections</code>: 10-50ms (100 items) - <code>GET /api/collections/{id}</code>: 5-20ms - <code>GET /api/statistics</code>: 20-100ms (aggregations) - <code>GET /api/search</code>: 50-200ms (LIKE query)</p>"},{"location":"modules/api/#optimization-tips","title":"Optimization Tips","text":"<ol> <li> <p>Pagination: Always use <code>limit</code> parameter    <pre><code># Good\nresponse = requests.get('/api/collections?limit=50')\n\n# Bad (loads all)\nresponse = requests.get('/api/collections?limit=10000')\n</code></pre></p> </li> <li> <p>Caching: Implement Redis caching for statistics    <pre><code>from fastapi_cache import FastAPICache\nfrom fastapi_cache.decorator import cache\n\n@app.get(\"/api/statistics\")\n@cache(expire=300)  # Cache for 5 minutes\nasync def get_statistics():\n    ...\n</code></pre></p> </li> <li> <p>Database Indexing: Add indexes to frequently queried fields    <pre><code>CREATE INDEX idx_content_type ON collections(content_type);\nCREATE INDEX idx_indexed ON collections(indexed);\n</code></pre></p> </li> <li> <p>Async Database Operations: Use async SQLite library    <pre><code>import aiosqlite\n\n@app.get(\"/api/collections\")\nasync def get_collections(...):\n    async with aiosqlite.connect(db_path) as db:\n        async with db.execute(\"SELECT ...\") as cursor:\n            rows = await cursor.fetchall()\n</code></pre></p> </li> </ol>"},{"location":"modules/api/#security-considerations","title":"Security Considerations","text":""},{"location":"modules/api/#production-deployment","title":"Production Deployment","text":"<ol> <li> <p>CORS: Restrict origins    <pre><code>allow_origins=[\"https://yourdomain.com\"]\n</code></pre></p> </li> <li> <p>Authentication: Add API key or OAuth    <pre><code>from fastapi.security import APIKeyHeader\n\napi_key_header = APIKeyHeader(name=\"X-API-Key\")\n\n@app.get(\"/api/collections\")\nasync def get_collections(api_key: str = Depends(api_key_header)):\n    if api_key != os.getenv(\"API_KEY\"):\n        raise HTTPException(401, \"Invalid API key\")\n    ...\n</code></pre></p> </li> <li> <p>Rate Limiting: Prevent abuse    <pre><code>from slowapi import Limiter\nfrom slowapi.util import get_remote_address\n\nlimiter = Limiter(key_func=get_remote_address)\n\n@app.get(\"/api/search\")\n@limiter.limit(\"10/minute\")\nasync def search(...):\n    ...\n</code></pre></p> </li> <li> <p>HTTPS: Use SSL/TLS in production    <pre><code>uvicorn app:app --host 0.0.0.0 --port 443 --ssl-keyfile key.pem --ssl-certfile cert.pem\n</code></pre></p> </li> </ol>"},{"location":"modules/api/#deployment","title":"Deployment","text":""},{"location":"modules/api/#docker-deployment","title":"Docker Deployment","text":"<p>Dockerfile:</p> <pre><code>FROM python:3.10-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nEXPOSE 8000\n\nCMD [\"uvicorn\", \"multi_modal_rag.api.api_server:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre> <p>docker-compose.yml:</p> <pre><code>version: '3.8'\n\nservices:\n  api:\n    build: .\n    ports:\n      - \"8000:8000\"\n    volumes:\n      - ./data:/app/data\n    environment:\n      - DATABASE_PATH=/app/data/collections.db\n</code></pre> <p>Run:</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"modules/api/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<p>deployment.yaml:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: research-api\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: research-api\n  template:\n    metadata:\n      labels:\n        app: research-api\n    spec:\n      containers:\n      - name: api\n        image: research-api:latest\n        ports:\n        - containerPort: 8000\n        env:\n        - name: DATABASE_PATH\n          value: \"/data/collections.db\"\n        volumeMounts:\n        - name: data\n          mountPath: /data\n      volumes:\n      - name: data\n        persistentVolumeClaim:\n          claimName: research-data-pvc\n</code></pre>"},{"location":"modules/api/#dependencies","title":"Dependencies","text":"<pre><code>from fastapi import FastAPI, Query, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.responses import HTMLResponse\nimport uvicorn\n</code></pre> <p>Installation:</p> <pre><code>pip install fastapi uvicorn[standard]\n</code></pre>"},{"location":"modules/api/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/api/#issue-port-already-in-use","title":"Issue: Port already in use","text":"<p>Error: <code>OSError: [Errno 48] Address already in use</code></p> <p>Solution: Use different port or kill existing process <pre><code># Find process\nlsof -i :8000\n\n# Kill process\nkill -9 &lt;PID&gt;\n\n# Or use different port\nuvicorn app:app --port 8001\n</code></pre></p>"},{"location":"modules/api/#issue-cors-errors-in-browser","title":"Issue: CORS errors in browser","text":"<p>Error: <code>Access to fetch at 'http://localhost:8000' from origin 'http://localhost:3000' has been blocked by CORS policy</code></p> <p>Solution: Ensure CORS middleware is configured correctly <pre><code>app.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3000\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n</code></pre></p>"},{"location":"modules/api/#issue-422-unprocessable-entity","title":"Issue: 422 Unprocessable Entity","text":"<p>Cause: Invalid query parameters</p> <p>Example: <pre><code># Missing required parameter 'q'\ncurl http://localhost:8000/api/search\n# Returns: {\"detail\":[{\"loc\":[\"query\",\"q\"],\"msg\":\"field required\",...}]}\n</code></pre></p> <p>Solution: Provide required parameters <pre><code>curl \"http://localhost:8000/api/search?q=test\"\n</code></pre></p>"},{"location":"modules/api/#api-documentation","title":"API Documentation","text":""},{"location":"modules/api/#auto-generated-docs","title":"Auto-Generated Docs","text":"<p>FastAPI automatically generates interactive API documentation:</p> <p>Swagger UI: http://localhost:8000/docs - Interactive testing - Try endpoints directly in browser - View request/response schemas</p> <p>ReDoc: http://localhost:8000/redoc - Clean, readable documentation - Three-panel layout - Better for sharing with team</p> <p>OpenAPI Schema: http://localhost:8000/openapi.json - Machine-readable API specification - Use for client generation - Import into Postman/Insomnia</p>"},{"location":"modules/data-collectors/","title":"Data Collectors Module","text":""},{"location":"modules/data-collectors/#overview","title":"Overview","text":"<p>The Data Collectors module provides a unified interface for collecting academic content from multiple free sources. It includes three main collectors for papers, videos, and podcasts, each implementing rate limiting and error handling to ensure respectful API usage.</p>"},{"location":"modules/data-collectors/#module-architecture","title":"Module Architecture","text":"<pre><code>multi_modal_rag/data_collectors/\n\u251c\u2500\u2500 paper_collector.py      # ArXiv, PubMed Central, Semantic Scholar\n\u251c\u2500\u2500 youtube_collector.py    # YouTube educational content\n\u2514\u2500\u2500 podcast_collector.py    # RSS podcast feeds\n</code></pre>"},{"location":"modules/data-collectors/#academicpapercollector","title":"AcademicPaperCollector","text":"<p>File: <code>multi_modal_rag/data_collectors/paper_collector.py</code></p>"},{"location":"modules/data-collectors/#class-overview","title":"Class Overview","text":"<p>Collects free academic papers from multiple sources including ArXiv, PubMed Central, and Semantic Scholar.</p>"},{"location":"modules/data-collectors/#initialization","title":"Initialization","text":"<pre><code>from multi_modal_rag.data_collectors import AcademicPaperCollector\n\ncollector = AcademicPaperCollector(save_dir=\"data/papers\")\n</code></pre> <p>Parameters: - <code>save_dir</code> (str, optional): Directory to save downloaded PDFs. Default: <code>\"data/papers\"</code></p>"},{"location":"modules/data-collectors/#methods","title":"Methods","text":""},{"location":"modules/data-collectors/#collect_arxiv_papersquery-str-max_results-int-100-listdict","title":"<code>collect_arxiv_papers(query: str, max_results: int = 100) -&gt; List[Dict]</code>","text":"<p>Collects papers from ArXiv, a free preprint repository.</p> <p>Parameters: - <code>query</code> (str): Search query (e.g., \"machine learning\", \"quantum computing\") - <code>max_results</code> (int, optional): Maximum number of papers to collect. Default: 100</p> <p>Returns: List of dictionaries with paper metadata:</p> <pre><code>{\n    'title': str,              # Paper title\n    'abstract': str,           # Paper abstract\n    'authors': List[str],      # List of author names\n    'pdf_url': str,           # Direct PDF URL\n    'arxiv_id': str,          # ArXiv identifier\n    'published': str,         # ISO format publication date\n    'categories': List[str],  # ArXiv categories\n    'local_path': str         # Path to downloaded PDF\n}\n</code></pre> <p>Example:</p> <pre><code>collector = AcademicPaperCollector()\npapers = collector.collect_arxiv_papers(\"deep learning\", max_results=50)\n\nfor paper in papers:\n    print(f\"Title: {paper['title']}\")\n    print(f\"Authors: {', '.join(paper['authors'])}\")\n    print(f\"PDF saved to: {paper['local_path']}\")\n</code></pre> <p>Rate Limiting: Includes 1-second delay between downloads to respect ArXiv API guidelines.</p>"},{"location":"modules/data-collectors/#collect_pubmed_centralquery-str-max_results-int-50-listdict","title":"<code>collect_pubmed_central(query: str, max_results: int = 50) -&gt; List[Dict]</code>","text":"<p>Collects from PubMed Central Open Access Subset (biomedical papers).</p> <p>Parameters: - <code>query</code> (str): Search query - <code>max_results</code> (int, optional): Maximum results. Default: 50</p> <p>Returns: List of dictionaries:</p> <pre><code>{\n    'pmc_id': str,           # PubMed Central ID\n    'source': str,           # Always 'pubmed_central'\n    'pdf_url': str           # PDF download URL\n}\n</code></pre> <p>Example:</p> <pre><code>papers = collector.collect_pubmed_central(\"COVID-19 treatment\", max_results=30)\n</code></pre> <p>Rate Limiting: 0.5-second delay between requests.</p> <p>Note: This method only returns metadata and PDF URLs. Papers must be downloaded separately.</p>"},{"location":"modules/data-collectors/#collect_semantic_scholarquery-str-max_results-int-50-listdict","title":"<code>collect_semantic_scholar(query: str, max_results: int = 50) -&gt; List[Dict]</code>","text":"<p>Collects from Semantic Scholar's free API, filtering for open-access PDFs.</p> <p>Parameters: - <code>query</code> (str): Search query - <code>max_results</code> (int, optional): Maximum results. Default: 50</p> <p>Returns: List of dictionaries:</p> <pre><code>{\n    'title': str,\n    'abstract': str,\n    'authors': List[Dict],  # Author objects with name, authorId\n    'year': int,\n    'pdf_url': str,        # Open access PDF URL\n    'source': str          # Always 'semantic_scholar'\n}\n</code></pre> <p>Example:</p> <pre><code>papers = collector.collect_semantic_scholar(\"transformer models\", max_results=25)\n\n# Filter for recent papers\nrecent_papers = [p for p in papers if p.get('year', 0) &gt;= 2023]\n</code></pre>"},{"location":"modules/data-collectors/#youtubelecturecollector","title":"YouTubeLectureCollector","text":"<p>File: <code>multi_modal_rag/data_collectors/youtube_collector.py</code></p>"},{"location":"modules/data-collectors/#class-overview_1","title":"Class Overview","text":"<p>Collects educational YouTube videos with transcripts using <code>yt-dlp</code> and <code>youtube-transcript-api</code>.</p>"},{"location":"modules/data-collectors/#initialization_1","title":"Initialization","text":"<pre><code>from multi_modal_rag.data_collectors import YouTubeLectureCollector\n\ncollector = YouTubeLectureCollector(save_dir=\"data/videos\")\n</code></pre> <p>Parameters: - <code>save_dir</code> (str, optional): Directory for video metadata. Default: <code>\"data/videos\"</code></p> <p>Dependencies: Requires <code>yt-dlp</code> to be installed: <pre><code>pip install yt-dlp\n</code></pre></p>"},{"location":"modules/data-collectors/#methods_1","title":"Methods","text":""},{"location":"modules/data-collectors/#get_educational_channels-liststr","title":"<code>get_educational_channels() -&gt; List[str]</code>","text":"<p>Returns a curated list of educational YouTube channels.</p> <p>Returns: List of channel URLs:</p> <pre><code>[\n    \"https://www.youtube.com/@mitocw\",         # MIT OpenCourseWare\n    \"https://www.youtube.com/@stanford\",       # Stanford\n    \"https://www.youtube.com/@GoogleDeepMind\", # DeepMind\n    \"https://www.youtube.com/@OpenAI\",         # OpenAI\n    \"https://www.youtube.com/@khanacademy\",    # Khan Academy\n    \"https://www.youtube.com/@3blue1brown\",    # 3Blue1Brown\n    \"https://www.youtube.com/@TwoMinutePapers\", # Two Minute Papers\n    \"https://www.youtube.com/@YannicKilcher\",  # Yannic Kilcher\n    \"https://www.youtube.com/@CSdojo\",         # CS Dojo\n]\n</code></pre>"},{"location":"modules/data-collectors/#collect_video_metadatavideo_url-str-dict","title":"<code>collect_video_metadata(video_url: str) -&gt; Dict</code>","text":"<p>Collects complete metadata and transcript for a single YouTube video.</p> <p>Parameters: - <code>video_url</code> (str): Full YouTube video URL</p> <p>Returns: Dictionary with video data:</p> <pre><code>{\n    'video_id': str,          # YouTube video ID\n    'title': str,             # Video title\n    'description': str,       # Video description\n    'author': str,            # Channel name/uploader\n    'length': int,            # Duration in seconds\n    'views': int,             # View count\n    'url': str,               # Original URL\n    'transcript': str,        # Full transcript text\n    'thumbnail_url': str,     # Thumbnail image URL\n    'publish_date': str       # Upload date (YYYYMMDD format)\n}\n</code></pre> <p>Example:</p> <pre><code>collector = YouTubeLectureCollector()\nvideo_url = \"https://www.youtube.com/watch?v=aircAruvnKk\"\nmetadata = collector.collect_video_metadata(video_url)\n\nprint(f\"Title: {metadata['title']}\")\nprint(f\"Channel: {metadata['author']}\")\nprint(f\"Duration: {metadata['length']} seconds\")\nprint(f\"Transcript length: {len(metadata['transcript'])} characters\")\n</code></pre> <p>Error Handling: - Returns <code>None</code> if <code>yt-dlp</code> is not installed - Returns metadata with <code>\"Transcript not available\"</code> if transcript extraction fails - Logs warnings for missing transcripts</p>"},{"location":"modules/data-collectors/#extract_video_idurl-str-str","title":"<code>extract_video_id(url: str) -&gt; str</code>","text":"<p>Extracts video ID from various YouTube URL formats.</p> <p>Parameters: - <code>url</code> (str): YouTube URL in any format</p> <p>Returns: Video ID string or <code>None</code> if not found</p> <p>Supported Formats: <pre><code># Standard watch URL\n\"https://www.youtube.com/watch?v=VIDEO_ID\"\n\n# Shortened URL\n\"https://youtu.be/VIDEO_ID\"\n\n# Embed URL\n\"https://www.youtube.com/embed/VIDEO_ID\"\n</code></pre></p>"},{"location":"modules/data-collectors/#search_youtube_lecturesquery-str-max_results-int-50-listdict","title":"<code>search_youtube_lectures(query: str, max_results: int = 50) -&gt; List[Dict]</code>","text":"<p>Searches YouTube for educational videos and collects their metadata.</p> <p>Parameters: - <code>query</code> (str): Search query (automatically appended with \"lecture tutorial course\") - <code>max_results</code> (int, optional): Maximum videos to collect. Default: 50</p> <p>Returns: List of video metadata dictionaries (same structure as <code>collect_video_metadata</code>)</p> <p>Example:</p> <pre><code>collector = YouTubeLectureCollector()\nvideos = collector.search_youtube_lectures(\"quantum computing\", max_results=20)\n\nfor video in videos:\n    if video['transcript'] != \"Transcript not available\":\n        print(f\"\u2713 {video['title']} - Has transcript\")\n    else:\n        print(f\"\u2717 {video['title']} - No transcript\")\n</code></pre> <p>Search Enhancement: Query is automatically enhanced with \" lecture tutorial course\" to focus on educational content.</p> <p>Error Handling: - Returns empty list if <code>yt-dlp</code> not installed - Logs detailed progress and errors - Skips videos that fail metadata collection</p>"},{"location":"modules/data-collectors/#podcastcollector","title":"PodcastCollector","text":"<p>File: <code>multi_modal_rag/data_collectors/podcast_collector.py</code></p>"},{"location":"modules/data-collectors/#class-overview_2","title":"Class Overview","text":"<p>Collects podcast episodes from RSS feeds with optional audio transcription using Whisper.</p>"},{"location":"modules/data-collectors/#initialization_2","title":"Initialization","text":"<pre><code>from multi_modal_rag.data_collectors import PodcastCollector\n\ncollector = PodcastCollector(save_dir=\"data/podcasts\")\n</code></pre> <p>Parameters: - <code>save_dir</code> (str, optional): Directory for audio files and transcripts. Default: <code>\"data/podcasts\"</code></p>"},{"location":"modules/data-collectors/#methods_2","title":"Methods","text":""},{"location":"modules/data-collectors/#get_educational_podcasts-dictstr-str","title":"<code>get_educational_podcasts() -&gt; Dict[str, str]</code>","text":"<p>Returns curated educational podcast RSS feeds.</p> <p>Returns: Dictionary mapping podcast names to RSS URLs:</p> <pre><code>{\n    \"Lex Fridman Podcast\": \"https://lexfridman.com/feed/podcast/\",\n    \"Machine Learning Street Talk\": \"https://anchor.fm/s/1e4a0eac/podcast/rss\",\n    \"Data Skeptic\": \"https://dataskeptic.com/feed.rss\",\n    \"The TWIML AI Podcast\": \"https://twimlai.com/feed/\",\n    \"Learning Machines 101\": \"http://www.learningmachines101.com/rss\",\n    \"Talking Machines\": \"http://www.thetalkingmachines.com/rss\",\n    \"AI in Business\": \"https://feeds.soundcloud.com/.../sounds.rss\",\n    \"Eye on AI\": \"https://www.eye-on.ai/podcast-rss.xml\"\n}\n</code></pre> <p>Example:</p> <pre><code>collector = PodcastCollector()\nfeeds = collector.get_educational_podcasts()\n\nfor name, rss_url in feeds.items():\n    print(f\"Podcast: {name}\")\n    print(f\"Feed: {rss_url}\")\n</code></pre>"},{"location":"modules/data-collectors/#collect_podcast_episodesrss_url-str-max_episodes-int-10-listdict","title":"<code>collect_podcast_episodes(rss_url: str, max_episodes: int = 10) -&gt; List[Dict]</code>","text":"<p>Collects episodes from a podcast RSS feed.</p> <p>Parameters: - <code>rss_url</code> (str): RSS feed URL - <code>max_episodes</code> (int, optional): Maximum episodes to collect. Default: 10</p> <p>Returns: List of episode dictionaries:</p> <pre><code>{\n    'title': str,          # Episode title\n    'description': str,    # Episode description/summary\n    'published': str,      # Publication date\n    'link': str,          # Episode web page URL\n    'audio_url': str,     # Direct audio file URL (MP3/M4A)\n    'transcript': None    # Initially None, populated by transcribe_audio()\n}\n</code></pre> <p>Example:</p> <pre><code>collector = PodcastCollector()\nrss_url = \"https://lexfridman.com/feed/podcast/\"\nepisodes = collector.collect_podcast_episodes(rss_url, max_episodes=5)\n\nfor ep in episodes:\n    print(f\"Title: {ep['title']}\")\n    print(f\"Published: {ep['published']}\")\n    print(f\"Audio URL: {ep['audio_url']}\")\n</code></pre> <p>Error Handling: - Returns empty list if RSS feed fails to parse - Logs warnings for malformed feeds - Attempts to find audio URL in multiple RSS locations (links, enclosures)</p>"},{"location":"modules/data-collectors/#transcribe_audioaudio_url-str-episode_id-str-str","title":"<code>transcribe_audio(audio_url: str, episode_id: str) -&gt; str</code>","text":"<p>Downloads and transcribes podcast audio using OpenAI's Whisper model.</p> <p>Parameters: - <code>audio_url</code> (str): Direct URL to audio file - <code>episode_id</code> (str): Unique identifier for the episode (used for filename)</p> <p>Returns: Transcript text as a string, or <code>None</code> on error</p> <p>Example:</p> <pre><code>collector = PodcastCollector()\n\n# Collect episodes\nepisodes = collector.collect_podcast_episodes(\n    \"https://lexfridman.com/feed/podcast/\",\n    max_episodes=1\n)\n\n# Transcribe first episode\nif episodes and episodes[0]['audio_url']:\n    transcript = collector.transcribe_audio(\n        episodes[0]['audio_url'],\n        episode_id=\"lex_001\"\n    )\n    print(f\"Transcript: {transcript[:500]}...\")\n</code></pre> <p>Whisper Model: - Uses <code>base</code> model by default (good balance of speed and accuracy) - Model is loaded once and cached for subsequent transcriptions - First load may take time to download model weights</p> <p>Performance: - Downloads audio file to disk before transcription - Transcription can take several minutes for long episodes - Logs download progress and transcription status</p> <p>Error Handling: - Returns <code>None</code> if download fails (network error, invalid URL) - Returns <code>None</code> if Whisper transcription fails - Logs detailed error messages</p>"},{"location":"modules/data-collectors/#integration-example","title":"Integration Example","text":"<p>Here's how to use all collectors together:</p> <pre><code>from multi_modal_rag.data_collectors import (\n    AcademicPaperCollector,\n    YouTubeLectureCollector,\n    PodcastCollector\n)\n\n# Initialize all collectors\npaper_collector = AcademicPaperCollector()\nvideo_collector = YouTubeLectureCollector()\npodcast_collector = PodcastCollector()\n\n# Collect content on a topic\ntopic = \"neural networks\"\n\n# 1. Collect papers\npapers = paper_collector.collect_arxiv_papers(topic, max_results=10)\nprint(f\"Collected {len(papers)} papers\")\n\n# 2. Collect videos\nvideos = video_collector.search_youtube_lectures(topic, max_results=5)\nprint(f\"Collected {len(videos)} videos\")\n\n# 3. Collect podcasts\npodcasts = []\nfor name, rss_url in podcast_collector.get_educational_podcasts().items():\n    episodes = podcast_collector.collect_podcast_episodes(rss_url, max_episodes=2)\n    podcasts.extend(episodes)\nprint(f\"Collected {len(podcasts)} podcast episodes\")\n\n# All content is now ready for processing and indexing\nall_content = {\n    'papers': papers,\n    'videos': videos,\n    'podcasts': podcasts\n}\n</code></pre>"},{"location":"modules/data-collectors/#rate-limiting-and-best-practices","title":"Rate Limiting and Best Practices","text":""},{"location":"modules/data-collectors/#arxiv","title":"ArXiv","text":"<ul> <li>Rate Limit: 1 second between requests (implemented)</li> <li>Best Practice: Use specific queries to reduce result set</li> <li>API Docs: https://info.arxiv.org/help/api/index.html</li> </ul>"},{"location":"modules/data-collectors/#pubmed-central","title":"PubMed Central","text":"<ul> <li>Rate Limit: 0.5 seconds between requests (implemented)</li> <li>Best Practice: Include \"open access\" filter in queries</li> <li>API Docs: https://www.ncbi.nlm.nih.gov/books/NBK25497/</li> </ul>"},{"location":"modules/data-collectors/#semantic-scholar","title":"Semantic Scholar","text":"<ul> <li>Rate Limit: None implemented (API is rate-limited server-side)</li> <li>Best Practice: Filter for <code>openAccessPdf</code> to ensure free content</li> <li>API Docs: https://api.semanticscholar.org/</li> </ul>"},{"location":"modules/data-collectors/#youtube","title":"YouTube","text":"<ul> <li>Dependencies: Requires <code>yt-dlp</code> installation</li> <li>Rate Limit: None implemented (yt-dlp handles this)</li> <li>Best Practice: Check for transcript availability before processing</li> </ul>"},{"location":"modules/data-collectors/#podcasts","title":"Podcasts","text":"<ul> <li>Dependencies: Requires <code>whisper</code> and <code>pydub</code> for transcription</li> <li>Rate Limit: None needed for RSS feeds</li> <li>Best Practice: Transcribe selectively due to processing time</li> </ul>"},{"location":"modules/data-collectors/#error-handling","title":"Error Handling","text":"<p>All collectors implement robust error handling:</p> <ol> <li>Network Errors: Gracefully handle connection failures</li> <li>API Errors: Log and skip problematic items</li> <li>File Errors: Create directories if they don't exist</li> <li>Data Validation: Handle missing or malformed fields</li> </ol> <p>Common Error Patterns:</p> <pre><code>try:\n    papers = collector.collect_arxiv_papers(\"query\", max_results=100)\nexcept Exception as e:\n    print(f\"Collection failed: {e}\")\n    papers = []  # Fallback to empty list\n</code></pre>"},{"location":"modules/data-collectors/#logging","title":"Logging","text":"<p>All collectors use the centralized logging system:</p> <pre><code>from multi_modal_rag.logging_config import get_logger\n\nlogger = get_logger(__name__)\n</code></pre> <p>Log Levels: - <code>INFO</code>: Collection start/end, counts, success messages - <code>DEBUG</code>: Detailed processing steps, API calls - <code>WARNING</code>: Missing data, failed transcripts, malformed content - <code>ERROR</code>: Critical failures, exceptions</p> <p>Example Log Output:</p> <pre><code>INFO - YouTubeLectureCollector initialized with save_dir: data/videos\nINFO - Starting YouTube search for query: 'quantum computing' with max_results: 20\nDEBUG - Using yt-dlp search query: 'ytsearch20:quantum computing lecture tutorial course'\nINFO - yt-dlp returned 20 results\nDEBUG - Processing video 1/20: https://www.youtube.com/watch?v=...\nINFO - Successfully collected metadata for: Quantum Computing Introduction by MIT\nINFO - Successfully collected 20 videos\n</code></pre>"},{"location":"modules/data-collectors/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/data-collectors/#issue-yt-dlp-not-found","title":"Issue: yt-dlp not found","text":"<p>Solution: <pre><code>pip install yt-dlp\n</code></pre></p>"},{"location":"modules/data-collectors/#issue-youtube-transcript-not-available","title":"Issue: YouTube transcript not available","text":"<p>Cause: Video doesn't have captions/subtitles</p> <p>Solution: Collectors handle this gracefully by setting <code>transcript: \"Transcript not available\"</code></p>"},{"location":"modules/data-collectors/#issue-whisper-model-download-fails","title":"Issue: Whisper model download fails","text":"<p>Cause: Network issues or insufficient disk space</p> <p>Solution: <pre><code># Pre-download Whisper model\nimport whisper\nmodel = whisper.load_model(\"base\")  # Downloads ~140MB\n</code></pre></p>"},{"location":"modules/data-collectors/#issue-arxiv-download-timeout","title":"Issue: ArXiv download timeout","text":"<p>Cause: Large PDFs or slow network</p> <p>Solution: Increase timeout in arxiv library (modify source or retry)</p>"},{"location":"modules/data-collectors/#issue-rss-feed-parsing-fails","title":"Issue: RSS feed parsing fails","text":"<p>Cause: Malformed XML or network errors</p> <p>Solution: Collectors log warnings and continue; check RSS feed validity</p>"},{"location":"modules/data-collectors/#module-dependencies","title":"Module Dependencies","text":"<pre><code># paper_collector.py\nimport arxiv\nimport requests\nfrom scholarly import scholarly\n\n# youtube_collector.py\nimport yt_dlp\nfrom youtube_transcript_api import YouTubeTranscriptApi\n\n# podcast_collector.py\nimport feedparser\nimport requests\nimport whisper\nfrom pydub import AudioSegment\n</code></pre> <p>Install all dependencies: <pre><code>pip install arxiv requests scholarly yt-dlp youtube-transcript-api feedparser openai-whisper pydub\n</code></pre></p>"},{"location":"modules/data-processors/","title":"Data Processors Module","text":""},{"location":"modules/data-processors/#overview","title":"Overview","text":"<p>The Data Processors module handles extraction and analysis of content from collected academic materials. It uses Google Gemini's multimodal AI capabilities to extract text, analyze diagrams, and understand video content.</p>"},{"location":"modules/data-processors/#module-architecture","title":"Module Architecture","text":"<pre><code>multi_modal_rag/data_processors/\n\u251c\u2500\u2500 pdf_processor.py      # PDF text/image extraction and analysis\n\u2514\u2500\u2500 video_processor.py    # Video content analysis\n</code></pre>"},{"location":"modules/data-processors/#pdfprocessor","title":"PDFProcessor","text":"<p>File: <code>multi_modal_rag/data_processors/pdf_processor.py</code></p>"},{"location":"modules/data-processors/#class-overview","title":"Class Overview","text":"<p>Processes PDF documents to extract text, images, and diagrams. Uses Google Gemini Vision to analyze visual content and generate textual descriptions that can be indexed and searched.</p>"},{"location":"modules/data-processors/#initialization","title":"Initialization","text":"<pre><code>from multi_modal_rag.data_processors import PDFProcessor\n\nprocessor = PDFProcessor(gemini_api_key=\"YOUR_API_KEY\")\n</code></pre> <p>Parameters: - <code>gemini_api_key</code> (str): Google Gemini API key from https://makersuite.google.com/app/apikey</p> <p>Models Used: - <code>gemini-2.0-flash</code>: Fast text analysis model (free tier) - <code>gemini-2.0-flash-exp</code>: Vision model for diagram analysis (free tier)</p>"},{"location":"modules/data-processors/#methods","title":"Methods","text":""},{"location":"modules/data-processors/#extract_text_and_imagespdf_path-str-dict","title":"<code>extract_text_and_images(pdf_path: str) -&gt; Dict</code>","text":"<p>Extracts all text and images from a PDF document using PyMuPDF (fitz).</p> <p>Parameters: - <code>pdf_path</code> (str): Absolute path to PDF file</p> <p>Returns: Dictionary with extracted content:</p> <pre><code>{\n    'text_pages': List[Dict[str, Any]],  # Text content per page\n    'images': List[Dict[str, Any]],      # Extracted images\n    'combined_text': str,                # All text concatenated\n    'metadata': {\n        'page_count': int,\n        'title': str,\n        'author': str\n    }\n}\n</code></pre> <p>Detailed Structure:</p> <pre><code># text_pages structure\ntext_pages = [\n    {\n        'page': 1,           # Page number (1-indexed)\n        'text': str          # Extracted text from page\n    },\n    # ... more pages\n]\n\n# images structure\nimages = [\n    {\n        'page': int,         # Page number where image appears\n        'index': int,        # Index of image on that page\n        'image': PIL.Image,  # PIL Image object\n        'bytes': bytes       # Raw image bytes\n    },\n    # ... more images\n]\n\n# combined_text format\ncombined_text = \"\"\"\n[Page 1]\nText from page 1...\n\n[Page 2]\nText from page 2...\n\"\"\"\n</code></pre> <p>Example:</p> <pre><code>processor = PDFProcessor(gemini_api_key=\"your_key\")\ncontent = processor.extract_text_and_images(\"papers/arxiv_paper.pdf\")\n\nprint(f\"Total pages: {content['metadata']['page_count']}\")\nprint(f\"Document title: {content['metadata']['title']}\")\nprint(f\"Images found: {len(content['images'])}\")\n\n# Access text from specific page\nfirst_page_text = content['text_pages'][0]['text']\nprint(f\"First page: {first_page_text[:500]}...\")\n\n# Access images\nfor img_data in content['images']:\n    print(f\"Image on page {img_data['page']}: {img_data['image'].size}\")\n</code></pre> <p>Technical Details: - Uses PyMuPDF (fitz) for robust PDF parsing - Extracts embedded images in original format - Preserves image metadata (page location, index) - Handles encrypted PDFs (if not password-protected) - Efficiently processes large PDFs</p>"},{"location":"modules/data-processors/#analyze_with_geminipdf_content-dict-dict","title":"<code>analyze_with_gemini(pdf_content: Dict) -&gt; Dict</code>","text":"<p>Analyzes extracted PDF content using Google Gemini AI for deeper understanding.</p> <p>Parameters: - <code>pdf_content</code> (Dict): Output from <code>extract_text_and_images()</code></p> <p>Returns: Analysis dictionary:</p> <pre><code>{\n    'summary': str,                          # AI-generated summary\n    'key_concepts': List[str],              # Extracted concepts\n    'diagram_descriptions': List[Dict],      # Visual content analysis\n    'extracted_equations': List[str],        # Mathematical equations (reserved)\n    'citations': List[str]                   # Referenced papers (reserved)\n}\n</code></pre> <p>Detailed Structure:</p> <pre><code># diagram_descriptions structure\ndiagram_descriptions = [\n    {\n        'page': int,             # Page number\n        'description': str       # AI-generated description\n    },\n    # ... more diagrams\n]\n\n# key_concepts extraction\nkey_concepts = [\n    \"Transformer architecture\",\n    \"Self-attention mechanism\",\n    \"Positional encoding\",\n    # ... more concepts\n]\n</code></pre> <p>Example:</p> <pre><code>processor = PDFProcessor(gemini_api_key=\"your_key\")\n\n# Step 1: Extract content\npdf_content = processor.extract_text_and_images(\"papers/transformer_paper.pdf\")\n\n# Step 2: Analyze with AI\nanalysis = processor.analyze_with_gemini(pdf_content)\n\n# View summary\nprint(\"Summary:\")\nprint(analysis['summary'])\n\n# View key concepts\nprint(\"\\nKey Concepts:\")\nfor concept in analysis['key_concepts']:\n    print(f\"  - {concept}\")\n\n# View diagram descriptions\nprint(\"\\nDiagrams:\")\nfor diagram in analysis['diagram_descriptions']:\n    print(f\"Page {diagram['page']}: {diagram['description']}\")\n</code></pre> <p>AI Analysis Workflow:</p> <ol> <li>Text Analysis (First 10,000 characters):</li> <li>Generates comprehensive 2-3 sentence summary</li> <li>Extracts 3-5 main concepts and definitions</li> <li> <p>Identifies key references (planned feature)</p> </li> <li> <p>Visual Analysis (First 5 images):</p> </li> <li>Identifies diagram type (flowchart, graph, architecture, etc.)</li> <li>Lists key components visible in diagram</li> <li>Explains the concept the diagram illustrates</li> <li>Extracts any text or labels from the image</li> </ol> <p>Prompt Template for Text:</p> <pre><code>Analyze this academic paper and extract:\n1. A comprehensive summary (2-3 sentences)\n2. Key concepts and definitions (list 3-5 main concepts)\n3. Any references mentioned\n\nPaper content:\n{first_10000_chars}\n\nProvide response in clear sections.\n</code></pre> <p>Prompt Template for Images:</p> <pre><code>Describe this diagram/figure from an academic paper:\n1. What type of diagram is it? (flowchart, graph, architecture, etc.)\n2. What are the key components?\n3. What concept does it illustrate?\n4. Extract any text or labels from the image\n</code></pre> <p>Example Output:</p> <pre><code>{\n    'summary': 'This paper introduces the Transformer architecture, a novel neural network model that relies entirely on attention mechanisms. The model achieves state-of-the-art results on machine translation tasks while being more parallelizable than recurrent architectures.',\n\n    'key_concepts': [\n        'Self-attention mechanism',\n        'Multi-head attention',\n        'Positional encoding',\n        'Encoder-decoder architecture',\n        'Layer normalization'\n    ],\n\n    'diagram_descriptions': [\n        {\n            'page': 3,\n            'description': 'This is an architecture diagram showing the Transformer model structure. The diagram shows two main components: an encoder stack on the left and decoder stack on the right. Key components include multi-head attention layers, feed-forward networks, and residual connections. The diagram labels show N=6 layers in each stack.'\n        },\n        {\n            'page': 5,\n            'description': 'This is a flowchart illustrating the scaled dot-product attention mechanism. The diagram shows matrix multiplication between Query (Q) and Key (K), followed by scaling, softmax, and multiplication with Value (V). The formula \"Attention(Q,K,V) = softmax(QK^T/\u221ad_k)V\" is visible.'\n        }\n    ],\n\n    'extracted_equations': [],  # Reserved for future enhancement\n    'citations': []             # Reserved for future enhancement\n}\n</code></pre> <p>Error Handling: - If Gemini API fails, returns raw text (first 500 chars) as summary - Logs warnings for failed image analyses but continues processing - Continues to next image if one fails (doesn't halt entire analysis)</p> <p>Performance Notes: - Text analysis: ~2-5 seconds - Per-image analysis: ~3-7 seconds - Total time for paper with 5 images: ~30-40 seconds - Uses free tier Gemini models (no cost)</p>"},{"location":"modules/data-processors/#videoprocessor","title":"VideoProcessor","text":"<p>File: <code>multi_modal_rag/data_processors/video_processor.py</code></p>"},{"location":"modules/data-processors/#class-overview_1","title":"Class Overview","text":"<p>Processes video content, primarily educational YouTube videos, by analyzing metadata, descriptions, and transcripts using Google Gemini AI.</p>"},{"location":"modules/data-processors/#initialization_1","title":"Initialization","text":"<pre><code>from multi_modal_rag.data_processors import VideoProcessor\n\nprocessor = VideoProcessor(gemini_api_key=\"YOUR_API_KEY\")\n</code></pre> <p>Parameters: - <code>gemini_api_key</code> (str): Google Gemini API key</p> <p>Model Used: - <code>gemini-2.0-flash</code>: Fast text analysis (free tier)</p>"},{"location":"modules/data-processors/#methods_1","title":"Methods","text":""},{"location":"modules/data-processors/#extract_key_framesvideo_url-str-num_frames-int-10-listimageimage","title":"<code>extract_key_frames(video_url: str, num_frames: int = 10) -&gt; List[Image.Image]</code>","text":"<p>Extracts key frames from video for visual analysis.</p> <p>Status: Simplified implementation (placeholder)</p> <p>Parameters: - <code>video_url</code> (str): Video URL - <code>num_frames</code> (int, optional): Number of frames to extract. Default: 10</p> <p>Returns: List of PIL Image objects (currently empty list)</p> <p>Note: Full implementation would require: <pre><code>import cv2\n\ndef extract_key_frames(self, video_path: str, num_frames: int = 10):\n    cap = cv2.VideoCapture(video_path)\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    interval = total_frames // num_frames\n\n    frames = []\n    for i in range(num_frames):\n        cap.set(cv2.CAP_PROP_POS_FRAMES, i * interval)\n        ret, frame = cap.read()\n        if ret:\n            image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n            frames.append(image)\n\n    cap.release()\n    return frames\n</code></pre></p>"},{"location":"modules/data-processors/#analyze_video_contentvideo_metadata-dict-dict","title":"<code>analyze_video_content(video_metadata: Dict) -&gt; Dict</code>","text":"<p>Analyzes video content using metadata, description, and transcript.</p> <p>Parameters: - <code>video_metadata</code> (Dict): Video data from YouTubeLectureCollector:</p> <pre><code>{\n    'title': str,\n    'description': str,\n    'transcript': str,\n    'author': str,\n    'length': int,\n    'views': int,\n    # ... other metadata\n}\n</code></pre> <p>Returns: String containing structured analysis (JSON format intended)</p> <p>Example:</p> <pre><code>from multi_modal_rag.data_collectors import YouTubeLectureCollector\nfrom multi_modal_rag.data_processors import VideoProcessor\n\n# Collect video metadata\ncollector = YouTubeLectureCollector()\nvideo_data = collector.collect_video_metadata(\n    \"https://www.youtube.com/watch?v=aircAruvnKk\"\n)\n\n# Analyze content\nprocessor = VideoProcessor(gemini_api_key=\"your_key\")\nanalysis = processor.analyze_video_content(video_data)\n\nprint(analysis)\n</code></pre> <p>Analysis Prompt Template:</p> <pre><code>Analyze this educational video:\nTitle: {title}\nDescription: {description}\nTranscript: {first_5000_chars_of_transcript}\n\nExtract:\n1. Main topics covered\n2. Key learning points\n3. Prerequisites needed\n4. Technical concepts explained\n5. Practical applications mentioned\n\nFormat as structured JSON.\n</code></pre> <p>Example Analysis Output:</p> <pre><code>{\n    \"main_topics\": [\n        \"Neural networks fundamentals\",\n        \"Gradient descent optimization\",\n        \"Backpropagation algorithm\"\n    ],\n    \"key_learning_points\": [\n        \"Understanding how neurons process information\",\n        \"Relationship between weights and predictions\",\n        \"How networks learn from errors\"\n    ],\n    \"prerequisites\": [\n        \"Basic calculus (derivatives)\",\n        \"Linear algebra (matrix multiplication)\",\n        \"Python programming\"\n    ],\n    \"technical_concepts\": [\n        \"Activation functions\",\n        \"Loss functions\",\n        \"Learning rate\",\n        \"Forward and backward passes\"\n    ],\n    \"practical_applications\": [\n        \"Image classification\",\n        \"Natural language processing\",\n        \"Recommendation systems\"\n    ]\n}\n</code></pre> <p>Limitations: - Uses first 5,000 characters of transcript (to fit within context limits) - Returns text response (JSON parsing needed by caller) - Does not analyze actual video frames (uses transcript only)</p>"},{"location":"modules/data-processors/#integration-workflow","title":"Integration Workflow","text":""},{"location":"modules/data-processors/#complete-pdf-processing-pipeline","title":"Complete PDF Processing Pipeline","text":"<pre><code>from multi_modal_rag.data_collectors import AcademicPaperCollector\nfrom multi_modal_rag.data_processors import PDFProcessor\n\n# Step 1: Collect papers\ncollector = AcademicPaperCollector()\npapers = collector.collect_arxiv_papers(\"attention is all you need\", max_results=1)\n\n# Step 2: Process PDFs\nprocessor = PDFProcessor(gemini_api_key=\"your_key\")\n\nfor paper in papers:\n    print(f\"\\nProcessing: {paper['title']}\")\n\n    # Extract content\n    content = processor.extract_text_and_images(paper['local_path'])\n    print(f\"  Pages: {content['metadata']['page_count']}\")\n    print(f\"  Images: {len(content['images'])}\")\n\n    # Analyze with AI\n    analysis = processor.analyze_with_gemini(content)\n\n    # Prepare for indexing\n    indexable_doc = {\n        'title': paper['title'],\n        'authors': paper['authors'],\n        'abstract': paper['abstract'],\n        'content': content['combined_text'],\n        'summary': analysis['summary'],\n        'key_concepts': analysis['key_concepts'],\n        'diagram_descriptions': [\n            d['description'] for d in analysis['diagram_descriptions']\n        ],\n        'publication_date': paper['published'],\n        'content_type': 'paper'\n    }\n\n    # Ready to index in OpenSearch\n    print(f\"  Key concepts: {', '.join(analysis['key_concepts'][:3])}\")\n</code></pre>"},{"location":"modules/data-processors/#complete-video-processing-pipeline","title":"Complete Video Processing Pipeline","text":"<pre><code>from multi_modal_rag.data_collectors import YouTubeLectureCollector\nfrom multi_modal_rag.data_processors import VideoProcessor\n\n# Step 1: Collect videos\ncollector = YouTubeLectureCollector()\nvideos = collector.search_youtube_lectures(\"neural networks\", max_results=3)\n\n# Step 2: Process videos\nprocessor = VideoProcessor(gemini_api_key=\"your_key\")\n\nfor video in videos:\n    if video['transcript'] != \"Transcript not available\":\n        print(f\"\\nProcessing: {video['title']}\")\n\n        # Analyze content\n        analysis = processor.analyze_video_content(video)\n\n        # Prepare for indexing\n        indexable_doc = {\n            'title': video['title'],\n            'authors': [video['author']],\n            'content': video['description'],\n            'transcript': video['transcript'],\n            'analysis': analysis,  # Structured analysis from Gemini\n            'url': video['url'],\n            'content_type': 'video'\n        }\n\n        print(f\"  Duration: {video['length']} seconds\")\n        print(f\"  Transcript length: {len(video['transcript'])} chars\")\n</code></pre>"},{"location":"modules/data-processors/#gemini-vision-integration","title":"Gemini Vision Integration","text":""},{"location":"modules/data-processors/#how-diagram-analysis-works","title":"How Diagram Analysis Works","text":"<p>The PDF processor uses Gemini's vision capabilities to \"see\" and understand diagrams:</p> <ol> <li>Image Extraction: PyMuPDF extracts images as PIL Image objects</li> <li>Image Conversion: PIL images converted to PNG bytes</li> <li>Multimodal Prompt: Image + text prompt sent to Gemini Vision</li> <li>Description Generation: AI generates textual description</li> <li>Indexing: Description stored as searchable text</li> </ol> <p>Code Flow:</p> <pre><code># Extract image from PDF (PyMuPDF)\nimage_bytes = doc.extract_image(xref)[\"image\"]\nimage = Image.open(io.BytesIO(image_bytes))\n\n# Convert to PNG for Gemini\nimg_bytes = io.BytesIO()\nimage.save(img_bytes, format='PNG')\nimg_bytes = img_bytes.getvalue()\n\n# Create multimodal content\ncontents = [\n    types.Content(\n        role=\"user\",\n        parts=[\n            types.Part.from_text(text=image_prompt),\n            types.Part.from_bytes(data=img_bytes, mime_type=\"image/png\")\n        ]\n    )\n]\n\n# Get AI description\nresponse = self.client.models.generate_content(\n    model=self.vision_model,\n    contents=contents\n)\n\ndescription = response.text\n</code></pre>"},{"location":"modules/data-processors/#why-this-matters","title":"Why This Matters","text":"<p>Traditional RAG systems can only search text. By converting diagrams to text descriptions:</p> <ol> <li>Searchability: Users can find papers by describing diagrams</li> <li>Query: \"architecture diagram with encoder and decoder\"</li> <li> <p>Matches: Transformer paper (from diagram description)</p> </li> <li> <p>Understanding: AI can explain complex visual concepts</p> </li> <li> <p>Diagram \u2192 \"This shows a neural network with 3 layers...\"</p> </li> <li> <p>Citation: LLM can reference visual evidence</p> </li> <li>Answer: \"As shown in the attention mechanism diagram [Paper, 2023]...\"</li> </ol>"},{"location":"modules/data-processors/#gemini-sdk-usage","title":"Gemini SDK Usage","text":""},{"location":"modules/data-processors/#new-sdk-pattern-2024","title":"New SDK Pattern (2024)","text":"<p>The processors use the latest Gemini SDK:</p> <pre><code>from google import genai\nfrom google.genai import types\n\n# Initialize client\nclient = genai.Client(api_key=\"YOUR_KEY\")\n\n# Text generation\ncontents = [\n    types.Content(\n        role=\"user\",\n        parts=[types.Part.from_text(text=\"Your prompt\")]\n    )\n]\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash\",\n    contents=contents\n)\n\nprint(response.text)\n\n# Vision (multimodal)\ncontents = [\n    types.Content(\n        role=\"user\",\n        parts=[\n            types.Part.from_text(text=\"Describe this image\"),\n            types.Part.from_bytes(data=image_bytes, mime_type=\"image/png\")\n        ]\n    )\n]\n\nresponse = client.models.generate_content(\n    model=\"gemini-2.0-flash-exp\",\n    contents=contents\n)\n</code></pre>"},{"location":"modules/data-processors/#free-tier-limits","title":"Free Tier Limits","text":"<ul> <li>gemini-2.0-flash: 15 requests/minute, 1 million tokens/minute</li> <li>gemini-2.0-flash-exp: Same limits</li> <li>Rate limiting: Not implemented (Gemini handles server-side)</li> </ul>"},{"location":"modules/data-processors/#error-handling","title":"Error Handling","text":""},{"location":"modules/data-processors/#pdf-processing-errors","title":"PDF Processing Errors","text":"<pre><code>try:\n    content = processor.extract_text_and_images(\"paper.pdf\")\nexcept Exception as e:\n    print(f\"Extraction failed: {e}\")\n    # Handle: file not found, corrupt PDF, permission error\n</code></pre> <p>Common Issues: - File not found: Check path is absolute and file exists - Corrupt PDF: Try redownloading or using different source - Encrypted PDF: Password-protected PDFs not supported - Memory error: Large PDFs may need streaming/chunking</p>"},{"location":"modules/data-processors/#gemini-api-errors","title":"Gemini API Errors","text":"<pre><code>try:\n    analysis = processor.analyze_with_gemini(content)\nexcept Exception as e:\n    print(f\"Analysis failed: {e}\")\n    # Fallback: use raw text\n    analysis = {\n        'summary': content['combined_text'][:500],\n        'key_concepts': [],\n        'diagram_descriptions': []\n    }\n</code></pre> <p>Common Issues: - API key invalid: Check key from https://makersuite.google.com - Rate limit exceeded: Wait and retry (15 req/min limit) - Content too long: Truncate to 10,000 chars (already implemented) - Image too large: Resize before sending (not currently implemented)</p>"},{"location":"modules/data-processors/#performance-optimization","title":"Performance Optimization","text":""},{"location":"modules/data-processors/#processing-speed","title":"Processing Speed","text":"<p>PDF Processing (100-page paper with 10 images): - Text extraction: ~2-5 seconds (PyMuPDF) - Text analysis: ~3-5 seconds (Gemini) - Image analysis (10 images): ~30-50 seconds (Gemini Vision) - Total: ~35-60 seconds</p> <p>Video Processing: - Transcript analysis: ~3-7 seconds (Gemini) - Total: ~3-7 seconds (no video frame analysis yet)</p>"},{"location":"modules/data-processors/#optimization-tips","title":"Optimization Tips","text":"<ol> <li> <p>Limit Images: Process first 5 images only (implemented)    <pre><code>for img_data in pdf_content['images'][:5]:  # Limit to 5\n</code></pre></p> </li> <li> <p>Batch Processing: Process multiple papers in parallel    <pre><code>from concurrent.futures import ThreadPoolExecutor\n\nwith ThreadPoolExecutor(max_workers=3) as executor:\n    futures = [executor.submit(process_pdf, path) for path in pdf_paths]\n    results = [f.result() for f in futures]\n</code></pre></p> </li> <li> <p>Cache Results: Store analysis to avoid reprocessing    <pre><code>import json\n\ncache_file = f\"cache/{paper_id}_analysis.json\"\nif os.path.exists(cache_file):\n    with open(cache_file) as f:\n        analysis = json.load(f)\nelse:\n    analysis = processor.analyze_with_gemini(content)\n    with open(cache_file, 'w') as f:\n        json.dump(analysis, f)\n</code></pre></p> </li> <li> <p>Truncate Transcripts: Limit to 5,000 chars (implemented)    <pre><code>transcript[:5000]  # First 5K characters only\n</code></pre></p> </li> </ol>"},{"location":"modules/data-processors/#dependencies","title":"Dependencies","text":"<pre><code># pdf_processor.py\nfrom google import genai\nfrom google.genai import types\nfrom pypdf import PdfReader\nfrom PIL import Image\nimport fitz  # PyMuPDF\n\n# video_processor.py\nfrom google import genai\nfrom google.genai import types\nfrom PIL import Image\n</code></pre> <p>Installation: <pre><code>pip install google-generativeai pypdf pillow pymupdf\n</code></pre></p>"},{"location":"modules/data-processors/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/data-processors/#issue-gemini-api-authentication-fails","title":"Issue: Gemini API authentication fails","text":"<p>Error: <code>Invalid API key</code></p> <p>Solution: 1. Get API key from https://makersuite.google.com/app/apikey 2. Ensure key is not expired 3. Check for extra spaces in key string</p>"},{"location":"modules/data-processors/#issue-pdf-extraction-returns-empty-text","title":"Issue: PDF extraction returns empty text","text":"<p>Cause: Scanned PDF (images of text, not real text)</p> <p>Solution: Use OCR (not currently implemented): <pre><code>from pdf2image import convert_from_path\nimport pytesseract\n\nimages = convert_from_path('scanned.pdf')\ntext = pytesseract.image_to_string(images[0])\n</code></pre></p>"},{"location":"modules/data-processors/#issue-gemini-returns-incomplete-json","title":"Issue: Gemini returns incomplete JSON","text":"<p>Cause: Model doesn't always format as JSON</p> <p>Solution: Parse flexibly or use prompt engineering: <pre><code>prompt = \"\"\"\nAnalyze this video. Respond ONLY with valid JSON in this exact format:\n{\n    \"main_topics\": [\"topic1\", \"topic2\"],\n    \"key_learning_points\": [\"point1\", \"point2\"]\n}\n\"\"\"\n</code></pre></p>"},{"location":"modules/data-processors/#issue-image-analysis-fails-silently","title":"Issue: Image analysis fails silently","text":"<p>Cause: Exception caught and logged, but processing continues</p> <p>Solution: Check logs for specific error: <pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n# Will show: \"Warning: Failed to analyze image on page X: &lt;error&gt;\"\n</code></pre></p>"},{"location":"modules/data-processors/#future-enhancements","title":"Future Enhancements","text":""},{"location":"modules/data-processors/#planned-features","title":"Planned Features","text":"<ol> <li>Equation Extraction: Parse LaTeX equations from PDFs</li> <li>Citation Parsing: Extract and link paper references</li> <li>Video Frame Analysis: Analyze actual video frames (not just transcript)</li> <li>Table Extraction: Parse tables from PDFs into structured data</li> <li>OCR Integration: Handle scanned PDFs</li> <li>Audio Analysis: Process video audio separately from transcript</li> </ol>"},{"location":"modules/data-processors/#extension-points","title":"Extension Points","text":"<pre><code># Add equation extraction\ndef extract_equations(self, pdf_content: Dict) -&gt; List[str]:\n    \"\"\"Extract LaTeX equations using regex or Gemini\"\"\"\n    pass\n\n# Add table parsing\ndef extract_tables(self, pdf_content: Dict) -&gt; List[Dict]:\n    \"\"\"Parse tables from PDF\"\"\"\n    pass\n\n# Add OCR for scanned PDFs\ndef ocr_scanned_pdf(self, pdf_path: str) -&gt; str:\n    \"\"\"Use OCR for image-based PDFs\"\"\"\n    pass\n</code></pre>"},{"location":"modules/database/","title":"Database Module","text":""},{"location":"modules/database/#overview","title":"Overview","text":"<p>The Database module provides SQLite-based tracking for all collected academic content. It maintains a comprehensive record of papers, videos, and podcasts, including collection metadata, indexing status, and usage statistics.</p>"},{"location":"modules/database/#module-architecture","title":"Module Architecture","text":"<pre><code>multi_modal_rag/database/\n\u2514\u2500\u2500 db_manager.py    # SQLite database manager\n</code></pre>"},{"location":"modules/database/#collectiondatabasemanager","title":"CollectionDatabaseManager","text":"<p>File: <code>multi_modal_rag/database/db_manager.py</code></p>"},{"location":"modules/database/#class-overview","title":"Class Overview","text":"<p>Manages a SQLite database for tracking collected research data, providing CRUD operations, search functionality, and analytics.</p>"},{"location":"modules/database/#database-location","title":"Database Location","text":"<p>Default Path: <code>data/collections.db</code></p> <p>The database file is automatically created with all necessary tables on first initialization.</p>"},{"location":"modules/database/#initialization","title":"Initialization","text":"<pre><code>from multi_modal_rag.database import CollectionDatabaseManager\n\ndb_manager = CollectionDatabaseManager(db_path=\"data/collections.db\")\n</code></pre> <p>Parameters: - <code>db_path</code> (str, optional): Path to SQLite database file. Default: <code>\"data/collections.db\"</code></p> <p>Automatic Setup: - Creates directory if it doesn't exist - Initializes database schema automatically - Creates all tables on first run</p>"},{"location":"modules/database/#database-schema","title":"Database Schema","text":""},{"location":"modules/database/#tables-overview","title":"Tables Overview","text":"<pre><code>collections.db\n\u251c\u2500\u2500 collections         # Main collection tracking\n\u251c\u2500\u2500 papers             # Paper-specific data\n\u251c\u2500\u2500 videos             # Video-specific data\n\u251c\u2500\u2500 podcasts           # Podcast-specific data\n\u2514\u2500\u2500 collection_stats   # Collection analytics\n</code></pre>"},{"location":"modules/database/#collections-table","title":"Collections Table","text":"<p>Main table tracking all collected items across content types.</p> <pre><code>CREATE TABLE collections (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    content_type TEXT NOT NULL,           -- 'paper', 'video', 'podcast'\n    title TEXT NOT NULL,\n    source TEXT,                           -- 'arxiv', 'youtube', 'rss', etc.\n    url TEXT,\n    collection_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    metadata TEXT,                         -- JSON string\n    status TEXT DEFAULT 'collected',       -- 'collected', 'processed', 'indexed'\n    indexed BOOLEAN DEFAULT 0              -- 0 = not indexed, 1 = indexed\n)\n</code></pre> <p>Fields: - <code>id</code>: Unique identifier (auto-increment) - <code>content_type</code>: Type of content (paper/video/podcast) - <code>title</code>: Content title - <code>source</code>: Source API/platform (arxiv, youtube, rss, etc.) - <code>url</code>: Original URL - <code>collection_date</code>: When item was collected (auto-set) - <code>metadata</code>: JSON string with additional metadata - <code>status</code>: Processing status - <code>indexed</code>: Whether item is indexed in OpenSearch</p>"},{"location":"modules/database/#papers-table","title":"Papers Table","text":"<p>Stores paper-specific metadata.</p> <pre><code>CREATE TABLE papers (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    collection_id INTEGER,                 -- Foreign key to collections\n    arxiv_id TEXT,\n    pmc_id TEXT,\n    abstract TEXT,\n    authors TEXT,                          -- JSON array\n    published_date TEXT,\n    categories TEXT,                       -- JSON array\n    pdf_path TEXT,\n    FOREIGN KEY (collection_id) REFERENCES collections(id)\n)\n</code></pre> <p>Fields: - <code>collection_id</code>: Links to main collections table - <code>arxiv_id</code>: ArXiv identifier (if applicable) - <code>pmc_id</code>: PubMed Central ID (if applicable) - <code>abstract</code>: Paper abstract - <code>authors</code>: JSON array of author names - <code>published_date</code>: Publication date (ISO format) - <code>categories</code>: JSON array of categories/topics - <code>pdf_path</code>: Local path to downloaded PDF</p>"},{"location":"modules/database/#videos-table","title":"Videos Table","text":"<p>Stores video-specific metadata.</p> <pre><code>CREATE TABLE videos (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    collection_id INTEGER,                 -- Foreign key to collections\n    video_id TEXT,                         -- YouTube video ID\n    channel TEXT,                          -- Channel/uploader name\n    duration INTEGER,                      -- Duration in seconds\n    views INTEGER,                         -- View count\n    thumbnail_url TEXT,\n    transcript_available BOOLEAN DEFAULT 0,\n    FOREIGN KEY (collection_id) REFERENCES collections(id)\n)\n</code></pre> <p>Fields: - <code>video_id</code>: YouTube video identifier - <code>channel</code>: Channel name - <code>duration</code>: Video length in seconds - <code>views</code>: View count at collection time - <code>thumbnail_url</code>: Thumbnail image URL - <code>transcript_available</code>: Whether transcript was retrieved</p>"},{"location":"modules/database/#podcasts-table","title":"Podcasts Table","text":"<p>Stores podcast-specific metadata.</p> <pre><code>CREATE TABLE podcasts (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    collection_id INTEGER,                 -- Foreign key to collections\n    episode_id TEXT,\n    podcast_name TEXT,\n    audio_url TEXT,                        -- Direct audio file URL\n    duration INTEGER,                      -- Duration in seconds\n    FOREIGN KEY (collection_id) REFERENCES collections(id)\n)\n</code></pre> <p>Fields: - <code>episode_id</code>: Unique episode identifier - <code>podcast_name</code>: Name of podcast show - <code>audio_url</code>: Direct link to audio file - <code>duration</code>: Episode length in seconds</p>"},{"location":"modules/database/#collection-stats-table","title":"Collection Stats Table","text":"<p>Tracks collection operations for analytics.</p> <pre><code>CREATE TABLE collection_stats (\n    id INTEGER PRIMARY KEY AUTOINCREMENT,\n    content_type TEXT,                     -- 'paper', 'video', 'podcast'\n    query TEXT,                            -- Search query used\n    results_count INTEGER,                 -- Number of results\n    collection_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    source_api TEXT                        -- API used (arxiv, youtube, etc.)\n)\n</code></pre> <p>Purpose: Tracks collection history for analytics and debugging.</p>"},{"location":"modules/database/#methods","title":"Methods","text":""},{"location":"modules/database/#collection-management","title":"Collection Management","text":""},{"location":"modules/database/#add_collectioncontent_type-str-title-str-source-str-url-str-metadata-dict-indexed-bool-false-int","title":"<code>add_collection(content_type: str, title: str, source: str, url: str, metadata: Dict, indexed: bool = False) -&gt; int</code>","text":"<p>Adds a new collection item to the database.</p> <p>Parameters: - <code>content_type</code> (str): 'paper', 'video', or 'podcast' - <code>title</code> (str): Content title - <code>source</code> (str): Source identifier (e.g., 'arxiv', 'youtube') - <code>url</code> (str): Content URL - <code>metadata</code> (Dict): Additional metadata (stored as JSON) - <code>indexed</code> (bool, optional): Whether already indexed. Default: False</p> <p>Returns: Collection ID (int) of the newly created record</p> <p>Example:</p> <pre><code>db_manager = CollectionDatabaseManager()\n\ncollection_id = db_manager.add_collection(\n    content_type='paper',\n    title='Attention Is All You Need',\n    source='arxiv',\n    url='https://arxiv.org/abs/1706.03762',\n    metadata={\n        'query': 'transformer models',\n        'categories': ['cs.CL', 'cs.LG']\n    },\n    indexed=False\n)\n\nprint(f\"Created collection with ID: {collection_id}\")\n</code></pre> <p>Database Operations: 1. Inserts record into <code>collections</code> table 2. Serializes <code>metadata</code> dict to JSON string 3. Returns auto-generated ID 4. Commits transaction automatically</p> <p>Error Handling: - Rolls back transaction on error - Raises exception for database errors - Logs error details</p>"},{"location":"modules/database/#add_papercollection_id-int-paper_data-dict","title":"<code>add_paper(collection_id: int, paper_data: Dict)</code>","text":"<p>Adds paper-specific data linked to a collection.</p> <p>Parameters: - <code>collection_id</code> (int): ID from <code>add_collection()</code> - <code>paper_data</code> (Dict): Paper metadata</p> <pre><code>{\n    'arxiv_id': str,              # Optional\n    'pmc_id': str,                # Optional\n    'abstract': str,\n    'authors': List[str],\n    'published': str,             # ISO date\n    'categories': List[str],\n    'local_path': str             # Path to PDF\n}\n</code></pre> <p>Example:</p> <pre><code># Step 1: Add to main collections\ncollection_id = db_manager.add_collection(\n    content_type='paper',\n    title='BERT: Pre-training of Deep Bidirectional Transformers',\n    source='arxiv',\n    url='https://arxiv.org/abs/1810.04805',\n    metadata={}\n)\n\n# Step 2: Add paper-specific details\npaper_data = {\n    'arxiv_id': '1810.04805',\n    'abstract': 'We introduce a new language representation model...',\n    'authors': ['Jacob Devlin', 'Ming-Wei Chang', 'Kenton Lee'],\n    'published': '2018-10-11',\n    'categories': ['cs.CL'],\n    'local_path': 'data/papers/1810.04805.pdf'\n}\n\ndb_manager.add_paper(collection_id, paper_data)\n</code></pre> <p>Database Operations: - Inserts into <code>papers</code> table - Serializes <code>authors</code> and <code>categories</code> to JSON - Links via <code>collection_id</code> foreign key</p>"},{"location":"modules/database/#add_videocollection_id-int-video_data-dict","title":"<code>add_video(collection_id: int, video_data: Dict)</code>","text":"<p>Adds video-specific data.</p> <p>Parameters: - <code>collection_id</code> (int): ID from <code>add_collection()</code> - <code>video_data</code> (Dict): Video metadata</p> <pre><code>{\n    'video_id': str,\n    'author': str,              # Channel name\n    'length': int,              # Duration in seconds\n    'views': int,\n    'thumbnail_url': str,\n    'transcript': str           # Or None\n}\n</code></pre> <p>Example:</p> <pre><code>collection_id = db_manager.add_collection(\n    content_type='video',\n    title='Neural Networks Explained',\n    source='youtube',\n    url='https://youtube.com/watch?v=...',\n    metadata={'query': 'deep learning'}\n)\n\nvideo_data = {\n    'video_id': 'aircAruvnKk',\n    'author': '3Blue1Brown',\n    'length': 1140,\n    'views': 5000000,\n    'thumbnail_url': 'https://...',\n    'transcript': 'Welcome to this video about neural networks...'\n}\n\ndb_manager.add_video(collection_id, video_data)\n</code></pre>"},{"location":"modules/database/#add_podcastcollection_id-int-podcast_data-dict","title":"<code>add_podcast(collection_id: int, podcast_data: Dict)</code>","text":"<p>Adds podcast-specific data.</p> <p>Parameters: - <code>collection_id</code> (int): ID from <code>add_collection()</code> - <code>podcast_data</code> (Dict): Podcast metadata</p> <pre><code>{\n    'episode_id': str,\n    'podcast_name': str,\n    'audio_url': str,\n    'duration': int              # Optional\n}\n</code></pre> <p>Example:</p> <pre><code>collection_id = db_manager.add_collection(\n    content_type='podcast',\n    title='The Future of AI with Yann LeCun',\n    source='podcast',\n    url='https://lexfridman.com/yann-lecun',\n    metadata={'query': 'artificial intelligence'}\n)\n\npodcast_data = {\n    'episode_id': 'lex_001',\n    'podcast_name': 'Lex Fridman Podcast',\n    'audio_url': 'https://media.blubrry.com/.../lex_001.mp3',\n    'duration': 7200\n}\n\ndb_manager.add_podcast(collection_id, podcast_data)\n</code></pre>"},{"location":"modules/database/#mark_as_indexedcollection_id-int","title":"<code>mark_as_indexed(collection_id: int)</code>","text":"<p>Marks a collection item as indexed in OpenSearch.</p> <p>Parameters: - <code>collection_id</code> (int): ID to mark as indexed</p> <p>Example:</p> <pre><code># After successful indexing\ndb_manager.mark_as_indexed(collection_id)\n\n# Later, query indexed items\nindexed_items = db_manager.get_all_collections()\nfor item in indexed_items:\n    if item['indexed']:\n        print(f\"\u2705 {item['title']} - Indexed\")\n</code></pre> <p>Database Operation: <pre><code>UPDATE collections SET indexed = 1 WHERE id = ?\n</code></pre></p>"},{"location":"modules/database/#statistics-and-logging","title":"Statistics and Logging","text":""},{"location":"modules/database/#log_collection_statscontent_type-str-query-str-results_count-int-source_api-str","title":"<code>log_collection_stats(content_type: str, query: str, results_count: int, source_api: str)</code>","text":"<p>Logs collection operation statistics.</p> <p>Parameters: - <code>content_type</code> (str): Type of content collected - <code>query</code> (str): Search query used - <code>results_count</code> (int): Number of results collected - <code>source_api</code> (str): API source (arxiv, youtube, rss)</p> <p>Example:</p> <pre><code># After collecting papers\npapers = paper_collector.collect_arxiv_papers(\"quantum computing\", max_results=50)\n\ndb_manager.log_collection_stats(\n    content_type='paper',\n    query='quantum computing',\n    results_count=len(papers),\n    source_api='arxiv'\n)\n</code></pre> <p>Usage: Tracks collection patterns for analytics and debugging.</p>"},{"location":"modules/database/#get_statistics-dict","title":"<code>get_statistics() -&gt; Dict</code>","text":"<p>Retrieves comprehensive database statistics.</p> <p>Returns: Dictionary with statistics:</p> <pre><code>{\n    'by_type': {                     # Count by content type\n        'paper': int,\n        'video': int,\n        'podcast': int\n    },\n    'indexed': int,                  # Total indexed items\n    'not_indexed': int,              # Total not indexed\n    'recent_7_days': int,            # Items collected in last 7 days\n    'collection_history': [          # Collection operation history\n        {\n            'type': str,\n            'source': str,\n            'total': int\n        },\n        # ... more stats\n    ]\n}\n</code></pre> <p>Example:</p> <pre><code>stats = db_manager.get_statistics()\n\nprint(f\"Total papers: {stats['by_type'].get('paper', 0)}\")\nprint(f\"Total videos: {stats['by_type'].get('video', 0)}\")\nprint(f\"Indexed: {stats['indexed']}\")\nprint(f\"Not indexed: {stats['not_indexed']}\")\nprint(f\"Recent (7 days): {stats['recent_7_days']}\")\n\nprint(\"\\nCollection History:\")\nfor entry in stats['collection_history']:\n    print(f\"  {entry['type']} from {entry['source']}: {entry['total']}\")\n</code></pre> <p>SQL Queries Used:</p> <pre><code>-- By type\nSELECT content_type, COUNT(*) as count\nFROM collections\nGROUP BY content_type\n\n-- Indexed vs not indexed\nSELECT indexed, COUNT(*) as count\nFROM collections\nGROUP BY indexed\n\n-- Recent collections\nSELECT COUNT(*) FROM collections\nWHERE collection_date &gt;= datetime('now', '-7 days')\n\n-- Collection history\nSELECT content_type, source_api, SUM(results_count) as total\nFROM collection_stats\nGROUP BY content_type, source_api\n</code></pre>"},{"location":"modules/database/#retrieval-methods","title":"Retrieval Methods","text":""},{"location":"modules/database/#get_all_collectionslimit-int-100-offset-int-0-listdict","title":"<code>get_all_collections(limit: int = 100, offset: int = 0) -&gt; List[Dict]</code>","text":"<p>Retrieves all collections with pagination.</p> <p>Parameters: - <code>limit</code> (int, optional): Maximum results. Default: 100 - <code>offset</code> (int, optional): Offset for pagination. Default: 0</p> <p>Returns: List of collection dictionaries</p> <p>Example:</p> <pre><code># Get first page (100 items)\ncollections = db_manager.get_all_collections(limit=100, offset=0)\n\n# Get second page\ncollections_page2 = db_manager.get_all_collections(limit=100, offset=100)\n\nfor item in collections:\n    print(f\"{item['id']}: {item['title']} ({item['content_type']})\")\n    print(f\"  Source: {item['source']}\")\n    print(f\"  Indexed: {item['indexed']}\")\n    print(f\"  Collected: {item['collection_date']}\")\n</code></pre> <p>Return Structure:</p> <pre><code>[\n    {\n        'id': int,\n        'content_type': str,\n        'title': str,\n        'source': str,\n        'url': str,\n        'collection_date': str,\n        'metadata': dict,          # Parsed from JSON\n        'status': str,\n        'indexed': bool\n    },\n    # ... more items\n]\n</code></pre>"},{"location":"modules/database/#get_collections_by_typecontent_type-str-limit-int-100-listdict","title":"<code>get_collections_by_type(content_type: str, limit: int = 100) -&gt; List[Dict]</code>","text":"<p>Retrieves collections filtered by content type.</p> <p>Parameters: - <code>content_type</code> (str): 'paper', 'video', or 'podcast' - <code>limit</code> (int, optional): Maximum results. Default: 100</p> <p>Example:</p> <pre><code># Get all papers\npapers = db_manager.get_collections_by_type('paper', limit=50)\n\n# Get all videos\nvideos = db_manager.get_collections_by_type('video', limit=30)\n\n# Get all podcasts\npodcasts = db_manager.get_collections_by_type('podcast')\n</code></pre>"},{"location":"modules/database/#get_collection_with_detailscollection_id-int-optionaldict","title":"<code>get_collection_with_details(collection_id: int) -&gt; Optional[Dict]</code>","text":"<p>Retrieves complete details for a collection, including type-specific data.</p> <p>Parameters: - <code>collection_id</code> (int): Collection ID</p> <p>Returns: Dict with all details, or <code>None</code> if not found</p> <p>Example:</p> <pre><code>details = db_manager.get_collection_with_details(collection_id=42)\n\nif details:\n    print(f\"Title: {details['title']}\")\n    print(f\"Type: {details['content_type']}\")\n\n    if details['content_type'] == 'paper':\n        paper_details = details['details']\n        print(f\"Authors: {', '.join(paper_details['authors'])}\")\n        print(f\"Abstract: {paper_details['abstract'][:200]}...\")\n        print(f\"PDF: {paper_details['pdf_path']}\")\n\n    elif details['content_type'] == 'video':\n        video_details = details['details']\n        print(f\"Channel: {video_details['channel']}\")\n        print(f\"Duration: {video_details['duration']} seconds\")\n        print(f\"Views: {video_details['views']}\")\n</code></pre> <p>Return Structure:</p> <pre><code>{\n    # Main collection fields\n    'id': int,\n    'content_type': str,\n    'title': str,\n    # ... other collection fields\n\n    # Type-specific details\n    'details': {\n        # For papers:\n        'arxiv_id': str,\n        'authors': List[str],      # Parsed from JSON\n        'abstract': str,\n        'categories': List[str],   # Parsed from JSON\n        # ...\n\n        # For videos:\n        'video_id': str,\n        'channel': str,\n        'duration': int,\n        # ...\n\n        # For podcasts:\n        'episode_id': str,\n        'podcast_name': str,\n        'audio_url': str,\n        # ...\n    }\n}\n</code></pre>"},{"location":"modules/database/#search_collectionsquery-str-limit-int-50-listdict","title":"<code>search_collections(query: str, limit: int = 50) -&gt; List[Dict]</code>","text":"<p>Searches collections by title or source.</p> <p>Parameters: - <code>query</code> (str): Search query - <code>limit</code> (int, optional): Maximum results. Default: 50</p> <p>Returns: List of matching collections</p> <p>Example:</p> <pre><code># Search by title\nresults = db_manager.search_collections(\"transformer\")\n\n# Search by source\narxiv_results = db_manager.search_collections(\"arxiv\")\n\nfor item in results:\n    print(f\"{item['title']} ({item['content_type']})\")\n</code></pre> <p>SQL Query: <pre><code>SELECT * FROM collections\nWHERE title LIKE ? OR source LIKE ?\nORDER BY collection_date DESC\nLIMIT ?\n</code></pre></p> <p>Search Behavior: - Case-insensitive (SQLite LIKE is case-insensitive by default) - Partial matching (uses <code>%query%</code> pattern) - Searches both <code>title</code> and <code>source</code> fields</p>"},{"location":"modules/database/#integration-examples","title":"Integration Examples","text":""},{"location":"modules/database/#complete-collection-workflow","title":"Complete Collection Workflow","text":"<pre><code>from multi_modal_rag.data_collectors import AcademicPaperCollector\nfrom multi_modal_rag.database import CollectionDatabaseManager\nfrom multi_modal_rag.indexing import OpenSearchManager\n\n# Initialize\npaper_collector = AcademicPaperCollector()\ndb_manager = CollectionDatabaseManager()\nopensearch_manager = OpenSearchManager()\n\n# Collect papers\nquery = \"neural machine translation\"\npapers = paper_collector.collect_arxiv_papers(query, max_results=20)\n\n# Track in database and index\nfor paper in papers:\n    # 1. Add to database\n    collection_id = db_manager.add_collection(\n        content_type='paper',\n        title=paper['title'],\n        source='arxiv',\n        url=paper['pdf_url'],\n        metadata={'query': query, 'categories': paper['categories']}\n    )\n\n    db_manager.add_paper(collection_id, paper)\n\n    # 2. Index in OpenSearch\n    doc = {\n        'content_type': 'paper',\n        'title': paper['title'],\n        'abstract': paper['abstract'],\n        'authors': paper['authors'],\n        # ... other fields\n    }\n    opensearch_manager.index_document('research_assistant', doc)\n\n    # 3. Mark as indexed\n    db_manager.mark_as_indexed(collection_id)\n\n# 4. Log statistics\ndb_manager.log_collection_stats(\n    content_type='paper',\n    query=query,\n    results_count=len(papers),\n    source_api='arxiv'\n)\n\n# 5. View statistics\nstats = db_manager.get_statistics()\nprint(f\"Total collections: {sum(stats['by_type'].values())}\")\nprint(f\"Indexed: {stats['indexed']}\")\n</code></pre>"},{"location":"modules/database/#analytics-dashboard","title":"Analytics Dashboard","text":"<pre><code># Get comprehensive statistics\nstats = db_manager.get_statistics()\n\nprint(\"=== Collection Statistics ===\")\nprint(f\"\\nBy Type:\")\nfor content_type, count in stats['by_type'].items():\n    print(f\"  {content_type}: {count}\")\n\nprint(f\"\\nIndexing Status:\")\nprint(f\"  Indexed: {stats['indexed']}\")\nprint(f\"  Not Indexed: {stats['not_indexed']}\")\ntotal = stats['indexed'] + stats['not_indexed']\nif total &gt; 0:\n    print(f\"  Percentage Indexed: {stats['indexed']/total*100:.1f}%\")\n\nprint(f\"\\nRecent Activity:\")\nprint(f\"  Last 7 days: {stats['recent_7_days']} new items\")\n\nprint(f\"\\nCollection History:\")\nfor entry in stats['collection_history']:\n    print(f\"  {entry['type']} from {entry['source']}: {entry['total']} total\")\n\n# Get recent collections\nrecent = db_manager.get_all_collections(limit=10)\nprint(\"\\n=== Recent Collections ===\")\nfor item in recent:\n    indexed_status = \"\u2705\" if item['indexed'] else \"\u274c\"\n    print(f\"{indexed_status} {item['title'][:50]}... ({item['content_type']})\")\n</code></pre>"},{"location":"modules/database/#performance-considerations","title":"Performance Considerations","text":""},{"location":"modules/database/#database-size","title":"Database Size","text":"<p>Typical Sizes: - 1,000 collections: ~2-5 MB - 10,000 collections: ~20-50 MB - 100,000 collections: ~200-500 MB</p> <p>Optimization: SQLite handles these sizes efficiently on modern hardware.</p>"},{"location":"modules/database/#query-performance","title":"Query Performance","text":"<p>Fast Queries (with indexing): - <code>get_all_collections()</code>: ~10-50ms (1000 records) - <code>get_collections_by_type()</code>: ~5-20ms (filtered) - <code>get_collection_with_details()</code>: ~2-10ms (single record)</p> <p>Slower Queries (without indexing): - <code>search_collections()</code>: ~50-200ms (LIKE query, 10K records)</p> <p>Optimization Tips:</p> <ol> <li> <p>Add Indexes:    <pre><code>cursor.execute(\"\"\"\n    CREATE INDEX IF NOT EXISTS idx_content_type\n    ON collections(content_type)\n\"\"\")\n\ncursor.execute(\"\"\"\n    CREATE INDEX IF NOT EXISTS idx_indexed\n    ON collections(indexed)\n\"\"\")\n</code></pre></p> </li> <li> <p>Limit Results:    <pre><code># Good: Limit to what you need\ncollections = db_manager.get_all_collections(limit=100)\n\n# Bad: Loading thousands unnecessarily\ncollections = db_manager.get_all_collections(limit=100000)\n</code></pre></p> </li> <li> <p>Use Pagination:    <pre><code>page_size = 50\nfor page in range(total_pages):\n    offset = page * page_size\n    items = db_manager.get_all_collections(limit=page_size, offset=offset)\n    process_items(items)\n</code></pre></p> </li> </ol>"},{"location":"modules/database/#error-handling","title":"Error Handling","text":""},{"location":"modules/database/#transaction-rollback","title":"Transaction Rollback","text":"<p>All write operations use transactions with automatic rollback:</p> <pre><code>def add_collection(self, ...):\n    conn = sqlite3.connect(self.db_path)\n    cursor = conn.cursor()\n\n    try:\n        cursor.execute(\"INSERT INTO collections ...\")\n        conn.commit()\n        return cursor.lastrowid\n    except Exception as e:\n        logger.error(f\"Error adding collection: {e}\")\n        conn.rollback()  # Rollback on error\n        raise\n    finally:\n        conn.close()\n</code></pre>"},{"location":"modules/database/#handling-database-errors","title":"Handling Database Errors","text":"<pre><code>try:\n    collection_id = db_manager.add_collection(...)\nexcept sqlite3.IntegrityError as e:\n    print(f\"Duplicate entry: {e}\")\nexcept sqlite3.OperationalError as e:\n    print(f\"Database locked or unavailable: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n</code></pre>"},{"location":"modules/database/#logging","title":"Logging","text":"<p>All database operations are logged:</p> <pre><code>from multi_modal_rag.logging_config import get_logger\n\nlogger = get_logger(__name__)\n</code></pre> <p>Log Examples:</p> <pre><code>INFO - CollectionDatabaseManager initialized with database at data/collections.db\nINFO - Database schema initialized successfully\nDEBUG - Added collection item: 42 - Attention Is All You Need\nDEBUG - Added paper data for collection_id: 42\nINFO - Successfully marked collection 42 as indexed\n</code></pre>"},{"location":"modules/database/#backup-and-export","title":"Backup and Export","text":""},{"location":"modules/database/#database-backup","title":"Database Backup","text":"<pre><code>import shutil\nfrom datetime import datetime\n\n# Create backup\nbackup_path = f\"data/backups/collections_{datetime.now():%Y%m%d_%H%M%S}.db\"\nshutil.copy2(\"data/collections.db\", backup_path)\nprint(f\"Backup created: {backup_path}\")\n</code></pre>"},{"location":"modules/database/#export-to-json","title":"Export to JSON","text":"<pre><code>import json\n\n# Export all collections\ncollections = db_manager.get_all_collections(limit=10000)\n\nwith open(\"collections_export.json\", \"w\") as f:\n    json.dump(collections, f, indent=2)\n\nprint(f\"Exported {len(collections)} collections\")\n</code></pre>"},{"location":"modules/database/#export-to-csv","title":"Export to CSV","text":"<pre><code>import csv\n\ncollections = db_manager.get_all_collections(limit=10000)\n\nwith open(\"collections_export.csv\", \"w\", newline=\"\") as f:\n    writer = csv.DictWriter(f, fieldnames=['id', 'title', 'content_type', 'source', 'indexed'])\n    writer.writeheader()\n    for item in collections:\n        writer.writerow({\n            'id': item['id'],\n            'title': item['title'],\n            'content_type': item['content_type'],\n            'source': item['source'],\n            'indexed': item['indexed']\n        })\n</code></pre>"},{"location":"modules/database/#dependencies","title":"Dependencies","text":"<pre><code>import sqlite3\nimport json\nfrom datetime import datetime\nimport os\n</code></pre> <p>Installation: Part of Python standard library (no external dependencies)</p>"},{"location":"modules/database/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/database/#issue-database-is-locked","title":"Issue: Database is locked","text":"<p>Error: <code>sqlite3.OperationalError: database is locked</code></p> <p>Causes: - Another process has database open - Long-running transaction - Disk I/O issues</p> <p>Solutions: 1. Ensure connections are closed:    <pre><code>conn.close()  # Always in finally block\n</code></pre></p> <ol> <li> <p>Increase timeout:    <pre><code>conn = sqlite3.connect(db_path, timeout=30.0)\n</code></pre></p> </li> <li> <p>Use WAL mode (Write-Ahead Logging):    <pre><code>conn.execute(\"PRAGMA journal_mode=WAL\")\n</code></pre></p> </li> </ol>"},{"location":"modules/database/#issue-corrupted-database","title":"Issue: Corrupted database","text":"<p>Symptoms: <code>sqlite3.DatabaseError: database disk image is malformed</code></p> <p>Recovery: <pre><code># Attempt to recover\nsqlite3 collections.db \".dump\" | sqlite3 recovered.db\n</code></pre></p>"},{"location":"modules/database/#issue-metadata-json-parse-error","title":"Issue: Metadata JSON parse error","text":"<p>Error: <code>json.decoder.JSONDecodeError</code></p> <p>Cause: Invalid JSON in metadata field</p> <p>Solution: Add error handling: <pre><code>try:\n    metadata = json.loads(result['metadata'])\nexcept json.JSONDecodeError:\n    metadata = {}  # Fallback to empty dict\n</code></pre></p>"},{"location":"modules/database/#future-enhancements","title":"Future Enhancements","text":""},{"location":"modules/database/#planned-features","title":"Planned Features","text":"<ol> <li>Full-Text Search: SQLite FTS5 for advanced text search</li> <li>Database Migrations: Version tracking and schema updates</li> <li>Relationship Tracking: Link related papers, citations</li> <li>Usage Analytics: Track query patterns, popular content</li> <li>Archiving: Move old collections to archive tables</li> </ol>"},{"location":"modules/database/#extension-points","title":"Extension Points","text":"<pre><code># Add full-text search\ndef create_fts_index(self):\n    \"\"\"Create FTS5 virtual table for search\"\"\"\n    pass\n\n# Add relationship tracking\ndef add_citation_link(self, source_id: int, cited_id: int):\n    \"\"\"Track paper citations\"\"\"\n    pass\n\n# Add analytics\ndef get_popular_content(self, days: int = 30) -&gt; List[Dict]:\n    \"\"\"Get most accessed content\"\"\"\n    pass\n</code></pre>"},{"location":"modules/indexing/","title":"Indexing Module","text":""},{"location":"modules/indexing/#overview","title":"Overview","text":"<p>The Indexing module manages OpenSearch integration for hybrid search capabilities. It combines traditional keyword search (BM25) with semantic vector search using embeddings, providing powerful retrieval for multi-modal academic content.</p>"},{"location":"modules/indexing/#module-architecture","title":"Module Architecture","text":"<pre><code>multi_modal_rag/indexing/\n\u2514\u2500\u2500 opensearch_manager.py    # OpenSearch client and search logic\n</code></pre>"},{"location":"modules/indexing/#opensearchmanager","title":"OpenSearchManager","text":"<p>File: <code>multi_modal_rag/indexing/opensearch_manager.py</code></p>"},{"location":"modules/indexing/#class-overview","title":"Class Overview","text":"<p>Manages all OpenSearch operations including index creation, document indexing, and hybrid search. Uses <code>sentence-transformers</code> for embedding generation and OpenSearch's kNN capabilities for semantic search.</p>"},{"location":"modules/indexing/#initialization","title":"Initialization","text":"<pre><code>from multi_modal_rag.indexing import OpenSearchManager\n\nmanager = OpenSearchManager(\n    host='localhost',\n    port=9200,\n    use_ssl=True,\n    username='admin',\n    password='MyStrongPassword@2024!'\n)\n</code></pre> <p>Parameters: - <code>host</code> (str, optional): OpenSearch host address. Default: <code>'localhost'</code> - <code>port</code> (int, optional): OpenSearch port. Default: <code>9200</code> - <code>use_ssl</code> (bool, optional): Use SSL/TLS connection. Default: <code>True</code> - <code>username</code> (str, optional): Authentication username. Default: <code>'admin'</code> - <code>password</code> (str, optional): Authentication password. Default: <code>'MyStrongPassword@2024!'</code></p> <p>Connection Testing: - Automatically tests connection on initialization - Sets <code>self.connected = True</code> if successful - Logs error and continues with limited functionality if connection fails</p> <p>Embedding Model: - Uses <code>SentenceTransformer('all-MiniLM-L6-v2')</code> - Generates 384-dimensional embeddings - Lightweight and fast (suitable for free-tier deployment)</p> <p>Example:</p> <pre><code>manager = OpenSearchManager(\n    host='localhost',\n    port=9200\n)\n\nif manager.connected:\n    print(\"\u2705 Connected to OpenSearch\")\nelse:\n    print(\"\u26a0\ufe0f  OpenSearch not available - limited functionality\")\n</code></pre>"},{"location":"modules/indexing/#methods","title":"Methods","text":""},{"location":"modules/indexing/#create_indexindex_name-str-bool","title":"<code>create_index(index_name: str) -&gt; bool</code>","text":"<p>Creates an OpenSearch index with mappings optimized for multi-modal academic content.</p> <p>Parameters: - <code>index_name</code> (str): Name of the index to create</p> <p>Returns: <code>True</code> if successful, <code>False</code> otherwise</p> <p>Index Configuration:</p> <pre><code>{\n    'settings': {\n        'index': {\n            'number_of_shards': 2,\n            'number_of_replicas': 1,\n            'knn': True  # Enable k-NN for vector search\n        }\n    },\n    'mappings': {\n        'properties': {\n            'content_type': {'type': 'keyword'},\n            'title': {\n                'type': 'text',\n                'fields': {'keyword': {'type': 'keyword'}}\n            },\n            'abstract': {'type': 'text'},\n            'content': {'type': 'text'},\n            'authors': {'type': 'keyword'},\n            'publication_date': {'type': 'date'},\n            'url': {'type': 'keyword'},\n            'transcript': {'type': 'text'},\n            'diagram_descriptions': {'type': 'text'},\n            'key_concepts': {'type': 'keyword'},\n            'citations': {\n                'type': 'nested',\n                'properties': {\n                    'text': {'type': 'text'},\n                    'source': {'type': 'keyword'}\n                }\n            },\n            'embedding': {\n                'type': 'knn_vector',\n                'dimension': 384\n            },\n            'metadata': {\n                'type': 'object',\n                'enabled': True\n            }\n        }\n    }\n}\n</code></pre> <p>Example:</p> <pre><code>manager = OpenSearchManager()\nsuccess = manager.create_index(\"research_assistant\")\n\nif success:\n    print(\"Index created successfully\")\nelse:\n    print(\"Failed to create index\")\n</code></pre> <p>Behavior: - Checks if index already exists before creating - Skips creation if index exists (doesn't overwrite) - Returns <code>False</code> if not connected to OpenSearch</p>"},{"location":"modules/indexing/#index_documentindex_name-str-document-dict-dict","title":"<code>index_document(index_name: str, document: Dict) -&gt; Dict</code>","text":"<p>Indexes a single document with automatic embedding generation.</p> <p>Parameters: - <code>index_name</code> (str): Target index name - <code>document</code> (Dict): Document to index</p> <p>Returns: OpenSearch response dict, or <code>None</code> on error</p> <p>Document Structure:</p> <pre><code>document = {\n    'content_type': str,        # 'paper', 'video', or 'podcast'\n    'title': str,\n    'abstract': str,            # For papers\n    'content': str,             # Main text content\n    'authors': List[str],\n    'publication_date': str,    # ISO format date\n    'url': str,\n    'transcript': str,          # For videos/podcasts\n    'diagram_descriptions': str,# For papers with diagrams\n    'key_concepts': List[str],\n    'metadata': Dict            # Additional metadata\n}\n</code></pre> <p>Automatic Processing: 1. Combines title + abstract + content (first 1000 chars) into searchable text 2. Generates 384-dim embedding using <code>SentenceTransformer</code> 3. Adds embedding to document 4. Indexes document in OpenSearch</p> <p>Example:</p> <pre><code>manager = OpenSearchManager()\n\npaper_doc = {\n    'content_type': 'paper',\n    'title': 'Attention Is All You Need',\n    'abstract': 'The dominant sequence transduction models...',\n    'content': 'We propose a new simple network architecture...',\n    'authors': ['Ashish Vaswani', 'Noam Shazeer'],\n    'publication_date': '2017-06-12',\n    'url': 'https://arxiv.org/abs/1706.03762',\n    'key_concepts': ['transformer', 'attention', 'neural networks']\n}\n\nresponse = manager.index_document(\"research_assistant\", paper_doc)\n\nif response:\n    print(f\"Indexed document with ID: {response['_id']}\")\n</code></pre> <p>Embedding Generation:</p> <pre><code># Internally performed by index_document()\nsearchable_text = f\"{document.get('title', '')} {document.get('abstract', '')} {document.get('content', '')[:1000]}\"\nembedding = self.embedding_model.encode(searchable_text).tolist()\ndocument['embedding'] = embedding  # 384-dimensional vector\n</code></pre>"},{"location":"modules/indexing/#bulk_indexindex_name-str-documents-listdict-int","title":"<code>bulk_index(index_name: str, documents: List[Dict]) -&gt; int</code>","text":"<p>Bulk indexes multiple documents efficiently.</p> <p>Parameters: - <code>index_name</code> (str): Target index name - <code>documents</code> (List[Dict]): List of documents to index</p> <p>Returns: Number of successfully indexed documents, or <code>None</code> on error</p> <p>Example:</p> <pre><code>manager = OpenSearchManager()\n\npapers = [\n    {\n        'content_type': 'paper',\n        'title': 'Paper 1',\n        'content': 'Content 1...',\n        # ... other fields\n    },\n    {\n        'content_type': 'paper',\n        'title': 'Paper 2',\n        'content': 'Content 2...',\n        # ... other fields\n    },\n    # ... more papers\n]\n\nsuccess_count = manager.bulk_index(\"research_assistant\", papers)\nprint(f\"Successfully indexed {success_count} documents\")\n</code></pre> <p>Performance: - Uses OpenSearch bulk API for efficiency - Processes embeddings for all documents before indexing - Much faster than individual <code>index_document()</code> calls - Recommended for batches &gt; 10 documents</p> <p>Progress Logging:</p> <pre><code>INFO - Starting bulk indexing of 50 documents to 'research_assistant'\nDEBUG - Processing document 1/50 for bulk index: Attention Is All You Need\nDEBUG - Processing document 2/50 for bulk index: BERT: Pre-training...\n...\nDEBUG - Executing bulk index operation...\nINFO - \u2705 Bulk indexed 50 documents successfully to 'research_assistant'\n</code></pre>"},{"location":"modules/indexing/#hybrid_searchindex_name-str-query-str-k-int-10-listdict","title":"<code>hybrid_search(index_name: str, query: str, k: int = 10) -&gt; List[Dict]</code>","text":"<p>Performs hybrid search combining keyword matching with semantic similarity.</p> <p>Parameters: - <code>index_name</code> (str): Index to search - <code>query</code> (str): Search query - <code>k</code> (int, optional): Number of results to return. Default: 10</p> <p>Returns: List of result dictionaries:</p> <pre><code>[\n    {\n        'score': float,      # Relevance score\n        'source': Dict       # Source document\n    },\n    # ... more results\n]\n</code></pre> <p>Search Algorithm:</p> <p>The current implementation uses text-based multi-match search with field boosting:</p> <pre><code>{\n    'size': k,\n    'query': {\n        'multi_match': {\n            'query': query,\n            'fields': [\n                'title^3',           # 3x weight\n                'abstract^2',        # 2x weight\n                'content',           # 1x weight\n                'transcript',        # 1x weight\n                'key_concepts^2'     # 2x weight\n            ],\n            'type': 'best_fields',\n            'fuzziness': 'AUTO'\n        }\n    }\n}\n</code></pre> <p>Field Boosting Explained: - <code>title^3</code>: Title matches weighted 3x (most important) - <code>abstract^2</code>: Abstract matches weighted 2x - <code>key_concepts^2</code>: Concept matches weighted 2x - <code>content</code>, <code>transcript</code>: Standard 1x weight</p> <p>Fuzziness: <code>AUTO</code> handles typos (1-2 character edits allowed)</p> <p>Example:</p> <pre><code>manager = OpenSearchManager()\nresults = manager.hybrid_search(\n    index_name=\"research_assistant\",\n    query=\"transformer architecture\",\n    k=5\n)\n\nfor result in results:\n    print(f\"Score: {result['score']:.2f}\")\n    print(f\"Title: {result['source']['title']}\")\n    print(f\"Type: {result['source']['content_type']}\")\n    print(\"---\")\n</code></pre> <p>Output:</p> <pre><code>Score: 15.42\nTitle: Attention Is All You Need\nType: paper\n---\nScore: 12.18\nTitle: BERT: Pre-training of Deep Bidirectional Transformers\nType: paper\n---\nScore: 8.94\nTitle: Illustrated Transformer\nType: video\n---\n</code></pre> <p>Vector Search (Disabled):</p> <p>Previous versions used kNN vector search, but it's currently disabled for OpenSearch 3.x compatibility:</p> <pre><code># Original hybrid search (commented out)\n{\n    'query': {\n        'bool': {\n            'should': [\n                # Keyword search\n                {'multi_match': {...}},\n                # Semantic search\n                {\n                    'knn': {\n                        'embedding': {\n                            'vector': query_embedding,\n                            'k': k\n                        }\n                    }\n                }\n            ]\n        }\n    }\n}\n</code></pre> <p>To re-enable vector search, modify the query structure and generate query embeddings.</p>"},{"location":"modules/indexing/#index-schema-deep-dive","title":"Index Schema Deep Dive","text":""},{"location":"modules/indexing/#field-types-and-purposes","title":"Field Types and Purposes","text":""},{"location":"modules/indexing/#content-type-content_type","title":"Content Type (<code>content_type</code>)","text":"<pre><code>'content_type': {'type': 'keyword'}\n</code></pre> <ul> <li>Purpose: Identify document type (paper, video, podcast)</li> <li>Type: <code>keyword</code> (exact match, not analyzed)</li> <li>Usage: Filtering by content type in queries</li> </ul> <p>Example Query:</p> <pre><code>{\n    'query': {\n        'bool': {\n            'must': [{'match': {'content': 'neural networks'}}],\n            'filter': [{'term': {'content_type': 'paper'}}]\n        }\n    }\n}\n</code></pre>"},{"location":"modules/indexing/#title-title","title":"Title (<code>title</code>)","text":"<pre><code>'title': {\n    'type': 'text',\n    'fields': {\n        'keyword': {'type': 'keyword'}\n    }\n}\n</code></pre> <ul> <li><code>text</code> field: Full-text search, analyzed (tokenized, lowercased)</li> <li><code>keyword</code> subfield: Exact match, sorting, aggregations</li> <li>Usage: Primary search field with 3x boost</li> </ul> <p>Example:</p> <pre><code># Text search (matches \"attention mechanism\")\n{'match': {'title': 'attention'}}\n\n# Exact match (must match entire title)\n{'term': {'title.keyword': 'Attention Is All You Need'}}\n\n# Sorting\n{'sort': [{'title.keyword': 'asc'}]}\n</code></pre>"},{"location":"modules/indexing/#authors-authors","title":"Authors (<code>authors</code>)","text":"<pre><code>'authors': {'type': 'keyword'}\n</code></pre> <ul> <li>Type: <code>keyword</code> array (exact match)</li> <li>Purpose: Filter by specific authors, aggregations</li> <li>Usage: Author filtering, co-author analysis</li> </ul> <p>Example:</p> <pre><code># Find all papers by author\n{'term': {'authors': 'Geoffrey Hinton'}}\n\n# Aggregation: top authors\n{\n    'aggs': {\n        'top_authors': {\n            'terms': {'field': 'authors', 'size': 10}\n        }\n    }\n}\n</code></pre>"},{"location":"modules/indexing/#embeddings-embedding","title":"Embeddings (<code>embedding</code>)","text":"<pre><code>'embedding': {\n    'type': 'knn_vector',\n    'dimension': 384\n}\n</code></pre> <ul> <li>Type: k-NN vector for semantic search</li> <li>Dimension: 384 (from <code>all-MiniLM-L6-v2</code>)</li> <li>Purpose: Semantic similarity matching</li> <li>Usage: Vector search for conceptual matching</li> </ul> <p>Example (when enabled):</p> <pre><code>query_embedding = embedding_model.encode(\"neural networks\").tolist()\n\n{\n    'query': {\n        'knn': {\n            'embedding': {\n                'vector': query_embedding,\n                'k': 10\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"modules/indexing/#citations-citations","title":"Citations (<code>citations</code>)","text":"<pre><code>'citations': {\n    'type': 'nested',\n    'properties': {\n        'text': {'type': 'text'},\n        'source': {'type': 'keyword'}\n    }\n}\n</code></pre> <ul> <li>Type: <code>nested</code> (allows querying within citation objects)</li> <li>Purpose: Store and search extracted citations</li> <li>Usage: Citation analysis, reference tracking</li> </ul> <p>Example:</p> <pre><code># Find documents citing specific source\n{\n    'query': {\n        'nested': {\n            'path': 'citations',\n            'query': {\n                'term': {'citations.source': 'Vaswani et al., 2017'}\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"modules/indexing/#embedding-generation","title":"Embedding Generation","text":""},{"location":"modules/indexing/#sentence-transformer-model","title":"Sentence Transformer Model","text":"<p>Model: <code>all-MiniLM-L6-v2</code></p> <p>Characteristics: - Size: 80MB (lightweight) - Dimension: 384 - Speed: ~1000 sentences/second (CPU) - Quality: Good for general semantic similarity</p> <p>Why This Model?: 1. Free: No API costs 2. Fast: Suitable for real-time indexing 3. Accurate: 0.68 Spearman correlation on STS benchmark 4. Lightweight: Runs on CPU without GPU</p>"},{"location":"modules/indexing/#embedding-process","title":"Embedding Process","text":"<pre><code># 1. Prepare searchable text\nsearchable_text = f\"{title} {abstract} {content[:1000]}\"\n\n# 2. Generate embedding\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nembedding = model.encode(searchable_text)  # numpy array (384,)\n\n# 3. Convert to list for JSON serialization\nembedding_list = embedding.tolist()  # List[float] (384 elements)\n\n# 4. Store in document\ndocument['embedding'] = embedding_list\n</code></pre>"},{"location":"modules/indexing/#semantic-search-benefits","title":"Semantic Search Benefits","text":"<p>Query: \"deep learning models for language understanding\"</p> <p>Traditional Keyword Search would miss: - \"neural architectures for NLP\" - \"transformer networks for text comprehension\"</p> <p>Semantic Search (using embeddings) finds: - Documents about BERT, GPT (even without exact keywords) - Papers on attention mechanisms (related concept) - Content about language models (semantic similarity)</p>"},{"location":"modules/indexing/#hybrid-search-strategy","title":"Hybrid Search Strategy","text":""},{"location":"modules/indexing/#why-hybrid","title":"Why Hybrid?","text":"<p>Combines strengths of both approaches:</p> Search Type Strengths Weaknesses Keyword (BM25) - Exact matches- Fast- Handles rare terms well - Misses synonyms- No semantic understanding Vector (kNN) - Semantic similarity- Finds related concepts- Handles paraphrasing - May miss exact terms- Slower- Requires embeddings Hybrid - Best of both worlds- Balanced precision/recall - More complex- Requires tuning"},{"location":"modules/indexing/#current-implementation-text-only","title":"Current Implementation (Text-Only)","text":"<p>The system currently uses multi-match with field boosting:</p> <p>Advantages: - Simple and fast - No vector computation at query time - Works well for exact and fuzzy matches</p> <p>Limitations: - No semantic similarity - Relies on keyword overlap - May miss conceptually similar content</p>"},{"location":"modules/indexing/#ideal-hybrid-implementation","title":"Ideal Hybrid Implementation","text":"<p>To re-enable full hybrid search:</p> <pre><code>def hybrid_search(self, index_name: str, query: str, k: int = 10):\n    # 1. Generate query embedding\n    query_embedding = self.embedding_model.encode(query).tolist()\n\n    # 2. Construct hybrid query\n    search_query = {\n        'size': k,\n        'query': {\n            'bool': {\n                'should': [\n                    # Keyword search (BM25)\n                    {\n                        'multi_match': {\n                            'query': query,\n                            'fields': ['title^3', 'abstract^2', 'content'],\n                            'type': 'best_fields'\n                        }\n                    },\n                    # Vector search (kNN)\n                    {\n                        'script_score': {\n                            'query': {'match_all': {}},\n                            'script': {\n                                'source': \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n                                'params': {'query_vector': query_embedding}\n                            }\n                        }\n                    }\n                ]\n            }\n        }\n    }\n\n    return self.client.search(index=index_name, body=search_query)\n</code></pre> <p>Score Combination: - BM25 score: 0-10 (keyword relevance) - Cosine similarity: 0-2 (semantic similarity, +1 offset) - Combined: Sum of both (higher = more relevant)</p>"},{"location":"modules/indexing/#search-query-examples","title":"Search Query Examples","text":""},{"location":"modules/indexing/#basic-text-search","title":"Basic Text Search","text":"<pre><code>manager = OpenSearchManager()\nresults = manager.hybrid_search(\"research_assistant\", \"machine learning\")\n</code></pre>"},{"location":"modules/indexing/#filter-by-content-type","title":"Filter by Content Type","text":"<pre><code># Direct OpenSearch query (bypass hybrid_search)\nquery = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'content': 'neural networks'}}\n            ],\n            'filter': [\n                {'term': {'content_type': 'video'}}\n            ]\n        }\n    }\n}\n\nresponse = manager.client.search(index=\"research_assistant\", body=query)\n</code></pre>"},{"location":"modules/indexing/#date-range-search","title":"Date Range Search","text":"<pre><code>query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'title': 'transformers'}}\n            ],\n            'filter': [\n                {\n                    'range': {\n                        'publication_date': {\n                            'gte': '2020-01-01',\n                            'lte': '2024-12-31'\n                        }\n                    }\n                }\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"modules/indexing/#author-filter","title":"Author Filter","text":"<pre><code>query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'content': 'attention mechanism'}}\n            ],\n            'filter': [\n                {'term': {'authors': 'Yoshua Bengio'}}\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"modules/indexing/#aggregations-analytics","title":"Aggregations (Analytics)","text":"<pre><code>query = {\n    'size': 0,  # Don't return documents\n    'aggs': {\n        'papers_per_year': {\n            'date_histogram': {\n                'field': 'publication_date',\n                'calendar_interval': 'year'\n            }\n        },\n        'top_concepts': {\n            'terms': {\n                'field': 'key_concepts',\n                'size': 20\n            }\n        }\n    }\n}\n\nresponse = manager.client.search(index=\"research_assistant\", body=query)\nprint(response['aggregations'])\n</code></pre>"},{"location":"modules/indexing/#performance-tuning","title":"Performance Tuning","text":""},{"location":"modules/indexing/#indexing-performance","title":"Indexing Performance","text":"<p>Single Document: - Embedding generation: ~10-50ms - Index operation: ~50-100ms - Total: ~60-150ms per document</p> <p>Bulk Indexing (100 documents): - Embedding generation: ~1-5 seconds - Bulk index operation: ~500ms-1s - Total: ~1.5-6 seconds (10-60ms per doc)</p> <p>Optimization Tips:</p> <ol> <li> <p>Use Bulk Indexing:    <pre><code># Bad: 100 individual calls\nfor doc in documents:\n    manager.index_document(index, doc)\n\n# Good: 1 bulk call\nmanager.bulk_index(index, documents)\n</code></pre></p> </li> <li> <p>Batch Embedding Generation:    <pre><code># Encode all texts at once (faster)\ntexts = [f\"{d['title']} {d['content']}\" for d in documents]\nembeddings = model.encode(texts)  # Batch processing\n\nfor doc, emb in zip(documents, embeddings):\n    doc['embedding'] = emb.tolist()\n</code></pre></p> </li> <li> <p>Increase Shard Count (for large indices):    <pre><code>'settings': {\n    'number_of_shards': 5,  # More shards = more parallelism\n    'number_of_replicas': 1\n}\n</code></pre></p> </li> </ol>"},{"location":"modules/indexing/#search-performance","title":"Search Performance","text":"<p>Text Search: - Query time: ~10-50ms (10K documents) - Query time: ~50-200ms (1M documents)</p> <p>Vector Search (when enabled): - Query time: ~50-100ms (10K documents) - Query time: ~200-500ms (1M documents)</p> <p>Optimization Tips:</p> <ol> <li> <p>Limit Result Size:    <pre><code>results = manager.hybrid_search(index, query, k=10)  # Not k=1000\n</code></pre></p> </li> <li> <p>Use Filters (before scoring):    <pre><code># Filters don't contribute to score (faster)\n{'filter': [{'term': {'content_type': 'paper'}}]}\n</code></pre></p> </li> <li> <p>Field Selection (return only needed fields):    <pre><code>{\n    'query': {...},\n    '_source': ['title', 'authors', 'url']  # Don't return large 'content' field\n}\n</code></pre></p> </li> <li> <p>Enable Caching:    <pre><code>{\n    'query': {\n        'bool': {\n            'filter': [\n                {'term': {'content_type': 'paper'}}  # Cached\n            ]\n        }\n    }\n}\n</code></pre></p> </li> </ol>"},{"location":"modules/indexing/#error-handling","title":"Error Handling","text":""},{"location":"modules/indexing/#connection-errors","title":"Connection Errors","text":"<pre><code>manager = OpenSearchManager(host='localhost', port=9200)\n\nif not manager.connected:\n    print(\"OpenSearch unavailable - using fallback search\")\n    # Implement fallback logic (e.g., SQLite FTS)\n</code></pre>"},{"location":"modules/indexing/#index-creation-errors","title":"Index Creation Errors","text":"<pre><code>success = manager.create_index(\"research_assistant\")\n\nif not success:\n    # Check if index exists\n    if manager.client.indices.exists(index=\"research_assistant\"):\n        print(\"Index already exists - using existing index\")\n    else:\n        print(\"Failed to create index - check permissions\")\n</code></pre>"},{"location":"modules/indexing/#indexing-errors","title":"Indexing Errors","text":"<pre><code>response = manager.index_document(index, document)\n\nif response is None:\n    # Log error and continue\n    logger.error(f\"Failed to index: {document.get('title')}\")\nelse:\n    logger.info(f\"Indexed: {response['_id']}\")\n</code></pre>"},{"location":"modules/indexing/#search-errors","title":"Search Errors","text":"<pre><code>try:\n    results = manager.hybrid_search(index, query)\nexcept Exception as e:\n    logger.error(f\"Search failed: {e}\")\n    results = []  # Return empty results\n</code></pre>"},{"location":"modules/indexing/#dependencies","title":"Dependencies","text":"<pre><code>from opensearchpy import OpenSearch, helpers\nfrom sentence_transformers import SentenceTransformer\n</code></pre> <p>Installation: <pre><code>pip install opensearch-py sentence-transformers\n</code></pre></p> <p>OpenSearch Server: <pre><code># Docker (recommended for development)\ndocker run -p 9200:9200 -e \"discovery.type=single-node\" opensearchproject/opensearch:latest\n\n# Verify connection\ncurl -X GET \"https://localhost:9200\" -u admin:admin -k\n</code></pre></p>"},{"location":"modules/indexing/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/indexing/#issue-connection-refused","title":"Issue: Connection refused","text":"<p>Error: <code>ConnectionError: Connection refused</code></p> <p>Solution: 1. Check OpenSearch is running: <code>docker ps</code> 2. Verify port: <code>curl http://localhost:9200</code> 3. Check firewall settings</p>"},{"location":"modules/indexing/#issue-ssl-certificate-verification-failed","title":"Issue: SSL certificate verification failed","text":"<p>Error: <code>SSLError: certificate verify failed</code></p> <p>Solution: Set <code>verify_certs=False</code> in initialization: <pre><code>manager = OpenSearchManager(\n    use_ssl=True,\n    verify_certs=False  # For self-signed certs\n)\n</code></pre></p>"},{"location":"modules/indexing/#issue-embedding-model-download-fails","title":"Issue: Embedding model download fails","text":"<p>Error: <code>OSError: Can't load model</code></p> <p>Solution: Pre-download model: <pre><code>from sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n# Downloads to ~/.cache/torch/sentence_transformers/\n</code></pre></p>"},{"location":"modules/indexing/#issue-index-creation-fails-with-resource_already_exists_exception","title":"Issue: Index creation fails with \"resource_already_exists_exception\"","text":"<p>Cause: Index already exists</p> <p>Solution: Delete and recreate, or use existing index: <pre><code># Delete existing index\nmanager.client.indices.delete(index=\"research_assistant\")\n\n# Recreate\nmanager.create_index(\"research_assistant\")\n</code></pre></p>"},{"location":"modules/indexing/#issue-search-returns-no-results-for-valid-query","title":"Issue: Search returns no results for valid query","text":"<p>Possible Causes: 1. Index is empty: Check document count    <pre><code>count = manager.client.count(index=\"research_assistant\")\nprint(f\"Documents: {count['count']}\")\n</code></pre></p> <ol> <li> <p>Field mismatch: Verify field names in index    <pre><code>mapping = manager.client.indices.get_mapping(index=\"research_assistant\")\nprint(mapping)\n</code></pre></p> </li> <li> <p>Query syntax error: Test with simple match query    <pre><code>{'query': {'match_all': {}}}  # Should return all docs\n</code></pre></p> </li> </ol>"},{"location":"modules/indexing/#advanced-usage","title":"Advanced Usage","text":""},{"location":"modules/indexing/#custom-analyzers","title":"Custom Analyzers","text":"<p>Add custom text analysis during index creation:</p> <pre><code>index_body = {\n    'settings': {\n        'analysis': {\n            'analyzer': {\n                'scientific_analyzer': {\n                    'type': 'custom',\n                    'tokenizer': 'standard',\n                    'filter': ['lowercase', 'asciifolding', 'porter_stem']\n                }\n            }\n        }\n    },\n    'mappings': {\n        'properties': {\n            'content': {\n                'type': 'text',\n                'analyzer': 'scientific_analyzer'\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"modules/indexing/#multi-index-search","title":"Multi-Index Search","text":"<p>Search across multiple indices:</p> <pre><code>results = manager.client.search(\n    index=['research_assistant', 'archived_papers'],\n    body={'query': {'match': {'title': 'transformers'}}}\n)\n</code></pre>"},{"location":"modules/indexing/#percolate-queries-reverse-search","title":"Percolate Queries (Reverse Search)","text":"<p>Store queries and match documents to them:</p> <pre><code># Index a query\nmanager.client.index(\n    index='research_queries',\n    body={\n        'query': {'match': {'content': 'neural networks'}}\n    }\n)\n\n# Percolate document against stored queries\nresponse = manager.client.search(\n    index='research_queries',\n    body={\n        'query': {\n            'percolate': {\n                'field': 'query',\n                'document': {\n                    'content': 'This paper discusses neural network architectures...'\n                }\n            }\n        }\n    }\n)\n</code></pre>"},{"location":"modules/indexing/#future-enhancements","title":"Future Enhancements","text":""},{"location":"modules/indexing/#planned-features","title":"Planned Features","text":"<ol> <li>Re-enable Vector Search: Full kNN + BM25 hybrid</li> <li>Query Expansion: Use LLM to expand queries before search</li> <li>Re-ranking: Use Gemini to re-rank top results</li> <li>Federated Search: Search external APIs alongside OpenSearch</li> <li>Caching Layer: Redis cache for frequent queries</li> </ol>"},{"location":"modules/indexing/#extension-points","title":"Extension Points","text":"<pre><code># Add query expansion\ndef expand_query(self, query: str) -&gt; str:\n    \"\"\"Use LLM to add synonyms and related terms\"\"\"\n    pass\n\n# Add re-ranking\ndef rerank_results(self, query: str, results: List[Dict]) -&gt; List[Dict]:\n    \"\"\"Use Gemini to re-rank results by relevance\"\"\"\n    pass\n\n# Add caching\ndef cached_search(self, query: str, k: int = 10) -&gt; List[Dict]:\n    \"\"\"Cache frequent query results\"\"\"\n    pass\n</code></pre>"},{"location":"modules/orchestration/","title":"Orchestration Module","text":""},{"location":"modules/orchestration/#overview","title":"Overview","text":"<p>The Orchestration module coordinates the end-to-end research query pipeline using LangChain and Google Gemini. It handles document retrieval, context formatting, response generation, citation extraction, and conversation memory management.</p>"},{"location":"modules/orchestration/#module-architecture","title":"Module Architecture","text":"<pre><code>multi_modal_rag/orchestration/\n\u251c\u2500\u2500 research_orchestrator.py    # Main query pipeline\n\u2514\u2500\u2500 citation_tracker.py          # Citation management\n</code></pre>"},{"location":"modules/orchestration/#researchorchestrator","title":"ResearchOrchestrator","text":"<p>File: <code>multi_modal_rag/orchestration/research_orchestrator.py</code></p>"},{"location":"modules/orchestration/#class-overview","title":"Class Overview","text":"<p>Orchestrates complex research queries by combining OpenSearch retrieval with LangChain-powered generation. Provides citation tracking, conversation memory, and related query suggestions.</p>"},{"location":"modules/orchestration/#initialization","title":"Initialization","text":"<pre><code>from multi_modal_rag.orchestration import ResearchOrchestrator\nfrom multi_modal_rag.indexing import OpenSearchManager\n\nopensearch = OpenSearchManager()\norchestrator = ResearchOrchestrator(\n    gemini_api_key=\"YOUR_API_KEY\",\n    opensearch_manager=opensearch\n)\n</code></pre> <p>Parameters: - <code>gemini_api_key</code> (str): Google Gemini API key - <code>opensearch_manager</code> (OpenSearchManager): Configured OpenSearch manager</p> <p>Components Initialized: - LangChain ChatGoogleGenerativeAI with <code>gemini-2.0-flash</code> model - ConversationBufferMemory for chat history - Temperature set to 0.3 (balanced creativity/accuracy)</p>"},{"location":"modules/orchestration/#methods","title":"Methods","text":""},{"location":"modules/orchestration/#create_research_chain-prompttemplate","title":"<code>create_research_chain() -&gt; PromptTemplate</code>","text":"<p>Creates a LangChain prompt template for research queries.</p> <p>Returns: PromptTemplate configured for research assistance</p> <p>Prompt Structure:</p> <pre><code>template = \"\"\"\nYou are a research assistant analyzing multi-modal academic content.\n\nContext from various sources:\n{context}\n\nPrevious conversation:\n{chat_history}\n\nQuestion: {question}\n\nInstructions:\n1. Provide a comprehensive answer based on the context\n2. Cite sources using [Author, Year] format\n3. Mention if information comes from videos or podcasts\n4. Highlight any diagrams or visual content that supports the answer\n5. Suggest related topics for further exploration\n\nAnswer:\n\"\"\"\n</code></pre> <p>Input Variables: - <code>context</code>: Formatted search results with citations - <code>chat_history</code>: Previous conversation messages - <code>question</code>: User's research query</p> <p>Example:</p> <pre><code>orchestrator = ResearchOrchestrator(api_key, opensearch_manager)\nprompt = orchestrator.create_research_chain()\n\n# Manually format prompt\nformatted = prompt.format(\n    context=\"Context here...\",\n    chat_history=\"Previous Q&amp;A...\",\n    question=\"What is attention mechanism?\"\n)\nprint(formatted)\n</code></pre>"},{"location":"modules/orchestration/#process_queryquery-str-index_name-str-dict","title":"<code>process_query(query: str, index_name: str) -&gt; Dict</code>","text":"<p>Main pipeline for processing research queries.</p> <p>Parameters: - <code>query</code> (str): User's research question - <code>index_name</code> (str): OpenSearch index to search (typically <code>\"research_assistant\"</code>)</p> <p>Returns: Dictionary with results:</p> <pre><code>{\n    'answer': str,                    # Generated response\n    'citations': List[Dict],          # Extracted citations\n    'source_documents': List[Dict],   # Retrieved documents\n    'related_queries': List[str]      # Suggested follow-up queries\n}\n</code></pre> <p>Pipeline Steps:</p> <ol> <li>Retrieval: Search OpenSearch for relevant documents</li> <li>Context Formatting: Format results with citation markers</li> <li>Generation: Generate response using Gemini</li> <li>Citation Extraction: Extract citations from response</li> <li>Memory Update: Save to conversation history</li> <li>Related Queries: Generate follow-up suggestions</li> </ol> <p>Example:</p> <pre><code>from multi_modal_rag.orchestration import ResearchOrchestrator\nfrom multi_modal_rag.indexing import OpenSearchManager\n\n# Initialize\nopensearch = OpenSearchManager()\norchestrator = ResearchOrchestrator(\"your_api_key\", opensearch)\n\n# Process query\nresult = orchestrator.process_query(\n    query=\"How do transformers use attention mechanisms?\",\n    index_name=\"research_assistant\"\n)\n\n# Access results\nprint(\"Answer:\")\nprint(result['answer'])\n\nprint(\"\\nCitations:\")\nfor citation in result['citations']:\n    print(f\"  - {citation['citation_text']}: {citation['title']}\")\n\nprint(\"\\nSource Documents:\")\nfor doc in result['source_documents']:\n    print(f\"  - {doc['source']['title']} (score: {doc['score']})\")\n\nprint(\"\\nRelated Queries:\")\nfor query in result['related_queries']:\n    print(f\"  - {query}\")\n</code></pre> <p>Output Example:</p> <pre><code>{\n    'answer': '''\n    Transformers use attention mechanisms to process sequences without recurrence.\n    The self-attention mechanism [Vaswani, 2017] allows each position to attend to\n    all positions in the previous layer. This is visualized in the architecture\n    diagram showing multi-head attention layers. The model computes attention\n    scores between query and key vectors, then uses these to weight value vectors.\n\n    Related video content [Video: Illustrated Transformer, 3Blue1Brown] provides\n    excellent visualizations of how attention weights are calculated.\n    ''',\n\n    'citations': [\n        {\n            'citation_text': ('Vaswani', '2017'),\n            'source': {...},\n            'content_type': 'paper',\n            'url': 'https://arxiv.org/abs/1706.03762',\n            'title': 'Attention Is All You Need'\n        },\n        {\n            'citation_text': ('Illustrated Transformer, 3Blue1Brown',),\n            'source': {...},\n            'content_type': 'video',\n            'url': 'https://youtube.com/watch?v=...',\n            'title': 'Illustrated Transformer'\n        }\n    ],\n\n    'source_documents': [\n        {\n            'score': 15.42,\n            'source': {\n                'title': 'Attention Is All You Need',\n                'content_type': 'paper',\n                'authors': ['Vaswani', 'Shazeer', ...],\n                ...\n            }\n        },\n        ...\n    ],\n\n    'related_queries': [\n        'What are the different types of attention mechanisms?',\n        'How does multi-head attention improve model performance?',\n        'What are the computational costs of attention?',\n        'How do transformers compare to RNNs?',\n        'What are recent improvements to attention mechanisms?'\n    ]\n}\n</code></pre>"},{"location":"modules/orchestration/#format_context_with_citationssearch_results-listdict-str","title":"<code>format_context_with_citations(search_results: List[Dict]) -&gt; str</code>","text":"<p>Formats search results into context string with citation markers.</p> <p>Parameters: - <code>search_results</code> (List[Dict]): Results from OpenSearch hybrid_search()</p> <p>Returns: Formatted context string</p> <p>Citation Formats: - Papers: <code>[FirstAuthor, Year]</code> (e.g., <code>[Vaswani, 2017]</code>) - Videos: <code>[Video: Channel, Title...]</code> (e.g., <code>[Video: 3Blue1Brown, Neural Networks...]</code>) - Podcasts: <code>[Podcast: Title...]</code> (e.g., <code>[Podcast: Lex Fridman discusses...]</code>)</p> <p>Example:</p> <pre><code>search_results = [\n    {\n        'score': 15.42,\n        'source': {\n            'content_type': 'paper',\n            'title': 'Attention Is All You Need',\n            'authors': ['Ashish Vaswani', 'Noam Shazeer'],\n            'publication_date': '2017-06-12',\n            'abstract': 'The dominant sequence transduction models...',\n            'diagram_descriptions': 'Architecture diagram showing...'\n        }\n    }\n]\n\ncontext = orchestrator.format_context_with_citations(search_results)\nprint(context)\n</code></pre> <p>Output:</p> <pre><code>Source 1 [Vaswani, 2017]:\nTitle: Attention Is All You Need\nType: paper\nContent: The dominant sequence transduction models are based on complex...\nVisual Content: Architecture diagram showing encoder-decoder structure with...\n</code></pre> <p>Full Context Structure:</p> <pre><code>\"\"\"\nSource 1 [Citation]:\nTitle: {title}\nType: {content_type}\nContent: {first_500_chars}...\nVisual Content: {diagram_descriptions}...\n\nSource 2 [Citation]:\nTitle: {title}\n...\n\"\"\"\n</code></pre>"},{"location":"modules/orchestration/#extract_citationsresponse-str-search_results-listdict-listdict","title":"<code>extract_citations(response: str, search_results: List[Dict]) -&gt; List[Dict]</code>","text":"<p>Extracts citations from generated response and matches them to source documents.</p> <p>Parameters: - <code>response</code> (str): Generated answer text - <code>search_results</code> (List[Dict]): Original search results</p> <p>Returns: List of citation dictionaries</p> <p>Citation Patterns (Regex): - <code>\\[([^,\\]]+),\\s*(\\d{4})\\]</code> - Paper citations: [Author, Year] - <code>\\[Video:\\s*([^\\]]+)\\]</code> - Video citations: [Video: Title] - <code>\\[Podcast:\\s*([^\\]]+)\\]</code> - Podcast citations: [Podcast: Title]</p> <p>Example:</p> <pre><code>response = \"\"\"\nTransformers were introduced by [Vaswani, 2017] and explained visually\nin [Video: Illustrated Transformer]. The podcast [Podcast: AI Explained]\nalso covers this topic.\n\"\"\"\n\ncitations = orchestrator.extract_citations(response, search_results)\n\nfor citation in citations:\n    print(f\"Found citation: {citation['citation_text']}\")\n    print(f\"  Matched to: {citation['title']}\")\n    print(f\"  Type: {citation['content_type']}\")\n    print(f\"  URL: {citation['url']}\")\n</code></pre> <p>Output:</p> <pre><code>[\n    {\n        'citation_text': ('Vaswani', '2017'),\n        'source': {...},  # Full source document\n        'content_type': 'paper',\n        'url': 'https://arxiv.org/abs/1706.03762',\n        'title': 'Attention Is All You Need'\n    },\n    {\n        'citation_text': ('Illustrated Transformer',),\n        'source': {...},\n        'content_type': 'video',\n        'url': 'https://youtube.com/watch?v=...',\n        'title': 'Illustrated Transformer'\n    },\n    {\n        'citation_text': ('AI Explained',),\n        'source': {...},\n        'content_type': 'podcast',\n        'url': 'https://...',\n        'title': 'AI Explained Episode'\n    }\n]\n</code></pre>"},{"location":"modules/orchestration/#citation_matches_sourcecitation_match-tuple-source-dict-bool","title":"<code>citation_matches_source(citation_match: tuple, source: Dict) -&gt; bool</code>","text":"<p>Checks if a citation regex match corresponds to a source document.</p> <p>Parameters: - <code>citation_match</code> (tuple): Regex match groups - <code>source</code> (Dict): Source document</p> <p>Returns: Boolean indicating match</p> <p>Matching Logic: - Papers: Match author name in first author - Videos: Match text in title - Podcasts: Match text in title</p> <p>Example:</p> <pre><code># Paper citation match\ncitation_match = ('Vaswani', '2017')\nsource = {\n    'content_type': 'paper',\n    'authors': ['Ashish Vaswani', 'Noam Shazeer']\n}\nmatches = orchestrator.citation_matches_source(citation_match, source)\n# Returns: True (Vaswani in first author)\n\n# Video citation match\ncitation_match = ('Illustrated Transformer',)\nsource = {\n    'content_type': 'video',\n    'title': 'The Illustrated Transformer'\n}\nmatches = orchestrator.citation_matches_source(citation_match, source)\n# Returns: True (text in title)\n</code></pre>"},{"location":"modules/orchestration/#generate_related_queriesoriginal_query-str-response-str-liststr","title":"<code>generate_related_queries(original_query: str, response: str) -&gt; List[str]</code>","text":"<p>Generates related research queries based on original query and response.</p> <p>Parameters: - <code>original_query</code> (str): User's original question - <code>response</code> (str): Generated answer (first 500 chars used)</p> <p>Returns: List of 5 related query strings</p> <p>Prompt Template:</p> <pre><code>prompt = f\"\"\"\nBased on this research query: \"{original_query}\"\nAnd this response: \"{response[:500]}...\"\n\nGenerate 5 related research questions that would deepen understanding of this topic.\nFormat as a JSON list.\n\"\"\"\n</code></pre> <p>Example:</p> <pre><code>original = \"How do transformers work?\"\nresponse = \"Transformers use self-attention mechanisms to process sequences...\"\n\nrelated = orchestrator.generate_related_queries(original, response)\n\nfor query in related:\n    print(f\"  \u2022 {query}\")\n</code></pre> <p>Output:</p> <pre><code>[\n    \"What are the key differences between transformers and RNNs?\",\n    \"How does multi-head attention improve model performance?\",\n    \"What are the computational requirements of transformer models?\",\n    \"How are transformers applied to computer vision tasks?\",\n    \"What are recent innovations in transformer architectures?\"\n]\n</code></pre> <p>Fallback (if JSON parsing fails):</p> <pre><code>[\n    f\"What are the key concepts in {original_query}?\",\n    f\"How does {original_query} relate to current research?\",\n    f\"What are recent developments in {original_query}?\"\n]\n</code></pre>"},{"location":"modules/orchestration/#citationtracker","title":"CitationTracker","text":"<p>File: <code>multi_modal_rag/orchestration/citation_tracker.py</code></p>"},{"location":"modules/orchestration/#class-overview_1","title":"Class Overview","text":"<p>Tracks and manages citations across research sessions. Provides citation analytics, usage history, and bibliography export in multiple formats.</p>"},{"location":"modules/orchestration/#initialization_1","title":"Initialization","text":"<pre><code>from multi_modal_rag.orchestration import CitationTracker\n\ntracker = CitationTracker(storage_path=\"data/citations.json\")\n</code></pre> <p>Parameters: - <code>storage_path</code> (str, optional): Path to JSON storage file. Default: <code>\"data/citations.json\"</code></p> <p>Storage Structure:</p> <pre><code>{\n    \"papers\": {\n        \"citation_id_1\": {\n            \"title\": \"Attention Is All You Need\",\n            \"authors\": [\"Ashish Vaswani\", \"Noam Shazeer\"],\n            \"url\": \"https://arxiv.org/abs/1706.03762\",\n            \"first_used\": \"2024-10-02T14:30:00\",\n            \"use_count\": 5,\n            \"queries\": [\n                {\"query\": \"How do transformers work?\", \"timestamp\": \"2024-10-02T14:30:00\"},\n                ...\n            ]\n        }\n    },\n    \"videos\": {...},\n    \"podcasts\": {...},\n    \"usage_history\": [\n        {\n            \"citation_id\": \"citation_id_1\",\n            \"content_type\": \"paper\",\n            \"query\": \"How do transformers work?\",\n            \"timestamp\": \"2024-10-02T14:30:00\"\n        },\n        ...\n    ]\n}\n</code></pre>"},{"location":"modules/orchestration/#methods_1","title":"Methods","text":""},{"location":"modules/orchestration/#load_citations-dict","title":"<code>load_citations() -&gt; Dict</code>","text":"<p>Loads existing citations from storage.</p> <p>Returns: Dictionary with citations or empty structure if file doesn't exist</p> <p>Example:</p> <pre><code>tracker = CitationTracker(\"data/citations.json\")\n# Automatically loads on initialization\n\n# Manual reload\ncitations = tracker.load_citations()\nprint(f\"Papers: {len(citations['papers'])}\")\nprint(f\"Videos: {len(citations['videos'])}\")\n</code></pre>"},{"location":"modules/orchestration/#save_citations","title":"<code>save_citations()</code>","text":"<p>Saves citations to storage file.</p> <p>Example:</p> <pre><code>tracker = CitationTracker()\n# Modify citations\ntracker.citations['papers']['new_id'] = {...}\n# Save changes\ntracker.save_citations()\n</code></pre> <p>Auto-save: Called automatically by <code>add_citation()</code></p>"},{"location":"modules/orchestration/#add_citationcitation-dict-query-str","title":"<code>add_citation(citation: Dict, query: str)</code>","text":"<p>Adds a new citation with usage tracking.</p> <p>Parameters: - <code>citation</code> (Dict): Citation information - <code>query</code> (str): Query that generated this citation</p> <p>Citation Structure:</p> <pre><code>{\n    'content_type': 'paper',  # or 'video', 'podcast'\n    'title': str,\n    'authors': List[str],\n    'url': str\n}\n</code></pre> <p>Example:</p> <pre><code>tracker = CitationTracker()\n\ncitation = {\n    'content_type': 'paper',\n    'title': 'Attention Is All You Need',\n    'authors': ['Ashish Vaswani', 'Noam Shazeer'],\n    'url': 'https://arxiv.org/abs/1706.03762'\n}\n\ntracker.add_citation(citation, query=\"How do transformers work?\")\n</code></pre> <p>Tracking Features: - Generates unique ID for citation (MD5 hash of title + URL) - Increments use count if citation exists - Stores query and timestamp for each use - Adds to usage history - Auto-saves to storage</p>"},{"location":"modules/orchestration/#generate_citation_idcitation-dict-str","title":"<code>generate_citation_id(citation: Dict) -&gt; str</code>","text":"<p>Generates unique ID for citation.</p> <p>Parameters: - <code>citation</code> (Dict): Citation dictionary</p> <p>Returns: 12-character MD5 hash</p> <p>Example:</p> <pre><code>citation = {\n    'title': 'Attention Is All You Need',\n    'url': 'https://arxiv.org/abs/1706.03762'\n}\n\ncitation_id = tracker.generate_citation_id(citation)\nprint(citation_id)  # e.g., \"a1b2c3d4e5f6\"\n</code></pre>"},{"location":"modules/orchestration/#get_citation_report-dict","title":"<code>get_citation_report() -&gt; Dict</code>","text":"<p>Generates citation usage report.</p> <p>Returns: Dictionary with statistics:</p> <pre><code>{\n    'total_papers': int,\n    'total_videos': int,\n    'total_podcasts': int,\n    'most_cited': List[Dict],      # Top 5 most used\n    'recent_citations': List[Dict]  # Last 10 citations\n}\n</code></pre> <p>Example:</p> <pre><code>tracker = CitationTracker()\nreport = tracker.get_citation_report()\n\nprint(f\"Total Papers: {report['total_papers']}\")\nprint(f\"Total Videos: {report['total_videos']}\")\n\nprint(\"\\nMost Cited Sources:\")\nfor item in report['most_cited']:\n    print(f\"  {item['title']} - used {item['use_count']} times\")\n\nprint(\"\\nRecent Citations:\")\nfor item in report['recent_citations']:\n    print(f\"  {item['query']} at {item['timestamp']}\")\n</code></pre>"},{"location":"modules/orchestration/#get_most_citedn-int-5-listdict","title":"<code>get_most_cited(n: int = 5) -&gt; List[Dict]</code>","text":"<p>Gets most frequently cited sources.</p> <p>Parameters: - <code>n</code> (int, optional): Number of results. Default: 5</p> <p>Returns: List of citation dictionaries sorted by use count</p> <p>Example:</p> <pre><code>top_citations = tracker.get_most_cited(n=10)\n\nfor i, citation in enumerate(top_citations, 1):\n    print(f\"{i}. {citation['title']}\")\n    print(f\"   Type: {citation['type']}, Used: {citation['use_count']} times\")\n</code></pre>"},{"location":"modules/orchestration/#get_recent_citationsn-int-10-listdict","title":"<code>get_recent_citations(n: int = 10) -&gt; List[Dict]</code>","text":"<p>Gets most recent citations.</p> <p>Parameters: - <code>n</code> (int, optional): Number of results. Default: 10</p> <p>Returns: List of recent citation events (reversed chronological order)</p> <p>Example:</p> <pre><code>recent = tracker.get_recent_citations(n=5)\n\nfor citation in recent:\n    print(f\"Query: {citation['query']}\")\n    print(f\"ID: {citation['citation_id']}\")\n    print(f\"Time: {citation['timestamp']}\")\n    print()\n</code></pre>"},{"location":"modules/orchestration/#export_bibliographyformat-str-bibtex-str","title":"<code>export_bibliography(format: str = 'bibtex') -&gt; str</code>","text":"<p>Exports citations in standard bibliography format.</p> <p>Parameters: - <code>format</code> (str, optional): Export format ('bibtex', 'apa', 'json'). Default: 'bibtex'</p> <p>Returns: Formatted bibliography string</p> <p>Supported Formats: - <code>'bibtex'</code>: BibTeX format - <code>'apa'</code>: APA citation format - <code>'json'</code>: JSON export</p> <p>Example:</p> <pre><code>tracker = CitationTracker()\n\n# BibTeX export\nbibtex = tracker.export_bibliography('bibtex')\nprint(bibtex)\n\n# APA export\napa = tracker.export_bibliography('apa')\nprint(apa)\n\n# JSON export\njson_export = tracker.export_bibliography('json')\nprint(json_export)\n</code></pre>"},{"location":"modules/orchestration/#export_bibtex-str","title":"<code>export_bibtex() -&gt; str</code>","text":"<p>Exports citations in BibTeX format.</p> <p>Returns: BibTeX-formatted string</p> <p>Example Output:</p> <pre><code>@article{a1b2c3d4e5f6,\n    title={Attention Is All You Need},\n    author={Ashish Vaswani and Noam Shazeer and Niki Parmar},\n    year={2017},\n    url={https://arxiv.org/abs/1706.03762}\n}\n\n@article{b2c3d4e5f6g7,\n    title={BERT: Pre-training of Deep Bidirectional Transformers},\n    author={Jacob Devlin and Ming-Wei Chang},\n    year={2018},\n    url={https://arxiv.org/abs/1810.04805}\n}\n</code></pre> <p>Usage:</p> <pre><code>bibtex = tracker.export_bibtex()\n\n# Save to file\nwith open('references.bib', 'w') as f:\n    f.write(bibtex)\n\n# Use in LaTeX\n# \\bibliography{references}\n</code></pre>"},{"location":"modules/orchestration/#export_apa-str","title":"<code>export_apa() -&gt; str</code>","text":"<p>Exports citations in APA format.</p> <p>Returns: APA-formatted string</p> <p>Example Output:</p> <pre><code>Devlin, J. et al. (2018). BERT: Pre-training of Deep Bidirectional Transformers. Retrieved from https://arxiv.org/abs/1810.04805\n\nVaswani, A. et al. (2017). Attention Is All You Need. Retrieved from https://arxiv.org/abs/1706.03762\n</code></pre> <p>Format Details: - Single author: <code>LastName, F. (Year).</code> - Multiple authors: <code>FirstAuthor et al. (Year).</code> - No date: Uses <code>n.d.</code> - Sorted alphabetically</p>"},{"location":"modules/orchestration/#integration-examples","title":"Integration Examples","text":""},{"location":"modules/orchestration/#complete-research-workflow","title":"Complete Research Workflow","text":"<pre><code>from multi_modal_rag.orchestration import ResearchOrchestrator, CitationTracker\nfrom multi_modal_rag.indexing import OpenSearchManager\n\n# Initialize components\nopensearch = OpenSearchManager()\norchestrator = ResearchOrchestrator(\"gemini_api_key\", opensearch)\ntracker = CitationTracker()\n\n# Process query\nquery = \"How do attention mechanisms work in transformers?\"\nresult = orchestrator.process_query(query, \"research_assistant\")\n\n# Display answer\nprint(\"Answer:\")\nprint(result['answer'])\nprint()\n\n# Track citations\nfor citation in result['citations']:\n    tracker.add_citation(citation, query)\n\n# View citation report\nreport = tracker.get_citation_report()\nprint(f\"Total citations tracked: {sum([report['total_papers'], report['total_videos'], report['total_podcasts']])}\")\n\n# Export bibliography\nbibtex = tracker.export_bibliography('bibtex')\nwith open('references.bib', 'w') as f:\n    f.write(bibtex)\n</code></pre>"},{"location":"modules/orchestration/#multi-turn-conversation","title":"Multi-Turn Conversation","text":"<pre><code>orchestrator = ResearchOrchestrator(\"api_key\", opensearch_manager)\n\nqueries = [\n    \"What is a transformer model?\",\n    \"How does self-attention work?\",\n    \"What are the advantages over RNNs?\"\n]\n\nfor query in queries:\n    result = orchestrator.process_query(query, \"research_assistant\")\n    print(f\"Q: {query}\")\n    print(f\"A: {result['answer']}\\n\")\n\n# Memory is preserved across queries\n# Later queries can reference earlier answers\n</code></pre>"},{"location":"modules/orchestration/#citation-analysis","title":"Citation Analysis","text":"<pre><code>tracker = CitationTracker()\n\n# Get analytics\nreport = tracker.get_citation_report()\n\nprint(\"=== Citation Analytics ===\\n\")\n\nprint(\"Most Cited Sources:\")\nfor i, item in enumerate(report['most_cited'][:5], 1):\n    print(f\"{i}. {item['title']} ({item['type']})\")\n    print(f\"   Used {item['use_count']} times\")\n    print()\n\nprint(\"Citation Distribution:\")\nprint(f\"  Papers: {report['total_papers']}\")\nprint(f\"  Videos: {report['total_videos']}\")\nprint(f\"  Podcasts: {report['total_podcasts']}\")\n\n# Export for different uses\nbibtex = tracker.export_bibliography('bibtex')\napa = tracker.export_bibliography('apa')\n\nwith open('references.bib', 'w') as f:\n    f.write(bibtex)\n\nwith open('references.txt', 'w') as f:\n    f.write(apa)\n</code></pre>"},{"location":"modules/orchestration/#langchain-integration","title":"LangChain Integration","text":""},{"location":"modules/orchestration/#components-used","title":"Components Used","text":"<p>LLM: <pre><code>from langchain_google_genai import ChatGoogleGenerativeAI\n\nllm = ChatGoogleGenerativeAI(\n    model=\"gemini-2.0-flash\",\n    google_api_key=api_key,\n    temperature=0.3,\n    convert_system_message_to_human=True\n)\n</code></pre></p> <p>Memory: <pre><code>from langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory(\n    memory_key=\"chat_history\",\n    return_messages=True\n)\n</code></pre></p> <p>Prompts: <pre><code>from langchain.prompts import PromptTemplate\n\nprompt = PromptTemplate(\n    template=template_string,\n    input_variables=[\"context\", \"chat_history\", \"question\"]\n)\n</code></pre></p>"},{"location":"modules/orchestration/#invocation-pattern","title":"Invocation Pattern","text":"<pre><code># Format prompt\nfull_prompt = prompt.format(\n    context=formatted_context,\n    chat_history=str(memory.chat_memory),\n    question=query\n)\n\n# Generate response\nresponse = llm.invoke(full_prompt).content\n\n# Update memory\nmemory.save_context(\n    {\"input\": query},\n    {\"output\": response}\n)\n</code></pre>"},{"location":"modules/orchestration/#error-handling","title":"Error Handling","text":""},{"location":"modules/orchestration/#query-processing-errors","title":"Query Processing Errors","text":"<pre><code>try:\n    result = orchestrator.process_query(query, index_name)\nexcept Exception as e:\n    logger.error(f\"Error processing query: {e}\")\n    result = {\n        'answer': f\"Error processing query: {str(e)}\",\n        'citations': [],\n        'source_documents': [],\n        'related_queries': []\n    }\n</code></pre>"},{"location":"modules/orchestration/#citation-tracking-errors","title":"Citation Tracking Errors","text":"<pre><code>try:\n    tracker.add_citation(citation, query)\nexcept Exception as e:\n    logger.error(f\"Error tracking citation: {e}\")\n    # Continue without tracking (non-critical)\n</code></pre>"},{"location":"modules/orchestration/#dependencies","title":"Dependencies","text":"<pre><code>from langchain.chains import RetrievalQA\nfrom langchain.prompts import PromptTemplate\nfrom langchain_google_genai import ChatGoogleGenerativeAI\nfrom langchain.memory import ConversationBufferMemory\nfrom langchain.schema import Document\n</code></pre> <p>Installation: <pre><code>pip install langchain langchain-google-genai\n</code></pre></p>"},{"location":"modules/orchestration/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/orchestration/#issue-related-queries-not-json","title":"Issue: Related queries not JSON","text":"<p>Error: <code>json.decoder.JSONDecodeError</code></p> <p>Cause: LLM doesn't always return valid JSON</p> <p>Solution: Use fallback queries (already implemented)</p>"},{"location":"modules/orchestration/#issue-citations-not-extracted","title":"Issue: Citations not extracted","text":"<p>Cause: Response doesn't match regex patterns</p> <p>Solution: Modify patterns or prompt engineering: <pre><code># Add to prompt\n\"IMPORTANT: Cite sources using exactly this format: [Author, Year]\"\n</code></pre></p>"},{"location":"modules/orchestration/#issue-memory-grows-too-large","title":"Issue: Memory grows too large","text":"<p>Cause: Long conversation history</p> <p>Solution: Use ConversationSummaryMemory or limit messages: <pre><code>from langchain.memory import ConversationSummaryMemory\n\nmemory = ConversationSummaryMemory(\n    llm=llm,\n    memory_key=\"chat_history\"\n)\n</code></pre></p>"},{"location":"modules/orchestration/#performance-considerations","title":"Performance Considerations","text":"<p>Query Processing Time: - OpenSearch retrieval: 10-50ms - Context formatting: 1-5ms - Gemini generation: 2-5 seconds - Citation extraction: 10-50ms - Related query generation: 2-3 seconds - Total: ~4-8 seconds per query</p> <p>Optimization Tips: 1. Cache frequent queries 2. Reduce retrieval count (k=5 instead of k=10) 3. Limit context size (truncate long documents) 4. Skip related query generation for faster responses</p>"},{"location":"modules/ui/","title":"UI Module","text":""},{"location":"modules/ui/#overview","title":"Overview","text":"<p>The UI module provides a Gradio-based web interface for the Multi-Modal Research Assistant. It offers tabs for research queries, data collection, citation management, settings configuration, and data visualization.</p>"},{"location":"modules/ui/#module-architecture","title":"Module Architecture","text":"<pre><code>multi_modal_rag/ui/\n\u2514\u2500\u2500 gradio_app.py    # Gradio application interface\n</code></pre>"},{"location":"modules/ui/#researchassistantui","title":"ResearchAssistantUI","text":"<p>File: <code>multi_modal_rag/ui/gradio_app.py</code></p>"},{"location":"modules/ui/#class-overview","title":"Class Overview","text":"<p>Creates a comprehensive Gradio interface with multiple tabs for different functionalities. Integrates with all system components including orchestrator, citation tracker, data collectors, and database manager.</p>"},{"location":"modules/ui/#initialization","title":"Initialization","text":"<pre><code>from multi_modal_rag.ui import ResearchAssistantUI\n\nui = ResearchAssistantUI(\n    orchestrator=orchestrator,\n    citation_tracker=citation_tracker,\n    data_collectors=data_collectors,\n    opensearch_manager=opensearch_manager,\n    db_manager=db_manager\n)\n</code></pre> <p>Parameters: - <code>orchestrator</code> (ResearchOrchestrator): Query processing orchestrator - <code>citation_tracker</code> (CitationTracker): Citation management system - <code>data_collectors</code> (Dict): Dictionary of data collectors   - <code>'paper_collector'</code>: AcademicPaperCollector   - <code>'video_collector'</code>: YouTubeLectureCollector   - <code>'podcast_collector'</code>: PodcastCollector - <code>opensearch_manager</code> (OpenSearchManager, optional): OpenSearch client - <code>db_manager</code> (CollectionDatabaseManager, optional): Database manager</p> <p>Example Setup:</p> <pre><code>from multi_modal_rag.orchestration import ResearchOrchestrator, CitationTracker\nfrom multi_modal_rag.data_collectors import (\n    AcademicPaperCollector,\n    YouTubeLectureCollector,\n    PodcastCollector\n)\nfrom multi_modal_rag.indexing import OpenSearchManager\nfrom multi_modal_rag.database import CollectionDatabaseManager\nfrom multi_modal_rag.ui import ResearchAssistantUI\n\n# Initialize components\norchestrator = ResearchOrchestrator(gemini_api_key, opensearch)\ncitation_tracker = CitationTracker()\ndata_collectors = {\n    'paper_collector': AcademicPaperCollector(),\n    'video_collector': YouTubeLectureCollector(),\n    'podcast_collector': PodcastCollector()\n}\nopensearch = OpenSearchManager()\ndb_manager = CollectionDatabaseManager()\n\n# Create UI\nui = ResearchAssistantUI(\n    orchestrator=orchestrator,\n    citation_tracker=citation_tracker,\n    data_collectors=data_collectors,\n    opensearch_manager=opensearch,\n    db_manager=db_manager\n)\n\n# Launch\napp = ui.create_interface()\napp.launch(share=True)\n</code></pre>"},{"location":"modules/ui/#interface-structure","title":"Interface Structure","text":""},{"location":"modules/ui/#main-application","title":"Main Application","text":"<pre><code>def create_interface(self) -&gt; gr.Blocks:\n    \"\"\"Creates Gradio interface with all tabs\"\"\"\n</code></pre> <p>Returns: Configured Gradio Blocks application</p> <p>Launch Options:</p> <pre><code>app = ui.create_interface()\n\n# Local only\napp.launch(server_name=\"127.0.0.1\", server_port=7860)\n\n# Public share link\napp.launch(share=True)\n\n# Custom settings\napp.launch(\n    server_name=\"0.0.0.0\",\n    server_port=7860,\n    share=True,\n    debug=True,\n    auth=(\"username\", \"password\")  # Basic auth\n)\n</code></pre>"},{"location":"modules/ui/#tabs-overview","title":"Tabs Overview","text":""},{"location":"modules/ui/#1-research-tab","title":"1. Research Tab","text":"<p>Purpose: Query the research system and view results with citations.</p> <p>Components:</p> <pre><code># Input\nquery_input = gr.Textbox(\n    label=\"Research Query\",\n    placeholder=\"Enter your research question...\",\n    lines=2\n)\n\nsearch_filters = gr.CheckboxGroup(\n    [\"Papers\", \"Videos\", \"Podcasts\"],\n    value=[\"Papers\", \"Videos\", \"Podcasts\"],\n    label=\"Content Types\"\n)\n\nsearch_btn = gr.Button(\"\ud83d\udd0d Search\", variant=\"primary\")\nclear_btn = gr.Button(\"Clear\")\n\n# Output\nanswer_output = gr.Markdown(label=\"Answer\")\ncitations_output = gr.JSON(label=\"Citations\")\nrelated_queries = gr.Markdown(label=\"Related Queries\")\n</code></pre> <p>Event Handler:</p> <pre><code>search_btn.click(\n    fn=self.handle_search,\n    inputs=[query_input, search_filters],\n    outputs=[answer_output, citations_output, related_queries]\n)\n</code></pre> <p>Example Usage: 1. Enter query: \"How do transformers work?\" 2. Select content types (papers, videos, podcasts) 3. Click \"\ud83d\udd0d Search\" 4. View formatted answer with citations 5. Explore related queries</p>"},{"location":"modules/ui/#2-data-collection-tab","title":"2. Data Collection Tab","text":"<p>Purpose: Collect new content from various sources and index it.</p> <p>Components:</p> <pre><code># Input\ncollection_type = gr.Radio(\n    [\"ArXiv Papers\", \"YouTube Lectures\", \"Podcasts\"],\n    label=\"Data Source\"\n)\n\ncollection_query = gr.Textbox(\n    label=\"Search Query\",\n    placeholder=\"e.g., machine learning, quantum computing\"\n)\n\nmax_results = gr.Slider(\n    minimum=5,\n    maximum=100,\n    value=20,\n    step=5,\n    label=\"Maximum Results\"\n)\n\ncollect_btn = gr.Button(\"\ud83d\udce5 Collect Data\", variant=\"primary\")\n\n# Output\ncollection_status = gr.Textbox(\n    label=\"Collection Status\",\n    lines=10\n)\n\ncollection_results = gr.JSON(label=\"Collection Results\")\n</code></pre> <p>Event Handler:</p> <pre><code>collect_btn.click(\n    fn=self.handle_data_collection,\n    inputs=[collection_type, collection_query, max_results],\n    outputs=[collection_status, collection_results]\n)\n</code></pre> <p>Workflow: 1. Select Source: Choose ArXiv Papers, YouTube Lectures, or Podcasts 2. Enter Query: Specify search terms 3. Set Limit: Choose max number of results (5-100) 4. Collect: Click \"\ud83d\udce5 Collect Data\" 5. Monitor: Watch real-time status updates 6. Auto-Index: Data automatically indexed in OpenSearch 7. Database Tracking: Items tracked in SQLite database</p> <p>Status Updates Example:</p> <pre><code>Collecting papers from ArXiv...\n\u2705 Collected 20 papers\n\n\ud83d\udcca Indexing data into OpenSearch...\n\u2705 Indexed 20 items into OpenSearch\n\n\u2705 Collection and indexing complete!\n</code></pre>"},{"location":"modules/ui/#3-citation-manager-tab","title":"3. Citation Manager Tab","text":"<p>Purpose: View citation statistics and export bibliographies.</p> <p>Components:</p> <pre><code># Report\ncitation_report = gr.JSON(label=\"Citation Report\")\nrefresh_report_btn = gr.Button(\"\ud83d\udd04 Refresh Report\")\n\n# Export\nexport_format = gr.Radio(\n    [\"BibTeX\", \"APA\", \"JSON\"],\n    value=\"BibTeX\",\n    label=\"Export Format\"\n)\n\nexport_btn = gr.Button(\"\ud83d\udce4 Export Citations\")\n\nexported_citations = gr.Textbox(\n    label=\"Exported Citations\",\n    lines=15\n)\n</code></pre> <p>Event Handlers:</p> <pre><code>refresh_report_btn.click(\n    fn=self.get_citation_report,\n    outputs=citation_report\n)\n\nexport_btn.click(\n    fn=self.export_citations,\n    inputs=export_format,\n    outputs=exported_citations\n)\n</code></pre> <p>Citation Report Structure:</p> <pre><code>{\n    \"total_papers\": 25,\n    \"total_videos\": 12,\n    \"total_podcasts\": 5,\n    \"most_cited\": [\n        {\n            \"id\": \"a1b2c3d4\",\n            \"type\": \"papers\",\n            \"title\": \"Attention Is All You Need\",\n            \"use_count\": 15\n        },\n        ...\n    ],\n    \"recent_citations\": [\n        {\n            \"citation_id\": \"a1b2c3d4\",\n            \"content_type\": \"paper\",\n            \"query\": \"How do transformers work?\",\n            \"timestamp\": \"2024-10-02T14:30:00\"\n        },\n        ...\n    ]\n}\n</code></pre>"},{"location":"modules/ui/#4-settings-tab","title":"4. Settings Tab","text":"<p>Purpose: Configure OpenSearch connection and manage indices.</p> <p>Components:</p> <pre><code># OpenSearch Settings\nopensearch_host = gr.Textbox(\n    label=\"Host\",\n    value=\"localhost\"\n)\n\nopensearch_port = gr.Number(\n    label=\"Port\",\n    value=9200\n)\n\n# API Keys\ngemini_key = gr.Textbox(\n    label=\"Gemini API Key\",\n    type=\"password\",\n    placeholder=\"Enter your Gemini API key\"\n)\n\nsave_settings_btn = gr.Button(\"\ud83d\udcbe Save Settings\")\n\n# Index Management\nindex_name = gr.Textbox(\n    label=\"Index Name\",\n    value=\"research_assistant\"\n)\n\ncreate_index_btn = gr.Button(\"Create Index\")\nreindex_btn = gr.Button(\"Reindex All Data\")\n\nindex_status = gr.Textbox(\n    label=\"Status\",\n    lines=5\n)\n</code></pre> <p>Event Handlers:</p> <pre><code>reindex_btn.click(\n    fn=self.handle_reindex,\n    inputs=[index_name],\n    outputs=[index_status]\n)\n</code></pre> <p>Reindex Functionality: - Reindexes all previously collected data - Useful after OpenSearch restart or schema changes - Shows progress and completion status</p>"},{"location":"modules/ui/#5-data-visualization-tab","title":"5. Data Visualization Tab","text":"<p>Purpose: View collection statistics and data tables.</p> <p>Components:</p> <pre><code># Statistics\nstats_display = gr.JSON(label=\"Statistics\")\nrefresh_stats_btn = gr.Button(\"\ud83d\udd04 Refresh Statistics\")\nquick_stats = gr.Markdown(\"\")\n\n# Filters\ncontent_type_filter = gr.Radio(\n    [\"All\", \"Papers\", \"Videos\", \"Podcasts\"],\n    value=\"All\",\n    label=\"Filter by Type\"\n)\n\nlimit_slider = gr.Slider(\n    minimum=10,\n    maximum=100,\n    value=20,\n    step=10,\n    label=\"Number of Items\"\n)\n\nrefresh_collections_btn = gr.Button(\"\ud83d\udcca Load Collections\")\n\n# Data Table\ncollections_table = gr.Dataframe(\n    headers=[\"ID\", \"Type\", \"Title\", \"Source\", \"Indexed\", \"Date\"],\n    label=\"Collection Data\",\n    wrap=True\n)\n</code></pre> <p>Event Handlers:</p> <pre><code>refresh_stats_btn.click(\n    fn=self.get_database_statistics,\n    outputs=[stats_display, quick_stats]\n)\n\nrefresh_collections_btn.click(\n    fn=self.get_collection_data,\n    inputs=[content_type_filter, limit_slider],\n    outputs=collections_table\n)\n</code></pre> <p>Quick Stats Display:</p> <pre><code>### Overview\n- **Total Collections**: 255\n- **Indexed**: 200 (78.4%)\n- **Recent (7 days)**: 45\n\n### By Type\n- **Papers**: 150\n- **Videos**: 75\n- **Podcasts**: 30\n</code></pre> <p>External Dashboard Link:</p> <p><pre><code>For advanced visualization with charts and filtering, visit the FastAPI dashboard:\n\n**[Open Visualization Dashboard](http://localhost:8000/viz)**\n\nTo start the FastAPI server, run:\n```bash\npython -m uvicorn multi_modal_rag.api.api_server:app --host 0.0.0.0 --port 8000\n</code></pre> <pre><code>---\n\n## Event Handler Methods\n\n### `handle_search(query: str, content_types: List[str]) -&gt; Tuple`\n\nHandles research query processing.\n\n**Parameters**:\n- `query` (str): User's research question\n- `content_types` (List[str]): Selected content types (not currently used for filtering)\n\n**Returns**: Tuple of (answer_markdown, citations_json, related_queries_markdown)\n\n**Implementation**:\n\n```python\ndef handle_search(self, query: str, content_types: List[str]) -&gt; Tuple:\n    # Process query\n    result = self.orchestrator.process_query(query, \"research_assistant\")\n\n    # Format answer with markdown\n    answer_md = f\"\"\"\n    ## Answer\n\n    {result['answer']}\n\n    ---\n\n    **Sources Used:** {len(result['source_documents'])}\n    \"\"\"\n\n    # Format related queries\n    related_md = \"### Related Research Questions\\n\\n\"\n    for i, q in enumerate(result['related_queries'], 1):\n        related_md += f\"{i}. {q}\\n\"\n\n    return answer_md, result['citations'], related_md\n</code></pre></p>"},{"location":"modules/ui/#handle_data_collectionsource_type-str-query-str-max_results-int-tuple","title":"<code>handle_data_collection(source_type: str, query: str, max_results: int) -&gt; Tuple</code>","text":"<p>Handles data collection and automatic indexing.</p> <p>Parameters: - <code>source_type</code> (str): \"ArXiv Papers\", \"YouTube Lectures\", or \"Podcasts\" - <code>query</code> (str): Search query - <code>max_results</code> (int): Maximum items to collect</p> <p>Returns: Tuple of (status_updates_text, results_json)</p> <p>Workflow:</p> <ol> <li>Collection: Collect from selected source</li> <li>Database Tracking: Save to SQLite database</li> <li>Indexing: Index in OpenSearch</li> <li>Mark Indexed: Update database status</li> <li>Log Statistics: Record collection stats</li> </ol> <p>Example Status Output:</p> <pre><code>Collecting papers from ArXiv...\n\u2705 Collected 20 papers\n\n\ud83d\udcca Indexing data into OpenSearch...\n\u2705 Indexed 20 items into OpenSearch\n\n\u2705 Collection and indexing complete!\n</code></pre> <p>Results JSON:</p> <pre><code>{\n    \"papers_collected\": 20,\n    \"items_indexed\": 20\n}\n</code></pre>"},{"location":"modules/ui/#_index_dataitems-list-source_type-str-int","title":"<code>_index_data(items: List, source_type: str) -&gt; int</code>","text":"<p>Helper method to index collected data into OpenSearch.</p> <p>Parameters: - <code>items</code> (List): Collected items (papers, videos, or podcasts) - <code>source_type</code> (str): Type identifier</p> <p>Returns: Number of items successfully indexed</p> <p>Document Formatting: - Converts collector output to OpenSearch document format - Handles different content types appropriately - Uses <code>_format_document()</code> helper</p>"},{"location":"modules/ui/#_format_documentitem-dict-source_type-str-dict","title":"<code>_format_document(item: dict, source_type: str) -&gt; dict</code>","text":"<p>Formats collected item into OpenSearch document.</p> <p>Parameters: - <code>item</code> (dict): Raw collector output - <code>source_type</code> (str): \"YouTube Lectures\", \"ArXiv Papers\", or \"Podcasts\"</p> <p>Returns: OpenSearch-compatible document</p> <p>Paper Format:</p> <pre><code>{\n    'content_type': 'paper',\n    'title': item.get('title', 'Unknown'),\n    'abstract': item.get('abstract', ''),\n    'content': item.get('content', ''),\n    'authors': item.get('authors', []),\n    'url': item.get('url', ''),\n    'publication_date': item.get('published', None),\n    'metadata': {\n        'arxiv_id': item.get('id', ''),\n        'categories': item.get('categories', [])\n    }\n}\n</code></pre> <p>Video Format:</p> <pre><code>{\n    'content_type': 'video',\n    'title': item.get('title', 'Unknown'),\n    'content': item.get('description', ''),\n    'transcript': item.get('transcript', ''),\n    'authors': [item.get('author', 'Unknown')],\n    'url': item.get('url', ''),\n    'publication_date': item.get('publish_date', None),\n    'metadata': {\n        'video_id': item.get('video_id', ''),\n        'length': item.get('length', 0),\n        'views': item.get('views', 0),\n        'thumbnail_url': item.get('thumbnail_url', '')\n    }\n}\n</code></pre>"},{"location":"modules/ui/#handle_reindexindex_name-str-str","title":"<code>handle_reindex(index_name: str) -&gt; str</code>","text":"<p>Reindexes all previously collected data.</p> <p>Parameters: - <code>index_name</code> (str): Target index name</p> <p>Returns: Status message</p> <p>Example:</p> <pre><code># Reindex all data\nstatus = ui.handle_reindex(\"research_assistant\")\nprint(status)\n# \"\u2705 Successfully reindexed 200 items to 'research_assistant'\"\n</code></pre>"},{"location":"modules/ui/#get_citation_report-dict","title":"<code>get_citation_report() -&gt; Dict</code>","text":"<p>Retrieves citation usage report.</p> <p>Returns: Citation tracker report dictionary</p>"},{"location":"modules/ui/#export_citationsformat-str-str","title":"<code>export_citations(format: str) -&gt; str</code>","text":"<p>Exports citations in specified format.</p> <p>Parameters: - <code>format</code> (str): \"BibTeX\", \"APA\", or \"JSON\"</p> <p>Returns: Formatted bibliography string</p>"},{"location":"modules/ui/#get_database_statistics-tuple","title":"<code>get_database_statistics() -&gt; Tuple</code>","text":"<p>Retrieves database statistics for visualization.</p> <p>Returns: Tuple of (stats_json, quick_stats_markdown)</p> <p>Stats JSON:</p> <pre><code>{\n    \"by_type\": {\n        \"paper\": 150,\n        \"video\": 75,\n        \"podcast\": 30\n    },\n    \"indexed\": 200,\n    \"not_indexed\": 55,\n    \"recent_7_days\": 45,\n    \"collection_history\": [...]\n}\n</code></pre>"},{"location":"modules/ui/#get_collection_datacontent_type_filter-str-limit-int-list","title":"<code>get_collection_data(content_type_filter: str, limit: int) -&gt; List</code>","text":"<p>Retrieves collection data for table display.</p> <p>Parameters: - <code>content_type_filter</code> (str): \"All\", \"Papers\", \"Videos\", or \"Podcasts\" - <code>limit</code> (int): Maximum rows</p> <p>Returns: List of lists for Gradio Dataframe</p> <p>Example Output:</p> <pre><code>[\n    [1, \"paper\", \"Attention Is All You Need\", \"arxiv\", \"Yes\", \"2024-10-02\"],\n    [2, \"video\", \"Neural Networks Explained\", \"youtube\", \"Yes\", \"2024-10-02\"],\n    ...\n]\n</code></pre>"},{"location":"modules/ui/#ui-customization","title":"UI Customization","text":""},{"location":"modules/ui/#theme-customization","title":"Theme Customization","text":"<pre><code>import gradio as gr\n\napp = gr.Blocks(\n    title=\"Multi-Modal Research Assistant\",\n    theme=gr.themes.Soft()  # or Base(), Monochrome(), Glass()\n)\n</code></pre> <p>Available Themes: - <code>gr.themes.Base()</code>: Default theme - <code>gr.themes.Soft()</code>: Softer colors - <code>gr.themes.Monochrome()</code>: Black and white - <code>gr.themes.Glass()</code>: Glassmorphism effect</p> <p>Custom Theme:</p> <pre><code>theme = gr.themes.Base(\n    primary_hue=\"blue\",\n    secondary_hue=\"gray\",\n    neutral_hue=\"slate\",\n    font=(\"Helvetica\", \"sans-serif\")\n)\n\napp = gr.Blocks(theme=theme)\n</code></pre>"},{"location":"modules/ui/#adding-custom-tabs","title":"Adding Custom Tabs","text":"<pre><code>def create_interface(self):\n    with gr.Blocks() as app:\n        # ... existing tabs ...\n\n        # Custom tab\n        with gr.TabItem(\"Analytics\"):\n            with gr.Row():\n                date_range = gr.DateTimePicker(label=\"Start Date\")\n                plot_btn = gr.Button(\"Generate Plot\")\n\n            plot_output = gr.Plot(label=\"Analytics\")\n\n            plot_btn.click(\n                fn=self.generate_analytics_plot,\n                inputs=[date_range],\n                outputs=[plot_output]\n            )\n\n    return app\n\ndef generate_analytics_plot(self, start_date):\n    import matplotlib.pyplot as plt\n    import pandas as pd\n\n    # Generate plot\n    fig, ax = plt.subplots()\n    # ... plotting logic ...\n    return fig\n</code></pre>"},{"location":"modules/ui/#launch-configurations","title":"Launch Configurations","text":""},{"location":"modules/ui/#local-development","title":"Local Development","text":"<pre><code>app.launch(\n    server_name=\"127.0.0.1\",\n    server_port=7860,\n    debug=True,\n    show_error=True\n)\n</code></pre>"},{"location":"modules/ui/#public-deployment","title":"Public Deployment","text":"<pre><code>app.launch(\n    server_name=\"0.0.0.0\",\n    server_port=7860,\n    share=True,  # Creates public link\n    auth=(\"admin\", \"password\"),  # Basic authentication\n    ssl_keyfile=\"key.pem\",\n    ssl_certfile=\"cert.pem\"\n)\n</code></pre>"},{"location":"modules/ui/#production-deployment","title":"Production Deployment","text":"<pre><code>import os\n\napp.launch(\n    server_name=\"0.0.0.0\",\n    server_port=int(os.getenv(\"PORT\", 7860)),\n    share=False,\n    auth=(os.getenv(\"USERNAME\"), os.getenv(\"PASSWORD\")),\n    show_api=False,  # Hide API docs\n    favicon_path=\"favicon.ico\"\n)\n</code></pre>"},{"location":"modules/ui/#integration-with-main-application","title":"Integration with Main Application","text":"<p>File: <code>main.py</code></p> <pre><code>from multi_modal_rag.orchestration import ResearchOrchestrator, CitationTracker\nfrom multi_modal_rag.data_collectors import (\n    AcademicPaperCollector,\n    YouTubeLectureCollector,\n    PodcastCollector\n)\nfrom multi_modal_rag.indexing import OpenSearchManager\nfrom multi_modal_rag.database import CollectionDatabaseManager\nfrom multi_modal_rag.ui import ResearchAssistantUI\n\ndef main():\n    # Load config\n    gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n\n    # Initialize components\n    opensearch = OpenSearchManager()\n    orchestrator = ResearchOrchestrator(gemini_api_key, opensearch)\n    citation_tracker = CitationTracker()\n\n    data_collectors = {\n        'paper_collector': AcademicPaperCollector(),\n        'video_collector': YouTubeLectureCollector(),\n        'podcast_collector': PodcastCollector()\n    }\n\n    db_manager = CollectionDatabaseManager()\n\n    # Create and launch UI\n    ui = ResearchAssistantUI(\n        orchestrator=orchestrator,\n        citation_tracker=citation_tracker,\n        data_collectors=data_collectors,\n        opensearch_manager=opensearch,\n        db_manager=db_manager\n    )\n\n    app = ui.create_interface()\n    app.launch(share=True)\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"modules/ui/#user-workflows","title":"User Workflows","text":""},{"location":"modules/ui/#workflow-1-research-query","title":"Workflow 1: Research Query","text":"<ol> <li>Navigate to Research tab</li> <li>Enter query: \"Explain attention mechanisms in transformers\"</li> <li>Select content types (Papers, Videos, Podcasts)</li> <li>Click \"\ud83d\udd0d Search\"</li> <li>Read formatted answer with citations</li> <li>Click related queries for deeper exploration</li> <li>View citations in Citation Manager</li> </ol>"},{"location":"modules/ui/#workflow-2-collect-new-content","title":"Workflow 2: Collect New Content","text":"<ol> <li>Navigate to Data Collection tab</li> <li>Select source: \"ArXiv Papers\"</li> <li>Enter query: \"quantum machine learning\"</li> <li>Set max results: 20</li> <li>Click \"\ud83d\udce5 Collect Data\"</li> <li>Monitor real-time status</li> <li>Data automatically indexed and ready for queries</li> </ol>"},{"location":"modules/ui/#workflow-3-export-bibliography","title":"Workflow 3: Export Bibliography","text":"<ol> <li>Navigate to Citation Manager tab</li> <li>Click \"\ud83d\udd04 Refresh Report\" to update</li> <li>Review most cited sources</li> <li>Select export format: \"BibTeX\"</li> <li>Click \"\ud83d\udce4 Export Citations\"</li> <li>Copy exported text</li> <li>Paste into LaTeX document or reference manager</li> </ol>"},{"location":"modules/ui/#workflow-4-view-analytics","title":"Workflow 4: View Analytics","text":"<ol> <li>Navigate to Data Visualization tab</li> <li>Click \"\ud83d\udd04 Refresh Statistics\"</li> <li>Review quick stats (total collections, indexed percentage)</li> <li>Select filter: \"Papers\"</li> <li>Adjust limit: 50</li> <li>Click \"\ud83d\udcca Load Collections\"</li> <li>Browse table of collected papers</li> <li>Open external dashboard for advanced charts</li> </ol>"},{"location":"modules/ui/#error-handling-in-ui","title":"Error Handling in UI","text":""},{"location":"modules/ui/#collection-errors","title":"Collection Errors","text":"<pre><code>def handle_data_collection(self, ...):\n    try:\n        # ... collection logic ...\n    except Exception as e:\n        error_msg = f\"\u274c Error: {str(e)}\"\n        status_updates.append(error_msg)\n        logger.error(f\"Collection error: {e}\", exc_info=True)\n\n    return '\\n'.join(status_updates), results\n</code></pre> <p>Displayed Error: <pre><code>Collecting papers from ArXiv...\n\u274c Error: Network connection timeout\n</code></pre></p>"},{"location":"modules/ui/#search-errors","title":"Search Errors","text":"<pre><code>def handle_search(self, query, content_types):\n    try:\n        result = self.orchestrator.process_query(query, \"research_assistant\")\n    except Exception as e:\n        return (\n            f\"## Error\\n\\n{str(e)}\",\n            [],\n            \"No related queries available\"\n        )\n</code></pre>"},{"location":"modules/ui/#performance-considerations","title":"Performance Considerations","text":""},{"location":"modules/ui/#ui-response-times","title":"UI Response Times","text":"<ul> <li>Search: 4-8 seconds (Gemini generation)</li> <li>Data Collection: 1-5 minutes (depending on count)</li> <li>Statistics: 50-200ms</li> <li>Export: 10-50ms</li> </ul>"},{"location":"modules/ui/#optimization-tips","title":"Optimization Tips","text":"<ol> <li> <p>Show Loading States:    <pre><code>with gr.Column():\n    search_btn = gr.Button(\"\ud83d\udd0d Search\")\n    loading = gr.HTML(\"\", visible=False)\n\ndef search_with_loading(query):\n    # Show loading\n    yield \"Searching...\", [], \"\", \"&lt;p&gt;Loading...&lt;/p&gt;\"\n\n    # Process\n    result = orchestrator.process_query(query, index)\n\n    # Hide loading\n    yield answer, citations, related, \"\"\n\nsearch_btn.click(\n    fn=search_with_loading,\n    inputs=[query_input],\n    outputs=[answer, citations, related, loading]\n)\n</code></pre></p> </li> <li> <p>Limit Result Display:    <pre><code># Don't display huge JSON objects\ncitations_output = gr.JSON(label=\"Citations\", max_height=400)\n</code></pre></p> </li> <li> <p>Async Operations:    <pre><code>async def handle_search_async(query):\n    result = await async_process_query(query)\n    return result\n</code></pre></p> </li> </ol>"},{"location":"modules/ui/#dependencies","title":"Dependencies","text":"<pre><code>import gradio as gr\nfrom typing import List, Tuple\n</code></pre> <p>Installation: <pre><code>pip install gradio\n</code></pre></p>"},{"location":"modules/ui/#troubleshooting","title":"Troubleshooting","text":""},{"location":"modules/ui/#issue-gradio-app-wont-launch","title":"Issue: Gradio app won't launch","text":"<p>Error: <code>Address already in use</code></p> <p>Solution: <pre><code>app.launch(server_port=7861)  # Use different port\n</code></pre></p>"},{"location":"modules/ui/#issue-share-link-doesnt-work","title":"Issue: Share link doesn't work","text":"<p>Cause: Firewall or network restrictions</p> <p>Solution: - Check firewall settings - Try local access first - Use ngrok as alternative:   <pre><code>ngrok http 7860\n</code></pre></p>"},{"location":"modules/ui/#issue-ui-freezes-during-collection","title":"Issue: UI freezes during collection","text":"<p>Cause: Long-running operation blocks UI</p> <p>Solution: Already implemented with status updates, but consider: <pre><code># Use queue for real-time updates\napp.queue()\napp.launch()\n</code></pre></p>"},{"location":"modules/ui/#issue-large-json-crashes-browser","title":"Issue: Large JSON crashes browser","text":"<p>Cause: Too much data in JSON component</p> <p>Solution: <pre><code># Limit JSON display\nlimited_citations = citations[:10]  # Show first 10 only\nreturn answer, limited_citations, related\n</code></pre></p>"},{"location":"modules/ui/#accessibility-features","title":"Accessibility Features","text":""},{"location":"modules/ui/#keyboard-navigation","title":"Keyboard Navigation","text":"<p>Gradio automatically supports: - Tab navigation between fields - Enter to submit forms - Arrow keys for sliders</p>"},{"location":"modules/ui/#screen-reader-support","title":"Screen Reader Support","text":"<p>Use descriptive labels: <pre><code>query_input = gr.Textbox(\n    label=\"Research Query\",\n    placeholder=\"Enter your research question...\",\n    info=\"Ask about papers, videos, or podcasts\"  # Additional help text\n)\n</code></pre></p>"},{"location":"modules/ui/#dark-mode","title":"Dark Mode","text":"<pre><code>app = gr.Blocks(theme=gr.themes.Soft(variant=\"dark\"))\n</code></pre>"},{"location":"modules/ui/#future-enhancements","title":"Future Enhancements","text":""},{"location":"modules/ui/#planned-features","title":"Planned Features","text":"<ol> <li>Advanced Filters: Filter search by date, author, source</li> <li>Saved Queries: Save and reuse frequent queries</li> <li>Export Options: Export results as PDF, Markdown</li> <li>Collaboration: Share query results with team</li> <li>Visualization: Charts showing citation networks</li> <li>Voice Input: Speech-to-text for queries</li> <li>Multi-language: Support for non-English content</li> </ol>"},{"location":"modules/ui/#extension-points","title":"Extension Points","text":"<pre><code># Add advanced search filters\ndef create_advanced_search_tab(self):\n    with gr.TabItem(\"Advanced Search\"):\n        # Date range\n        date_from = gr.DateTime(label=\"From\")\n        date_to = gr.DateTime(label=\"To\")\n\n        # Author filter\n        author_filter = gr.Textbox(label=\"Author\")\n\n        # Advanced search\n        advanced_search_btn = gr.Button(\"Advanced Search\")\n\n# Add export options\ndef export_results(self, format: str):\n    if format == \"PDF\":\n        return self.generate_pdf_report()\n    elif format == \"Markdown\":\n        return self.generate_markdown_report()\n</code></pre>"},{"location":"setup/configuration/","title":"Configuration Guide","text":"<p>Comprehensive guide to configuring the Multi-Modal Academic Research System for optimal performance.</p>"},{"location":"setup/configuration/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Environment Variables</li> <li>OpenSearch Configuration</li> <li>API Configuration</li> <li>Logging Configuration</li> <li>Application Settings</li> <li>Advanced Configuration</li> <li>Performance Tuning</li> <li>Security Considerations</li> </ul>"},{"location":"setup/configuration/#environment-variables","title":"Environment Variables","text":"<p>The system uses a <code>.env</code> file in the project root to manage configuration. All environment variables are optional except <code>GEMINI_API_KEY</code>.</p>"},{"location":"setup/configuration/#creating-the-configuration-file","title":"Creating the Configuration File","text":"<pre><code># Copy the example file\ncp .env.example .env\n\n# Edit with your preferred editor\nnano .env\n# or\ncode .env\n# or\nvim .env\n</code></pre>"},{"location":"setup/configuration/#available-environment-variables","title":"Available Environment Variables","text":""},{"location":"setup/configuration/#required-variables","title":"Required Variables","text":"<p><code>GEMINI_API_KEY</code> (Required) - Description: Google Gemini API key for AI-powered analysis and generation - Default: None (must be provided) - How to get: https://makersuite.google.com/app/apikey - Example: <code>GEMINI_API_KEY=AIzaSyAbc123def456ghi789jkl012mno345pqr</code> - Notes:   - Free tier available (no credit card required)   - Used for PDF diagram analysis and research query responses   - Do NOT use quotes around the key</p>"},{"location":"setup/configuration/#opensearch-variables","title":"OpenSearch Variables","text":"<p><code>OPENSEARCH_HOST</code> - Description: Hostname or IP address of the OpenSearch server - Default: <code>localhost</code> - Example: <code>OPENSEARCH_HOST=localhost</code> - Valid values:   - <code>localhost</code> (local Docker container)   - <code>127.0.0.1</code> (local IP)   - Any valid hostname or IP address</p> <p><code>OPENSEARCH_PORT</code> - Description: Port number for OpenSearch connection - Default: <code>9200</code> - Example: <code>OPENSEARCH_PORT=9200</code> - Valid values: Any valid port number (1-65535) - Notes: Default OpenSearch port is 9200</p> <p><code>OPENSEARCH_USERNAME</code> (Not in .env.example, but supported) - Description: Username for OpenSearch authentication - Default: <code>admin</code> (hardcoded in opensearch_manager.py) - Example: <code>OPENSEARCH_USERNAME=admin</code> - Notes: Currently not exposed in .env but can be added</p> <p><code>OPENSEARCH_PASSWORD</code> (Not in .env.example, but supported) - Description: Password for OpenSearch authentication - Default: <code>MyStrongPassword@2024!</code> (hardcoded in opensearch_manager.py) - Example: <code>OPENSEARCH_PASSWORD=MyStrongPassword@2024!</code> - Security: Should match the password set when starting OpenSearch container</p>"},{"location":"setup/configuration/#example-env-file","title":"Example .env File","text":"<p>Minimal configuration: <pre><code>GEMINI_API_KEY=AIzaSyAbc123def456ghi789jkl012mno345pqr\nOPENSEARCH_HOST=localhost\nOPENSEARCH_PORT=9200\n</code></pre></p> <p>Custom OpenSearch server: <pre><code>GEMINI_API_KEY=AIzaSyAbc123def456ghi789jkl012mno345pqr\nOPENSEARCH_HOST=192.168.1.100\nOPENSEARCH_PORT=9201\n</code></pre></p> <p>Development environment: <pre><code># Gemini API\nGEMINI_API_KEY=AIzaSyAbc123def456ghi789jkl012mno345pqr\n\n# OpenSearch (local Docker)\nOPENSEARCH_HOST=localhost\nOPENSEARCH_PORT=9200\n\n# Optional: Add comments for clarity\n# Get API key from: https://makersuite.google.com/app/apikey\n</code></pre></p>"},{"location":"setup/configuration/#environment-variable-best-practices","title":"Environment Variable Best Practices","text":"<ol> <li>Never commit .env to version control</li> <li>Already in <code>.gitignore</code></li> <li> <p>Keep sensitive keys private</p> </li> <li> <p>Use separate .env files for different environments</p> </li> <li><code>.env.development</code></li> <li><code>.env.production</code></li> <li> <p><code>.env.testing</code></p> </li> <li> <p>No quotes around values <pre><code># Correct\nGEMINI_API_KEY=AIzaSyAbc123\n\n# Incorrect (will include quotes in the value)\nGEMINI_API_KEY=\"AIzaSyAbc123\"\n</code></pre></p> </li> <li> <p>No spaces around equals sign <pre><code># Correct\nOPENSEARCH_HOST=localhost\n\n# Incorrect\nOPENSEARCH_HOST = localhost\n</code></pre></p> </li> </ol>"},{"location":"setup/configuration/#opensearch-configuration","title":"OpenSearch Configuration","text":"<p>OpenSearch is the vector database and search engine powering the research system.</p>"},{"location":"setup/configuration/#local-development-setup-docker","title":"Local Development Setup (Docker)","text":"<p>Standard configuration: <pre><code>docker run -d \\\n  --name opensearch-research \\\n  -p 9200:9200 \\\n  -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword@2024!\" \\\n  opensearchproject/opensearch:latest\n</code></pre></p> <p>With persistent storage: <pre><code>docker run -d \\\n  --name opensearch-research \\\n  -p 9200:9200 \\\n  -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword@2024!\" \\\n  -v opensearch-data:/usr/share/opensearch/data \\\n  opensearchproject/opensearch:latest\n</code></pre></p> <p>With custom memory limits: <pre><code>docker run -d \\\n  --name opensearch-research \\\n  -p 9200:9200 \\\n  -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword@2024!\" \\\n  -e \"OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n  opensearchproject/opensearch:latest\n</code></pre></p>"},{"location":"setup/configuration/#index-configuration","title":"Index Configuration","text":"<p>The system creates a <code>research_assistant</code> index with the following settings:</p> <p>Default Index Settings (defined in <code>opensearch_manager.py</code>): <pre><code>{\n    'settings': {\n        'index': {\n            'number_of_shards': 2,\n            'number_of_replicas': 1,\n            'knn': True  # Enable k-nearest neighbors for vector search\n        }\n    }\n}\n</code></pre></p> <p>Index Mappings: - <code>content_type</code>: Keyword (paper, video, podcast) - <code>title</code>: Text with keyword sub-field - <code>abstract</code>: Text - <code>content</code>: Text (main searchable content) - <code>authors</code>: Keyword array - <code>publication_date</code>: Date - <code>url</code>: Keyword - <code>transcript</code>: Text (for videos/podcasts) - <code>diagram_descriptions</code>: Text (from Gemini Vision) - <code>key_concepts</code>: Keyword array - <code>citations</code>: Nested objects - <code>embedding</code>: kNN vector (384 dimensions, all-MiniLM-L6-v2) - <code>metadata</code>: Object (flexible additional data)</p>"},{"location":"setup/configuration/#index-management","title":"Index Management","text":"<p>Check index status (via Settings tab in UI): - View connection status - See index statistics - Verify document count</p> <p>Delete and recreate index: <pre><code># Via Python console\nfrom multi_modal_rag.indexing.opensearch_manager import OpenSearchManager\nmanager = OpenSearchManager()\nmanager.client.indices.delete(index='research_assistant')\nmanager.create_index('research_assistant')\n</code></pre></p> <p>Backup index data: <pre><code># Using OpenSearch API\ncurl -X POST \"https://localhost:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true\" \\\n  -ku admin:MyStrongPassword@2024!\n</code></pre></p>"},{"location":"setup/configuration/#connection-settings","title":"Connection Settings","text":"<p>SSL Configuration (in <code>opensearch_manager.py</code>): <pre><code>OpenSearch(\n    hosts=[{'host': host, 'port': port}],\n    http_auth=(username, password),\n    http_compress=True,\n    use_ssl=True,              # Enable SSL\n    verify_certs=False,        # Disable cert verification (local dev)\n    ssl_assert_hostname=False,\n    ssl_show_warn=False,\n    timeout=5                  # 5 second timeout\n)\n</code></pre></p> <p>Modify connection timeout: Edit <code>multi_modal_rag/indexing/opensearch_manager.py</code>: <pre><code>timeout=30  # Increase for slow networks\n</code></pre></p>"},{"location":"setup/configuration/#api-configuration","title":"API Configuration","text":""},{"location":"setup/configuration/#google-gemini-api","title":"Google Gemini API","text":"<p>API Key Setup: 1. Visit: https://makersuite.google.com/app/apikey 2. Sign in with Google account 3. Create new API key 4. Copy to <code>.env</code> file</p> <p>Rate Limits (Free Tier): - 60 requests per minute - 1,500 requests per day - The system includes rate limiting to avoid exceeding these limits</p> <p>Models Used: 1. Gemini Pro (<code>gemini-1.5-pro-latest</code>):    - Research query responses    - Text analysis and synthesis    - Citation generation</p> <ol> <li>Gemini Vision (<code>gemini-1.5-flash</code>):</li> <li>PDF diagram analysis</li> <li>Image description generation</li> <li>Visual content understanding</li> </ol> <p>Switching Models (in code): Edit <code>multi_modal_rag/orchestration/research_orchestrator.py</code>: <pre><code># Current\nself.llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")\n\n# Alternative (faster, less capable)\nself.llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n</code></pre></p>"},{"location":"setup/configuration/#academic-data-source-apis","title":"Academic Data Source APIs","text":"<p>ArXiv (via <code>arxiv</code> package): - No API key required - Rate limit: 1 request per 3 seconds (built-in) - Free and unlimited</p> <p>Semantic Scholar (via <code>scholarly</code> package): - No API key required - May require rate limiting for heavy use - Free tier available</p> <p>YouTube (via <code>youtube-transcript-api</code>): - No API key required - Uses public transcript API - Subject to YouTube rate limits</p> <p>PubMed Central: - No API key required - E-utilities API (free) - Rate limit: 3 requests per second</p>"},{"location":"setup/configuration/#logging-configuration","title":"Logging Configuration","text":"<p>The system uses Python's built-in logging with custom configuration.</p>"},{"location":"setup/configuration/#log-file-location","title":"Log File Location","text":"<p>Default: <code>logs/research_system_YYYYMMDD_HHMMSS.log</code></p> <p>Example: <code>logs/research_system_20241002_143022.log</code></p>"},{"location":"setup/configuration/#log-levels","title":"Log Levels","text":"<p>File Handler (detailed logging): - Level: <code>DEBUG</code> - Captures all events including debug information - Format: <code>timestamp - module - level - file:line - function() - message</code></p> <p>Console Handler (important messages): - Level: <code>INFO</code> - Shows only important events in terminal - Format: <code>level - module - message</code></p>"},{"location":"setup/configuration/#log-configuration","title":"Log Configuration","text":"<p>Defined in: <code>multi_modal_rag/logging_config.py</code></p> <p>File Handler Configuration: <pre><code>file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')\nfile_handler.setLevel(logging.DEBUG)\n\nfile_formatter = logging.Formatter(\n    '%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(funcName)s() - %(message)s',\n    datefmt='%Y-%m-%d %H:%M:%S'\n)\n</code></pre></p> <p>Console Handler Configuration: <pre><code>console_handler = logging.StreamHandler()\nconsole_handler.setLevel(logging.INFO)\n\nconsole_formatter = logging.Formatter(\n    '%(levelname)s - %(name)s - %(message)s'\n)\n</code></pre></p>"},{"location":"setup/configuration/#customizing-logging","title":"Customizing Logging","text":"<p>Change log level (more or less verbose):</p> <p>Edit <code>multi_modal_rag/logging_config.py</code>: <pre><code># More verbose (show everything)\nlogger.setLevel(logging.DEBUG)\nconsole_handler.setLevel(logging.DEBUG)\n\n# Less verbose (errors only)\nlogger.setLevel(logging.ERROR)\nconsole_handler.setLevel(logging.ERROR)\n</code></pre></p> <p>Change log file location: <pre><code># In setup_logging() function\nlog_dir = \"custom_logs\"  # Change from \"logs\"\n</code></pre></p> <p>Disable console output: <pre><code># Comment out console handler\n# logger.addHandler(console_handler)\n</code></pre></p> <p>Log rotation (for long-running applications): <pre><code>from logging.handlers import RotatingFileHandler\n\nfile_handler = RotatingFileHandler(\n    log_file,\n    maxBytes=10*1024*1024,  # 10MB\n    backupCount=5\n)\n</code></pre></p>"},{"location":"setup/configuration/#log-file-management","title":"Log File Management","text":"<p>Automatic: Log files accumulate in <code>logs/</code> directory</p> <p>Manual cleanup: <pre><code># Delete logs older than 7 days\nfind logs/ -name \"*.log\" -mtime +7 -delete\n\n# Keep only last 10 log files\nls -t logs/*.log | tail -n +11 | xargs rm\n</code></pre></p> <p>Archive logs: <pre><code># Compress old logs\ntar -czf logs_archive_$(date +%Y%m%d).tar.gz logs/*.log\n</code></pre></p>"},{"location":"setup/configuration/#application-settings","title":"Application Settings","text":""},{"location":"setup/configuration/#gradio-ui-configuration","title":"Gradio UI Configuration","text":"<p>Defined in: <code>main.py</code></p> <p>Default settings: <pre><code>app.launch(\n    server_name=\"0.0.0.0\",  # Listen on all interfaces\n    server_port=7860,        # Default Gradio port\n    share=True               # Create public URL\n)\n</code></pre></p> <p>Custom port: <pre><code>app.launch(\n    server_name=\"0.0.0.0\",\n    server_port=8080,  # Custom port\n    share=True\n)\n</code></pre></p> <p>Disable public sharing: <pre><code>app.launch(\n    server_name=\"127.0.0.1\",  # Localhost only\n    server_port=7860,\n    share=False  # No public URL\n)\n</code></pre></p> <p>Authentication (add password protection): <pre><code>app.launch(\n    server_name=\"0.0.0.0\",\n    server_port=7860,\n    share=True,\n    auth=(\"username\", \"password\")  # Basic auth\n)\n</code></pre></p>"},{"location":"setup/configuration/#data-storage-locations","title":"Data Storage Locations","text":"<p>Default directories (created automatically): <pre><code>data/\n\u251c\u2500\u2500 papers/          # Downloaded PDFs\n\u251c\u2500\u2500 videos/          # Video metadata and transcripts\n\u251c\u2500\u2500 podcasts/        # Podcast episode data\n\u2514\u2500\u2500 processed/       # Processed content ready for indexing\n</code></pre></p> <p>Change data location (edit collector classes): <pre><code># In data_collectors/paper_collector.py\nself.download_dir = \"custom_papers_location\"\n</code></pre></p>"},{"location":"setup/configuration/#embedding-model-configuration","title":"Embedding Model Configuration","text":"<p>Default model: <code>all-MiniLM-L6-v2</code> - Dimension: 384 - Speed: Fast - Quality: Good for most use cases</p> <p>Change model (in <code>opensearch_manager.py</code>): <pre><code># Higher quality, slower\nself.embedding_model = SentenceTransformer('all-mpnet-base-v2')  # 768 dim\n\n# Faster, lower quality\nself.embedding_model = SentenceTransformer('all-MiniLM-L12-v2')  # 384 dim\n</code></pre></p> <p>Important: If you change the embedding model, you must: 1. Update the dimension in index mapping 2. Delete and recreate the index 3. Re-index all documents</p>"},{"location":"setup/configuration/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"setup/configuration/#hybrid-search-parameters","title":"Hybrid Search Parameters","text":"<p>Defined in: <code>multi_modal_rag/indexing/opensearch_manager.py</code></p> <p>Search query structure: <pre><code>query = {\n    \"query\": {\n        \"bool\": {\n            \"should\": [\n                # Keyword search (BM25)\n                {\n                    \"multi_match\": {\n                        \"query\": query_text,\n                        \"fields\": [\"title^2\", \"abstract\", \"content\", \"transcript\"],\n                        \"type\": \"best_fields\"\n                    }\n                },\n                # Vector similarity search\n                {\n                    \"knn\": {\n                        \"embedding\": {\n                            \"vector\": query_embedding,\n                            \"k\": 10\n                        }\n                    }\n                }\n            ]\n        }\n    }\n}\n</code></pre></p> <p>Adjust field weights: <pre><code>\"fields\": [\"title^3\", \"abstract^2\", \"content\", \"transcript\"]\n# title is 3x more important\n# abstract is 2x more important\n</code></pre></p> <p>Change k-NN neighbors: <pre><code>\"k\": 20  # Consider top 20 nearest neighbors instead of 10\n</code></pre></p>"},{"location":"setup/configuration/#langchain-configuration","title":"LangChain Configuration","text":"<p>Memory settings (in <code>research_orchestrator.py</code>): <pre><code># Current: Last 10 messages\nself.memory = ConversationBufferWindowMemory(k=10)\n\n# More context (uses more tokens)\nself.memory = ConversationBufferWindowMemory(k=20)\n\n# Full conversation history\nself.memory = ConversationBufferMemory()\n</code></pre></p> <p>Prompt template customization: <pre><code># Edit in research_orchestrator.py\nRESEARCH_TEMPLATE = \"\"\"\nCustom instructions here...\n\nContext: {context}\nQuestion: {question}\n\"\"\"\n</code></pre></p>"},{"location":"setup/configuration/#pdf-processing-configuration","title":"PDF Processing Configuration","text":"<p>Defined in: <code>multi_modal_rag/data_processors/pdf_processor.py</code></p> <p>Diagram extraction settings: - Currently uses Gemini Vision for analysis - Can be configured to extract specific image types - Adjustable image resolution and quality</p> <p>Text extraction: - Uses PyPDF2 and PyMuPDF - Fallback mechanisms for different PDF formats</p>"},{"location":"setup/configuration/#performance-tuning","title":"Performance Tuning","text":""},{"location":"setup/configuration/#memory-optimization","title":"Memory Optimization","text":"<p>OpenSearch JVM heap: <pre><code># Start with more memory\ndocker run -d \\\n  -e \"OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g\" \\\n  opensearchproject/opensearch:latest\n</code></pre></p> <p>Python process: - Process documents in batches - Clear memory between large operations - Use generators for large datasets</p>"},{"location":"setup/configuration/#indexing-performance","title":"Indexing Performance","text":"<p>Bulk indexing (already implemented): <pre><code># Batch multiple documents\nhelpers.bulk(client, actions, chunk_size=100)\n</code></pre></p> <p>Optimize for speed: <pre><code># Reduce replicas during bulk indexing\nindex_settings = {\n    'number_of_shards': 2,\n    'number_of_replicas': 0,  # Restore to 1 after indexing\n    'refresh_interval': '30s'  # Default is 1s\n}\n</code></pre></p>"},{"location":"setup/configuration/#query-performance","title":"Query Performance","text":"<p>Limit result size: <pre><code># In hybrid_search()\nresults = self.client.search(\n    index=index_name,\n    body=query,\n    size=5  # Return top 5 instead of 10\n)\n</code></pre></p> <p>Cache embeddings: - Embeddings are generated once during indexing - Reused for all searches (already optimized)</p>"},{"location":"setup/configuration/#network-optimization","title":"Network Optimization","text":"<p>OpenSearch connection pooling (already enabled): <pre><code>http_compress=True  # Compress HTTP traffic\n</code></pre></p> <p>Timeout tuning: <pre><code>timeout=30  # Increase for slow networks\n</code></pre></p>"},{"location":"setup/configuration/#security-considerations","title":"Security Considerations","text":""},{"location":"setup/configuration/#api-key-security","title":"API Key Security","text":"<p>Best practices: 1. Never commit <code>.env</code> to version control (already in <code>.gitignore</code>) 2. Use separate API keys for development/production 3. Rotate keys periodically 4. Limit API key permissions when possible</p> <p>Environment-specific keys: <pre><code># Development\nGEMINI_API_KEY=dev_key_here\n\n# Production\nGEMINI_API_KEY=prod_key_here\n</code></pre></p>"},{"location":"setup/configuration/#opensearch-security","title":"OpenSearch Security","text":"<p>Production recommendations: 1. Enable SSL certificate verification:    <pre><code>verify_certs=True,\nssl_assert_hostname=True\n</code></pre></p> <ol> <li> <p>Use strong passwords:    <pre><code>OPENSEARCH_INITIAL_ADMIN_PASSWORD=VeryStr0ng!P@ssw0rd#2024\n</code></pre></p> </li> <li> <p>Network security:</p> </li> <li>Don't expose OpenSearch port (9200) publicly</li> <li>Use firewall rules</li> <li> <p>Run on private network</p> </li> <li> <p>Authentication:</p> </li> <li>Change default admin credentials</li> <li>Create role-based access</li> <li>Use separate users for read/write operations</li> </ol>"},{"location":"setup/configuration/#gradio-ui-security","title":"Gradio UI Security","text":"<p>For production: <pre><code>app.launch(\n    server_name=\"127.0.0.1\",  # Localhost only\n    share=False,              # No public URL\n    auth=(\"admin\", \"secure_password\"),  # Require authentication\n    ssl_keyfile=\"path/to/key.pem\",\n    ssl_certfile=\"path/to/cert.pem\"\n)\n</code></pre></p> <p>Behind reverse proxy (recommended): - Use nginx or Apache as reverse proxy - Handle SSL/TLS termination at proxy - Add rate limiting - Implement authentication at proxy level</p>"},{"location":"setup/configuration/#data-privacy","title":"Data Privacy","text":"<p>Sensitive data handling: 1. Review PDFs before indexing (no proprietary content) 2. Clear conversation history regularly 3. Don't index personal or confidential information 4. Consider data retention policies</p> <p>Local-first approach: - All data stored locally by default - No data sent to third parties except API calls - OpenSearch runs on your machine - Control your own data</p>"},{"location":"setup/configuration/#configuration-checklist","title":"Configuration Checklist","text":""},{"location":"setup/configuration/#initial-setup","title":"Initial Setup","text":"<ul> <li> Copy <code>.env.example</code> to <code>.env</code></li> <li> Add Gemini API key</li> <li> Configure OpenSearch host/port</li> <li> Start OpenSearch container</li> <li> Verify connection in Settings tab</li> </ul>"},{"location":"setup/configuration/#production-deployment","title":"Production Deployment","text":"<ul> <li> Use strong OpenSearch password</li> <li> Enable SSL certificate verification</li> <li> Set up Gradio authentication</li> <li> Configure firewall rules</li> <li> Set up log rotation</li> <li> Configure backups for OpenSearch data</li> <li> Use environment-specific API keys</li> <li> Implement rate limiting</li> <li> Set up monitoring and alerts</li> </ul>"},{"location":"setup/configuration/#performance-optimization","title":"Performance Optimization","text":"<ul> <li> Adjust OpenSearch JVM heap size</li> <li> Configure index refresh interval</li> <li> Tune k-NN parameters</li> <li> Optimize field weights for your use case</li> <li> Set appropriate timeout values</li> <li> Enable HTTP compression</li> </ul>"},{"location":"setup/configuration/#maintenance","title":"Maintenance","text":"<ul> <li> Regular log cleanup</li> <li> Periodic API key rotation</li> <li> Index optimization</li> <li> Data backup schedule</li> <li> Update dependencies regularly</li> </ul>"},{"location":"setup/configuration/#troubleshooting-configuration-issues","title":"Troubleshooting Configuration Issues","text":""},{"location":"setup/configuration/#issue-changes-to-env-not-taking-effect","title":"Issue: Changes to .env not taking effect","text":"<p>Solution: 1. Restart the application (Ctrl+C and run <code>python main.py</code> again) 2. Verify <code>.env</code> is in project root directory 3. Check for syntax errors (no quotes, no spaces around <code>=</code>) 4. Ensure variable names are spelled correctly</p>"},{"location":"setup/configuration/#issue-opensearch-connection-fails-with-ssl-error","title":"Issue: OpenSearch connection fails with SSL error","text":"<p>Solution: 1. Check <code>verify_certs=False</code> in opensearch_manager.py 2. Verify OpenSearch is running: <code>docker ps</code> 3. Test connection: <code>curl -k https://localhost:9200</code> 4. Check firewall settings</p>"},{"location":"setup/configuration/#issue-logs-not-being-created","title":"Issue: Logs not being created","text":"<p>Solution: 1. Verify <code>logs/</code> directory exists and is writable 2. Check disk space 3. Review file permissions 4. Check logging configuration in <code>logging_config.py</code></p>"},{"location":"setup/configuration/#issue-out-of-memory-during-pdf-processing","title":"Issue: Out of memory during PDF processing","text":"<p>Solution: 1. Increase Docker memory limit 2. Process fewer documents at once 3. Reduce OpenSearch JVM heap size if needed 4. Close other applications</p>"},{"location":"setup/configuration/#next-steps","title":"Next Steps","text":"<p>After configuring your system:</p> <ol> <li>Test Configuration: Run through Quick Start Guide to verify everything works</li> <li>Explore Features: Learn about the system in Technology Stack</li> <li>Optimize: Use this guide to tune performance for your use case</li> <li>Monitor: Check logs regularly for issues</li> </ol> <p>Your Multi-Modal Academic Research System is now fully configured and ready for production use!</p>"},{"location":"setup/installation/","title":"Installation Guide","text":"<p>Complete step-by-step instructions for installing the Multi-Modal Academic Research System.</p>"},{"location":"setup/installation/#table-of-contents","title":"Table of Contents","text":"<ul> <li>System Requirements</li> <li>Prerequisites</li> <li>Installation Steps</li> <li>Verifying Installation</li> <li>Common Installation Issues</li> <li>Platform-Specific Notes</li> </ul>"},{"location":"setup/installation/#system-requirements","title":"System Requirements","text":""},{"location":"setup/installation/#minimum-requirements","title":"Minimum Requirements","text":"<ul> <li>Operating System: macOS, Linux, or Windows 10/11</li> <li>Python: Python 3.9 or higher (Python 3.11 recommended)</li> <li>RAM: 4GB minimum, 8GB recommended</li> <li>Disk Space: 5GB free space (for dependencies, models, and data)</li> <li>Internet: Stable internet connection for downloading dependencies and API access</li> </ul>"},{"location":"setup/installation/#recommended-specifications","title":"Recommended Specifications","text":"<ul> <li>Python: Python 3.11.x</li> <li>RAM: 8GB or more (for processing large PDFs and running embedding models)</li> <li>Disk Space: 10GB+ for storing papers, videos, and processed data</li> <li>GPU: Optional, but helpful for faster embedding generation</li> </ul>"},{"location":"setup/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing the Multi-Modal Academic Research System, ensure you have:</p> <ol> <li> <p>Python 3.9+ installed on your system    <pre><code>python --version  # Should show Python 3.9.x or higher\n</code></pre></p> </li> <li> <p>pip package manager (comes with Python)    <pre><code>pip --version\n</code></pre></p> </li> <li> <p>Docker installed (for OpenSearch)</p> </li> <li>Download from: https://www.docker.com/get-started</li> <li> <p>Verify installation: <code>docker --version</code></p> </li> <li> <p>Git (optional, for cloning the repository)    <pre><code>git --version\n</code></pre></p> </li> <li> <p>Google Gemini API Key (free tier available)</p> </li> <li>Get your key at: https://makersuite.google.com/app/apikey</li> <li>No credit card required for the free tier</li> </ol>"},{"location":"setup/installation/#installation-steps","title":"Installation Steps","text":""},{"location":"setup/installation/#step-1-clone-or-download-the-repository","title":"Step 1: Clone or Download the Repository","text":"<p>Option A: Using Git <pre><code>git clone &lt;repository-url&gt;\ncd multi-modal-academic-research-system\n</code></pre></p> <p>Option B: Download ZIP - Download and extract the project ZIP file - Navigate to the extracted directory</p>"},{"location":"setup/installation/#step-2-create-a-virtual-environment","title":"Step 2: Create a Virtual Environment","text":"<p>Creating a virtual environment isolates the project dependencies from your system Python.</p> <p>macOS/Linux: <pre><code>python -m venv venv\n</code></pre></p> <p>Windows: <pre><code>python -m venv venv\n</code></pre></p>"},{"location":"setup/installation/#step-3-activate-the-virtual-environment","title":"Step 3: Activate the Virtual Environment","text":"<p>macOS/Linux: <pre><code>source venv/bin/activate\n</code></pre></p> <p>Windows Command Prompt: <pre><code>venv\\Scripts\\activate\n</code></pre></p> <p>Windows PowerShell: <pre><code>venv\\Scripts\\Activate.ps1\n</code></pre></p> <p>You should see <code>(venv)</code> prepended to your command prompt, indicating the virtual environment is active.</p>"},{"location":"setup/installation/#step-4-upgrade-pip-recommended","title":"Step 4: Upgrade pip (Recommended)","text":"<pre><code>pip install --upgrade pip\n</code></pre>"},{"location":"setup/installation/#step-5-install-python-dependencies","title":"Step 5: Install Python Dependencies","text":"<p>Install all required packages from <code>requirements.txt</code>:</p> <pre><code>pip install -r requirements.txt\n</code></pre> <p>This will install approximately 30+ packages including: - OpenSearch client - LangChain and Google Gemini integration - Gradio for the web UI - PDF processing libraries - YouTube and podcast collectors - Sentence transformers for embeddings - And many more...</p> <p>Expected installation time: 5-10 minutes depending on your internet connection.</p>"},{"location":"setup/installation/#step-6-configure-environment-variables","title":"Step 6: Configure Environment Variables","text":"<ol> <li> <p>Copy the example environment file:    <pre><code>cp .env.example .env\n</code></pre></p> </li> <li> <p>Edit the <code>.env</code> file with your preferred text editor:    <pre><code># On macOS/Linux\nnano .env\n\n# Or use any text editor\ncode .env  # VS Code\nvim .env   # Vim\n</code></pre></p> </li> <li> <p>Add your Gemini API key:    <pre><code>GEMINI_API_KEY=your_actual_api_key_here\nOPENSEARCH_HOST=localhost\nOPENSEARCH_PORT=9200\n</code></pre></p> </li> </ol>"},{"location":"setup/installation/#step-7-start-opensearch","title":"Step 7: Start OpenSearch","text":"<p>OpenSearch is required for indexing and searching academic content.</p> <p>Using Docker (Recommended):</p> <pre><code>docker run -d \\\n  --name opensearch-research \\\n  -p 9200:9200 \\\n  -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword@2024!\" \\\n  opensearchproject/opensearch:latest\n</code></pre> <p>Verify OpenSearch is running: <pre><code>curl -X GET https://localhost:9200 -ku admin:MyStrongPassword@2024!\n</code></pre></p> <p>You should see JSON output with cluster information.</p>"},{"location":"setup/installation/#step-8-initialize-data-directories","title":"Step 8: Initialize Data Directories","text":"<p>The application will create these automatically, but you can create them manually:</p> <pre><code>mkdir -p data/papers data/videos data/podcasts data/processed\nmkdir -p logs configs\n</code></pre>"},{"location":"setup/installation/#step-9-download-embedding-models","title":"Step 9: Download Embedding Models","text":"<p>On first run, the sentence transformer model will be downloaded automatically (~90MB). To download it now:</p> <pre><code>python -c \"from sentence_transformers import SentenceTransformer; SentenceTransformer('all-MiniLM-L6-v2')\"\n</code></pre>"},{"location":"setup/installation/#verifying-installation","title":"Verifying Installation","text":""},{"location":"setup/installation/#test-1-check-python-environment","title":"Test 1: Check Python Environment","text":"<pre><code>python -c \"import sys; print(f'Python {sys.version}')\"\n</code></pre>"},{"location":"setup/installation/#test-2-verify-dependencies","title":"Test 2: Verify Dependencies","text":"<pre><code>python -c \"import opensearchpy, langchain, gradio, google.generativeai; print('All core dependencies installed successfully')\"\n</code></pre>"},{"location":"setup/installation/#test-3-check-opensearch-connection","title":"Test 3: Check OpenSearch Connection","text":"<pre><code>python -c \"from opensearchpy import OpenSearch; client = OpenSearch(hosts=[{'host': 'localhost', 'port': 9200}], http_auth=('admin', 'MyStrongPassword@2024!'), use_ssl=True, verify_certs=False); print(client.info())\"\n</code></pre>"},{"location":"setup/installation/#test-4-run-the-application","title":"Test 4: Run the Application","text":"<pre><code>python main.py\n</code></pre> <p>You should see: <pre><code>\ud83d\ude80 Initializing Multi-Modal Research Assistant...\n\u2705 Connected to OpenSearch at localhost:9200\n\u2705 Research Assistant ready!\n\ud83c\udf10 Opening web interface...\nRunning on local URL:  http://0.0.0.0:7860\nRunning on public URL: https://[random-id].gradio.live\n</code></pre></p> <p>Open the local URL in your browser. If you see the Research Assistant interface, installation is complete!</p>"},{"location":"setup/installation/#common-installation-issues","title":"Common Installation Issues","text":""},{"location":"setup/installation/#issue-1-python-version-mismatch","title":"Issue 1: Python Version Mismatch","text":"<p>Problem: <code>python --version</code> shows Python 2.x or Python &lt; 3.9</p> <p>Solution: - Try <code>python3 --version</code> instead - Use <code>python3</code> and <code>pip3</code> commands throughout installation - Install Python 3.11 from python.org</p>"},{"location":"setup/installation/#issue-2-pip-install-fails-with-permission-error","title":"Issue 2: pip Install Fails with Permission Error","text":"<p>Problem: <code>ERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied</code></p> <p>Solution: - Ensure virtual environment is activated (you should see <code>(venv)</code>) - If not in venv: Activate it again: <code>source venv/bin/activate</code> - Never use <code>sudo pip install</code> - this can break your system Python</p>"},{"location":"setup/installation/#issue-3-opensearch-wont-start","title":"Issue 3: OpenSearch Won't Start","text":"<p>Problem: Docker container fails or port 9200 is already in use</p> <p>Solutions: 1. Check if OpenSearch is already running:    <pre><code>docker ps | grep opensearch\n</code></pre></p> <ol> <li> <p>Stop existing container:    <pre><code>docker stop opensearch-research\ndocker rm opensearch-research\n</code></pre></p> </li> <li> <p>Check if port 9200 is in use:    <pre><code># macOS/Linux\nlsof -i :9200\n\n# Windows\nnetstat -ano | findstr :9200\n</code></pre></p> </li> <li> <p>Use a different port if needed (update <code>.env</code> file):    <pre><code>docker run -d -p 9201:9200 -e \"discovery.type=single-node\" opensearchproject/opensearch:latest\n</code></pre>    Then set <code>OPENSEARCH_PORT=9201</code> in <code>.env</code></p> </li> </ol>"},{"location":"setup/installation/#issue-4-modulenotfounderror","title":"Issue 4: ModuleNotFoundError","text":"<p>Problem: <code>ModuleNotFoundError: No module named 'opensearchpy'</code> (or other package)</p> <p>Solutions: 1. Verify virtual environment is active:    <pre><code>which python  # Should show path to venv/bin/python\n</code></pre></p> <ol> <li> <p>Reinstall requirements:    <pre><code>pip install -r requirements.txt\n</code></pre></p> </li> <li> <p>Install missing package individually:    <pre><code>pip install opensearch-py\n</code></pre></p> </li> </ol>"},{"location":"setup/installation/#issue-5-gemini-api-key-not-recognized","title":"Issue 5: Gemini API Key Not Recognized","text":"<p>Problem: <code>\u26a0\ufe0f  Please set GEMINI_API_KEY in your .env file</code></p> <p>Solutions: 1. Verify <code>.env</code> file exists in project root:    <pre><code>ls -la .env\n</code></pre></p> <ol> <li> <p>Check the file content (key should not have quotes):    <pre><code># Correct\nGEMINI_API_KEY=AIzaSyAbc123...\n\n# Incorrect\nGEMINI_API_KEY=\"AIzaSyAbc123...\"  # Remove quotes\n</code></pre></p> </li> <li> <p>Ensure no trailing spaces or newlines</p> </li> <li> <p>Restart the application after editing <code>.env</code></p> </li> </ol>"},{"location":"setup/installation/#issue-6-ssl-certificate-errors-with-opensearch","title":"Issue 6: SSL Certificate Errors with OpenSearch","text":"<p>Problem: <code>SSL: CERTIFICATE_VERIFY_FAILED</code> errors</p> <p>Solution: The application already disables SSL verification for local OpenSearch. If issues persist: 1. Check firewall settings 2. Verify OpenSearch container is running: <code>docker ps</code> 3. Try accessing OpenSearch directly: <code>curl -k https://localhost:9200</code></p>"},{"location":"setup/installation/#issue-7-out-of-memory-errors","title":"Issue 7: Out of Memory Errors","text":"<p>Problem: System runs out of memory during PDF processing or embedding generation</p> <p>Solutions: 1. Close other applications 2. Process fewer documents at once 3. Restart the application 4. Increase Docker memory limits if using Docker Desktop</p>"},{"location":"setup/installation/#issue-8-slow-download-of-embedding-models","title":"Issue 8: Slow Download of Embedding Models","text":"<p>Problem: First run takes very long downloading models</p> <p>Solution: - Be patient - the all-MiniLM-L6-v2 model is ~90MB - Check internet connection - Download manually using the command in Step 9 - The model is cached locally after first download</p>"},{"location":"setup/installation/#issue-9-port-7860-already-in-use","title":"Issue 9: Port 7860 Already in Use","text":"<p>Problem: Gradio cannot start because port 7860 is occupied</p> <p>Solution: 1. Find what's using the port:    <pre><code># macOS/Linux\nlsof -i :7860\n\n# Windows\nnetstat -ano | findstr :7860\n</code></pre></p> <ol> <li>Kill the process or modify <code>main.py</code> to use a different port:    <pre><code>app.launch(\n    server_name=\"0.0.0.0\",\n    server_port=7861,  # Changed port\n    share=True\n)\n</code></pre></li> </ol>"},{"location":"setup/installation/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"setup/installation/#macos","title":"macOS","text":"<ul> <li>M1/M2 Macs: All dependencies are compatible with ARM architecture</li> <li>Rosetta: Not required; native ARM support available</li> <li>Permission Issues: You may need to allow terminal to access folders in System Preferences</li> </ul>"},{"location":"setup/installation/#linux","title":"Linux","text":"<ul> <li> <p>Ubuntu/Debian: Install system dependencies:   <pre><code>sudo apt-get update\nsudo apt-get install python3-dev python3-pip python3-venv\n</code></pre></p> </li> <li> <p>Fedora/RHEL:   <pre><code>sudo dnf install python3-devel python3-pip\n</code></pre></p> </li> </ul>"},{"location":"setup/installation/#windows","title":"Windows","text":"<ul> <li> <p>PowerShell Execution Policy: If activation fails:   <pre><code>Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\n</code></pre></p> </li> <li> <p>Long Path Support: Enable long paths in Windows (required for some packages):</p> </li> <li> <p>Run as Administrator:     <pre><code>reg add \"HKLM\\SYSTEM\\CurrentControlSet\\Control\\FileSystem\" /v LongPathsEnabled /t REG_DWORD /d 1 /f\n</code></pre></p> </li> <li> <p>Visual C++ Redistributables: Some packages require Visual Studio build tools:</p> </li> <li>Download from: https://visualstudio.microsoft.com/visual-cpp-build-tools/</li> </ul>"},{"location":"setup/installation/#next-steps","title":"Next Steps","text":"<p>After successful installation:</p> <ol> <li>Quick Start: Follow the Quick Start Guide to run your first query</li> <li>Configuration: Review the Configuration Guide for advanced settings</li> <li>Architecture: Learn about the system in the Technology Stack document</li> </ol>"},{"location":"setup/installation/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here:</p> <ol> <li>Check the logs in the <code>logs/</code> directory</li> <li>Review the Configuration Guide</li> <li>Consult the main CLAUDE.md file</li> <li>Check GitHub issues or create a new one</li> </ol> <p>Installation complete! You're ready to start researching with your Multi-Modal Academic Research System.</p>"},{"location":"setup/quick-start/","title":"Quick Start Guide","text":"<p>Get up and running with the Multi-Modal Academic Research System in 5 minutes.</p>"},{"location":"setup/quick-start/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Prerequisites Checklist</li> <li>5-Minute Setup</li> <li>Your First Query</li> <li>Collecting Your First Papers</li> <li>Understanding the Interface</li> <li>Next Steps</li> </ul>"},{"location":"setup/quick-start/#prerequisites-checklist","title":"Prerequisites Checklist","text":"<p>Before you begin, ensure you have completed:</p> <ul> <li> Python 3.9+ installed (<code>python --version</code>)</li> <li> Docker installed and running (<code>docker --version</code>)</li> <li> Google Gemini API key (free from https://makersuite.google.com/app/apikey)</li> <li> Project downloaded/cloned to your local machine</li> </ul> <p>Not ready? See the full Installation Guide for detailed setup instructions.</p>"},{"location":"setup/quick-start/#5-minute-setup","title":"5-Minute Setup","text":""},{"location":"setup/quick-start/#step-1-start-opensearch-1-minute","title":"Step 1: Start OpenSearch (1 minute)","text":"<p>Open a terminal and run:</p> <pre><code>docker run -d \\\n  --name opensearch-research \\\n  -p 9200:9200 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_INITIAL_ADMIN_PASSWORD=MyStrongPassword@2024!\" \\\n  opensearchproject/opensearch:latest\n</code></pre> <p>Wait 30 seconds for OpenSearch to initialize.</p>"},{"location":"setup/quick-start/#step-2-set-up-python-environment-2-minutes","title":"Step 2: Set Up Python Environment (2 minutes)","text":"<p>Navigate to the project directory and run:</p> <pre><code># Create and activate virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"setup/quick-start/#step-3-configure-api-key-1-minute","title":"Step 3: Configure API Key (1 minute)","text":"<p>Create your <code>.env</code> file:</p> <pre><code>cp .env.example .env\n</code></pre> <p>Edit <code>.env</code> and add your Gemini API key:</p> <pre><code>GEMINI_API_KEY=your_actual_api_key_here\nOPENSEARCH_HOST=localhost\nOPENSEARCH_PORT=9200\n</code></pre>"},{"location":"setup/quick-start/#step-4-launch-the-application-1-minute","title":"Step 4: Launch the Application (1 minute)","text":"<pre><code>python main.py\n</code></pre> <p>You should see:</p> <pre><code>\ud83d\ude80 Initializing Multi-Modal Research Assistant...\n\u2705 Connected to OpenSearch at localhost:9200\n\u2705 Research Assistant ready!\n\ud83c\udf10 Opening web interface...\n\nRunning on local URL:  http://0.0.0.0:7860\nRunning on public URL: https://xxxxx.gradio.live\n</code></pre> <p>Success! Open http://localhost:7860 in your browser.</p>"},{"location":"setup/quick-start/#your-first-query","title":"Your First Query","text":"<p>The system comes with no data initially. Let's test it with a simple query to understand the interface, then collect some papers.</p>"},{"location":"setup/quick-start/#test-the-system","title":"Test the System","text":"<ol> <li>Navigate to the Research tab (should be open by default)</li> <li>In the query box, type: \"What is machine learning?\"</li> <li>Click Ask Question</li> </ol> <p>Expected Result: You'll see a message indicating no documents are available yet. This is normal - you need to collect data first!</p>"},{"location":"setup/quick-start/#collecting-your-first-papers","title":"Collecting Your First Papers","text":"<p>Let's populate the system with academic papers about a topic.</p>"},{"location":"setup/quick-start/#step-1-navigate-to-data-collection","title":"Step 1: Navigate to Data Collection","text":"<ol> <li>Click the Data Collection tab at the top of the interface</li> </ol>"},{"location":"setup/quick-start/#step-2-collect-papers-from-arxiv","title":"Step 2: Collect Papers from ArXiv","text":"<ol> <li>Find the Collect Papers section</li> <li>Enter a topic you're interested in, for example:</li> <li>\"machine learning\"</li> <li>\"natural language processing\"</li> <li>\"computer vision\"</li> <li> <p>\"quantum computing\"</p> </li> <li> <p>Set Number of papers to: <code>5</code> (for a quick start)</p> </li> <li> <p>Click Collect Papers</p> </li> </ol> <p>What happens: The system will: - Search ArXiv for the latest papers on your topic - Download the PDFs - Extract text and diagrams - Analyze diagrams using Gemini Vision - Generate embeddings - Index everything in OpenSearch</p> <p>Time: Expect 2-5 minutes for 5 papers.</p>"},{"location":"setup/quick-start/#step-3-monitor-progress","title":"Step 3: Monitor Progress","text":"<p>You'll see status updates like: <pre><code>\u2705 Collected 5 papers on 'machine learning'\nProcessing paper 1/5: \"Deep Learning for Computer Vision\"...\n\u2705 Indexed paper: Deep Learning for Computer Vision\nProcessing paper 2/5: \"Attention Is All You Need\"...\n...\n</code></pre></p>"},{"location":"setup/quick-start/#step-4-run-your-first-real-query","title":"Step 4: Run Your First Real Query","text":"<ol> <li>Go back to the Research tab</li> <li>Enter a query related to your collected papers:</li> <li>\"What are the key concepts in machine learning?\"</li> <li>\"Explain neural networks\"</li> <li> <p>\"How do transformers work?\"</p> </li> <li> <p>Click Ask Question</p> </li> </ol> <p>Expected Result: You'll receive: - A comprehensive answer synthesized from the papers - Citations in brackets [1], [2], etc. - Source information showing which papers were used</p> <p>Example response: <pre><code>Machine learning is a subset of artificial intelligence that enables\nsystems to learn and improve from experience [1]. Key concepts include:\n\n1. Neural Networks: Computational models inspired by biological neurons [1][2]\n2. Training: The process of adjusting model parameters using data [2]\n3. Deep Learning: Multi-layer neural networks for complex patterns [3]\n\nSources:\n[1] \"Deep Learning Fundamentals\" (Smith et al., 2023)\n[2] \"Introduction to Neural Networks\" (Johnson, 2023)\n[3] \"Modern Machine Learning\" (Lee et al., 2024)\n</code></pre></p>"},{"location":"setup/quick-start/#understanding-the-interface","title":"Understanding the Interface","text":"<p>The Research Assistant has four main tabs:</p>"},{"location":"setup/quick-start/#1-research-tab","title":"1. Research Tab","text":"<p>Purpose: Query your knowledge base and get AI-powered answers with citations</p> <p>Key Features: - Query input box - AI-generated responses with citations - Conversation history - Source attribution</p> <p>Usage Tips: - Ask specific questions for better results - Use follow-up questions to dive deeper - Check citations to verify information</p>"},{"location":"setup/quick-start/#2-data-collection-tab","title":"2. Data Collection Tab","text":"<p>Purpose: Gather academic content from multiple sources</p> <p>Sources Available: - Academic Papers: ArXiv, PubMed Central, Semantic Scholar - YouTube Videos: Educational channels and lectures - Podcasts: Academic and educational podcast episodes</p> <p>Parameters: - Topic/search query - Number of items to collect - Source preference</p> <p>Usage Tips: - Start with 5-10 papers to avoid long wait times - Choose topics that match your research interests - Mix different sources (papers, videos, podcasts) for diverse perspectives</p>"},{"location":"setup/quick-start/#3-citation-manager-tab","title":"3. Citation Manager Tab","text":"<p>Purpose: View and export citations from your research sessions</p> <p>Features: - List of all cited sources - Export to BibTeX format - Citation details (authors, title, date, URL)</p> <p>Usage Tips: - Export citations after each research session - Use BibTeX exports in your LaTeX documents - Keep track of sources for academic writing</p>"},{"location":"setup/quick-start/#4-settings-tab","title":"4. Settings Tab","text":"<p>Purpose: Configure system settings and connections</p> <p>Settings: - OpenSearch connection (host, port) - API keys (Gemini) - Index management - System health status</p> <p>Usage Tips: - Check connection status if searches fail - Verify OpenSearch is running - Update API keys if needed</p>"},{"location":"setup/quick-start/#quick-tips-for-success","title":"Quick Tips for Success","text":""},{"location":"setup/quick-start/#1-collection-strategy","title":"1. Collection Strategy","text":"<p>Start Small: Collect 5-10 papers initially to test the system - Faster processing - Easier to verify quality - Quick feedback on topics</p> <p>Scale Up: Once comfortable, collect 20-50 papers per topic - Better coverage - More comprehensive answers - Diverse perspectives</p>"},{"location":"setup/quick-start/#2-query-techniques","title":"2. Query Techniques","text":"<p>Be Specific: - Good: \"What is the attention mechanism in transformers?\" - Less effective: \"Tell me about AI\"</p> <p>Ask Follow-ups: - \"Can you explain that in simpler terms?\" - \"What are the practical applications?\" - \"How does this compare to other approaches?\"</p> <p>Request Evidence: - \"What evidence supports this claim?\" - \"Which papers discuss this topic?\"</p>"},{"location":"setup/quick-start/#3-content-diversity","title":"3. Content Diversity","text":"<p>Mix different content types for richer research: - Papers: Detailed technical information, formulas, experiments - Videos: Visual explanations, demonstrations, lectures - Podcasts: Discussions, interviews, high-level overviews</p>"},{"location":"setup/quick-start/#4-regular-maintenance","title":"4. Regular Maintenance","text":"<p>Update Your Knowledge Base: - Collect new papers weekly on your topics - Keep content current with latest research</p> <p>Monitor Storage: - PDFs and processed data accumulate in <code>data/</code> folder - Clean up old content periodically</p> <p>Check Logs: - Review <code>logs/</code> directory for any errors - Helps troubleshoot issues early</p>"},{"location":"setup/quick-start/#common-quick-start-issues","title":"Common Quick Start Issues","text":""},{"location":"setup/quick-start/#issue-cannot-connect-to-opensearch","title":"Issue: \"Cannot connect to OpenSearch\"","text":"<p>Quick Fix: <pre><code># Check if OpenSearch is running\ndocker ps | grep opensearch\n\n# If not running, start it\ndocker start opensearch-research\n\n# If container doesn't exist, create it (see Step 1)\n</code></pre></p>"},{"location":"setup/quick-start/#issue-gemini_api_key-not-found","title":"Issue: \"GEMINI_API_KEY not found\"","text":"<p>Quick Fix: 1. Verify <code>.env</code> file exists: <code>ls -la .env</code> 2. Check content: <code>cat .env</code> 3. Ensure key has no quotes: <code>GEMINI_API_KEY=AIza...</code> not <code>GEMINI_API_KEY=\"AIza...\"</code> 4. Restart application: <code>python main.py</code></p>"},{"location":"setup/quick-start/#issue-papers-collecting-but-not-processing","title":"Issue: Papers collecting but not processing","text":"<p>Quick Fix: - Check logs in <code>logs/</code> directory for errors - Verify Gemini API key is valid - Try with fewer papers (1-2) to isolate issues - Check internet connection</p>"},{"location":"setup/quick-start/#issue-slow-performance","title":"Issue: Slow performance","text":"<p>Quick Fix: - Start with fewer papers (5 instead of 20) - Close other applications to free memory - Wait for first-time model downloads to complete - Check Docker has enough memory allocated (4GB+ recommended)</p>"},{"location":"setup/quick-start/#example-workflows","title":"Example Workflows","text":""},{"location":"setup/quick-start/#workflow-1-research-a-new-topic","title":"Workflow 1: Research a New Topic","text":"<ol> <li>Collect: Data Collection \u2192 Enter \"quantum computing\" \u2192 Collect 10 papers</li> <li>Explore: Research \u2192 \"What is quantum computing?\"</li> <li>Deep Dive: Research \u2192 \"How do quantum gates work?\"</li> <li>Compare: Research \u2192 \"What are the differences between quantum and classical computing?\"</li> <li>Export: Citation Manager \u2192 Export BibTeX</li> </ol>"},{"location":"setup/quick-start/#workflow-2-literature-review","title":"Workflow 2: Literature Review","text":"<ol> <li>Broad Collection: Collect 30 papers on your research area</li> <li>Overview: \"What are the main research directions in [topic]?\"</li> <li>Specific Topics: \"What methods are used for [specific problem]?\"</li> <li>Gaps: \"What are open challenges in [topic]?\"</li> <li>Timeline: \"How has [topic] evolved over time?\"</li> </ol>"},{"location":"setup/quick-start/#workflow-3-learning-a-new-concept","title":"Workflow 3: Learning a New Concept","text":"<ol> <li>Mixed Media: Collect papers + YouTube videos on the topic</li> <li>Introduction: \"Explain [concept] in simple terms\"</li> <li>Technical: \"What is the mathematical foundation of [concept]?\"</li> <li>Visual: Videos provide diagrams and animations</li> <li>Practice: \"What are example applications of [concept]?\"</li> </ol>"},{"location":"setup/quick-start/#next-steps","title":"Next Steps","text":"<p>Now that you're up and running:</p>"},{"location":"setup/quick-start/#learn-more","title":"Learn More","text":"<ol> <li>Configuration Guide: Customize settings, logging, and advanced options</li> <li> <p>See Configuration Guide</p> </li> <li> <p>Architecture: Understand how the system works under the hood</p> </li> <li> <p>See Technology Stack</p> </li> <li> <p>Full Documentation: Explore all features and capabilities</p> </li> <li>See Main README</li> </ol>"},{"location":"setup/quick-start/#expand-your-knowledge-base","title":"Expand Your Knowledge Base","text":"<ul> <li>Collect papers from multiple sources (ArXiv, PubMed, Semantic Scholar)</li> <li>Add YouTube lectures from educational channels</li> <li>Include podcast episodes for diverse perspectives</li> </ul>"},{"location":"setup/quick-start/#optimize-your-workflow","title":"Optimize Your Workflow","text":"<ul> <li>Create topic-specific collections</li> <li>Use citation exports for your papers</li> <li>Experiment with different query styles</li> <li>Build a comprehensive research database</li> </ul>"},{"location":"setup/quick-start/#troubleshooting","title":"Troubleshooting","text":"<p>Still having issues?</p> <ol> <li>Check Logs: <code>logs/research_system_*.log</code> contains detailed error information</li> <li>Verify Setup: Run through the Installation Guide checklist</li> <li>Review Configuration: See Configuration Guide</li> <li>Common Issues: Full list in Installation Guide - Common Issues</li> </ol>"},{"location":"setup/quick-start/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: Start with CLAUDE.md in the project root</li> <li>Logs: Check <code>logs/</code> directory for error details</li> <li>Issues: Report bugs or request features on GitHub</li> </ul> <p>Congratulations! You're now ready to conduct AI-powered academic research with multi-modal sources.</p> <p>Happy researching!</p>"},{"location":"troubleshooting/api-errors/","title":"API Error Troubleshooting Guide","text":"<p>Comprehensive guide for diagnosing and resolving API-related errors in the Multi-Modal Academic Research System.</p>"},{"location":"troubleshooting/api-errors/#table-of-contents","title":"Table of Contents","text":"<ul> <li>HTTP Status Codes</li> <li>Request Validation Errors</li> <li>Authentication Issues</li> <li>Rate Limiting</li> <li>Timeout Errors</li> <li>API-Specific Issues</li> <li>Error Handling Best Practices</li> </ul>"},{"location":"troubleshooting/api-errors/#http-status-codes","title":"HTTP Status Codes","text":""},{"location":"troubleshooting/api-errors/#400-bad-request","title":"400 Bad Request","text":"<p>Meaning: The server cannot process the request due to invalid syntax or parameters.</p> <p>Common Causes: - Malformed JSON in request body - Missing required parameters - Invalid parameter values - Incorrect content type</p> <p>Example Error: <pre><code>400 Bad Request: {\"error\": \"Invalid query parameter\"}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Validate request format: <pre><code>import requests\nimport json\n\n# Correct format\ndata = {\n    \"query\": \"machine learning\",\n    \"max_results\": 10\n}\n\nresponse = requests.post(\n    api_url,\n    headers={\"Content-Type\": \"application/json\"},\n    data=json.dumps(data)  # Ensure proper JSON encoding\n)\n\n# Check response\nif response.status_code == 400:\n    print(f\"Bad request: {response.json()}\")\n</code></pre></p> </li> <li> <p>Validate parameters: <pre><code>def validate_query_params(params):\n    \"\"\"Validate API query parameters.\"\"\"\n    required = ['query']\n    for field in required:\n        if field not in params:\n            raise ValueError(f\"Missing required field: {field}\")\n\n    if 'max_results' in params:\n        if not isinstance(params['max_results'], int):\n            raise ValueError(\"max_results must be an integer\")\n        if params['max_results'] &lt; 1 or params['max_results'] &gt; 100:\n            raise ValueError(\"max_results must be between 1 and 100\")\n\n    return True\n\n# Use before making request\ntry:\n    validate_query_params(params)\n    response = requests.get(api_url, params=params)\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/api-errors/#401-unauthorized","title":"401 Unauthorized","text":"<p>Meaning: Authentication is required or has failed.</p> <p>Common Causes: - Missing API key - Invalid API key - Expired credentials - Wrong authentication method</p> <p>Example Error: <pre><code>401 Unauthorized: {\"error\": \"Invalid API key\"}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify API key: <pre><code>import os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\napi_key = os.getenv('GEMINI_API_KEY')\n\nif not api_key:\n    raise ValueError(\"GEMINI_API_KEY not found in environment\")\n\n# Test API key\nresponse = requests.get(\n    f\"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}\"\n)\n\nif response.status_code == 401:\n    print(\"Invalid API key. Get a new one from https://makersuite.google.com/app/apikey\")\n</code></pre></p> </li> <li> <p>Use correct authentication method: <pre><code># For Gemini API - use query parameter\nimport google.generativeai as genai\n\ngenai.configure(api_key=api_key)\nmodel = genai.GenerativeModel('gemini-pro')\n\n# For other APIs - use headers\nheaders = {\n    'Authorization': f'Bearer {api_key}',\n    'Content-Type': 'application/json'\n}\n\nresponse = requests.get(api_url, headers=headers)\n</code></pre></p> </li> <li> <p>Handle expired credentials: <pre><code>def call_api_with_retry(url, api_key):\n    \"\"\"Call API with automatic key refresh.\"\"\"\n    response = requests.get(\n        url,\n        headers={'Authorization': f'Bearer {api_key}'}\n    )\n\n    if response.status_code == 401:\n        # Refresh credentials\n        new_api_key = refresh_credentials()\n        response = requests.get(\n            url,\n            headers={'Authorization': f'Bearer {new_api_key}'}\n        )\n\n    return response\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/api-errors/#403-forbidden","title":"403 Forbidden","text":"<p>Meaning: Server understands the request but refuses to authorize it.</p> <p>Common Causes: - Insufficient permissions - API access not enabled - Blocked by firewall or security policy - Accessing restricted resources</p> <p>Example Error: <pre><code>403 Forbidden: {\"error\": \"API not enabled for this project\"}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Enable required APIs: <pre><code># For Google Cloud APIs\ngcloud services enable generativelanguage.googleapis.com\n\n# Or enable in console:\n# https://console.cloud.google.com/apis/library\n</code></pre></p> </li> <li> <p>Check API quotas and limits: <pre><code>import google.generativeai as genai\n\ntry:\n    response = model.generate_content(prompt)\nexcept Exception as e:\n    if \"403\" in str(e):\n        print(\"API access denied. Check:\")\n        print(\"1. API is enabled in Google Cloud Console\")\n        print(\"2. Billing is enabled (if required)\")\n        print(\"3. You have necessary permissions\")\n</code></pre></p> </li> <li> <p>Verify resource access: <pre><code># Check if resource is accessible\nresponse = requests.head(resource_url)\n\nif response.status_code == 403:\n    print(f\"Access denied to {resource_url}\")\n    print(\"Possible reasons:\")\n    print(\"- Private resource\")\n    print(\"- Geographic restrictions\")\n    print(\"- Account limitations\")\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/api-errors/#404-not-found","title":"404 Not Found","text":"<p>Meaning: The requested resource doesn't exist.</p> <p>Common Causes: - Incorrect URL or endpoint - Resource has been deleted - Typo in resource ID - API version mismatch</p> <p>Example Error: <pre><code>404 Not Found: {\"error\": \"Resource not found\"}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Verify endpoint URL: <pre><code># Correct ArXiv API endpoint\nARXIV_API = \"http://export.arxiv.org/api/query\"\n\n# Common mistakes:\n# Wrong: \"http://arxiv.org/api/query\"\n# Wrong: \"http://export.arxiv.org/query\"\n\nresponse = requests.get(ARXIV_API, params=params)\nif response.status_code == 404:\n    print(f\"Invalid endpoint: {ARXIV_API}\")\n</code></pre></p> </li> <li> <p>Validate resource IDs: <pre><code>def validate_arxiv_id(arxiv_id):\n    \"\"\"Validate ArXiv ID format.\"\"\"\n    import re\n\n    # Format: YYMM.NNNNN or YYMM.NNNNNN\n    pattern = r'^\\d{4}\\.\\d{4,5}(v\\d+)?$'\n\n    if not re.match(pattern, arxiv_id):\n        raise ValueError(f\"Invalid ArXiv ID format: {arxiv_id}\")\n\n    return True\n\n# Use before fetching\ntry:\n    validate_arxiv_id(\"2301.12345\")\n    response = fetch_paper(arxiv_id)\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n</code></pre></p> </li> <li> <p>Handle missing resources gracefully: <pre><code>def fetch_resource_safe(resource_id):\n    \"\"\"Fetch resource with fallback.\"\"\"\n    response = requests.get(f\"{api_url}/{resource_id}\")\n\n    if response.status_code == 404:\n        print(f\"Resource {resource_id} not found\")\n        # Try alternative source\n        return fetch_from_alternative(resource_id)\n\n    return response.json()\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/api-errors/#429-too-many-requests","title":"429 Too Many Requests","text":"<p>Meaning: Rate limit has been exceeded.</p> <p>Common Causes: - Too many requests in short time - Exceeded quota limits - No rate limiting implemented - Multiple concurrent requests</p> <p>Example Error: <pre><code>429 Too Many Requests: {\"error\": \"Rate limit exceeded. Retry after 60 seconds.\"}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Implement rate limiting: <pre><code>import time\nfrom functools import wraps\n\ndef rate_limit(calls_per_second=1):\n    \"\"\"Decorator to rate limit function calls.\"\"\"\n    min_interval = 1.0 / calls_per_second\n    last_called = [0.0]\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            elapsed = time.time() - last_called[0]\n            wait_time = min_interval - elapsed\n\n            if wait_time &gt; 0:\n                time.sleep(wait_time)\n\n            result = func(*args, **kwargs)\n            last_called[0] = time.time()\n            return result\n\n        return wrapper\n    return decorator\n\n@rate_limit(calls_per_second=2)  # Max 2 calls per second\ndef call_api(url):\n    return requests.get(url)\n</code></pre></p> </li> <li> <p>Implement exponential backoff: <pre><code>import time\nimport random\n\ndef exponential_backoff(func, max_retries=5):\n    \"\"\"Retry with exponential backoff.\"\"\"\n    for attempt in range(max_retries):\n        try:\n            response = func()\n\n            if response.status_code == 429:\n                # Check Retry-After header\n                retry_after = response.headers.get('Retry-After')\n\n                if retry_after:\n                    wait_time = int(retry_after)\n                else:\n                    # Exponential backoff: 2^attempt + random jitter\n                    wait_time = (2 ** attempt) + random.uniform(0, 1)\n\n                print(f\"Rate limited. Waiting {wait_time}s...\")\n                time.sleep(wait_time)\n                continue\n\n            return response\n\n        except Exception as e:\n            if attempt == max_retries - 1:\n                raise\n            time.sleep(2 ** attempt)\n\n    raise Exception(f\"Max retries ({max_retries}) exceeded\")\n\n# Usage\nresponse = exponential_backoff(\n    lambda: requests.get(api_url, params=params)\n)\n</code></pre></p> </li> <li> <p>Use token bucket algorithm: <pre><code>import threading\nimport time\n\nclass TokenBucket:\n    \"\"\"Token bucket rate limiter.\"\"\"\n\n    def __init__(self, rate, capacity):\n        \"\"\"\n        Args:\n            rate: Tokens added per second\n            capacity: Maximum tokens\n        \"\"\"\n        self.rate = rate\n        self.capacity = capacity\n        self.tokens = capacity\n        self.last_update = time.time()\n        self.lock = threading.Lock()\n\n    def consume(self, tokens=1):\n        \"\"\"Consume tokens, waiting if necessary.\"\"\"\n        with self.lock:\n            # Refill tokens\n            now = time.time()\n            elapsed = now - self.last_update\n            self.tokens = min(\n                self.capacity,\n                self.tokens + elapsed * self.rate\n            )\n            self.last_update = now\n\n            # Wait if not enough tokens\n            if self.tokens &lt; tokens:\n                wait_time = (tokens - self.tokens) / self.rate\n                time.sleep(wait_time)\n                self.tokens = 0\n            else:\n                self.tokens -= tokens\n\n            return True\n\n# Usage\nlimiter = TokenBucket(rate=10, capacity=20)  # 10 requests/sec\n\ndef make_api_call():\n    limiter.consume()\n    return requests.get(api_url)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/api-errors/#500-internal-server-error","title":"500 Internal Server Error","text":"<p>Meaning: Server encountered an unexpected condition.</p> <p>Common Causes: - Server-side bug - Database issues - Timeout on server - Invalid data causing crash</p> <p>Example Error: <pre><code>500 Internal Server Error: {\"error\": \"Internal server error\"}\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Retry with backoff: <pre><code>def retry_on_server_error(func, max_retries=3):\n    \"\"\"Retry on 5xx errors.\"\"\"\n    for attempt in range(max_retries):\n        try:\n            response = func()\n\n            if 500 &lt;= response.status_code &lt; 600:\n                print(f\"Server error (attempt {attempt + 1}/{max_retries})\")\n                time.sleep(2 ** attempt)\n                continue\n\n            return response\n\n        except Exception as e:\n            if attempt == max_retries - 1:\n                raise\n            time.sleep(2 ** attempt)\n\n    return None\n</code></pre></p> </li> <li> <p>Validate input data: <pre><code>def sanitize_input(text):\n    \"\"\"Clean input to prevent server errors.\"\"\"\n    # Remove null bytes\n    text = text.replace('\\x00', '')\n\n    # Limit length\n    max_length = 10000\n    if len(text) &gt; max_length:\n        text = text[:max_length]\n\n    # Remove invalid unicode\n    text = text.encode('utf-8', 'ignore').decode('utf-8')\n\n    return text\n\n# Use before API calls\ncleaned_text = sanitize_input(user_input)\nresponse = api_call(cleaned_text)\n</code></pre></p> </li> <li> <p>Log errors for debugging: <pre><code>import logging\n\nlogging.basicConfig(level=logging.ERROR)\n\ndef call_api_with_logging(url, data):\n    \"\"\"Call API with comprehensive logging.\"\"\"\n    try:\n        response = requests.post(url, json=data)\n\n        if response.status_code == 500:\n            logging.error(f\"Server error for URL: {url}\")\n            logging.error(f\"Request data: {data}\")\n            logging.error(f\"Response: {response.text}\")\n\n        return response\n\n    except Exception as e:\n        logging.error(f\"Exception calling {url}: {e}\")\n        raise\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/api-errors/#503-service-unavailable","title":"503 Service Unavailable","text":"<p>Meaning: Server is temporarily unable to handle the request.</p> <p>Common Causes: - Server maintenance - Overloaded server - Temporary outage - Dependency failure</p> <p>Solutions:</p> <ol> <li> <p>Implement circuit breaker: <pre><code>import time\n\nclass CircuitBreaker:\n    \"\"\"Circuit breaker pattern for API calls.\"\"\"\n\n    def __init__(self, failure_threshold=5, timeout=60):\n        self.failure_threshold = failure_threshold\n        self.timeout = timeout\n        self.failures = 0\n        self.last_failure_time = None\n        self.state = 'closed'  # closed, open, half_open\n\n    def call(self, func):\n        \"\"\"Execute function with circuit breaker.\"\"\"\n        if self.state == 'open':\n            if time.time() - self.last_failure_time &gt; self.timeout:\n                self.state = 'half_open'\n            else:\n                raise Exception(\"Circuit breaker is open\")\n\n        try:\n            result = func()\n\n            if self.state == 'half_open':\n                self.state = 'closed'\n                self.failures = 0\n\n            return result\n\n        except Exception as e:\n            self.failures += 1\n            self.last_failure_time = time.time()\n\n            if self.failures &gt;= self.failure_threshold:\n                self.state = 'open'\n\n            raise\n\n# Usage\nbreaker = CircuitBreaker(failure_threshold=3, timeout=60)\n\ndef make_api_call():\n    try:\n        return breaker.call(lambda: requests.get(api_url))\n    except Exception as e:\n        print(f\"Circuit breaker error: {e}\")\n        return None\n</code></pre></p> </li> <li> <p>Check service status: <pre><code>def check_service_health(base_url):\n    \"\"\"Check if service is available.\"\"\"\n    health_endpoint = f\"{base_url}/health\"\n\n    try:\n        response = requests.get(health_endpoint, timeout=5)\n        return response.status_code == 200\n    except:\n        return False\n\n# Use before making requests\nif not check_service_health(api_base_url):\n    print(\"Service is unavailable. Waiting...\")\n    time.sleep(30)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/api-errors/#request-validation-errors","title":"Request Validation Errors","text":""},{"location":"troubleshooting/api-errors/#invalid-json-format","title":"Invalid JSON Format","text":"<p>Problem: Request body is not valid JSON.</p> <p>Solutions:</p> <pre><code>import json\n\ndef safe_json_request(url, data):\n    \"\"\"Make JSON request with validation.\"\"\"\n    try:\n        # Validate JSON before sending\n        json_data = json.dumps(data)\n        json.loads(json_data)  # Verify it's valid\n\n        response = requests.post(\n            url,\n            headers={'Content-Type': 'application/json'},\n            data=json_data\n        )\n\n        return response\n\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON: {e}\")\n        return None\n</code></pre>"},{"location":"troubleshooting/api-errors/#missing-required-fields","title":"Missing Required Fields","text":"<p>Problem: Required parameters not provided.</p> <p>Solutions:</p> <pre><code>from typing import Dict, List\n\ndef validate_required_fields(data: Dict, required: List[str]):\n    \"\"\"Validate required fields in request.\"\"\"\n    missing = [field for field in required if field not in data]\n\n    if missing:\n        raise ValueError(f\"Missing required fields: {', '.join(missing)}\")\n\n    return True\n\n# Usage\nrequest_data = {\n    'query': 'machine learning',\n    'max_results': 10\n}\n\nrequired_fields = ['query', 'max_results']\n\ntry:\n    validate_required_fields(request_data, required_fields)\n    response = requests.post(api_url, json=request_data)\nexcept ValueError as e:\n    print(f\"Validation error: {e}\")\n</code></pre>"},{"location":"troubleshooting/api-errors/#invalid-parameter-types","title":"Invalid Parameter Types","text":"<p>Problem: Parameters have wrong data types.</p> <p>Solutions:</p> <pre><code>from typing import Any, Dict, Type\n\ndef validate_types(data: Dict[str, Any], schema: Dict[str, Type]):\n    \"\"\"Validate parameter types.\"\"\"\n    for field, expected_type in schema.items():\n        if field in data:\n            if not isinstance(data[field], expected_type):\n                raise TypeError(\n                    f\"Field '{field}' must be {expected_type.__name__}, \"\n                    f\"got {type(data[field]).__name__}\"\n                )\n\n    return True\n\n# Usage\nschema = {\n    'query': str,\n    'max_results': int,\n    'include_abstract': bool\n}\n\ntry:\n    validate_types(request_data, schema)\n    response = requests.post(api_url, json=request_data)\nexcept TypeError as e:\n    print(f\"Type error: {e}\")\n</code></pre>"},{"location":"troubleshooting/api-errors/#api-specific-issues","title":"API-Specific Issues","text":""},{"location":"troubleshooting/api-errors/#gemini-api","title":"Gemini API","text":"<p>Common Errors:</p> <ol> <li> <p>Safety settings blocking: <pre><code>import google.generativeai as genai\n\n# Configure safety settings\nsafety_settings = [\n    {\n        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n    },\n    {\n        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n    }\n]\n\nmodel = genai.GenerativeModel(\n    'gemini-pro',\n    safety_settings=safety_settings\n)\n\ntry:\n    response = model.generate_content(prompt)\nexcept Exception as e:\n    if \"safety\" in str(e).lower():\n        print(\"Content blocked by safety filters\")\n        print(\"Try rephrasing or adjusting safety settings\")\n</code></pre></p> </li> <li> <p>Token limit exceeded: <pre><code>def truncate_prompt(prompt, max_tokens=30000):\n    \"\"\"Truncate prompt to fit token limit.\"\"\"\n    # Rough estimate: 1 token \u2248 4 characters\n    max_chars = max_tokens * 4\n\n    if len(prompt) &gt; max_chars:\n        prompt = prompt[:max_chars]\n        print(f\"Prompt truncated to {max_tokens} tokens\")\n\n    return prompt\n\n# Usage\nsafe_prompt = truncate_prompt(long_prompt)\nresponse = model.generate_content(safe_prompt)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/api-errors/#arxiv-api","title":"ArXiv API","text":"<p>Common Errors:</p> <ol> <li> <p>Malformed query: <pre><code>def build_arxiv_query(search_terms, category=None):\n    \"\"\"Build valid ArXiv query.\"\"\"\n    # Escape special characters\n    search_terms = search_terms.replace('\"', '\\\\\"')\n\n    # Build query\n    query_parts = [f'all:{search_terms}']\n\n    if category:\n        query_parts.append(f'cat:{category}')\n\n    return ' AND '.join(query_parts)\n\n# Usage\nquery = build_arxiv_query(\"machine learning\", category=\"cs.LG\")\n</code></pre></p> </li> <li> <p>Empty results: <pre><code>import arxiv\n\ndef search_arxiv_with_fallback(query, max_results=10):\n    \"\"\"Search ArXiv with fallback to broader query.\"\"\"\n    search = arxiv.Search(\n        query=query,\n        max_results=max_results,\n        sort_by=arxiv.SortCriterion.Relevance\n    )\n\n    results = list(search.results())\n\n    if not results:\n        # Try broader query\n        broader_query = query.split()[0]  # Use first word only\n        search = arxiv.Search(\n            query=broader_query,\n            max_results=max_results\n        )\n        results = list(search.results())\n\n    return results\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/api-errors/#youtube-api","title":"YouTube API","text":"<p>Common Errors:</p> <ol> <li>Transcript not available: <pre><code>from youtube_transcript_api import YouTubeTranscriptApi\nfrom youtube_transcript_api._errors import (\n    NoTranscriptFound,\n    TranscriptsDisabled\n)\n\ndef get_transcript_safe(video_id):\n    \"\"\"Get transcript with error handling.\"\"\"\n    try:\n        # Try to get transcript\n        transcript = YouTubeTranscriptApi.get_transcript(video_id)\n        return transcript\n\n    except NoTranscriptFound:\n        # Try auto-generated captions\n        try:\n            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)\n            transcript = transcript_list.find_generated_transcript(['en'])\n            return transcript.fetch()\n        except:\n            print(f\"No transcript available for {video_id}\")\n            return None\n\n    except TranscriptsDisabled:\n        print(f\"Transcripts disabled for {video_id}\")\n        return None\n</code></pre></li> </ol>"},{"location":"troubleshooting/api-errors/#error-handling-best-practices","title":"Error Handling Best Practices","text":""},{"location":"troubleshooting/api-errors/#comprehensive-error-handler","title":"Comprehensive Error Handler","text":"<pre><code>import requests\nfrom requests.exceptions import (\n    Timeout,\n    ConnectionError,\n    HTTPError,\n    RequestException\n)\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\n\ndef robust_api_call(url, method='GET', **kwargs):\n    \"\"\"Make API call with comprehensive error handling.\"\"\"\n    max_retries = 3\n    timeout = kwargs.get('timeout', 30)\n\n    for attempt in range(max_retries):\n        try:\n            # Make request\n            if method == 'GET':\n                response = requests.get(url, timeout=timeout, **kwargs)\n            elif method == 'POST':\n                response = requests.post(url, timeout=timeout, **kwargs)\n            else:\n                raise ValueError(f\"Unsupported method: {method}\")\n\n            # Check status code\n            if response.status_code == 200:\n                return response\n\n            elif response.status_code == 400:\n                logging.error(f\"Bad request: {response.text}\")\n                return None\n\n            elif response.status_code == 401:\n                logging.error(\"Authentication failed\")\n                return None\n\n            elif response.status_code == 403:\n                logging.error(\"Access forbidden\")\n                return None\n\n            elif response.status_code == 404:\n                logging.error(f\"Resource not found: {url}\")\n                return None\n\n            elif response.status_code == 429:\n                wait_time = int(response.headers.get('Retry-After', 60))\n                logging.warning(f\"Rate limited. Waiting {wait_time}s...\")\n                time.sleep(wait_time)\n                continue\n\n            elif 500 &lt;= response.status_code &lt; 600:\n                logging.error(f\"Server error: {response.status_code}\")\n                if attempt &lt; max_retries - 1:\n                    time.sleep(2 ** attempt)\n                    continue\n                return None\n\n            else:\n                logging.error(f\"Unexpected status: {response.status_code}\")\n                return None\n\n        except Timeout:\n            logging.error(f\"Request timeout (attempt {attempt + 1}/{max_retries})\")\n            if attempt &lt; max_retries - 1:\n                time.sleep(2 ** attempt)\n                continue\n            return None\n\n        except ConnectionError:\n            logging.error(f\"Connection error (attempt {attempt + 1}/{max_retries})\")\n            if attempt &lt; max_retries - 1:\n                time.sleep(2 ** attempt)\n                continue\n            return None\n\n        except RequestException as e:\n            logging.error(f\"Request exception: {e}\")\n            return None\n\n    return None\n\n# Usage\nresponse = robust_api_call(\n    'https://api.example.com/data',\n    method='GET',\n    params={'query': 'test'},\n    timeout=30\n)\n\nif response:\n    data = response.json()\nelse:\n    print(\"API call failed after retries\")\n</code></pre>"},{"location":"troubleshooting/api-errors/#additional-resources","title":"Additional Resources","text":"<ul> <li>Common Issues</li> <li>OpenSearch Troubleshooting</li> <li>FAQ</li> <li>Performance Optimization</li> </ul>"},{"location":"troubleshooting/common-issues/","title":"Common Issues and Solutions","text":"<p>This guide covers the most frequently encountered issues when using the Multi-Modal Academic Research System.</p>"},{"location":"troubleshooting/common-issues/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation Issues</li> <li>Runtime Errors</li> <li>Data Collection Failures</li> <li>Search Problems</li> <li>UI Issues</li> <li>Configuration Issues</li> <li>Performance Issues</li> </ul>"},{"location":"troubleshooting/common-issues/#installation-issues","title":"Installation Issues","text":""},{"location":"troubleshooting/common-issues/#1-pip-install-fails-with-dependency-conflicts","title":"1. pip install fails with dependency conflicts","text":"<p>Problem: Installation fails with messages about incompatible package versions.</p> <p>Cause: Conflicting dependencies between packages or outdated pip.</p> <p>Solution: <pre><code># Update pip first\npip install --upgrade pip\n\n# Install with --upgrade flag\npip install --upgrade -r requirements.txt\n\n# If still failing, use a clean virtual environment\ndeactivate\nrm -rf venv\npython -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre></p> <p>Prevention: Always use a virtual environment and keep pip updated.</p>"},{"location":"troubleshooting/common-issues/#2-modulenotfounderror-after-installation","title":"2. ModuleNotFoundError after installation","text":"<p>Problem: <code>ModuleNotFoundError: No module named 'opensearchpy'</code> or similar.</p> <p>Cause: Virtual environment not activated or installation incomplete.</p> <p>Solution: <pre><code># Ensure venv is activated (you should see (venv) in prompt)\nsource venv/bin/activate  # Mac/Linux\n# or\nvenv\\Scripts\\activate  # Windows\n\n# Verify installation\npip list | grep opensearch\n\n# Reinstall if needed\npip install opensearch-py\n</code></pre></p> <p>Prevention: Always activate virtual environment before running the application.</p>"},{"location":"troubleshooting/common-issues/#3-python-version-compatibility-issues","title":"3. Python version compatibility issues","text":"<p>Problem: Syntax errors or import failures related to Python version.</p> <p>Cause: Using Python &lt; 3.8 (minimum required version).</p> <p>Solution: <pre><code># Check Python version\npython --version\n\n# Use Python 3.8+ to create virtual environment\npython3.10 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n</code></pre></p> <p>Prevention: Ensure Python 3.8 or higher is installed before starting.</p>"},{"location":"troubleshooting/common-issues/#4-ssl-certificate-verification-failed","title":"4. SSL certificate verification failed","text":"<p>Problem: <code>SSLError: [SSL: CERTIFICATE_VERIFY_FAILED]</code> during package installation.</p> <p>Cause: Corporate proxy or network security blocking SSL connections.</p> <p>Solution: <pre><code># Option 1: Update certificates (recommended)\npip install --upgrade certifi\n\n# Option 2: Use trusted host (less secure)\npip install --trusted-host pypi.org --trusted-host files.pythonhosted.org -r requirements.txt\n</code></pre></p> <p>Prevention: Ensure your network allows HTTPS connections to PyPI.</p>"},{"location":"troubleshooting/common-issues/#runtime-errors","title":"Runtime Errors","text":""},{"location":"troubleshooting/common-issues/#5-gemini-api-key-not-found-or-invalid","title":"5. Gemini API key not found or invalid","text":"<p>Problem: <code>Error: GEMINI_API_KEY not found in environment</code> or 401 Unauthorized.</p> <p>Cause: Missing or incorrect API key in <code>.env</code> file.</p> <p>Solution: <pre><code># Create .env file from example\ncp .env.example .env\n\n# Edit .env and add your key\n# GEMINI_API_KEY=your_actual_api_key_here\n\n# Get API key from: https://makersuite.google.com/app/apikey\n</code></pre></p> <p>Prevention: Verify API key validity by testing in Google AI Studio first.</p>"},{"location":"troubleshooting/common-issues/#6-opensearch-connection-refused","title":"6. OpenSearch connection refused","text":"<p>Problem: <code>ConnectionError: Connection to OpenSearch failed</code> or similar.</p> <p>Cause: OpenSearch service not running or wrong host/port.</p> <p>Solution: <pre><code># Check if OpenSearch is running\ncurl http://localhost:9200\n\n# If not running, start Docker container\ndocker run -p 9200:9200 -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"DISABLE_SECURITY_PLUGIN=true\" \\\n  opensearchproject/opensearch:latest\n\n# Verify connection\ncurl http://localhost:9200/_cluster/health\n</code></pre></p> <p>Prevention: Start OpenSearch before running the application.</p>"},{"location":"troubleshooting/common-issues/#7-out-of-memory-errors","title":"7. Out of memory errors","text":"<p>Problem: <code>MemoryError</code> or process killed during processing.</p> <p>Cause: Processing large PDFs or too many documents simultaneously.</p> <p>Solution: <pre><code># Reduce batch size in opensearch_manager.py\n# Change from:\nbulk_data = []  # Process all at once\n\n# To:\nBATCH_SIZE = 100\nfor i in range(0, len(documents), BATCH_SIZE):\n    batch = documents[i:i+BATCH_SIZE]\n    # Process batch\n</code></pre></p> <p>Prevention: Process documents in smaller batches, increase system memory.</p>"},{"location":"troubleshooting/common-issues/#8-rate-limiting-from-external-apis","title":"8. Rate limiting from external APIs","text":"<p>Problem: <code>HTTP 429: Too Many Requests</code> from ArXiv, YouTube, etc.</p> <p>Cause: Sending too many requests too quickly.</p> <p>Solution: <pre><code># Add delays between requests in collectors\nimport time\n\nfor query in queries:\n    results = fetch_data(query)\n    time.sleep(3)  # Wait 3 seconds between requests\n</code></pre></p> <p>Prevention: Implement exponential backoff and respect API rate limits.</p>"},{"location":"troubleshooting/common-issues/#9-encoding-errors-when-processing-pdfs","title":"9. Encoding errors when processing PDFs","text":"<p>Problem: <code>UnicodeDecodeError</code> or garbled text from PDFs.</p> <p>Cause: PDFs with non-standard encoding or scanned images.</p> <p>Solution: <pre><code># In pdf_processor.py, handle encoding errors gracefully\ntry:\n    text = page.get_text(encoding='utf-8')\nexcept UnicodeDecodeError:\n    text = page.get_text(encoding='utf-8', errors='ignore')\n\n# For scanned PDFs, consider OCR\nfrom pdf2image import convert_from_path\nimport pytesseract\n\nimages = convert_from_path(pdf_path)\ntext = pytesseract.image_to_string(images[0])\n</code></pre></p> <p>Prevention: Validate PDF quality before processing.</p>"},{"location":"troubleshooting/common-issues/#10-gradio-interface-wont-start","title":"10. Gradio interface won't start","text":"<p>Problem: <code>OSError: [Errno 48] Address already in use</code> or similar.</p> <p>Cause: Port 7860 already occupied by another process.</p> <p>Solution: <pre><code># Find process using port 7860\nlsof -i :7860\n\n# Kill the process\nkill -9 &lt;PID&gt;\n\n# Or use different port in main.py\ninterface.launch(server_port=7861, share=True)\n</code></pre></p> <p>Prevention: Check port availability before launching.</p>"},{"location":"troubleshooting/common-issues/#data-collection-failures","title":"Data Collection Failures","text":""},{"location":"troubleshooting/common-issues/#11-arxiv-queries-return-no-results","title":"11. ArXiv queries return no results","text":"<p>Problem: Searches return empty results or errors.</p> <p>Cause: Invalid query syntax or overly restrictive search terms.</p> <p>Solution: <pre><code># Use broader search terms\nquery = \"machine learning\"  # Instead of very specific terms\n\n# Check ArXiv query syntax\n# Valid: ti:\"neural networks\"\n# Invalid: title:neural networks (wrong field name)\n\n# Test query directly at https://arxiv.org/search/\n</code></pre></p> <p>Prevention: Start with broad queries and refine based on results.</p>"},{"location":"troubleshooting/common-issues/#12-youtube-transcript-not-available","title":"12. YouTube transcript not available","text":"<p>Problem: <code>NoTranscriptFound</code> or <code>TranscriptsDisabled</code> error.</p> <p>Cause: Video doesn't have captions or they're disabled.</p> <p>Solution: <pre><code># Add error handling in youtube_collector.py\nfrom youtube_transcript_api._errors import NoTranscriptFound\n\ntry:\n    transcript = YouTubeTranscriptApi.get_transcript(video_id)\nexcept NoTranscriptFound:\n    print(f\"No transcript for {video_id}, skipping...\")\n    continue\n</code></pre></p> <p>Prevention: Filter for videos with available transcripts.</p>"},{"location":"troubleshooting/common-issues/#13-pdf-download-fails","title":"13. PDF download fails","text":"<p>Problem: PDFs fail to download from ArXiv or other sources.</p> <p>Cause: Network issues, invalid URLs, or access restrictions.</p> <p>Solution: <pre><code># Add retry logic with exponential backoff\nimport requests\nfrom requests.adapters import HTTPAdapter\nfrom urllib3.util.retry import Retry\n\nsession = requests.Session()\nretry = Retry(total=3, backoff_factor=1)\nadapter = HTTPAdapter(max_retries=retry)\nsession.mount('http://', adapter)\nsession.mount('https://', adapter)\n\nresponse = session.get(pdf_url, timeout=30)\n</code></pre></p> <p>Prevention: Implement robust error handling and retry mechanisms.</p>"},{"location":"troubleshooting/common-issues/#14-podcast-rss-feed-parsing-errors","title":"14. Podcast RSS feed parsing errors","text":"<p>Problem: <code>XMLSyntaxError</code> or malformed feed errors.</p> <p>Cause: Invalid or non-standard RSS feed format.</p> <p>Solution: <pre><code># Use feedparser which is more forgiving\nimport feedparser\n\nfeed = feedparser.parse(rss_url)\nif feed.bozo:  # Indicates malformed feed\n    print(f\"Warning: Malformed feed {rss_url}\")\n    # Still try to extract data\n    entries = feed.entries\n</code></pre></p> <p>Prevention: Validate RSS URLs before processing.</p>"},{"location":"troubleshooting/common-issues/#15-semantic-scholar-api-timeouts","title":"15. Semantic Scholar API timeouts","text":"<p>Problem: Requests to Semantic Scholar timeout or fail.</p> <p>Cause: API server issues or network latency.</p> <p>Solution: <pre><code># Increase timeout and add retry logic\nimport requests\n\ntry:\n    response = requests.get(\n        api_url,\n        timeout=60,  # Increase from default\n        headers={'User-Agent': 'YourApp/1.0'}\n    )\n    response.raise_for_status()\nexcept requests.Timeout:\n    print(\"Request timed out, retrying...\")\n    time.sleep(5)\n    response = requests.get(api_url, timeout=90)\n</code></pre></p> <p>Prevention: Monitor API status at https://api.semanticscholar.org/</p>"},{"location":"troubleshooting/common-issues/#search-problems","title":"Search Problems","text":""},{"location":"troubleshooting/common-issues/#16-search-returns-no-results","title":"16. Search returns no results","text":"<p>Problem: Queries return empty results even though documents are indexed.</p> <p>Cause: Mismatch between query terms and indexed content, or index not created.</p> <p>Solution: <pre><code># Check if index exists and has documents\ncurl http://localhost:9200/research_assistant/_count\n\n# Check index mapping\ncurl http://localhost:9200/research_assistant/_mapping\n\n# Try broader query\n# Instead of: \"specific technical term\"\n# Try: \"general concept\"\n</code></pre></p> <p>Prevention: Verify indexing completed successfully before querying.</p>"},{"location":"troubleshooting/common-issues/#17-search-results-are-irrelevant","title":"17. Search results are irrelevant","text":"<p>Problem: Results don't match query intent or are poorly ranked.</p> <p>Cause: Incorrect field weights or hybrid search configuration.</p> <p>Solution: <pre><code># Adjust field weights in opensearch_manager.py\nquery = {\n    \"query\": {\n        \"multi_match\": {\n            \"query\": query_text,\n            \"fields\": [\n                \"title^3\",      # Increase title weight\n                \"abstract^2\",   # Increase abstract weight\n                \"content^1\",\n                \"key_concepts^2\"\n            ]\n        }\n    }\n}\n</code></pre></p> <p>Prevention: Test with various queries and tune weights accordingly.</p>"},{"location":"troubleshooting/common-issues/#18-embeddings-generation-is-slow","title":"18. Embeddings generation is slow","text":"<p>Problem: Generating embeddings takes too long during indexing.</p> <p>Cause: Processing on CPU instead of GPU or large batch size.</p> <p>Solution: <pre><code># Use GPU if available\nfrom sentence_transformers import SentenceTransformer\n\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\nif torch.cuda.is_available():\n    model = model.to('cuda')\n\n# Process in smaller batches\nembeddings = model.encode(\n    texts,\n    batch_size=32,  # Reduce if memory issues\n    show_progress_bar=True\n)\n</code></pre></p> <p>Prevention: Use GPU-enabled environment for large-scale indexing.</p>"},{"location":"troubleshooting/common-issues/#19-knn-search-fails-or-returns-errors","title":"19. kNN search fails or returns errors","text":"<p>Problem: Vector search errors like <code>invalid knn query</code> or no results.</p> <p>Cause: Index not configured for kNN or embedding dimension mismatch.</p> <p>Solution: <pre><code># Verify index has kNN settings\ncurl http://localhost:9200/research_assistant/_settings\n\n# Recreate index with correct kNN configuration\nindex_settings = {\n    \"settings\": {\n        \"index\": {\n            \"knn\": True,\n            \"knn.space_type\": \"cosinesimil\"\n        }\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"embedding\": {\n                \"type\": \"knn_vector\",\n                \"dimension\": 384  # Must match model output\n            }\n        }\n    }\n}\n</code></pre></p> <p>Prevention: Ensure index created with correct kNN settings before indexing.</p>"},{"location":"troubleshooting/common-issues/#20-search-performance-degrades-over-time","title":"20. Search performance degrades over time","text":"<p>Problem: Queries become slower as more documents are added.</p> <p>Cause: Index fragmentation or insufficient resources.</p> <p>Solution: <pre><code># Force merge index to reduce segments\ncurl -X POST \"localhost:9200/research_assistant/_forcemerge?max_num_segments=1\"\n\n# Increase OpenSearch memory\ndocker run -p 9200:9200 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g\" \\\n  opensearchproject/opensearch:latest\n</code></pre></p> <p>Prevention: Regular index maintenance and monitoring.</p>"},{"location":"troubleshooting/common-issues/#ui-issues","title":"UI Issues","text":""},{"location":"troubleshooting/common-issues/#21-gradio-interface-is-unresponsive","title":"21. Gradio interface is unresponsive","text":"<p>Problem: UI freezes or buttons don't respond.</p> <p>Cause: Long-running operations blocking the UI thread.</p> <p>Solution: <pre><code># Use async functions for long operations\nasync def query_system(query_text):\n    results = await asyncio.to_thread(\n        orchestrator.process_query, query_text\n    )\n    return results\n\n# Or use Gradio's queue\ninterface.queue().launch()\n</code></pre></p> <p>Prevention: Keep UI operations non-blocking.</p>"},{"location":"troubleshooting/common-issues/#22-share-link-not-working","title":"22. Share link not working","text":"<p>Problem: Public share URL doesn't open or shows errors.</p> <p>Cause: Network restrictions or Gradio service issues.</p> <p>Solution: <pre><code># Try without share link first\ninterface.launch(share=False, server_port=7860)\n\n# Access locally at http://localhost:7860\n\n# If share needed, check firewall settings\n# or use alternative like ngrok\n</code></pre></p> <p>Prevention: Test local access first before using share links.</p>"},{"location":"troubleshooting/common-issues/#23-citation-manager-not-updating","title":"23. Citation manager not updating","text":"<p>Problem: Citations don't appear in the manager tab.</p> <p>Cause: Citation extraction regex not matching response format.</p> <p>Solution: <pre><code># Update citation patterns in citation_tracker.py\ncitation_patterns = [\n    r'\\[(\\d+)\\]',           # [1], [2], etc.\n    r'\\((\\d+)\\)',           # (1), (2), etc.\n    r'\\[([A-Za-z]+\\d+)\\]',  # [Smith2023], etc.\n]\n\n# Test extraction\nimport re\ntext = \"According to [1], machine learning...\"\nmatches = re.findall(r'\\[(\\d+)\\]', text)\nprint(matches)  # Should print ['1']\n</code></pre></p> <p>Prevention: Standardize citation format in prompts.</p>"},{"location":"troubleshooting/common-issues/#24-file-upload-fails-in-ui","title":"24. File upload fails in UI","text":"<p>Problem: Cannot upload PDFs or other files through Gradio interface.</p> <p>Cause: File size limits or incorrect file type handling.</p> <p>Solution: <pre><code># Increase file size limit\ngr.File(\n    file_count=\"single\",\n    file_types=[\".pdf\"],\n    max_size=50_000_000  # 50MB limit\n)\n\n# Handle upload errors gracefully\ndef handle_upload(file):\n    if file is None:\n        return \"No file uploaded\"\n    try:\n        process_file(file.name)\n        return \"Success\"\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n</code></pre></p> <p>Prevention: Validate file before processing.</p>"},{"location":"troubleshooting/common-issues/#configuration-issues","title":"Configuration Issues","text":""},{"location":"troubleshooting/common-issues/#25-environment-variables-not-loading","title":"25. Environment variables not loading","text":"<p>Problem: Application can't read values from <code>.env</code> file.</p> <p>Cause: <code>.env</code> file not in correct location or wrong format.</p> <p>Solution: <pre><code># Ensure .env is in project root\nls -la .env\n\n# Check file format (no spaces around =)\n# Correct: GEMINI_API_KEY=abc123\n# Wrong:   GEMINI_API_KEY = abc123\n\n# Load manually if needed\npython -c \"from dotenv import load_dotenv; load_dotenv(); import os; print(os.getenv('GEMINI_API_KEY'))\"\n</code></pre></p> <p>Prevention: Use <code>.env.example</code> as template.</p>"},{"location":"troubleshooting/common-issues/#26-opensearch-hostport-configuration-ignored","title":"26. OpenSearch host/port configuration ignored","text":"<p>Problem: Application connects to wrong OpenSearch instance.</p> <p>Cause: Hardcoded values overriding configuration.</p> <p>Solution: <pre><code># In opensearch_manager.py, ensure env vars are used\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nhost = os.getenv('OPENSEARCH_HOST', 'localhost')\nport = int(os.getenv('OPENSEARCH_PORT', 9200))\n\nclient = OpenSearch(\n    hosts=[{'host': host, 'port': port}],\n    http_compress=True,\n    use_ssl=False\n)\n</code></pre></p> <p>Prevention: Always use environment variables for configuration.</p>"},{"location":"troubleshooting/common-issues/#performance-issues","title":"Performance Issues","text":""},{"location":"troubleshooting/common-issues/#27-slow-query-responses","title":"27. Slow query responses","text":"<p>Problem: Queries take 30+ seconds to complete.</p> <p>Cause: Large result sets, complex queries, or unoptimized retrieval.</p> <p>Solution: <pre><code># Limit result size\nresults = opensearch.search(\n    index='research_assistant',\n    body=query,\n    size=10  # Reduce from default 100\n)\n\n# Use pagination for large result sets\n# Add timeout to prevent hanging\nresults = opensearch.search(\n    body=query,\n    request_timeout=30\n)\n</code></pre></p> <p>Prevention: Optimize queries and use appropriate result limits.</p>"},{"location":"troubleshooting/common-issues/#28-high-memory-usage-during-indexing","title":"28. High memory usage during indexing","text":"<p>Problem: Application consumes excessive memory when indexing.</p> <p>Cause: Loading all documents into memory at once.</p> <p>Solution: <pre><code># Process documents in batches\ndef index_documents_batch(documents, batch_size=50):\n    for i in range(0, len(documents), batch_size):\n        batch = documents[i:i+batch_size]\n        index_batch(batch)\n        # Force garbage collection\n        import gc\n        gc.collect()\n</code></pre></p> <p>Prevention: Stream processing instead of batch loading.</p>"},{"location":"troubleshooting/common-issues/#29-gemini-api-quota-exceeded","title":"29. Gemini API quota exceeded","text":"<p>Problem: <code>QuotaExceeded</code> or <code>ResourceExhausted</code> errors from Gemini.</p> <p>Cause: Exceeding free tier limits (60 requests per minute).</p> <p>Solution: <pre><code># Add rate limiting\nimport time\nfrom functools import wraps\n\ndef rate_limit(calls_per_minute=60):\n    min_interval = 60.0 / calls_per_minute\n    last_called = [0.0]\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            elapsed = time.time() - last_called[0]\n            wait = min_interval - elapsed\n            if wait &gt; 0:\n                time.sleep(wait)\n            result = func(*args, **kwargs)\n            last_called[0] = time.time()\n            return result\n        return wrapper\n    return decorator\n\n@rate_limit(calls_per_minute=50)\ndef call_gemini(prompt):\n    return model.generate_content(prompt)\n</code></pre></p> <p>Prevention: Monitor API usage in Google Cloud Console.</p>"},{"location":"troubleshooting/common-issues/#30-docker-container-crashes","title":"30. Docker container crashes","text":"<p>Problem: OpenSearch Docker container stops unexpectedly.</p> <p>Cause: Insufficient memory allocation or disk space.</p> <p>Solution: <pre><code># Increase memory limits\ndocker run -p 9200:9200 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g\" \\\n  --memory=2g \\\n  opensearchproject/opensearch:latest\n\n# Check container logs\ndocker logs &lt;container_id&gt;\n\n# Clean up disk space\ndocker system prune -a\n</code></pre></p> <p>Prevention: Monitor container resource usage with <code>docker stats</code>.</p>"},{"location":"troubleshooting/common-issues/#additional-resources","title":"Additional Resources","text":"<ul> <li>OpenSearch Troubleshooting</li> <li>API Error Guide</li> <li>FAQ</li> <li>Performance Optimization</li> </ul>"},{"location":"troubleshooting/common-issues/#getting-help","title":"Getting Help","text":"<p>If you encounter an issue not covered here:</p> <ol> <li>Check the FAQ</li> <li>Review application logs in <code>logs/</code> directory</li> <li>Enable debug logging: <code>logging.basicConfig(level=logging.DEBUG)</code></li> <li>Search existing GitHub issues</li> <li>Create a new issue with:</li> <li>Error message and full stack trace</li> <li>Steps to reproduce</li> <li>System information (OS, Python version, etc.)</li> <li>Relevant configuration (sanitized)</li> </ol>"},{"location":"troubleshooting/faq/","title":"Frequently Asked Questions (FAQ)","text":"<p>Common questions and answers about the Multi-Modal Academic Research System.</p>"},{"location":"troubleshooting/faq/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Installation &amp; Setup</li> <li>Configuration</li> <li>Data Collection</li> <li>Search &amp; Retrieval</li> <li>Performance</li> <li>Features &amp; Capabilities</li> <li>Troubleshooting</li> <li>Advanced Topics</li> </ul>"},{"location":"troubleshooting/faq/#installation-setup","title":"Installation &amp; Setup","text":""},{"location":"troubleshooting/faq/#q-what-are-the-system-requirements","title":"Q: What are the system requirements?","text":"<p>A: Minimum requirements: - Python: 3.8 or higher - RAM: 4GB minimum, 8GB recommended - Disk: 10GB free space (more for storing papers/videos) - Docker: For running OpenSearch - Internet: Required for API calls and data collection</p>"},{"location":"troubleshooting/faq/#q-do-i-need-to-pay-for-any-services","title":"Q: Do I need to pay for any services?","text":"<p>A: No, the system uses free services: - Gemini API: Free tier (60 requests/minute) - OpenSearch: Self-hosted locally (no cost) - ArXiv, YouTube, etc.: Free public APIs - Embedding model: Runs locally (no API costs)</p>"},{"location":"troubleshooting/faq/#q-can-i-run-this-without-docker","title":"Q: Can I run this without Docker?","text":"<p>A: Docker is required only for OpenSearch. Alternatives: 1. Install OpenSearch locally without Docker 2. Use Elasticsearch instead (similar API) 3. Connect to a remote OpenSearch instance</p> <p>However, Docker is the recommended and easiest method.</p>"},{"location":"troubleshooting/faq/#q-why-does-installation-take-so-long","title":"Q: Why does installation take so long?","text":"<p>A: Common reasons: - Large dependencies: PyTorch, transformers (can be 1-2GB) - Slow internet: Downloads from PyPI - Compiling packages: Some packages compile from source</p> <p>Speed up installation: <pre><code># Use binary wheels when available\npip install --only-binary=:all: -r requirements.txt\n\n# Or use conda for pre-compiled packages\nconda install pytorch sentence-transformers\n</code></pre></p>"},{"location":"troubleshooting/faq/#q-can-i-use-this-on-windows","title":"Q: Can I use this on Windows?","text":"<p>A: Yes, but with some considerations: - Use <code>venv\\Scripts\\activate</code> instead of <code>source venv/bin/activate</code> - Docker Desktop required for Windows - Path separators are different (<code>\\</code> vs <code>/</code>) - Some shell commands may differ</p> <p>Consider using WSL2 (Windows Subsystem for Linux) for better compatibility.</p>"},{"location":"troubleshooting/faq/#configuration","title":"Configuration","text":""},{"location":"troubleshooting/faq/#q-how-do-i-get-a-gemini-api-key","title":"Q: How do I get a Gemini API key?","text":"<p>A: Follow these steps: 1. Visit https://makersuite.google.com/app/apikey 2. Sign in with your Google account 3. Click \"Create API Key\" 4. Copy the key to your <code>.env</code> file:    <pre><code>GEMINI_API_KEY=your_key_here\n</code></pre></p>"},{"location":"troubleshooting/faq/#q-can-i-use-other-llms-instead-of-gemini","title":"Q: Can I use other LLMs instead of Gemini?","text":"<p>A: Yes, the system can be adapted for other LLMs: - OpenAI GPT: Modify <code>research_orchestrator.py</code> to use OpenAI API - Local LLMs: Use Ollama or LM Studio - Claude: Use Anthropic API - Open-source models: Use Hugging Face transformers</p> <p>See Advanced Topics for implementation details.</p>"},{"location":"troubleshooting/faq/#q-where-are-my-downloaded-papers-stored","title":"Q: Where are my downloaded papers stored?","text":"<p>A: Papers are stored in: - PDFs: <code>data/papers/</code> - Videos: <code>data/videos/</code> - Podcasts: <code>data/podcasts/</code> - Processed data: <code>data/processed/</code></p> <p>You can change locations in configuration files.</p>"},{"location":"troubleshooting/faq/#q-how-do-i-change-the-opensearch-port","title":"Q: How do I change the OpenSearch port?","text":"<p>A: Update your <code>.env</code> file: <pre><code>OPENSEARCH_HOST=localhost\nOPENSEARCH_PORT=9201  # Change from default 9200\n</code></pre></p> <p>Then start OpenSearch with the new port: <pre><code>docker run -p 9201:9200 opensearchproject/opensearch:latest\n</code></pre></p>"},{"location":"troubleshooting/faq/#q-can-i-use-a-remote-opensearch-instance","title":"Q: Can I use a remote OpenSearch instance?","text":"<p>A: Yes, update <code>.env</code>: <pre><code>OPENSEARCH_HOST=your-opensearch-host.com\nOPENSEARCH_PORT=9200\nOPENSEARCH_USE_SSL=true\nOPENSEARCH_USER=admin\nOPENSEARCH_PASSWORD=your_password\n</code></pre></p>"},{"location":"troubleshooting/faq/#data-collection","title":"Data Collection","text":""},{"location":"troubleshooting/faq/#q-what-data-sources-are-supported","title":"Q: What data sources are supported?","text":"<p>A: Current sources: - Papers: ArXiv, PubMed Central, Semantic Scholar - Videos: YouTube (educational channels) - Podcasts: RSS feeds</p> <p>See Custom Collectors to add more sources.</p>"},{"location":"troubleshooting/faq/#q-how-many-papers-can-i-collect-at-once","title":"Q: How many papers can I collect at once?","text":"<p>A: Limits: - ArXiv: 2000 per query (API limit) - Semantic Scholar: Rate-limited (100/minute) - YouTube: No hard limit, but respect rate limits - Local storage: Limited by disk space</p> <p>Recommended: Start with 10-50 papers for testing.</p>"},{"location":"troubleshooting/faq/#q-can-i-collect-papers-from-specific-journals","title":"Q: Can I collect papers from specific journals?","text":"<p>A: Partially: - ArXiv: Yes, filter by category (e.g., <code>cs.LG</code> for ML) - PubMed: Yes, filter by journal name - Semantic Scholar: Yes, use field filters</p> <p>Example ArXiv query: <pre><code>query = \"cat:cs.LG AND ti:neural networks\"\n</code></pre></p>"},{"location":"troubleshooting/faq/#q-how-do-i-collect-papers-published-in-a-specific-year","title":"Q: How do I collect papers published in a specific year?","text":"<p>A: Use date filters:</p> <pre><code># ArXiv\nquery = \"submittedDate:[20230101 TO 20231231] AND all:machine learning\"\n\n# In the UI, you can filter after collection\n# Or modify the collector to add date filters\n</code></pre>"},{"location":"troubleshooting/faq/#q-why-cant-i-download-some-papers","title":"Q: Why can't I download some papers?","text":"<p>A: Common reasons: - Access restrictions: Some papers require subscriptions - Invalid URLs: Paper may have been removed - Rate limiting: Too many requests too fast - Network issues: Firewall or proxy blocking</p> <p>The system focuses on open-access content (ArXiv, PMC).</p>"},{"location":"troubleshooting/faq/#q-can-i-import-my-own-pdfs","title":"Q: Can I import my own PDFs?","text":"<p>A: Yes, you can: 1. Place PDFs in <code>data/papers/</code> 2. Use the processing pipeline:    <pre><code>from multi_modal_rag.data_processors import pdf_processor\n\nprocessor = pdf_processor.PDFProcessor()\nresult = processor.process_pdf(\"path/to/paper.pdf\")\n</code></pre> 3. Index the processed content</p>"},{"location":"troubleshooting/faq/#q-how-do-i-collect-videos-from-specific-youtube-channels","title":"Q: How do I collect videos from specific YouTube channels?","text":"<p>A: Modify <code>youtube_collector.py</code>:</p> <pre><code>def collect_from_channel(channel_id, max_videos=50):\n    \"\"\"Collect videos from specific channel.\"\"\"\n    from googleapiclient.discovery import build\n\n    youtube = build('youtube', 'v3', developerKey=api_key)\n\n    request = youtube.search().list(\n        part='snippet',\n        channelId=channel_id,\n        maxResults=max_videos,\n        type='video'\n    )\n\n    response = request.execute()\n    return response['items']\n</code></pre>"},{"location":"troubleshooting/faq/#search-retrieval","title":"Search &amp; Retrieval","text":""},{"location":"troubleshooting/faq/#q-how-does-hybrid-search-work","title":"Q: How does hybrid search work?","text":"<p>A: Hybrid search combines: 1. Keyword search: BM25 algorithm (like traditional search) 2. Semantic search: Vector similarity using embeddings</p> <p>Results from both are combined and ranked. See Hybrid Search Guide for details.</p>"},{"location":"troubleshooting/faq/#q-why-are-my-search-results-not-relevant","title":"Q: Why are my search results not relevant?","text":"<p>A: Possible causes: - Mismatch between query and content: Try different keywords - Not enough indexed content: Add more documents - Poor field weights: Adjust in <code>opensearch_manager.py</code> - Wrong search mode: Try semantic-only or keyword-only</p> <p>Tips: - Use specific technical terms - Try multiple phrasings - Check if documents are actually indexed</p>"},{"location":"troubleshooting/faq/#q-how-many-documents-should-i-index-for-good-results","title":"Q: How many documents should I index for good results?","text":"<p>A: Recommendations: - Minimum: 10-20 papers for basic testing - Good: 100-200 papers for decent coverage - Excellent: 500+ papers for comprehensive results</p> <p>More documents = better context, but slower indexing.</p>"},{"location":"troubleshooting/faq/#q-can-i-search-only-specific-content-types","title":"Q: Can I search only specific content types?","text":"<p>A: Yes, filter by content type:</p> <pre><code>query = {\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\"match\": {\"content\": \"machine learning\"}}\n            ],\n            \"filter\": [\n                {\"term\": {\"content_type\": \"paper\"}}  # or \"video\", \"podcast\"\n            ]\n        }\n    }\n}\n</code></pre> <p>Or use the UI filters (if implemented).</p>"},{"location":"troubleshooting/faq/#q-how-do-i-improve-search-speed","title":"Q: How do I improve search speed?","text":"<p>A: Optimization strategies: 1. Reduce result size: Return fewer documents 2. Use filters: Pre-filter before searching 3. Optimize OpenSearch: Increase memory, reduce shards 4. Cache results: Cache common queries 5. Use pagination: Don't load all results at once</p> <p>See Performance Guide for details.</p>"},{"location":"troubleshooting/faq/#q-can-i-search-by-author-name","title":"Q: Can I search by author name?","text":"<p>A: Yes:</p> <pre><code>query = {\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\"match\": {\"content\": \"neural networks\"}}\n            ],\n            \"filter\": [\n                {\"term\": {\"authors\": \"Geoffrey Hinton\"}}\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"troubleshooting/faq/#performance","title":"Performance","text":""},{"location":"troubleshooting/faq/#q-why-is-the-first-query-slow","title":"Q: Why is the first query slow?","text":"<p>A: First query may be slow due to: - Model loading: Embedding model loaded into memory - Index warming: OpenSearch caches are cold - LLM initialization: Gemini client initialization</p> <p>Subsequent queries are faster (cached models, warm indices).</p>"},{"location":"troubleshooting/faq/#q-how-much-ram-does-the-system-use","title":"Q: How much RAM does the system use?","text":"<p>A: Typical usage: - Python application: 1-2GB - OpenSearch: 2-4GB (configurable) - Embedding model: 500MB-1GB - Total: 4-8GB recommended</p> <p>For large-scale usage, 16GB+ recommended.</p>"},{"location":"troubleshooting/faq/#q-can-i-run-this-on-a-raspberry-pi","title":"Q: Can I run this on a Raspberry Pi?","text":"<p>A: Possible but not recommended: - RAM limitation: Need at least 4GB - CPU: Will be very slow - Storage: Need sufficient space</p> <p>Better options: Use cloud instance or local machine.</p>"},{"location":"troubleshooting/faq/#q-how-do-i-process-documents-faster","title":"Q: How do I process documents faster?","text":"<p>A: Speed improvements: 1. Use GPU: For embedding generation 2. Batch processing: Process multiple docs at once 3. Reduce Gemini calls: Cache vision analysis results 4. Parallel processing: Use multiprocessing 5. Skip large PDFs: Set size limits</p> <p>Example: <pre><code># Process in parallel\nfrom multiprocessing import Pool\n\nwith Pool(processes=4) as pool:\n    results = pool.map(process_pdf, pdf_files)\n</code></pre></p>"},{"location":"troubleshooting/faq/#q-why-is-indexing-slow","title":"Q: Why is indexing slow?","text":"<p>A: Common bottlenecks: - Embedding generation: CPU-bound operation - Gemini API calls: Rate-limited to 60/min - OpenSearch indexing: Network and disk I/O - PDF processing: Complex PDFs with many images</p> <p>Solutions: See Performance Optimization.</p>"},{"location":"troubleshooting/faq/#features-capabilities","title":"Features &amp; Capabilities","text":""},{"location":"troubleshooting/faq/#q-does-the-system-support-multiple-languages","title":"Q: Does the system support multiple languages?","text":"<p>A: Limited support: - Papers: Primarily English (ArXiv, PMC) - Embeddings: Model supports multiple languages - Gemini: Supports many languages - Search: Works with non-English content</p> <p>For full multilingual support, you'd need: - Multilingual embedding model - Language-specific data sources - Translation capabilities</p>"},{"location":"troubleshooting/faq/#q-can-i-export-search-results","title":"Q: Can I export search results?","text":"<p>A: Yes, export options: - Citations: Export via Citation Manager tab - Results: Save as JSON, CSV, or BibTeX - Summaries: Copy from UI or save to file</p> <p>Implementation: <pre><code>import json\n\n# Export results\nwith open('results.json', 'w') as f:\n    json.dump(search_results, f, indent=2)\n</code></pre></p>"},{"location":"troubleshooting/faq/#q-does-the-system-support-collaborative-research","title":"Q: Does the system support collaborative research?","text":"<p>A: Not built-in, but you could: - Shared index: Multiple users connect to same OpenSearch - Cloud deployment: Deploy on server, share URL - Export/import: Share indexed content between instances</p> <p>Future enhancement could add user accounts and sharing features.</p>"},{"location":"troubleshooting/faq/#q-can-i-integrate-this-with-zotero-or-mendeley","title":"Q: Can I integrate this with Zotero or Mendeley?","text":"<p>A: Not directly, but possible: 1. Export papers from Zotero 2. Import PDFs into this system 3. Use citation export to import back</p> <p>Or build a custom integration using their APIs.</p>"},{"location":"troubleshooting/faq/#q-does-it-support-citation-management","title":"Q: Does it support citation management?","text":"<p>A: Yes, basic features: - Track citations: From LLM responses - View bibliography: In Citation Manager - Export citations: BibTeX, JSON formats</p> <p>For advanced features, use dedicated tools like Zotero.</p>"},{"location":"troubleshooting/faq/#q-can-i-add-annotations-or-notes-to-papers","title":"Q: Can I add annotations or notes to papers?","text":"<p>A: Not currently implemented, but could be added: - Store notes in OpenSearch alongside documents - Add UI for note-taking - Include notes in search results</p>"},{"location":"troubleshooting/faq/#q-does-it-support-pdf-highlighting-or-markup","title":"Q: Does it support PDF highlighting or markup?","text":"<p>A: No, this is a retrieval and question-answering system, not a PDF reader. Use dedicated PDF tools for markup.</p>"},{"location":"troubleshooting/faq/#troubleshooting","title":"Troubleshooting","text":""},{"location":"troubleshooting/faq/#q-opensearch-wont-start-what-should-i-do","title":"Q: OpenSearch won't start. What should I do?","text":"<p>A: Troubleshooting steps: 1. Check Docker is running: <code>docker ps</code> 2. Check port availability: <code>lsof -i :9200</code> 3. Check Docker logs: <code>docker logs &lt;container_id&gt;</code> 4. Try different port: <code>-p 9201:9200</code> 5. Increase memory: Add <code>--memory=4g</code></p> <p>See OpenSearch Troubleshooting for details.</p>"},{"location":"troubleshooting/faq/#q-i-get-gemini-api-key-invalid-how-do-i-fix-this","title":"Q: I get \"Gemini API key invalid\". How do I fix this?","text":"<p>A: Steps to fix: 1. Verify key in <code>.env</code> file (no quotes, no spaces) 2. Test key at https://makersuite.google.com/ 3. Generate new key if expired 4. Check for typos or extra characters 5. Ensure <code>.env</code> is in project root</p>"},{"location":"troubleshooting/faq/#q-search-returns-no-results-why","title":"Q: Search returns no results. Why?","text":"<p>A: Check these: 1. Index exists: <code>curl http://localhost:9200/_cat/indices</code> 2. Documents indexed: <code>curl http://localhost:9200/research_assistant/_count</code> 3. Query format: Test with simple query 4. Content mismatch: Verify indexed content matches query</p>"},{"location":"troubleshooting/faq/#q-the-ui-wont-load-whats-wrong","title":"Q: The UI won't load. What's wrong?","text":"<p>A: Common issues: 1. Port in use: Kill process using port 7860 2. Python error: Check terminal for stack trace 3. Missing dependencies: Reinstall requirements 4. OpenSearch down: Start OpenSearch first</p>"},{"location":"troubleshooting/faq/#q-how-do-i-enable-debug-logging","title":"Q: How do I enable debug logging?","text":"<p>A: Add to your code:</p> <pre><code>import logging\n\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n</code></pre> <p>Or set in main.py before launching.</p>"},{"location":"troubleshooting/faq/#q-where-can-i-find-error-logs","title":"Q: Where can I find error logs?","text":"<p>A: Logs are in: - Console output: Check terminal - Log files: <code>logs/</code> directory (if enabled) - OpenSearch logs: <code>docker logs opensearch-node</code> - Gradio logs: In console output</p>"},{"location":"troubleshooting/faq/#advanced-topics","title":"Advanced Topics","text":""},{"location":"troubleshooting/faq/#q-can-i-use-a-different-embedding-model","title":"Q: Can I use a different embedding model?","text":"<p>A: Yes, modify <code>opensearch_manager.py</code>:</p> <pre><code>from sentence_transformers import SentenceTransformer\n\n# Change model\nmodel = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n\n# Update dimension in index mapping (768 for above model)\n</code></pre> <p>See Embedding Models Guide.</p>"},{"location":"troubleshooting/faq/#q-how-do-i-add-a-custom-data-source","title":"Q: How do I add a custom data source?","text":"<p>A: Create a new collector:</p> <ol> <li>Create <code>custom_collector.py</code> in <code>data_collectors/</code></li> <li>Implement collection logic</li> <li>Register in <code>main.py</code></li> <li>Add UI option in <code>gradio_app.py</code></li> </ol> <p>See Custom Collectors Guide.</p>"},{"location":"troubleshooting/faq/#q-can-i-use-this-for-non-academic-content","title":"Q: Can I use this for non-academic content?","text":"<p>A: Yes, adapt for any content: - Modify collectors for your sources - Adjust data schema in OpenSearch - Update UI for your use case</p> <p>The architecture is general-purpose RAG.</p>"},{"location":"troubleshooting/faq/#q-how-do-i-fine-tune-the-search-ranking","title":"Q: How do I fine-tune the search ranking?","text":"<p>A: Adjust field weights:</p> <pre><code>query = {\n    \"query\": {\n        \"multi_match\": {\n            \"query\": query_text,\n            \"fields\": [\n                \"title^3\",      # 3x weight\n                \"abstract^2\",   # 2x weight\n                \"content^1\",    # 1x weight\n                \"key_concepts^2\"\n            ]\n        }\n    }\n}\n</code></pre> <p>Test different weights for your use case.</p>"},{"location":"troubleshooting/faq/#q-can-i-deploy-this-to-production","title":"Q: Can I deploy this to production?","text":"<p>A: Yes, but consider: - Authentication: Add user auth - Scaling: Use managed OpenSearch (AWS, etc.) - Rate limiting: Implement proper limits - Monitoring: Add logging and metrics - Security: Sanitize inputs, use HTTPS - Costs: Monitor API usage</p>"},{"location":"troubleshooting/faq/#q-how-do-i-backup-my-data","title":"Q: How do I backup my data?","text":"<p>A: Backup strategies:</p> <ol> <li> <p>OpenSearch snapshots: <pre><code>curl -X PUT \"localhost:9200/_snapshot/backup/snapshot_1?wait_for_completion=true\"\n</code></pre></p> </li> <li> <p>File backup: <pre><code>tar -czf backup.tar.gz data/\n</code></pre></p> </li> <li> <p>Export to JSON: <pre><code># Export all documents\nfrom opensearchpy import helpers\n\ndocs = helpers.scan(client, index='research_assistant')\nwith open('backup.json', 'w') as f:\n    json.dump(list(docs), f)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/faq/#q-can-i-contribute-to-the-project","title":"Q: Can I contribute to the project?","text":"<p>A: Yes! Contributions welcome: - Submit bug reports - Suggest features - Submit pull requests - Improve documentation</p> <p>See CONTRIBUTING.md for guidelines (if available).</p>"},{"location":"troubleshooting/faq/#q-whats-the-difference-between-this-and-chatgpt-with-plugins","title":"Q: What's the difference between this and ChatGPT with plugins?","text":"<p>A: Key differences: - Local control: You control the data and index - Free: No subscription costs (except API usage) - Customizable: Modify for your needs - Private: Data stays local - Academic focus: Specialized for research - Multi-modal: Integrates papers, videos, podcasts</p>"},{"location":"troubleshooting/faq/#q-is-there-a-roadmap-for-future-features","title":"Q: Is there a roadmap for future features?","text":"<p>A: Potential enhancements: - More data sources (Google Scholar, JSTOR) - Better visualization (knowledge graphs) - Collaborative features (sharing, comments) - Mobile app - Better citation management - Integration with reference managers - Support for more file formats</p>"},{"location":"troubleshooting/faq/#still-have-questions","title":"Still Have Questions?","text":"<p>If your question isn't answered here:</p> <ol> <li>Check the Troubleshooting Guide</li> <li>Review the CLAUDE.md project overview</li> <li>Search GitHub issues</li> <li>Create a new issue with your question</li> </ol>"},{"location":"troubleshooting/faq/#additional-resources","title":"Additional Resources","text":"<ul> <li>Common Issues</li> <li>OpenSearch Troubleshooting</li> <li>API Errors</li> <li>Performance Guide</li> <li>Custom Collectors</li> <li>Hybrid Search</li> </ul>"},{"location":"troubleshooting/opensearch/","title":"OpenSearch Troubleshooting Guide","text":"<p>Comprehensive troubleshooting guide for OpenSearch-related issues in the Multi-Modal Academic Research System.</p>"},{"location":"troubleshooting/opensearch/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Connection Issues</li> <li>Indexing Failures</li> <li>Search Performance Problems</li> <li>Memory Issues</li> <li>Cluster Health</li> <li>Index Corruption</li> <li>Mapping Conflicts</li> <li>Diagnostic Commands</li> </ul>"},{"location":"troubleshooting/opensearch/#connection-issues","title":"Connection Issues","text":""},{"location":"troubleshooting/opensearch/#cannot-connect-to-opensearch","title":"Cannot connect to OpenSearch","text":"<p>Symptoms: - <code>ConnectionError: Connection refused</code> - <code>ConnectionTimeout</code> - <code>TransportError(N/A, 'Unable to connect')</code></p> <p>Diagnosis: <pre><code># Check if OpenSearch is running\ncurl http://localhost:9200\n\n# Check Docker containers\ndocker ps | grep opensearch\n\n# Check port availability\nlsof -i :9200\nnetstat -an | grep 9200\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Start OpenSearch if not running: <pre><code>docker run -d \\\n  --name opensearch-node \\\n  -p 9200:9200 -p 9600:9600 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"DISABLE_SECURITY_PLUGIN=true\" \\\n  opensearchproject/opensearch:latest\n</code></pre></p> </li> <li> <p>Check Docker daemon: <pre><code># Ensure Docker is running\ndocker info\n\n# Restart Docker if needed\n# Mac: Restart Docker Desktop\n# Linux: sudo systemctl restart docker\n</code></pre></p> </li> <li> <p>Verify network configuration: <pre><code># Test connectivity\ntelnet localhost 9200\n\n# Check firewall rules\nsudo iptables -L | grep 9200  # Linux\n# or\nsudo pfctl -s rules | grep 9200  # Mac\n</code></pre></p> </li> <li> <p>Fix host/port mismatch: <pre><code># In opensearch_manager.py\nclient = OpenSearch(\n    hosts=[{'host': 'localhost', 'port': 9200}],\n    http_compress=True,\n    use_ssl=False,\n    verify_certs=False,\n    timeout=30\n)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#ssltls-connection-errors","title":"SSL/TLS Connection Errors","text":"<p>Symptoms: - <code>SSLError: [SSL: CERTIFICATE_VERIFY_FAILED]</code> - <code>ConnectionError: Caused by SSLError</code></p> <p>Solutions:</p> <ol> <li> <p>Disable SSL for local development: <pre><code>docker run -d \\\n  --name opensearch-node \\\n  -p 9200:9200 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"DISABLE_SECURITY_PLUGIN=true\" \\\n  -e \"plugins.security.ssl.http.enabled=false\" \\\n  opensearchproject/opensearch:latest\n</code></pre></p> </li> <li> <p>Update client configuration: <pre><code>from opensearchpy import OpenSearch\n\nclient = OpenSearch(\n    hosts=[{'host': 'localhost', 'port': 9200}],\n    http_compress=True,\n    use_ssl=False,\n    verify_certs=False,\n    ssl_show_warn=False\n)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#authentication-failures","title":"Authentication Failures","text":"<p>Symptoms: - <code>AuthenticationException</code> - <code>403 Forbidden</code> - <code>401 Unauthorized</code></p> <p>Solutions:</p> <ol> <li> <p>Disable security for local development: <pre><code>docker run -d \\\n  --name opensearch-node \\\n  -p 9200:9200 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"DISABLE_SECURITY_PLUGIN=true\" \\\n  opensearchproject/opensearch:latest\n</code></pre></p> </li> <li> <p>Use basic authentication (if security enabled): <pre><code>client = OpenSearch(\n    hosts=[{'host': 'localhost', 'port': 9200}],\n    http_auth=('admin', 'admin'),  # Default credentials\n    use_ssl=True,\n    verify_certs=False\n)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#indexing-failures","title":"Indexing Failures","text":""},{"location":"troubleshooting/opensearch/#index-creation-fails","title":"Index Creation Fails","text":"<p>Symptoms: - <code>RequestError: resource_already_exists_exception</code> - <code>TransportError(400, 'illegal_argument_exception')</code></p> <p>Diagnosis: <pre><code># Check if index exists\ncurl http://localhost:9200/_cat/indices?v\n\n# Get index details\ncurl http://localhost:9200/research_assistant\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Delete existing index (WARNING: loses data): <pre><code>curl -X DELETE http://localhost:9200/research_assistant\n</code></pre></p> </li> <li> <p>Handle in code: <pre><code>from opensearchpy.exceptions import RequestError\n\ntry:\n    client.indices.create(index='research_assistant', body=settings)\nexcept RequestError as e:\n    if e.error == 'resource_already_exists_exception':\n        print(f\"Index already exists\")\n    else:\n        raise\n</code></pre></p> </li> <li> <p>Use index templates for reusability: <pre><code>index_template = {\n    \"index_patterns\": [\"research_*\"],\n    \"template\": {\n        \"settings\": {\n            \"number_of_shards\": 1,\n            \"number_of_replicas\": 0\n        },\n        \"mappings\": {\n            \"properties\": {\n                \"embedding\": {\n                    \"type\": \"knn_vector\",\n                    \"dimension\": 384\n                }\n            }\n        }\n    }\n}\n\nclient.indices.put_index_template(\n    name='research_template',\n    body=index_template\n)\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#bulk-indexing-errors","title":"Bulk Indexing Errors","text":"<p>Symptoms: - <code>BulkIndexError</code> - Documents not appearing in index - Partial indexing success</p> <p>Diagnosis: <pre><code># Check bulk response\nresponse = client.bulk(body=bulk_data)\n\nif response['errors']:\n    for item in response['items']:\n        if 'error' in item.get('index', {}):\n            print(f\"Error: {item['index']['error']}\")\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Handle errors gracefully: <pre><code>from opensearchpy import helpers\n\ndef index_documents(documents):\n    actions = [\n        {\n            \"_index\": \"research_assistant\",\n            \"_id\": doc['id'],\n            \"_source\": doc\n        }\n        for doc in documents\n    ]\n\n    success, failed = helpers.bulk(\n        client,\n        actions,\n        raise_on_error=False,\n        raise_on_exception=False\n    )\n\n    print(f\"Indexed: {success}, Failed: {len(failed)}\")\n\n    for item in failed:\n        print(f\"Failed document: {item}\")\n</code></pre></p> </li> <li> <p>Reduce batch size: <pre><code>def index_in_batches(documents, batch_size=100):\n    for i in range(0, len(documents), batch_size):\n        batch = documents[i:i+batch_size]\n        helpers.bulk(client, prepare_actions(batch))\n        time.sleep(1)  # Rate limiting\n</code></pre></p> </li> <li> <p>Validate data before indexing: <pre><code>def validate_document(doc):\n    required_fields = ['id', 'title', 'content']\n    for field in required_fields:\n        if field not in doc:\n            raise ValueError(f\"Missing field: {field}\")\n\n    # Validate embedding dimension\n    if 'embedding' in doc:\n        if len(doc['embedding']) != 384:\n            raise ValueError(f\"Invalid embedding dimension\")\n\n    return True\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#mapping-conflicts","title":"Mapping Conflicts","text":"<p>Symptoms: - <code>mapper_parsing_exception</code> - <code>illegal_argument_exception: mapper [field] cannot be changed</code></p> <p>Diagnosis: <pre><code># Get current mapping\ncurl http://localhost:9200/research_assistant/_mapping?pretty\n\n# Check field types\ncurl http://localhost:9200/research_assistant/_mapping/field/embedding\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Reindex with correct mapping: <pre><code># Create new index with correct mapping\nnew_index_settings = {\n    \"mappings\": {\n        \"properties\": {\n            \"embedding\": {\n                \"type\": \"knn_vector\",\n                \"dimension\": 384\n            },\n            \"publication_date\": {\n                \"type\": \"date\",\n                \"format\": \"yyyy-MM-dd||epoch_millis\"\n            }\n        }\n    }\n}\n\nclient.indices.create(index='research_assistant_v2', body=new_index_settings)\n\n# Reindex data\nclient.reindex(\n    body={\n        \"source\": {\"index\": \"research_assistant\"},\n        \"dest\": {\"index\": \"research_assistant_v2\"}\n    }\n)\n\n# Switch alias\nclient.indices.delete_alias(index='research_assistant', name='research')\nclient.indices.put_alias(index='research_assistant_v2', name='research')\n</code></pre></p> </li> <li> <p>Use dynamic mapping carefully: <pre><code>index_settings = {\n    \"settings\": {\n        \"index\": {\n            \"mapping\": {\n                \"ignore_malformed\": True,  # Ignore badly formatted data\n                \"coerce\": True  # Try to convert types\n            }\n        }\n    }\n}\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#search-performance-problems","title":"Search Performance Problems","text":""},{"location":"troubleshooting/opensearch/#slow-query-performance","title":"Slow Query Performance","text":"<p>Symptoms: - Queries taking &gt; 5 seconds - Timeout errors - High CPU usage</p> <p>Diagnosis: <pre><code># Check query performance\ncurl -X GET \"localhost:9200/research_assistant/_search?pretty\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"profile\": true, \"query\": {\"match_all\": {}}}'\n\n# Check cluster stats\ncurl http://localhost:9200/_cluster/stats?pretty\n\n# Monitor slow queries\ncurl http://localhost:9200/_nodes/stats/indices/search?pretty\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Optimize query structure: <pre><code># Use filters instead of queries when possible (cached)\nquery = {\n    \"query\": {\n        \"bool\": {\n            \"must\": [\n                {\"match\": {\"content\": query_text}}\n            ],\n            \"filter\": [  # Filters are faster and cached\n                {\"term\": {\"content_type\": \"paper\"}},\n                {\"range\": {\"publication_date\": {\"gte\": \"2020-01-01\"}}}\n            ]\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>Add result size limits: <pre><code>results = client.search(\n    index='research_assistant',\n    body=query,\n    size=10,  # Limit results\n    request_timeout=30\n)\n</code></pre></p> </li> <li> <p>Use pagination for large result sets: <pre><code>from opensearchpy import helpers\n\ndef search_with_pagination(query, page_size=100):\n    results = helpers.scan(\n        client,\n        index='research_assistant',\n        query=query,\n        size=page_size,\n        scroll='2m'\n    )\n\n    for hit in results:\n        yield hit\n</code></pre></p> </li> <li> <p>Optimize kNN search: <pre><code># Reduce candidates for kNN\nknn_query = {\n    \"size\": 10,\n    \"query\": {\n        \"knn\": {\n            \"embedding\": {\n                \"vector\": query_embedding,\n                \"k\": 10,  # Number of nearest neighbors\n                \"method_parameters\": {\n                    \"ef_search\": 100  # Reduce for faster search\n                }\n            }\n        }\n    }\n}\n</code></pre></p> </li> <li> <p>Enable request caching: <pre><code># Update index settings\ncurl -X PUT \"localhost:9200/research_assistant/_settings\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"index.requests.cache.enable\": true,\n    \"index.queries.cache.enabled\": true\n  }'\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#high-disk-io","title":"High Disk I/O","text":"<p>Symptoms: - Slow search and indexing - High disk usage in <code>docker stats</code></p> <p>Solutions:</p> <ol> <li> <p>Increase refresh interval: <pre><code># Reduce index refresh frequency\nclient.indices.put_settings(\n    index='research_assistant',\n    body={\n        \"index\": {\n            \"refresh_interval\": \"30s\"  # Default is 1s\n        }\n    }\n)\n\n# Disable during bulk indexing\nclient.indices.put_settings(\n    index='research_assistant',\n    body={\"index\": {\"refresh_interval\": \"-1\"}}\n)\n\n# Re-enable after indexing\nclient.indices.put_settings(\n    index='research_assistant',\n    body={\"index\": {\"refresh_interval\": \"1s\"}}\n)\n</code></pre></p> </li> <li> <p>Force merge segments: <pre><code># Reduce number of segments\ncurl -X POST \"localhost:9200/research_assistant/_forcemerge?max_num_segments=1\"\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#memory-issues","title":"Memory Issues","text":""},{"location":"troubleshooting/opensearch/#out-of-memory-errors","title":"Out of Memory Errors","text":"<p>Symptoms: - <code>OutOfMemoryError: Java heap space</code> - Container crashes - Degraded performance</p> <p>Diagnosis: <pre><code># Check memory usage\ndocker stats opensearch-node\n\n# Check JVM heap\ncurl http://localhost:9200/_nodes/stats/jvm?pretty\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Increase heap size: <pre><code>docker run -d \\\n  --name opensearch-node \\\n  -p 9200:9200 \\\n  -e \"discovery.type=single-node\" \\\n  -e \"OPENSEARCH_JAVA_OPTS=-Xms2g -Xmx2g\" \\\n  --memory=4g \\\n  opensearchproject/opensearch:latest\n</code></pre></p> </li> <li> <p>Reduce field data cache: <pre><code>curl -X PUT \"localhost:9200/_cluster/settings\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"persistent\": {\n      \"indices.fielddata.cache.size\": \"20%\"\n    }\n  }'\n</code></pre></p> </li> <li> <p>Clear caches: <pre><code># Clear field data cache\ncurl -X POST \"localhost:9200/_cache/clear?fielddata=true\"\n\n# Clear query cache\ncurl -X POST \"localhost:9200/_cache/clear?query=true\"\n\n# Clear all caches\ncurl -X POST \"localhost:9200/_cache/clear\"\n</code></pre></p> </li> <li> <p>Optimize index settings: <pre><code>index_settings = {\n    \"settings\": {\n        \"number_of_shards\": 1,  # Reduce for single-node\n        \"number_of_replicas\": 0,  # No replicas for local dev\n        \"codec\": \"best_compression\"  # Trade CPU for memory\n    }\n}\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#cluster-health","title":"Cluster Health","text":""},{"location":"troubleshooting/opensearch/#cluster-health-is-yellow-or-red","title":"Cluster Health is Yellow or Red","text":"<p>Symptoms: - Yellow cluster status - Red cluster status - Unassigned shards</p> <p>Diagnosis: <pre><code># Check cluster health\ncurl http://localhost:9200/_cluster/health?pretty\n\n# Check shard allocation\ncurl http://localhost:9200/_cat/shards?v\n\n# Get allocation explanation\ncurl http://localhost:9200/_cluster/allocation/explain?pretty\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Yellow status (unassigned replicas): <pre><code># Normal for single-node cluster\n# Set replicas to 0\ncurl -X PUT \"localhost:9200/research_assistant/_settings\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\"index\": {\"number_of_replicas\": 0}}'\n</code></pre></p> </li> <li> <p>Red status (missing primary shards): <pre><code># Try to reroute shards\ncurl -X POST \"localhost:9200/_cluster/reroute?retry_failed=true\"\n\n# If that fails, may need to restore from snapshot\n</code></pre></p> </li> <li> <p>Enable shard allocation: <pre><code>curl -X PUT \"localhost:9200/_cluster/settings\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"persistent\": {\n      \"cluster.routing.allocation.enable\": \"all\"\n    }\n  }'\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#index-corruption","title":"Index Corruption","text":""},{"location":"troubleshooting/opensearch/#corrupt-index-or-shards","title":"Corrupt Index or Shards","text":"<p>Symptoms: - <code>CorruptIndexException</code> - Missing or corrupted data - Search returns incomplete results</p> <p>Diagnosis: <pre><code># Check index health\ncurl http://localhost:9200/_cat/indices/research_assistant?v\n\n# Verify shard status\ncurl http://localhost:9200/_cat/shards/research_assistant?v\n</code></pre></p> <p>Solutions:</p> <ol> <li> <p>Close and reopen index: <pre><code>curl -X POST \"localhost:9200/research_assistant/_close\"\ncurl -X POST \"localhost:9200/research_assistant/_open\"\n</code></pre></p> </li> <li> <p>Try to recover: <pre><code>curl -X POST \"localhost:9200/_cluster/reroute?retry_failed=true\"\n</code></pre></p> </li> <li> <p>Recreate index from source data: <pre><code># Delete corrupted index\nclient.indices.delete(index='research_assistant')\n\n# Recreate with proper settings\nclient.indices.create(index='research_assistant', body=index_settings)\n\n# Reindex all documents\n# Run your data collection and indexing pipeline again\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#diagnostic-commands","title":"Diagnostic Commands","text":""},{"location":"troubleshooting/opensearch/#essential-health-checks","title":"Essential Health Checks","text":"<pre><code># Cluster health overview\ncurl http://localhost:9200/_cluster/health?pretty\n\n# Node information\ncurl http://localhost:9200/_nodes/stats?pretty\n\n# Index statistics\ncurl http://localhost:9200/_cat/indices?v\n\n# Shard allocation\ncurl http://localhost:9200/_cat/shards?v\n\n# Pending tasks\ncurl http://localhost:9200/_cat/pending_tasks?v\n\n# Thread pool stats\ncurl http://localhost:9200/_cat/thread_pool?v\n\n# Hot threads\ncurl http://localhost:9200/_nodes/hot_threads\n</code></pre>"},{"location":"troubleshooting/opensearch/#performance-monitoring","title":"Performance Monitoring","text":"<pre><code># Search performance\ncurl http://localhost:9200/_nodes/stats/indices/search?pretty\n\n# Indexing performance\ncurl http://localhost:9200/_nodes/stats/indices/indexing?pretty\n\n# Cache statistics\ncurl http://localhost:9200/_nodes/stats/indices/query_cache,fielddata,request_cache?pretty\n\n# JVM memory\ncurl http://localhost:9200/_nodes/stats/jvm?pretty\n\n# Disk usage\ncurl http://localhost:9200/_nodes/stats/fs?pretty\n</code></pre>"},{"location":"troubleshooting/opensearch/#index-analysis","title":"Index Analysis","text":"<pre><code># Index settings\ncurl http://localhost:9200/research_assistant/_settings?pretty\n\n# Index mappings\ncurl http://localhost:9200/research_assistant/_mapping?pretty\n\n# Index stats\ncurl http://localhost:9200/research_assistant/_stats?pretty\n\n# Document count\ncurl http://localhost:9200/research_assistant/_count\n\n# Sample documents\ncurl -X GET \"localhost:9200/research_assistant/_search?size=1&amp;pretty\"\n</code></pre>"},{"location":"troubleshooting/opensearch/#preventive-maintenance","title":"Preventive Maintenance","text":""},{"location":"troubleshooting/opensearch/#regular-maintenance-tasks","title":"Regular Maintenance Tasks","text":"<ol> <li> <p>Monitor cluster health: <pre><code># Set up monitoring script\n#!/bin/bash\nwhile true; do\n    curl -s http://localhost:9200/_cluster/health | jq .status\n    sleep 60\ndone\n</code></pre></p> </li> <li> <p>Clear old logs: <pre><code>docker logs opensearch-node --tail 1000 &gt; opensearch.log\ndocker exec opensearch-node find /usr/share/opensearch/logs -mtime +7 -delete\n</code></pre></p> </li> <li> <p>Optimize indices regularly: <pre><code># Weekly optimization\ncurl -X POST \"localhost:9200/research_assistant/_forcemerge?max_num_segments=1\"\n</code></pre></p> </li> <li> <p>Backup important indices: <pre><code># Create snapshot repository\ncurl -X PUT \"localhost:9200/_snapshot/backup\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{\n    \"type\": \"fs\",\n    \"settings\": {\n      \"location\": \"/usr/share/opensearch/backup\"\n    }\n  }'\n\n# Create snapshot\ncurl -X PUT \"localhost:9200/_snapshot/backup/snapshot_1?wait_for_completion=true\"\n</code></pre></p> </li> </ol>"},{"location":"troubleshooting/opensearch/#additional-resources","title":"Additional Resources","text":"<ul> <li>Common Issues</li> <li>Performance Optimization</li> <li>OpenSearch Documentation</li> <li>FAQ</li> </ul>"},{"location":"troubleshooting/opensearch/#getting-help","title":"Getting Help","text":"<p>For OpenSearch-specific issues: 1. Check OpenSearch logs: <code>docker logs opensearch-node</code> 2. Enable debug logging: Set <code>OPENSEARCH_JAVA_OPTS</code> with <code>-Xlog:gc*</code> 3. Visit OpenSearch forums: https://forum.opensearch.org/ 4. Check GitHub issues: https://github.com/opensearch-project/OpenSearch</p>"},{"location":"tutorials/","title":"Multi-Modal Academic Research System - Tutorials","text":"<p>Comprehensive hands-on tutorials for using and extending the Multi-Modal Academic Research System.</p>"},{"location":"tutorials/#quick-start","title":"Quick Start","text":"<p>If you're new to the system, we recommend following the tutorials in this order:</p> <ol> <li>Collecting Papers - Learn how to collect academic content</li> <li>Custom Searches - Master advanced search techniques</li> <li>Exporting Citations - Manage and export your research citations</li> <li>Visualization Dashboard - Analyze your collection with visualizations</li> <li>Extending the System - Customize and extend functionality</li> </ol>"},{"location":"tutorials/#tutorial-overview","title":"Tutorial Overview","text":""},{"location":"tutorials/#1-collecting-papers-tutorial","title":"1. Collecting Papers Tutorial","text":"<p>File: collect-papers.md Level: Beginner Time: 30-45 minutes</p> <p>Learn how to collect academic papers from multiple sources including ArXiv, Semantic Scholar, and PubMed Central.</p> <p>Topics Covered: - Using the Gradio UI for data collection - Python API for programmatic collection - Different search strategies for each source - Batch collection and automation - Troubleshooting common issues - Best practices for paper collection</p> <p>What You'll Build: - A collection of 100+ papers on your research topic - Automated collection scripts - Deduplication and filtering workflows</p>"},{"location":"tutorials/#2-custom-searches-tutorial","title":"2. Custom Searches Tutorial","text":"<p>File: custom-searches.md Level: Intermediate Time: 45-60 minutes</p> <p>Master advanced search techniques using Boolean operators, field boosting, filters, and OpenSearch Query DSL.</p> <p>Topics Covered: - Advanced query syntax (AND, OR, NOT, wildcards) - Field-specific searches and boosting - Combining multiple filters - Date, author, and category filtering - OpenSearch Query DSL - Search relevance optimization - Custom re-ranking algorithms</p> <p>What You'll Build: - Custom search queries for precise results - Multi-criteria filtering scripts - Relevance tuning configurations - Similarity search functionality</p>"},{"location":"tutorials/#3-exporting-citations-tutorial","title":"3. Exporting Citations Tutorial","text":"<p>File: export-citations.md Level: Beginner to Intermediate Time: 30-40 minutes</p> <p>Learn how to export and manage citations in various formats for your research writing.</p> <p>Topics Covered: - Understanding citation tracking - Exporting from the Gradio UI - Programmatic export via Python - Multiple citation formats (BibTeX, APA, MLA, Chicago) - Integrating with Zotero, Mendeley, and EndNote - Creating custom citation formats - Automated export workflows</p> <p>What You'll Build: - Bibliography files in multiple formats - Integration with reference managers - Custom citation formatters - Automated export scripts - Citation usage reports</p>"},{"location":"tutorials/#4-visualization-dashboard-tutorial","title":"4. Visualization Dashboard Tutorial","text":"<p>File: visualization.md Level: Intermediate Time: 40-50 minutes</p> <p>Explore and analyze your research collection using the FastAPI visualization dashboard.</p> <p>Topics Covered: - Starting the FastAPI dashboard - Understanding collection statistics - Filtering and searching data - Exporting data in various formats - Creating custom visualizations - Using the REST API - Real-time monitoring</p> <p>What You'll Build: - Interactive charts and graphs - Custom analytics dashboards - Data export pipelines - API client for automation - Collection monitoring tools</p>"},{"location":"tutorials/#5-extending-the-system-tutorial","title":"5. Extending the System Tutorial","text":"<p>File: extending.md Level: Advanced Time: 60-90 minutes</p> <p>Learn how to extend the system with new data collectors, processors, UI components, and search filters.</p> <p>Topics Covered: - System architecture overview - Creating new data collectors - Building custom processors - Modifying the Gradio UI - Adding search filters - Writing tests - Contributing to the project</p> <p>What You'll Build: - Custom blog post collector - GitHub repository collector - Custom data processors - New UI components - Advanced search filters - Test suites</p>"},{"location":"tutorials/#learning-paths","title":"Learning Paths","text":""},{"location":"tutorials/#for-researchers","title":"For Researchers","text":"<p>Focus on using the system for your research:</p> <ol> <li>Collecting Papers - Build your research database</li> <li>Custom Searches - Find relevant papers efficiently</li> <li>Exporting Citations - Manage citations for writing</li> <li>Visualization Dashboard - Analyze your collection</li> </ol>"},{"location":"tutorials/#for-developers","title":"For Developers","text":"<p>Focus on extending and customizing the system:</p> <ol> <li>Collecting Papers - Understand data flow</li> <li>Custom Searches - Learn search architecture</li> <li>Extending the System - Add new features</li> <li>Visualization Dashboard - Build analytics tools</li> </ol>"},{"location":"tutorials/#for-data-scientists","title":"For Data Scientists","text":"<p>Focus on data analysis and visualization:</p> <ol> <li>Collecting Papers - Gather data</li> <li>Visualization Dashboard - Analyze patterns</li> <li>Custom Searches - Extract insights</li> <li>Extending the System - Add custom analytics</li> </ol>"},{"location":"tutorials/#prerequisites","title":"Prerequisites","text":"<p>Before starting the tutorials, ensure you have:</p> <ol> <li>Python 3.8+ installed</li> <li>Virtual environment activated</li> <li>Dependencies installed (<code>pip install -r requirements.txt</code>)</li> <li>OpenSearch running (via Docker)</li> <li>Gemini API key configured in <code>.env</code></li> </ol> <p>Quick setup:</p> <pre><code># Clone repository\ngit clone https://github.com/your-repo/multi-modal-academic-research-system.git\ncd multi-modal-academic-research-system\n\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # Mac/Linux\nvenv\\Scripts\\activate     # Windows\n\n# Install dependencies\npip install -r requirements.txt\n\n# Configure environment\ncp .env.example .env\n# Edit .env and add your GEMINI_API_KEY\n\n# Start OpenSearch\ndocker run -p 9200:9200 -e \"discovery.type=single-node\" opensearchproject/opensearch:latest\n\n# Start application\npython main.py\n</code></pre>"},{"location":"tutorials/#tutorial-features","title":"Tutorial Features","text":"<p>Each tutorial includes:</p> <ul> <li>Step-by-step instructions with clear explanations</li> <li>Complete code examples that you can copy and run</li> <li>Practical use cases based on real research scenarios</li> <li>Troubleshooting sections for common issues</li> <li>Best practices and tips</li> <li>Common pitfalls to avoid</li> <li>Next steps and related tutorials</li> </ul>"},{"location":"tutorials/#additional-resources","title":"Additional Resources","text":""},{"location":"tutorials/#documentation","title":"Documentation","text":"<ul> <li>Main Documentation</li> <li>API Reference</li> <li>Architecture Overview</li> <li>Setup Guide</li> </ul>"},{"location":"tutorials/#code-examples","title":"Code Examples","text":"<p>All code examples from the tutorials are available in the <code>examples/</code> directory: - <code>examples/collection/</code> - Paper collection scripts - <code>examples/search/</code> - Advanced search examples - <code>examples/citations/</code> - Citation export scripts - <code>examples/visualization/</code> - Visualization examples - <code>examples/extensions/</code> - Custom extensions</p>"},{"location":"tutorials/#community","title":"Community","text":"<ul> <li>GitHub Issues: Report bugs or request features</li> <li>Discussions: Ask questions and share ideas</li> <li>Pull Requests: Contribute improvements</li> </ul>"},{"location":"tutorials/#getting-help","title":"Getting Help","text":"<p>If you encounter issues while following the tutorials:</p> <ol> <li>Check the troubleshooting section in each tutorial</li> <li>Review the logs in <code>logs/</code> directory</li> <li>Consult the main documentation in <code>docs/</code></li> <li>Search GitHub issues for similar problems</li> <li>Ask for help in GitHub Discussions</li> </ol>"},{"location":"tutorials/#contributing-to-tutorials","title":"Contributing to Tutorials","text":"<p>We welcome improvements to these tutorials! If you:</p> <ul> <li>Find an error or typo</li> <li>Have a suggestion for clarification</li> <li>Want to add a new example</li> <li>Discovered a better approach</li> </ul> <p>Please submit a pull request or open an issue.</p>"},{"location":"tutorials/#tutorial-writing-guidelines","title":"Tutorial Writing Guidelines","text":"<p>If you'd like to contribute a new tutorial:</p> <ol> <li>Follow the existing tutorial structure</li> <li>Include practical, working code examples</li> <li>Test all code examples before submitting</li> <li>Add troubleshooting tips based on real issues</li> <li>Include screenshots or diagrams where helpful</li> <li>Link to related tutorials and documentation</li> </ol>"},{"location":"tutorials/#feedback","title":"Feedback","text":"<p>We'd love to hear your feedback on these tutorials:</p> <ul> <li>What worked well?</li> <li>What was confusing?</li> <li>What's missing?</li> <li>What would you like to learn more about?</li> </ul> <p>Please share your thoughts via GitHub issues or discussions.</p> <p>Last Updated: October 2024 Version: 1.0.0 Maintained by: Multi-Modal Research System Team</p>"},{"location":"tutorials/collect-papers/","title":"Tutorial: Collecting Academic Papers","text":"<p>This tutorial provides step-by-step instructions for collecting academic papers using the Multi-Modal Academic Research System. You'll learn how to use both the Gradio UI and Python API directly to gather papers from multiple sources.</p>"},{"location":"tutorials/collect-papers/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisites</li> <li>Using the Gradio UI</li> <li>Using the Python API</li> <li>Different Search Strategies</li> <li>Troubleshooting</li> </ol>"},{"location":"tutorials/collect-papers/#prerequisites","title":"Prerequisites","text":"<p>Before collecting papers, ensure:</p> <ol> <li> <p>Your virtual environment is activated:    <pre><code>source venv/bin/activate  # Mac/Linux\nvenv\\Scripts\\activate     # Windows\n</code></pre></p> </li> <li> <p>OpenSearch is running (for automatic indexing):    <pre><code>docker run -p 9200:9200 -e \"discovery.type=single-node\" opensearchproject/opensearch:latest\n</code></pre></p> </li> <li> <p>Your <code>.env</code> file contains your Gemini API key:    <pre><code>GEMINI_API_KEY=your_api_key_here\nOPENSEARCH_HOST=localhost\nOPENSEARCH_PORT=9200\n</code></pre></p> </li> </ol>"},{"location":"tutorials/collect-papers/#using-the-gradio-ui","title":"Using the Gradio UI","text":""},{"location":"tutorials/collect-papers/#step-1-launch-the-application","title":"Step 1: Launch the Application","text":"<p>Start the main application:</p> <pre><code>python main.py\n</code></pre> <p>You should see output like: <pre><code>Starting Multi-Modal Research Assistant Application\nConnected to OpenSearch at localhost:9200\nResearch Assistant ready!\nOpening web interface...\nRunning on local URL: http://0.0.0.0:7860\nRunning on public URL: https://xxxxx.gradio.live\n</code></pre></p>"},{"location":"tutorials/collect-papers/#step-2-navigate-to-data-collection-tab","title":"Step 2: Navigate to Data Collection Tab","text":"<ol> <li>Open the local URL (<code>http://localhost:7860</code>) in your web browser</li> <li>Click on the \"Data Collection\" tab at the top</li> <li>You'll see three main sections:</li> <li>Left panel: Collection options and controls</li> <li>Right panel: Status updates and results</li> </ol>"},{"location":"tutorials/collect-papers/#step-3-configure-your-search","title":"Step 3: Configure Your Search","text":"<p>Select Data Source: - Choose \"ArXiv Papers\" from the radio button options - Other options include \"YouTube Lectures\" and \"Podcasts\"</p> <p>Enter Search Query: - Type your research topic in the \"Search Query\" field - Examples:   - <code>machine learning</code>   - <code>quantum computing</code>   - <code>natural language processing</code>   - <code>computer vision transformers</code></p> <p>Set Maximum Results: - Use the slider to choose how many papers to collect (5-100) - Start with 10-20 for testing - Note: Larger values take longer to process</p>"},{"location":"tutorials/collect-papers/#step-4-collect-papers","title":"Step 4: Collect Papers","text":"<ol> <li>Click the \"Collect Data\" button</li> <li> <p>Watch the status updates in the \"Collection Status\" box:    <pre><code>Collecting papers from ArXiv...\nCollected 15 papers\n\nIndexing data into OpenSearch...\nIndexed 15 items into OpenSearch\n\nCollection and indexing complete!\n</code></pre></p> </li> <li> <p>Review the results in the \"Collection Results\" JSON output:    <pre><code>{\n  \"papers_collected\": 15,\n  \"items_indexed\": 15\n}\n</code></pre></p> </li> </ol>"},{"location":"tutorials/collect-papers/#step-5-verify-collection","title":"Step 5: Verify Collection","text":"<p>Option 1: Check the Data Visualization Tab 1. Click on the \"Data Visualization\" tab 2. Click \"Refresh Statistics\" 3. You should see your newly collected papers in the totals</p> <p>Option 2: Use the Research Tab 1. Go to the \"Research\" tab 2. Enter a query related to your collected papers 3. The system should retrieve relevant papers from your collection</p>"},{"location":"tutorials/collect-papers/#what-happens-behind-the-scenes","title":"What Happens Behind the Scenes","text":"<p>When you collect papers via the UI:</p> <ol> <li>Collection Phase:</li> <li>System queries the ArXiv API with your search terms</li> <li>Downloads PDFs to <code>data/papers/</code> directory</li> <li> <p>Extracts metadata (title, authors, abstract, etc.)</p> </li> <li> <p>Database Tracking:</p> </li> <li>Each paper is logged in the SQLite database</li> <li>Collection statistics are recorded</li> <li> <p>Metadata is stored for future reference</p> </li> <li> <p>Indexing Phase:</p> </li> <li>Paper content is formatted for OpenSearch</li> <li>Embeddings are generated using SentenceTransformer</li> <li> <p>Documents are bulk-indexed for fast retrieval</p> </li> <li> <p>Completion:</p> </li> <li>Papers marked as indexed in the database</li> <li>Ready for searching and querying</li> </ol>"},{"location":"tutorials/collect-papers/#using-the-python-api","title":"Using the Python API","text":"<p>For more control or automation, use the Python API directly.</p>"},{"location":"tutorials/collect-papers/#basic-example","title":"Basic Example","text":"<p>Create a Python script (<code>collect_papers.py</code>):</p> <pre><code>from dotenv import load_dotenv\nfrom multi_modal_rag.data_collectors.paper_collector import AcademicPaperCollector\nfrom multi_modal_rag.indexing.opensearch_manager import OpenSearchManager\nfrom multi_modal_rag.database import CollectionDatabaseManager\n\n# Load environment variables\nload_dotenv()\n\n# Initialize components\npaper_collector = AcademicPaperCollector()\nopensearch_manager = OpenSearchManager()\ndb_manager = CollectionDatabaseManager()\n\n# Collect papers from ArXiv\nquery = \"deep learning neural networks\"\nmax_results = 20\n\nprint(f\"Collecting papers for: {query}\")\npapers = paper_collector.collect_arxiv_papers(query, max_results)\n\nprint(f\"Collected {len(papers)} papers\")\n\n# Process and track each paper\nfor paper in papers:\n    # Add to database\n    collection_id = db_manager.add_collection(\n        content_type='paper',\n        title=paper['title'],\n        source='arxiv',\n        url=paper.get('pdf_url', ''),\n        metadata={'query': query}\n    )\n\n    # Store paper details\n    db_manager.add_paper(collection_id, paper)\n\n    # Index in OpenSearch\n    document = {\n        'content_type': 'paper',\n        'title': paper['title'],\n        'abstract': paper['abstract'],\n        'authors': paper['authors'],\n        'url': paper.get('pdf_url', ''),\n        'publication_date': paper['published'],\n        'metadata': {\n            'arxiv_id': paper['arxiv_id'],\n            'categories': paper['categories']\n        }\n    }\n\n    opensearch_manager.index_document('research_assistant', document)\n    db_manager.mark_as_indexed(collection_id)\n\n    print(f\"  - {paper['title'][:80]}...\")\n\n# Log collection statistics\ndb_manager.log_collection_stats('paper', query, len(papers), 'arxiv')\n\nprint(\"Collection complete!\")\n</code></pre> <p>Run the script:</p> <pre><code>python collect_papers.py\n</code></pre>"},{"location":"tutorials/collect-papers/#advanced-example-batch-collection","title":"Advanced Example: Batch Collection","text":"<p>Collect papers for multiple topics:</p> <pre><code>from multi_modal_rag.data_collectors.paper_collector import AcademicPaperCollector\nfrom multi_modal_rag.indexing.opensearch_manager import OpenSearchManager\nfrom multi_modal_rag.database import CollectionDatabaseManager\nfrom dotenv import load_dotenv\nimport time\n\nload_dotenv()\n\n# Initialize\npaper_collector = AcademicPaperCollector()\nopensearch_manager = OpenSearchManager()\ndb_manager = CollectionDatabaseManager()\n\n# Define topics\ntopics = [\n    \"transformer architecture attention mechanisms\",\n    \"reinforcement learning robotics\",\n    \"graph neural networks\",\n    \"few-shot learning meta-learning\",\n    \"generative adversarial networks\"\n]\n\n# Collect for each topic\nfor topic in topics:\n    print(f\"\\nCollecting papers for: {topic}\")\n\n    papers = paper_collector.collect_arxiv_papers(topic, max_results=10)\n\n    # Prepare documents for bulk indexing\n    documents = []\n    for paper in papers:\n        # Track in database\n        collection_id = db_manager.add_collection(\n            content_type='paper',\n            title=paper['title'],\n            source='arxiv',\n            url=paper.get('pdf_url', ''),\n            metadata={'query': topic, 'categories': paper['categories']}\n        )\n        db_manager.add_paper(collection_id, paper)\n\n        # Prepare for indexing\n        doc = {\n            'content_type': 'paper',\n            'title': paper['title'],\n            'abstract': paper['abstract'],\n            'authors': paper['authors'],\n            'url': paper.get('pdf_url', ''),\n            'publication_date': paper['published'],\n            'metadata': {\n                'arxiv_id': paper['arxiv_id'],\n                'categories': paper['categories']\n            }\n        }\n        documents.append(doc)\n\n    # Bulk index\n    if documents:\n        opensearch_manager.bulk_index('research_assistant', documents)\n        print(f\"Indexed {len(documents)} papers\")\n\n        # Mark as indexed\n        for paper in papers:\n            # Get collection_id and mark\n            pass  # Simplified for brevity\n\n    # Log stats\n    db_manager.log_collection_stats('paper', topic, len(papers), 'arxiv')\n\n    # Be respectful to the API\n    time.sleep(3)\n\nprint(\"\\nBatch collection complete!\")\n</code></pre>"},{"location":"tutorials/collect-papers/#using-collection-filters","title":"Using Collection Filters","text":"<p>Filter papers by specific criteria:</p> <pre><code># Collect only recent papers (ArXiv example)\npapers = paper_collector.collect_arxiv_papers(\n    \"machine learning\",\n    max_results=50\n)\n\n# Filter by publication year\nfrom datetime import datetime, timedelta\n\nrecent_papers = [\n    p for p in papers\n    if datetime.fromisoformat(p['published']) &gt; datetime.now() - timedelta(days=365)\n]\n\nprint(f\"Found {len(recent_papers)} papers from the last year\")\n\n# Filter by category\nml_papers = [\n    p for p in papers\n    if any(cat.startswith('cs.LG') for cat in p['categories'])\n]\n\nprint(f\"Found {len(ml_papers)} machine learning papers\")\n</code></pre>"},{"location":"tutorials/collect-papers/#different-search-strategies","title":"Different Search Strategies","text":""},{"location":"tutorials/collect-papers/#1-arxiv-papers","title":"1. ArXiv Papers","text":"<p>Best for: Computer science, physics, mathematics, quantitative biology</p> <p>Search Tips: - Use specific technical terms: <code>\"attention mechanisms\"</code> instead of <code>\"AI\"</code> - Include category codes: <code>cat:cs.LG</code> for machine learning - Use Boolean operators: <code>machine learning AND interpretability</code> - Filter by date: <code>submittedDate:[20230101 TO 20231231]</code></p> <p>Example Searches: <pre><code># Specific subfield\npapers = paper_collector.collect_arxiv_papers(\n    \"cat:cs.CV AND (object detection OR semantic segmentation)\",\n    max_results=30\n)\n\n# Recent papers on a topic\npapers = paper_collector.collect_arxiv_papers(\n    \"large language models AND submittedDate:[20230101 TO *]\",\n    max_results=50\n)\n\n# Papers by specific author\npapers = paper_collector.collect_arxiv_papers(\n    \"au:Hinton AND cat:cs.LG\",\n    max_results=20\n)\n</code></pre></p>"},{"location":"tutorials/collect-papers/#2-semantic-scholar","title":"2. Semantic Scholar","text":"<p>Best for: Open access papers across all disciplines</p> <p>Search Tips: - Broader coverage than ArXiv - Automatically filters for open access PDFs - Good for interdisciplinary research</p> <p>Example: <pre><code># Collect from Semantic Scholar\npapers = paper_collector.collect_semantic_scholar(\n    \"climate change machine learning\",\n    max_results=30\n)\n\n# Filter for papers with PDFs\npapers_with_pdfs = [p for p in papers if p.get('pdf_url')]\n</code></pre></p>"},{"location":"tutorials/collect-papers/#3-pubmed-central","title":"3. PubMed Central","text":"<p>Best for: Biomedical and life sciences research</p> <p>Search Tips: - Use MeSH terms for better results - Filter for open access content - Combine with Boolean operators</p> <p>Example: <pre><code># Collect biomedical papers\npapers = paper_collector.collect_pubmed_central(\n    \"CRISPR gene editing\",\n    max_results=25\n)\n\n# Search with MeSH terms\npapers = paper_collector.collect_pubmed_central(\n    '\"Machine Learning\"[MeSH] AND \"Cancer\"[MeSH]',\n    max_results=30\n)\n</code></pre></p>"},{"location":"tutorials/collect-papers/#4-combined-strategy","title":"4. Combined Strategy","text":"<p>Collect from multiple sources:</p> <pre><code>from multi_modal_rag.data_collectors.paper_collector import AcademicPaperCollector\n\ncollector = AcademicPaperCollector()\nall_papers = []\n\n# Collect from ArXiv\narxiv_papers = collector.collect_arxiv_papers(\"neural networks\", 20)\nall_papers.extend(arxiv_papers)\n\n# Collect from Semantic Scholar\nss_papers = collector.collect_semantic_scholar(\"neural networks\", 20)\nall_papers.extend(ss_papers)\n\n# Collect from PubMed Central (if biomedical topic)\npmc_papers = collector.collect_pubmed_central(\"neural networks medical imaging\", 15)\nall_papers.extend(pmc_papers)\n\n# Deduplicate by title\nunique_papers = []\nseen_titles = set()\n\nfor paper in all_papers:\n    title = paper['title'].lower().strip()\n    if title not in seen_titles:\n        unique_papers.append(paper)\n        seen_titles.add(title)\n\nprint(f\"Collected {len(unique_papers)} unique papers from {len(all_papers)} total\")\n</code></pre>"},{"location":"tutorials/collect-papers/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/collect-papers/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"tutorials/collect-papers/#issue-1-no-papers-collected","title":"Issue 1: No Papers Collected","text":"<p>Symptoms: <pre><code>Collected 0 papers\n</code></pre></p> <p>Solutions: 1. Check your query: Make it more general    <pre><code># Too specific\npapers = collector.collect_arxiv_papers(\"very specific rare topic XYZ123\", 50)\n\n# Better\npapers = collector.collect_arxiv_papers(\"machine learning\", 50)\n</code></pre></p> <ol> <li> <p>Verify internet connection: ArXiv requires network access    <pre><code>curl https://arxiv.org\n</code></pre></p> </li> <li> <p>Check for API rate limits: Add delays between requests    <pre><code>import time\ntime.sleep(3)  # Wait 3 seconds between collections\n</code></pre></p> </li> </ol>"},{"location":"tutorials/collect-papers/#issue-2-opensearch-not-available","title":"Issue 2: OpenSearch Not Available","text":"<p>Symptoms: <pre><code>Cannot index document - OpenSearch not connected\n</code></pre></p> <p>Solutions: 1. Start OpenSearch: <pre><code>docker run -p 9200:9200 -e \"discovery.type=single-node\" opensearchproject/opensearch:latest\n</code></pre></p> <ol> <li> <p>Verify OpenSearch is running: <pre><code>curl http://localhost:9200\n</code></pre></p> </li> <li> <p>Check your .env file: <pre><code>OPENSEARCH_HOST=localhost\nOPENSEARCH_PORT=9200\n</code></pre></p> </li> </ol>"},{"location":"tutorials/collect-papers/#issue-3-pdf-download-failures","title":"Issue 3: PDF Download Failures","text":"<p>Symptoms: <pre><code>Error downloading PDF for paper: Connection timeout\n</code></pre></p> <p>Solutions: 1. Increase timeout in paper_collector.py: <pre><code>result.download_pdf(dirpath=self.save_dir, timeout=120)\n</code></pre></p> <ol> <li> <p>Skip PDFs and index metadata only: <pre><code># Don't download PDFs, just index metadata\nfor result in search.results():\n    paper_data = {\n        'title': result.title,\n        'abstract': result.summary,\n        # ... other metadata\n        'local_path': None  # Skip PDF download\n    }\n    papers.append(paper_data)\n</code></pre></p> </li> <li> <p>Check disk space: <pre><code>df -h data/papers/\n</code></pre></p> </li> </ol>"},{"location":"tutorials/collect-papers/#issue-4-duplicate-papers","title":"Issue 4: Duplicate Papers","text":"<p>Symptoms: Multiple copies of the same paper in search results</p> <p>Solutions: 1. Implement deduplication: <pre><code>def deduplicate_papers(papers):\n    seen = set()\n    unique = []\n\n    for paper in papers:\n        # Use arxiv_id or URL as unique identifier\n        identifier = paper.get('arxiv_id') or paper.get('pdf_url')\n\n        if identifier and identifier not in seen:\n            seen.add(identifier)\n            unique.append(paper)\n\n    return unique\n\npapers = deduplicate_papers(collected_papers)\n</code></pre></p> <ol> <li>Check database for existing entries: <pre><code>from multi_modal_rag.database import CollectionDatabaseManager\n\ndb = CollectionDatabaseManager()\n\n# Before adding, check if URL exists\nexisting = db.search_collections(paper['pdf_url'], limit=1)\nif not existing:\n    # Add paper\n    pass\n</code></pre></li> </ol>"},{"location":"tutorials/collect-papers/#issue-5-memory-issues-with-large-collections","title":"Issue 5: Memory Issues with Large Collections","text":"<p>Symptoms: <pre><code>MemoryError: Unable to allocate array\n</code></pre></p> <p>Solutions: 1. Process papers in batches: <pre><code>batch_size = 10\ntotal_papers = 100\n\nfor i in range(0, total_papers, batch_size):\n    batch_papers = collector.collect_arxiv_papers(\n        query,\n        max_results=min(batch_size, total_papers - i)\n    )\n\n    # Process batch\n    opensearch_manager.bulk_index('research_assistant', batch_papers)\n\n    # Clear memory\n    del batch_papers\n</code></pre></p> <ol> <li>Reduce embedding model memory: <pre><code># Use smaller model\nfrom sentence_transformers import SentenceTransformer\nmodel = SentenceTransformer('all-MiniLM-L6-v2')  # Smaller, faster\n</code></pre></li> </ol>"},{"location":"tutorials/collect-papers/#issue-6-slow-collection","title":"Issue 6: Slow Collection","text":"<p>Symptoms: Collecting papers takes a very long time</p> <p>Solutions: 1. Reduce max_results: <pre><code># Instead of\npapers = collector.collect_arxiv_papers(query, max_results=100)\n\n# Try\npapers = collector.collect_arxiv_papers(query, max_results=20)\n</code></pre></p> <ol> <li> <p>Skip PDF processing (index metadata only): <pre><code># Modify collection to skip downloads\nfor result in search.results():\n    # Don't call result.download_pdf()\n    papers.append(metadata_only)\n</code></pre></p> </li> <li> <p>Use parallel processing: <pre><code>from concurrent.futures import ThreadPoolExecutor\n\ndef collect_batch(query_batch):\n    return collector.collect_arxiv_papers(query_batch, 10)\n\nqueries = [\"ML topic 1\", \"ML topic 2\", \"ML topic 3\"]\n\nwith ThreadPoolExecutor(max_workers=3) as executor:\n    results = list(executor.map(collect_batch, queries))\n</code></pre></p> </li> </ol>"},{"location":"tutorials/collect-papers/#getting-help","title":"Getting Help","text":"<p>If you encounter issues not covered here:</p> <ol> <li> <p>Check the logs: <pre><code>tail -f logs/research_assistant_YYYYMMDD_HHMMSS.log\n</code></pre></p> </li> <li> <p>Enable debug logging:    Edit <code>multi_modal_rag/logging_config.py</code> and set level to <code>DEBUG</code></p> </li> <li> <p>Test components individually: <pre><code># Test collector\nfrom multi_modal_rag.data_collectors.paper_collector import AcademicPaperCollector\ncollector = AcademicPaperCollector()\npapers = collector.collect_arxiv_papers(\"test\", 1)\nprint(papers)\n\n# Test OpenSearch\nfrom multi_modal_rag.indexing.opensearch_manager import OpenSearchManager\nmanager = OpenSearchManager()\nprint(manager.connected)\n</code></pre></p> </li> <li> <p>Check database integrity: <pre><code>from multi_modal_rag.database import CollectionDatabaseManager\ndb = CollectionDatabaseManager()\nstats = db.get_statistics()\nprint(stats)\n</code></pre></p> </li> </ol>"},{"location":"tutorials/collect-papers/#best-practices","title":"Best Practices","text":"<ol> <li>Start Small: Begin with 10-20 papers to test your setup</li> <li>Use Specific Queries: More specific queries yield better results</li> <li>Monitor Resources: Watch disk space and memory usage</li> <li>Regular Backups: Backup your <code>data/</code> directory regularly</li> <li>Respect APIs: Use appropriate delays between requests</li> <li>Verify Indexing: Always check that papers are indexed successfully</li> <li>Track Collections: Use the database to avoid duplicate collections</li> </ol>"},{"location":"tutorials/collect-papers/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Custom Searches to query your collected papers</li> <li>Explore Exporting Citations for research writing</li> <li>Check Visualization Dashboard to analyze your collection</li> <li>Read Extending the System to add new data sources</li> </ul>"},{"location":"tutorials/custom-searches/","title":"Tutorial: Custom Searches and Advanced Queries","text":"<p>This tutorial teaches you how to perform advanced searches using the Multi-Modal Academic Research System. You'll learn about query syntax, field boosting, filters, OpenSearch DSL, and optimizing search relevance.</p>"},{"location":"tutorials/custom-searches/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Basic Search Concepts</li> <li>Advanced Query Syntax</li> <li>Field Boosting</li> <li>Combining Filters</li> <li>OpenSearch Query DSL</li> <li>Optimizing Search Relevance</li> <li>Practical Examples</li> </ol>"},{"location":"tutorials/custom-searches/#basic-search-concepts","title":"Basic Search Concepts","text":""},{"location":"tutorials/custom-searches/#how-search-works","title":"How Search Works","text":"<p>The system uses hybrid search combining:</p> <ol> <li>Keyword Matching (BM25): Traditional text search</li> <li>Semantic Similarity: Embedding-based similarity using SentenceTransformer</li> <li>Field Weighting: Different fields have different importance</li> </ol>"},{"location":"tutorials/custom-searches/#searchable-fields","title":"Searchable Fields","text":"<p>When you search, the system looks through these fields:</p> <ul> <li><code>title</code> (3x weight): Paper/video/podcast title</li> <li><code>abstract</code> (2x weight): Paper abstract or description</li> <li><code>content</code>: Full text content</li> <li><code>transcript</code>: Video/podcast transcripts</li> <li><code>key_concepts</code> (2x weight): Extracted concepts</li> <li><code>authors</code>: Author names</li> <li><code>metadata</code>: Additional metadata fields</li> </ul>"},{"location":"tutorials/custom-searches/#simple-search-examples","title":"Simple Search Examples","text":"<p>Using the Gradio UI Research tab:</p> <pre><code>Query: \"machine learning transformers\"\nResult: Searches across all fields, prioritizing title matches\n</code></pre> <pre><code>Query: \"attention mechanisms in neural networks\"\nResult: Semantic search finds related papers even with different wording\n</code></pre>"},{"location":"tutorials/custom-searches/#advanced-query-syntax","title":"Advanced Query Syntax","text":""},{"location":"tutorials/custom-searches/#boolean-operators","title":"Boolean Operators","text":"<p>Combine terms using Boolean logic:</p> <p>AND operator: <pre><code>machine learning AND transformers\n</code></pre> Both terms must appear in the document.</p> <p>OR operator: <pre><code>transformers OR attention mechanisms\n</code></pre> Either term can appear in the document.</p> <p>NOT operator: <pre><code>neural networks NOT convolutional\n</code></pre> Excludes documents containing \"convolutional\".</p> <p>Grouping with parentheses: <pre><code>(deep learning OR neural networks) AND (computer vision OR image recognition)\n</code></pre></p>"},{"location":"tutorials/custom-searches/#phrase-matching","title":"Phrase Matching","text":"<p>Search for exact phrases using quotes:</p> <p><pre><code>\"attention is all you need\"\n</code></pre> Matches only documents containing this exact phrase.</p> <p><pre><code>\"generative adversarial network\"\n</code></pre> More precise than individual words.</p>"},{"location":"tutorials/custom-searches/#wildcards","title":"Wildcards","text":"<p>Use wildcards for pattern matching:</p> <p>Asterisk (*): Matches any characters <pre><code>transform*\n</code></pre> Matches: transformer, transformers, transformation, transformed</p> <p>Question mark (?): Matches single character <pre><code>neural networ?\n</code></pre> Matches: neural network (typo tolerance)</p>"},{"location":"tutorials/custom-searches/#fuzzy-search","title":"Fuzzy Search","text":"<p>Handle typos and variations:</p> <p><pre><code>transformer~\n</code></pre> Finds similar words like: transformers, transformer, transformed</p> <p>Specify edit distance: <pre><code>transformer~2\n</code></pre> Allows up to 2 character differences.</p>"},{"location":"tutorials/custom-searches/#range-queries","title":"Range Queries","text":"<p>Search within date or numeric ranges:</p> <p>Date ranges: <pre><code>publication_date:[2023-01-01 TO 2023-12-31]\n</code></pre></p> <p>Numeric ranges: <pre><code>views:[1000 TO *]\n</code></pre> Videos with 1000+ views.</p>"},{"location":"tutorials/custom-searches/#field-boosting","title":"Field Boosting","text":"<p>Boost importance of specific fields in your searches.</p>"},{"location":"tutorials/custom-searches/#default-field-weights","title":"Default Field Weights","text":"<p>The system uses these default weights: - <code>title</code>: 3x - <code>abstract</code>: 2x - <code>key_concepts</code>: 2x - <code>content</code>: 1x - <code>transcript</code>: 1x</p>"},{"location":"tutorials/custom-searches/#custom-field-boosting","title":"Custom Field Boosting","text":"<p>Search specific fields with custom weights using Python API:</p> <pre><code>from multi_modal_rag.indexing.opensearch_manager import OpenSearchManager\n\nmanager = OpenSearchManager()\n\n# Custom search query\nsearch_query = {\n    'query': {\n        'multi_match': {\n            'query': 'deep learning',\n            'fields': [\n                'title^5',        # 5x weight on title\n                'abstract^3',     # 3x weight on abstract\n                'content^1',      # 1x weight on content\n                'key_concepts^4'  # 4x weight on concepts\n            ],\n            'type': 'best_fields'\n        }\n    },\n    'size': 20\n}\n\nresults = manager.client.search(\n    index='research_assistant',\n    body=search_query\n)\n</code></pre>"},{"location":"tutorials/custom-searches/#field-specific-searches","title":"Field-Specific Searches","text":"<p>Search only in specific fields:</p> <pre><code># Search only in titles\nsearch_query = {\n    'query': {\n        'match': {\n            'title': {\n                'query': 'transformers',\n                'boost': 1.0\n            }\n        }\n    }\n}\n\n# Search only in abstracts\nsearch_query = {\n    'query': {\n        'match': {\n            'abstract': 'attention mechanisms'\n        }\n    }\n}\n\n# Search only in transcripts (for videos)\nsearch_query = {\n    'query': {\n        'match': {\n            'transcript': 'neural network architectures'\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#combining-multiple-fields","title":"Combining Multiple Fields","text":"<pre><code># Title must match, abstract should match\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'title': 'transformer'}}\n            ],\n            'should': [\n                {'match': {'abstract': 'attention mechanisms'}}\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#combining-filters","title":"Combining Filters","text":"<p>Filters narrow down results without affecting relevance scores.</p>"},{"location":"tutorials/custom-searches/#content-type-filters","title":"Content Type Filters","text":"<p>Filter by content type (paper, video, podcast):</p> <pre><code># Only papers\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'multi_match': {'query': 'machine learning', 'fields': ['title', 'abstract']}}\n            ],\n            'filter': [\n                {'term': {'content_type': 'paper'}}\n            ]\n        }\n    }\n}\n\n# Only videos\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'multi_match': {'query': 'deep learning tutorial', 'fields': ['title', 'transcript']}}\n            ],\n            'filter': [\n                {'term': {'content_type': 'video'}}\n            ]\n        }\n    }\n}\n\n# Papers or videos (exclude podcasts)\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'title': 'neural networks'}}\n            ],\n            'filter': [\n                {'terms': {'content_type': ['paper', 'video']}}\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#date-filters","title":"Date Filters","text":"<p>Filter by publication date:</p> <pre><code># Papers from last year\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'title': 'transformers'}}\n            ],\n            'filter': [\n                {\n                    'range': {\n                        'publication_date': {\n                            'gte': '2023-01-01',\n                            'lte': '2023-12-31'\n                        }\n                    }\n                }\n            ]\n        }\n    }\n}\n\n# Recent papers (last 6 months)\nfrom datetime import datetime, timedelta\n\nsix_months_ago = (datetime.now() - timedelta(days=180)).isoformat()\n\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'content': 'deep learning'}}\n            ],\n            'filter': [\n                {\n                    'range': {\n                        'publication_date': {\n                            'gte': six_months_ago\n                        }\n                    }\n                }\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#author-filters","title":"Author Filters","text":"<p>Filter by specific authors:</p> <pre><code># Papers by specific author\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'content': 'attention mechanisms'}}\n            ],\n            'filter': [\n                {'term': {'authors': 'Vaswani'}}\n            ]\n        }\n    }\n}\n\n# Multiple authors\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'title': 'transformers'}}\n            ],\n            'filter': [\n                {'terms': {'authors': ['Vaswani', 'Hinton', 'Bengio']}}\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#category-filters","title":"Category Filters","text":"<p>Filter by ArXiv categories or tags:</p> <pre><code># Machine learning papers\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match': {'title': 'neural networks'}}\n            ],\n            'filter': [\n                {'term': {'metadata.categories': 'cs.LG'}}\n            ]\n        }\n    }\n}\n\n# Multiple categories\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {'match_all': {}}\n            ],\n            'filter': [\n                {\n                    'terms': {\n                        'metadata.categories': ['cs.LG', 'cs.AI', 'cs.CV']\n                    }\n                }\n            ]\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#combining-multiple-filters","title":"Combining Multiple Filters","text":"<pre><code># Papers from 2023, in computer vision, with high relevance\nsearch_query = {\n    'query': {\n        'bool': {\n            'must': [\n                {\n                    'multi_match': {\n                        'query': 'object detection',\n                        'fields': ['title^3', 'abstract^2', 'content']\n                    }\n                }\n            ],\n            'filter': [\n                {'term': {'content_type': 'paper'}},\n                {\n                    'range': {\n                        'publication_date': {\n                            'gte': '2023-01-01',\n                            'lte': '2023-12-31'\n                        }\n                    }\n                },\n                {'term': {'metadata.categories': 'cs.CV'}}\n            ]\n        }\n    },\n    'size': 50\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#opensearch-query-dsl","title":"OpenSearch Query DSL","text":"<p>For maximum control, use OpenSearch Query DSL directly.</p>"},{"location":"tutorials/custom-searches/#basic-structure","title":"Basic Structure","text":"<pre><code>from multi_modal_rag.indexing.opensearch_manager import OpenSearchManager\n\nmanager = OpenSearchManager()\n\nquery_dsl = {\n    'query': {\n        # Query goes here\n    },\n    'size': 10,           # Number of results\n    'from': 0,            # Offset for pagination\n    'sort': [],           # Sorting criteria\n    '_source': []         # Fields to return\n}\n\nresults = manager.client.search(\n    index='research_assistant',\n    body=query_dsl\n)\n</code></pre>"},{"location":"tutorials/custom-searches/#match-query","title":"Match Query","text":"<p>Simple text matching:</p> <pre><code>query_dsl = {\n    'query': {\n        'match': {\n            'title': {\n                'query': 'machine learning',\n                'operator': 'and',  # Both words must appear\n                'fuzziness': 'AUTO'  # Allow typos\n            }\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#multi-match-query","title":"Multi-Match Query","text":"<p>Search across multiple fields:</p> <pre><code>query_dsl = {\n    'query': {\n        'multi_match': {\n            'query': 'deep learning neural networks',\n            'fields': ['title^3', 'abstract^2', 'content'],\n            'type': 'best_fields',  # Use best matching field\n            'tie_breaker': 0.3,      # Consider other fields\n            'minimum_should_match': '75%'\n        }\n    }\n}\n</code></pre> <p>Match types: - <code>best_fields</code>: Use highest scoring field (default) - <code>most_fields</code>: Combine scores from all fields - <code>cross_fields</code>: Treat fields as one big field - <code>phrase</code>: Match as phrase across fields</p>"},{"location":"tutorials/custom-searches/#bool-query","title":"Bool Query","text":"<p>Combine multiple query clauses:</p> <pre><code>query_dsl = {\n    'query': {\n        'bool': {\n            'must': [\n                # Must match all of these\n                {'match': {'title': 'transformers'}}\n            ],\n            'should': [\n                # Should match some of these (boosts score)\n                {'match': {'abstract': 'attention'}},\n                {'match': {'content': 'self-attention'}}\n            ],\n            'must_not': [\n                # Must not match any of these\n                {'match': {'content': 'deprecated'}}\n            ],\n            'filter': [\n                # Must match but doesn't affect score\n                {'term': {'content_type': 'paper'}},\n                {'range': {'publication_date': {'gte': '2023-01-01'}}}\n            ],\n            'minimum_should_match': 1  # At least 1 should clause\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#boosting-queries","title":"Boosting Queries","text":"<p>Boost or demote documents:</p> <pre><code>query_dsl = {\n    'query': {\n        'boosting': {\n            'positive': {\n                # Boost documents matching this\n                'match': {'title': 'neural networks'}\n            },\n            'negative': {\n                # Demote documents matching this\n                'match': {'content': 'outdated'}\n            },\n            'negative_boost': 0.3  # Reduce score to 30%\n        }\n    }\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#aggregations","title":"Aggregations","text":"<p>Get statistics about your search results:</p> <pre><code>query_dsl = {\n    'query': {\n        'match_all': {}\n    },\n    'size': 0,  # Don't return documents\n    'aggs': {\n        'by_content_type': {\n            'terms': {\n                'field': 'content_type',\n                'size': 10\n            }\n        },\n        'by_year': {\n            'date_histogram': {\n                'field': 'publication_date',\n                'calendar_interval': 'year'\n            }\n        },\n        'by_author': {\n            'terms': {\n                'field': 'authors',\n                'size': 20\n            }\n        }\n    }\n}\n\nresults = manager.client.search(index='research_assistant', body=query_dsl)\naggregations = results['aggregations']\n</code></pre>"},{"location":"tutorials/custom-searches/#sorting","title":"Sorting","text":"<p>Custom sort order:</p> <pre><code>query_dsl = {\n    'query': {\n        'match': {'title': 'machine learning'}\n    },\n    'sort': [\n        {'publication_date': {'order': 'desc'}},  # Newest first\n        {'_score': {'order': 'desc'}},             # Then by relevance\n        {'title.keyword': {'order': 'asc'}}        # Then alphabetically\n    ]\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#highlighting","title":"Highlighting","text":"<p>Highlight matching terms in results:</p> <pre><code>query_dsl = {\n    'query': {\n        'match': {'content': 'neural networks'}\n    },\n    'highlight': {\n        'fields': {\n            'content': {\n                'fragment_size': 150,\n                'number_of_fragments': 3,\n                'pre_tags': ['&lt;strong&gt;'],\n                'post_tags': ['&lt;/strong&gt;']\n            }\n        }\n    }\n}\n\nresults = manager.client.search(index='research_assistant', body=query_dsl)\nfor hit in results['hits']['hits']:\n    if 'highlight' in hit:\n        print(hit['highlight']['content'])\n</code></pre>"},{"location":"tutorials/custom-searches/#optimizing-search-relevance","title":"Optimizing Search Relevance","text":""},{"location":"tutorials/custom-searches/#tuning-the-hybrid-search","title":"Tuning the Hybrid Search","text":"<p>Modify the hybrid search in <code>opensearch_manager.py</code>:</p> <pre><code>def custom_hybrid_search(self, index_name: str, query: str, k: int = 10) -&gt; List[Dict]:\n    \"\"\"Custom hybrid search with adjusted weights\"\"\"\n\n    # Generate query embedding\n    query_embedding = self.embedding_model.encode(query).tolist()\n\n    search_query = {\n        'size': k,\n        'query': {\n            'bool': {\n                'should': [\n                    # Text search with custom weights\n                    {\n                        'multi_match': {\n                            'query': query,\n                            'fields': [\n                                'title^5',           # Increase title weight\n                                'abstract^3',        # Increase abstract weight\n                                'key_concepts^4',    # Increase concepts weight\n                                'content^1',\n                                'transcript^1'\n                            ],\n                            'type': 'best_fields',\n                            'tie_breaker': 0.3,\n                            'fuzziness': 'AUTO'\n                        },\n                        'boost': 1.0  # Text search weight\n                    },\n                    # Add vector search if needed\n                ]\n            }\n        }\n    }\n\n    response = self.client.search(index=index_name, body=search_query)\n    return [{'score': hit['_score'], 'source': hit['_source']}\n            for hit in response['hits']['hits']]\n</code></pre>"},{"location":"tutorials/custom-searches/#relevance-tuning-tips","title":"Relevance Tuning Tips","text":"<p>1. Adjust field weights based on your use case:</p> <p>For technical papers: <pre><code>'fields': ['abstract^4', 'title^3', 'key_concepts^3', 'content^1']\n</code></pre></p> <p>For finding specific concepts: <pre><code>'fields': ['key_concepts^5', 'title^2', 'abstract^2', 'content^1']\n</code></pre></p> <p>For broad topic search: <pre><code>'fields': ['title^2', 'abstract^2', 'content^2', 'transcript^2']\n</code></pre></p> <p>2. Use minimum_should_match:</p> <pre><code>'multi_match': {\n    'query': 'machine learning neural networks deep',\n    'fields': ['title', 'abstract'],\n    'minimum_should_match': '75%'  # Match at least 3 of 4 words\n}\n</code></pre> <p>3. Enable fuzzy matching for typo tolerance:</p> <pre><code>'match': {\n    'title': {\n        'query': 'transformr',  # Typo\n        'fuzziness': 'AUTO'\n    }\n}\n</code></pre> <p>4. Use phrase matching for exact terms:</p> <pre><code>'bool': {\n    'must': [\n        {'match_phrase': {'title': 'attention is all you need'}}\n    ]\n}\n</code></pre>"},{"location":"tutorials/custom-searches/#re-ranking-results","title":"Re-ranking Results","text":"<p>Implement custom re-ranking logic:</p> <pre><code>from multi_modal_rag.indexing.opensearch_manager import OpenSearchManager\n\ndef rerank_results(results, query, boost_recent=True):\n    \"\"\"Custom re-ranking function\"\"\"\n    from datetime import datetime\n\n    reranked = []\n\n    for result in results:\n        score = result['score']\n        source = result['source']\n\n        # Boost recent papers\n        if boost_recent and 'publication_date' in source:\n            pub_date = datetime.fromisoformat(source['publication_date'])\n            days_old = (datetime.now() - pub_date).days\n\n            # Boost papers less than 1 year old\n            if days_old &lt; 365:\n                recency_boost = 1.0 + (365 - days_old) / 365 * 0.5\n                score *= recency_boost\n\n        # Boost papers with more authors (collaborative work)\n        if 'authors' in source and len(source['authors']) &gt; 3:\n            score *= 1.1\n\n        # Boost papers with key concepts matching query terms\n        if 'key_concepts' in source:\n            query_terms = set(query.lower().split())\n            concepts = set(c.lower() for c in source['key_concepts'])\n            overlap = len(query_terms &amp; concepts)\n            if overlap &gt; 0:\n                score *= 1.0 + (overlap * 0.1)\n\n        reranked.append({\n            'score': score,\n            'source': source\n        })\n\n    # Sort by new scores\n    reranked.sort(key=lambda x: x['score'], reverse=True)\n    return reranked\n\n# Usage\nmanager = OpenSearchManager()\nresults = manager.hybrid_search('research_assistant', 'machine learning', k=50)\nreranked = rerank_results(results, 'machine learning', boost_recent=True)\ntop_10 = reranked[:10]\n</code></pre>"},{"location":"tutorials/custom-searches/#practical-examples","title":"Practical Examples","text":""},{"location":"tutorials/custom-searches/#example-1-find-recent-papers-on-specific-topic","title":"Example 1: Find Recent Papers on Specific Topic","text":"<pre><code>from multi_modal_rag.indexing.opensearch_manager import OpenSearchManager\nfrom datetime import datetime, timedelta\n\nmanager = OpenSearchManager()\n\n# Search for papers from last 3 months\nthree_months_ago = (datetime.now() - timedelta(days=90)).isoformat()\n\nquery = {\n    'query': {\n        'bool': {\n            'must': [\n                {\n                    'multi_match': {\n                        'query': 'large language models',\n                        'fields': ['title^3', 'abstract^2', 'content'],\n                        'fuzziness': 'AUTO'\n                    }\n                }\n            ],\n            'filter': [\n                {'term': {'content_type': 'paper'}},\n                {\n                    'range': {\n                        'publication_date': {\n                            'gte': three_months_ago\n                        }\n                    }\n                }\n            ]\n        }\n    },\n    'sort': [\n        {'publication_date': {'order': 'desc'}},\n        {'_score': {'order': 'desc'}}\n    ],\n    'size': 20\n}\n\nresults = manager.client.search(index='research_assistant', body=query)\n\nprint(f\"Found {results['hits']['total']['value']} recent papers\")\nfor hit in results['hits']['hits']:\n    source = hit['_source']\n    print(f\"\\n{source['title']}\")\n    print(f\"Published: {source['publication_date']}\")\n    print(f\"Authors: {', '.join(source['authors'][:3])}\")\n</code></pre>"},{"location":"tutorials/custom-searches/#example-2-search-with-author-and-topic-filter","title":"Example 2: Search with Author and Topic Filter","text":"<pre><code># Find papers by specific author on a topic\nquery = {\n    'query': {\n        'bool': {\n            'must': [\n                {\n                    'multi_match': {\n                        'query': 'reinforcement learning',\n                        'fields': ['title', 'abstract']\n                    }\n                }\n            ],\n            'filter': [\n                {'term': {'authors': 'Sutton'}}\n            ]\n        }\n    }\n}\n\nresults = manager.client.search(index='research_assistant', body=query)\n</code></pre>"},{"location":"tutorials/custom-searches/#example-3-multi-source-search-papers-videos-podcasts","title":"Example 3: Multi-Source Search (Papers, Videos, Podcasts)","text":"<pre><code># Search across all content types, group by type\nquery = {\n    'query': {\n        'multi_match': {\n            'query': 'neural network architectures',\n            'fields': ['title^3', 'abstract^2', 'content', 'transcript']\n        }\n    },\n    'aggs': {\n        'by_type': {\n            'terms': {\n                'field': 'content_type'\n            },\n            'aggs': {\n                'top_by_type': {\n                    'top_hits': {\n                        'size': 5,\n                        'sort': [{'_score': {'order': 'desc'}}]\n                    }\n                }\n            }\n        }\n    },\n    'size': 30\n}\n\nresults = manager.client.search(index='research_assistant', body=query)\n\n# Extract top items per type\nfor bucket in results['aggregations']['by_type']['buckets']:\n    content_type = bucket['key']\n    count = bucket['doc_count']\n    top_items = bucket['top_by_type']['hits']['hits']\n\n    print(f\"\\n{content_type.upper()} ({count} total):\")\n    for item in top_items:\n        print(f\"  - {item['_source']['title']}\")\n</code></pre>"},{"location":"tutorials/custom-searches/#example-4-similarity-search","title":"Example 4: Similarity Search","text":"<p>Find papers similar to a specific paper:</p> <pre><code># Get a reference paper\nreference_query = {\n    'query': {\n        'match': {'title': 'Attention is All You Need'}\n    },\n    'size': 1\n}\n\nref_result = manager.client.search(index='research_assistant', body=reference_query)\nreference_paper = ref_result['hits']['hits'][0]['_source']\n\n# Search for similar papers using key concepts and abstract\nsimilar_query = {\n    'query': {\n        'more_like_this': {\n            'fields': ['abstract', 'key_concepts', 'content'],\n            'like': [\n                {\n                    '_index': 'research_assistant',\n                    '_id': ref_result['hits']['hits'][0]['_id']\n                }\n            ],\n            'min_term_freq': 1,\n            'max_query_terms': 25,\n            'min_doc_freq': 1\n        }\n    },\n    'size': 10\n}\n\nsimilar_results = manager.client.search(index='research_assistant', body=similar_query)\n\nprint(f\"Papers similar to '{reference_paper['title']}':\")\nfor hit in similar_results['hits']['hits']:\n    print(f\"  - {hit['_source']['title']} (score: {hit['_score']:.2f})\")\n</code></pre>"},{"location":"tutorials/custom-searches/#example-5-faceted-search","title":"Example 5: Faceted Search","text":"<pre><code># Faceted search with multiple filters\nquery = {\n    'query': {\n        'match': {'content': 'computer vision'}\n    },\n    'aggs': {\n        'content_types': {\n            'terms': {'field': 'content_type'}\n        },\n        'publication_years': {\n            'date_histogram': {\n                'field': 'publication_date',\n                'calendar_interval': 'year'\n            }\n        },\n        'top_authors': {\n            'terms': {\n                'field': 'authors',\n                'size': 10\n            }\n        },\n        'categories': {\n            'terms': {\n                'field': 'metadata.categories',\n                'size': 20\n            }\n        }\n    },\n    'size': 0  # Only get facets, not documents\n}\n\nresults = manager.client.search(index='research_assistant', body=query)\n\n# Display facets\nprint(\"Content Types:\")\nfor bucket in results['aggregations']['content_types']['buckets']:\n    print(f\"  {bucket['key']}: {bucket['doc_count']}\")\n\nprint(\"\\nTop Authors:\")\nfor bucket in results['aggregations']['top_authors']['buckets']:\n    print(f\"  {bucket['key']}: {bucket['doc_count']} papers\")\n</code></pre>"},{"location":"tutorials/custom-searches/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Exporting Citations for your research</li> <li>Explore Visualization Dashboard to analyze search patterns</li> <li>Check Extending the System to customize search behavior</li> <li>Review Collecting Papers to build your research database</li> </ul>"},{"location":"tutorials/export-citations/","title":"Tutorial: Exporting Citations","text":"<p>This tutorial shows you how to export citations from the Multi-Modal Academic Research System in various formats. You'll learn how to use the UI, programmatic export via Python, integrate with reference managers, and create custom citation formats.</p>"},{"location":"tutorials/export-citations/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Understanding Citation Tracking</li> <li>Exporting from the UI</li> <li>Programmatic Export via Python</li> <li>Citation Formats</li> <li>Integrating with Reference Managers</li> <li>Custom Citation Formats</li> <li>Advanced Usage</li> </ol>"},{"location":"tutorials/export-citations/#understanding-citation-tracking","title":"Understanding Citation Tracking","text":""},{"location":"tutorials/export-citations/#how-citations-are-tracked","title":"How Citations are Tracked","text":"<p>The system automatically tracks citations when you:</p> <ol> <li>Perform a research query - The orchestrator identifies sources used in responses</li> <li>View search results - Sources are logged with usage statistics</li> <li>Generate answers - Citations are extracted and stored</li> </ol>"},{"location":"tutorials/export-citations/#citation-storage","title":"Citation Storage","text":"<p>Citations are stored in: - Location: <code>data/citations.json</code> - Database: SQLite database for additional tracking - Format: JSON with metadata and usage history</p>"},{"location":"tutorials/export-citations/#citation-data-structure","title":"Citation Data Structure","text":"<pre><code>{\n  \"papers\": {\n    \"abc123def456\": {\n      \"title\": \"Attention is All You Need\",\n      \"authors\": [\"Vaswani\", \"Shazeer\", \"Parmar\"],\n      \"url\": \"https://arxiv.org/abs/1706.03762\",\n      \"first_used\": \"2024-01-15T10:30:00\",\n      \"use_count\": 5,\n      \"queries\": [\n        {\n          \"query\": \"transformer architecture\",\n          \"timestamp\": \"2024-01-15T10:30:00\"\n        }\n      ]\n    }\n  },\n  \"videos\": {},\n  \"podcasts\": {},\n  \"usage_history\": []\n}\n</code></pre>"},{"location":"tutorials/export-citations/#exporting-from-the-ui","title":"Exporting from the UI","text":""},{"location":"tutorials/export-citations/#step-1-access-citation-manager","title":"Step 1: Access Citation Manager","text":"<ol> <li> <p>Start the application:    <pre><code>python main.py\n</code></pre></p> </li> <li> <p>Open the web interface at <code>http://localhost:7860</code></p> </li> <li> <p>Click on the \"Citation Manager\" tab</p> </li> </ol>"},{"location":"tutorials/export-citations/#step-2-view-citation-report","title":"Step 2: View Citation Report","text":"<ol> <li> <p>Click \"Refresh Report\" to see your citation statistics</p> </li> <li> <p>Review the report showing:</p> </li> <li>Total papers, videos, and podcasts cited</li> <li>Most frequently cited sources</li> <li>Recent citations</li> </ol> <p>Example report: <pre><code>{\n  \"total_papers\": 25,\n  \"total_videos\": 8,\n  \"total_podcasts\": 3,\n  \"most_cited\": [\n    {\n      \"id\": \"abc123\",\n      \"type\": \"papers\",\n      \"title\": \"Attention is All You Need\",\n      \"use_count\": 12\n    }\n  ],\n  \"recent_citations\": [...]\n}\n</code></pre></p>"},{"location":"tutorials/export-citations/#step-3-choose-export-format","title":"Step 3: Choose Export Format","text":"<p>Select from available formats: - BibTeX - For LaTeX documents - APA - For Word documents and general use - JSON - For programmatic use or custom processing</p>"},{"location":"tutorials/export-citations/#step-4-export-citations","title":"Step 4: Export Citations","text":"<ol> <li>Select your desired format using the radio buttons</li> <li>Click \"Export Citations\"</li> <li>Copy the output from the text box</li> </ol> <p>BibTeX Output Example: <pre><code>@article{abc123def456,\n    title={Attention is All You Need},\n    author={Vaswani and Shazeer and Parmar},\n    year={2024},\n    url={https://arxiv.org/abs/1706.03762}\n}\n</code></pre></p> <p>APA Output Example: <pre><code>Vaswani et al. (2024). Attention is All You Need. Retrieved from https://arxiv.org/abs/1706.03762\n</code></pre></p>"},{"location":"tutorials/export-citations/#step-5-use-exported-citations","title":"Step 5: Use Exported Citations","text":"<p>For LaTeX: 1. Copy BibTeX output 2. Paste into your <code>.bib</code> file 3. Reference with <code>\\cite{citation_id}</code></p> <p>For Word: 1. Copy APA output 2. Paste into your document's references section 3. Use Word's citation manager to link references</p> <p>For Custom Processing: 1. Export as JSON 2. Process with your own scripts or tools</p>"},{"location":"tutorials/export-citations/#programmatic-export-via-python","title":"Programmatic Export via Python","text":""},{"location":"tutorials/export-citations/#basic-export-script","title":"Basic Export Script","text":"<p>Create a Python script to export citations:</p> <pre><code>from multi_modal_rag.orchestration.citation_tracker import CitationTracker\n\n# Initialize citation tracker\ntracker = CitationTracker()\n\n# Export in different formats\nbibtex = tracker.export_bibliography('bibtex')\napa = tracker.export_bibliography('apa')\njson_data = tracker.export_bibliography('json')\n\n# Save to files\nwith open('references.bib', 'w') as f:\n    f.write(bibtex)\n\nwith open('references_apa.txt', 'w') as f:\n    f.write(apa)\n\nwith open('citations.json', 'w') as f:\n    f.write(json_data)\n\nprint(\"Citations exported successfully!\")\n</code></pre>"},{"location":"tutorials/export-citations/#export-specific-citation-types","title":"Export Specific Citation Types","text":"<p>Export only papers, videos, or podcasts:</p> <pre><code>from multi_modal_rag.orchestration.citation_tracker import CitationTracker\nimport json\n\ntracker = CitationTracker()\n\n# Export only papers\npapers_only = {\n    'papers': tracker.citations['papers'],\n    'total': len(tracker.citations['papers'])\n}\n\nwith open('papers_only.json', 'w') as f:\n    json.dump(papers_only, f, indent=2)\n\n# Export only videos\nvideos_only = {\n    'videos': tracker.citations['videos'],\n    'total': len(tracker.citations['videos'])\n}\n\nwith open('videos_only.json', 'w') as f:\n    json.dump(videos_only, f, indent=2)\n</code></pre>"},{"location":"tutorials/export-citations/#export-most-cited-sources","title":"Export Most Cited Sources","text":"<pre><code>from multi_modal_rag.orchestration.citation_tracker import CitationTracker\n\ntracker = CitationTracker()\n\n# Get top 10 most cited sources\nmost_cited = tracker.get_most_cited(10)\n\n# Create BibTeX for top sources only\nbibtex_entries = []\n\nfor citation in most_cited:\n    citation_type = citation['type']\n    citation_id = citation['id']\n\n    # Get full citation data\n    if citation_type in tracker.citations:\n        full_data = tracker.citations[citation_type].get(citation_id)\n\n        if full_data:\n            entry = f\"\"\"@article{{{citation_id},\n    title={{{full_data['title']}}},\n    author={{{' and '.join(full_data.get('authors', ['Unknown']))}}},\n    year={{{full_data.get('first_used', '')[:4]}}},\n    url={{{full_data.get('url', '')}}},\n    note={{Cited {citation['use_count']} times}}\n}}\"\"\"\n            bibtex_entries.append(entry)\n\n# Save top citations\nwith open('top_citations.bib', 'w') as f:\n    f.write('\\n\\n'.join(bibtex_entries))\n\nprint(f\"Exported {len(bibtex_entries)} top citations\")\n</code></pre>"},{"location":"tutorials/export-citations/#export-by-date-range","title":"Export by Date Range","text":"<pre><code>from multi_modal_rag.orchestration.citation_tracker import CitationTracker\nfrom datetime import datetime, timedelta\n\ntracker = CitationTracker()\n\n# Get citations from last 30 days\nthirty_days_ago = datetime.now() - timedelta(days=30)\n\nrecent_citations = []\n\nfor entry in tracker.citations['usage_history']:\n    timestamp = datetime.fromisoformat(entry['timestamp'])\n\n    if timestamp &gt;= thirty_days_ago:\n        citation_id = entry['citation_id']\n        content_type = entry['content_type']\n\n        # Get full citation\n        citation_data = tracker.citations[f'{content_type}s'].get(citation_id)\n        if citation_data:\n            recent_citations.append({\n                'id': citation_id,\n                'type': content_type,\n                'data': citation_data,\n                'query': entry['query'],\n                'timestamp': entry['timestamp']\n            })\n\n# Export recent citations\nimport json\nwith open('recent_citations.json', 'w') as f:\n    json.dump(recent_citations, f, indent=2)\n\nprint(f\"Exported {len(recent_citations)} recent citations\")\n</code></pre>"},{"location":"tutorials/export-citations/#citation-formats","title":"Citation Formats","text":""},{"location":"tutorials/export-citations/#bibtex-format","title":"BibTeX Format","text":"<p>Used primarily with LaTeX documents.</p> <p>Standard Entry: <pre><code>@article{unique_id,\n    title={Paper Title},\n    author={Author1 and Author2 and Author3},\n    year={2024},\n    url={https://example.com/paper.pdf}\n}\n</code></pre></p> <p>Entry Types: - <code>@article</code> - Journal articles - <code>@inproceedings</code> - Conference papers - <code>@misc</code> - Videos, podcasts, other media</p> <p>Enhanced BibTeX Export:</p> <pre><code>def export_enhanced_bibtex(tracker):\n    \"\"\"Export BibTeX with more fields\"\"\"\n    bibtex = []\n\n    for cid, paper in tracker.citations['papers'].items():\n        # Determine entry type based on metadata\n        entry_type = 'article'\n        if 'conference' in str(paper.get('metadata', {})).lower():\n            entry_type = 'inproceedings'\n\n        entry = f\"\"\"@{entry_type}{{{cid},\n    title={{{paper['title']}}},\n    author={{{' and '.join(paper.get('authors', ['Unknown']))}}},\n    year={{{paper.get('first_used', '')[:4]}}},\n    url={{{paper.get('url', '')}}},\n    abstract={{{paper.get('abstract', 'N/A')}}},\n    keywords={{{', '.join(paper.get('key_concepts', []))}}},\n    note={{Used {paper['use_count']} times in research}}\n}}\"\"\"\n        bibtex.append(entry)\n\n    return '\\n\\n'.join(bibtex)\n</code></pre>"},{"location":"tutorials/export-citations/#apa-format","title":"APA Format","text":"<p>Used in academic writing, especially social sciences.</p> <p>Standard Format: <pre><code>Author, A. A., Author, B. B., &amp; Author, C. C. (Year). Title of article. Retrieved from URL\n</code></pre></p> <p>Enhanced APA Export:</p> <pre><code>def export_enhanced_apa(tracker):\n    \"\"\"Export APA format with proper formatting\"\"\"\n    apa = []\n\n    for paper in tracker.citations['papers'].values():\n        authors = paper.get('authors', ['Unknown'])\n        year = paper.get('first_used', '')[:4] or 'n.d.'\n\n        # Format authors (APA style)\n        if len(authors) == 1:\n            author_str = authors[0]\n        elif len(authors) == 2:\n            author_str = f\"{authors[0]} &amp; {authors[1]}\"\n        elif len(authors) &gt; 2:\n            author_str = f\"{authors[0]} et al.\"\n        else:\n            author_str = \"Unknown\"\n\n        # Get journal/conference if available\n        venue = paper.get('metadata', {}).get('venue', '')\n        venue_str = f\" {venue}.\" if venue else \"\"\n\n        citation = f\"{author_str} ({year}). {paper['title']}.{venue_str} Retrieved from {paper.get('url', 'N/A')}\"\n        apa.append(citation)\n\n    return '\\n\\n'.join(sorted(apa))\n\n# Usage\ntracker = CitationTracker()\napa_text = export_enhanced_apa(tracker)\nprint(apa_text)\n</code></pre>"},{"location":"tutorials/export-citations/#mla-format","title":"MLA Format","text":"<p>Modern Language Association format.</p> <p>Standard Format: <pre><code>Author(s). \"Title.\" Website/Source, Date, URL.\n</code></pre></p> <p>MLA Export Implementation:</p> <pre><code>def export_mla(tracker):\n    \"\"\"Export citations in MLA format\"\"\"\n    mla = []\n\n    for paper in tracker.citations['papers'].values():\n        authors = paper.get('authors', ['Unknown'])\n\n        # Format authors (MLA style)\n        if len(authors) == 1:\n            author_str = f\"{authors[0]}.\"\n        elif len(authors) == 2:\n            author_str = f\"{authors[0]} and {authors[1]}.\"\n        elif len(authors) &gt; 2:\n            author_str = f\"{authors[0]}, et al.\"\n        else:\n            author_str = \"Unknown.\"\n\n        # Format date\n        date_str = paper.get('first_used', '')[:10]  # YYYY-MM-DD\n\n        citation = f'{author_str} \"{paper[\"title\"]}.\" ArXiv, {date_str}, {paper.get(\"url\", \"N/A\")}.'\n        mla.append(citation)\n\n    return '\\n\\n'.join(sorted(mla))\n\n# Add to CitationTracker class\nfrom multi_modal_rag.orchestration.citation_tracker import CitationTracker\n\ntracker = CitationTracker()\nmla_text = export_mla(tracker)\n\nwith open('references_mla.txt', 'w') as f:\n    f.write(mla_text)\n</code></pre>"},{"location":"tutorials/export-citations/#chicago-format","title":"Chicago Format","text":"<p>Chicago Manual of Style format.</p> <pre><code>def export_chicago(tracker):\n    \"\"\"Export citations in Chicago format\"\"\"\n    chicago = []\n\n    for paper in tracker.citations['papers'].values():\n        authors = paper.get('authors', ['Unknown'])\n\n        # Format authors (Chicago style)\n        if len(authors) == 1:\n            author_str = f\"{authors[0]}\"\n        elif len(authors) &gt; 1:\n            author_str = f\"{authors[0]} et al.\"\n        else:\n            author_str = \"Unknown\"\n\n        year = paper.get('first_used', '')[:4] or 'n.d.'\n\n        citation = f'{author_str}. {year}. \"{paper[\"title\"]}.\" Accessed {paper.get(\"first_used\", \"\")[:10]}. {paper.get(\"url\", \"N/A\")}.'\n        chicago.append(citation)\n\n    return '\\n\\n'.join(sorted(chicago))\n</code></pre>"},{"location":"tutorials/export-citations/#integrating-with-reference-managers","title":"Integrating with Reference Managers","text":""},{"location":"tutorials/export-citations/#zotero-integration","title":"Zotero Integration","text":"<p>Export to Zotero-compatible format:</p> <pre><code>import json\n\ndef export_for_zotero(tracker):\n    \"\"\"Export in Zotero-compatible JSON format\"\"\"\n    zotero_items = []\n\n    for cid, paper in tracker.citations['papers'].items():\n        item = {\n            \"itemType\": \"journalArticle\",\n            \"title\": paper['title'],\n            \"creators\": [\n                {\"creatorType\": \"author\", \"name\": author}\n                for author in paper.get('authors', [])\n            ],\n            \"abstractNote\": paper.get('abstract', ''),\n            \"url\": paper.get('url', ''),\n            \"accessDate\": paper.get('first_used', ''),\n            \"tags\": [\n                {\"tag\": concept}\n                for concept in paper.get('key_concepts', [])\n            ],\n            \"notes\": [\n                {\"note\": f\"Used {paper['use_count']} times in research\"}\n            ]\n        }\n        zotero_items.append(item)\n\n    with open('zotero_import.json', 'w') as f:\n        json.dump(zotero_items, f, indent=2)\n\n    return len(zotero_items)\n\n# Usage\ntracker = CitationTracker()\ncount = export_for_zotero(tracker)\nprint(f\"Exported {count} items for Zotero\")\n</code></pre> <p>Import to Zotero: 1. Open Zotero 2. Go to File &gt; Import 3. Select <code>zotero_import.json</code> 4. Citations are added to your library</p>"},{"location":"tutorials/export-citations/#mendeley-integration","title":"Mendeley Integration","text":"<p>Export for Mendeley:</p> <pre><code>def export_for_mendeley(tracker):\n    \"\"\"Export BibTeX for Mendeley import\"\"\"\n    # Mendeley uses BibTeX format\n    bibtex = tracker.export_bibliography('bibtex')\n\n    with open('mendeley_import.bib', 'w') as f:\n        f.write(bibtex)\n\n    return \"mendeley_import.bib\"\n\n# Usage\ntracker = CitationTracker()\nfilename = export_for_mendeley(tracker)\nprint(f\"Import {filename} into Mendeley\")\n</code></pre> <p>Import to Mendeley: 1. Open Mendeley Desktop 2. Go to File &gt; Import &gt; BibTeX 3. Select <code>mendeley_import.bib</code></p>"},{"location":"tutorials/export-citations/#endnote-integration","title":"EndNote Integration","text":"<pre><code>def export_for_endnote(tracker):\n    \"\"\"Export in EndNote format (RIS)\"\"\"\n    ris_entries = []\n\n    for paper in tracker.citations['papers'].values():\n        entry = f\"\"\"TY  - JOUR\nTI  - {paper['title']}\n{\"\".join([f\"AU  - {author}\\n\" for author in paper.get('authors', [])])}PY  - {paper.get('first_used', '')[:4]}\nUR  - {paper.get('url', '')}\nAB  - {paper.get('abstract', '')}\nER  -\n\"\"\"\n        ris_entries.append(entry)\n\n    with open('endnote_import.ris', 'w') as f:\n        f.write('\\n'.join(ris_entries))\n\n    return len(ris_entries)\n\n# Usage\ntracker = CitationTracker()\ncount = export_for_endnote(tracker)\nprint(f\"Exported {count} citations for EndNote\")\n</code></pre>"},{"location":"tutorials/export-citations/#custom-citation-formats","title":"Custom Citation Formats","text":""},{"location":"tutorials/export-citations/#creating-custom-formats","title":"Creating Custom Formats","text":"<p>Add custom export methods to the CitationTracker:</p> <pre><code>from multi_modal_rag.orchestration.citation_tracker import CitationTracker\n\nclass CustomCitationTracker(CitationTracker):\n    \"\"\"Extended citation tracker with custom formats\"\"\"\n\n    def export_markdown(self) -&gt; str:\n        \"\"\"Export citations as markdown list\"\"\"\n        md = \"# Research Citations\\n\\n\"\n\n        # Papers section\n        if self.citations['papers']:\n            md += \"## Papers\\n\\n\"\n            for cid, paper in sorted(\n                self.citations['papers'].items(),\n                key=lambda x: x[1]['use_count'],\n                reverse=True\n            ):\n                authors = ', '.join(paper.get('authors', ['Unknown'])[:3])\n                if len(paper.get('authors', [])) &gt; 3:\n                    authors += \" et al.\"\n\n                md += f\"- **{paper['title']}**\\n\"\n                md += f\"  - Authors: {authors}\\n\"\n                md += f\"  - URL: [{paper.get('url', 'N/A')}]({paper.get('url', '#')})\\n\"\n                md += f\"  - Used {paper['use_count']} times\\n\\n\"\n\n        # Videos section\n        if self.citations['videos']:\n            md += \"## Videos\\n\\n\"\n            for cid, video in self.citations['videos'].items():\n                md += f\"- **{video['title']}**\\n\"\n                md += f\"  - Creator: {', '.join(video.get('authors', ['Unknown']))}\\n\"\n                md += f\"  - URL: [{video.get('url', 'N/A')}]({video.get('url', '#')})\\n\\n\"\n\n        # Podcasts section\n        if self.citations['podcasts']:\n            md += \"## Podcasts\\n\\n\"\n            for cid, podcast in self.citations['podcasts'].items():\n                md += f\"- **{podcast['title']}**\\n\"\n                md += f\"  - Host: {', '.join(podcast.get('authors', ['Unknown']))}\\n\"\n                md += f\"  - URL: [{podcast.get('url', 'N/A')}]({podcast.get('url', '#')})\\n\\n\"\n\n        return md\n\n    def export_html(self) -&gt; str:\n        \"\"\"Export citations as HTML\"\"\"\n        html = \"\"\"&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;title&gt;Research Citations&lt;/title&gt;\n    &lt;style&gt;\n        body { font-family: Arial, sans-serif; max-width: 800px; margin: 50px auto; }\n        h1 { color: #333; }\n        .citation { margin-bottom: 20px; padding: 10px; border-left: 3px solid #007bff; }\n        .title { font-weight: bold; font-size: 1.1em; }\n        .meta { color: #666; font-size: 0.9em; }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Research Citations&lt;/h1&gt;\n\"\"\"\n\n        for cid, paper in self.citations['papers'].items():\n            authors = ', '.join(paper.get('authors', ['Unknown'])[:3])\n            html += f\"\"\"\n    &lt;div class=\"citation\"&gt;\n        &lt;div class=\"title\"&gt;{paper['title']}&lt;/div&gt;\n        &lt;div class=\"meta\"&gt;\n            Authors: {authors}&lt;br&gt;\n            URL: &lt;a href=\"{paper.get('url', '#')}\"&gt;{paper.get('url', 'N/A')}&lt;/a&gt;&lt;br&gt;\n            Used {paper['use_count']} times\n        &lt;/div&gt;\n    &lt;/div&gt;\n\"\"\"\n\n        html += \"\"\"\n&lt;/body&gt;\n&lt;/html&gt;\n\"\"\"\n        return html\n\n    def export_csv(self) -&gt; str:\n        \"\"\"Export citations as CSV\"\"\"\n        import csv\n        from io import StringIO\n\n        output = StringIO()\n        writer = csv.writer(output)\n\n        # Header\n        writer.writerow(['Type', 'Title', 'Authors', 'URL', 'Use Count', 'First Used'])\n\n        # Papers\n        for paper in self.citations['papers'].values():\n            writer.writerow([\n                'Paper',\n                paper['title'],\n                '; '.join(paper.get('authors', [])),\n                paper.get('url', ''),\n                paper['use_count'],\n                paper.get('first_used', '')\n            ])\n\n        # Videos\n        for video in self.citations['videos'].values():\n            writer.writerow([\n                'Video',\n                video['title'],\n                '; '.join(video.get('authors', [])),\n                video.get('url', ''),\n                video['use_count'],\n                video.get('first_used', '')\n            ])\n\n        return output.getvalue()\n\n# Usage\ntracker = CustomCitationTracker()\n\n# Export as markdown\nmd = tracker.export_markdown()\nwith open('citations.md', 'w') as f:\n    f.write(md)\n\n# Export as HTML\nhtml = tracker.export_html()\nwith open('citations.html', 'w') as f:\n    f.write(html)\n\n# Export as CSV\ncsv_data = tracker.export_csv()\nwith open('citations.csv', 'w') as f:\n    f.write(csv_data)\n\nprint(\"Exported citations in markdown, HTML, and CSV formats\")\n</code></pre>"},{"location":"tutorials/export-citations/#advanced-usage","title":"Advanced Usage","text":""},{"location":"tutorials/export-citations/#filtered-export","title":"Filtered Export","text":"<p>Export only certain citations based on criteria:</p> <pre><code>from multi_modal_rag.orchestration.citation_tracker import CitationTracker\n\ndef export_filtered_citations(tracker, min_use_count=2, content_types=['papers']):\n    \"\"\"Export only frequently used citations\"\"\"\n    filtered = {\n        'papers': {},\n        'videos': {},\n        'podcasts': {}\n    }\n\n    for content_type in content_types:\n        type_key = f'{content_type}' if content_type.endswith('s') else f'{content_type}s'\n\n        for cid, citation in tracker.citations[type_key].items():\n            if citation['use_count'] &gt;= min_use_count:\n                filtered[type_key][cid] = citation\n\n    # Export to BibTeX\n    bibtex = []\n    for cid, paper in filtered['papers'].items():\n        entry = f\"\"\"@article{{{cid},\n    title={{{paper['title']}}},\n    author={{{' and '.join(paper.get('authors', ['Unknown']))}}},\n    year={{{paper.get('first_used', '')[:4]}}},\n    url={{{paper.get('url', '')}}}\n}}\"\"\"\n        bibtex.append(entry)\n\n    return '\\n\\n'.join(bibtex)\n\n# Usage\ntracker = CitationTracker()\nfrequently_cited = export_filtered_citations(tracker, min_use_count=3)\n\nwith open('frequently_cited.bib', 'w') as f:\n    f.write(frequently_cited)\n</code></pre>"},{"location":"tutorials/export-citations/#automated-export-workflow","title":"Automated Export Workflow","text":"<p>Create a script that automatically exports citations after each research session:</p> <pre><code>import os\nfrom datetime import datetime\nfrom multi_modal_rag.orchestration.citation_tracker import CitationTracker\n\ndef auto_export_citations():\n    \"\"\"Automatically export citations in multiple formats\"\"\"\n\n    tracker = CitationTracker()\n\n    # Create exports directory\n    export_dir = 'exports/citations'\n    os.makedirs(export_dir, exist_ok=True)\n\n    # Timestamp for versioning\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n\n    # Export in all formats\n    formats = {\n        'bibtex': tracker.export_bibliography('bibtex'),\n        'apa': tracker.export_bibliography('apa'),\n        'json': tracker.export_bibliography('json')\n    }\n\n    exported_files = []\n\n    for format_name, content in formats.items():\n        filename = f'{export_dir}/citations_{timestamp}.{format_name}'\n        if format_name == 'json':\n            filename = f'{export_dir}/citations_{timestamp}.json'\n        elif format_name == 'bibtex':\n            filename = f'{export_dir}/citations_{timestamp}.bib'\n        else:\n            filename = f'{export_dir}/citations_{timestamp}.txt'\n\n        with open(filename, 'w') as f:\n            f.write(content)\n\n        exported_files.append(filename)\n\n    # Also create a latest version (overwrite)\n    for format_name, content in formats.items():\n        latest_filename = f'{export_dir}/citations_latest.{format_name if format_name == \"json\" else \"bib\" if format_name == \"bibtex\" else \"txt\"}'\n        with open(latest_filename, 'w') as f:\n            f.write(content)\n\n        exported_files.append(latest_filename)\n\n    print(f\"Exported {len(formats)} citation formats:\")\n    for file in exported_files:\n        print(f\"  - {file}\")\n\n    return exported_files\n\n# Run automatic export\nif __name__ == '__main__':\n    auto_export_citations()\n</code></pre>"},{"location":"tutorials/export-citations/#citation-report-generation","title":"Citation Report Generation","text":"<p>Generate detailed citation reports:</p> <pre><code>from multi_modal_rag.orchestration.citation_tracker import CitationTracker\nfrom datetime import datetime\n\ndef generate_citation_report(tracker):\n    \"\"\"Generate comprehensive citation report\"\"\"\n\n    report = []\n    report.append(\"=\"*60)\n    report.append(\"CITATION USAGE REPORT\")\n    report.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    report.append(\"=\"*60)\n\n    # Summary statistics\n    total_papers = len(tracker.citations['papers'])\n    total_videos = len(tracker.citations['videos'])\n    total_podcasts = len(tracker.citations['podcasts'])\n    total_citations = total_papers + total_videos + total_podcasts\n\n    report.append(f\"\\nTOTAL CITATIONS: {total_citations}\")\n    report.append(f\"  Papers: {total_papers}\")\n    report.append(f\"  Videos: {total_videos}\")\n    report.append(f\"  Podcasts: {total_podcasts}\")\n\n    # Most cited sources\n    report.append(\"\\n\" + \"=\"*60)\n    report.append(\"TOP 10 MOST CITED SOURCES\")\n    report.append(\"=\"*60)\n\n    most_cited = tracker.get_most_cited(10)\n    for i, citation in enumerate(most_cited, 1):\n        report.append(f\"\\n{i}. {citation['title']}\")\n        report.append(f\"   Type: {citation['type']}\")\n        report.append(f\"   Citations: {citation['use_count']}\")\n\n    # Recent activity\n    report.append(\"\\n\" + \"=\"*60)\n    report.append(\"RECENT CITATION ACTIVITY (Last 10)\")\n    report.append(\"=\"*60)\n\n    recent = tracker.get_recent_citations(10)\n    for entry in recent:\n        report.append(f\"\\n{entry['timestamp']}\")\n        report.append(f\"  Query: {entry['query']}\")\n        report.append(f\"  Source: {entry['citation_id']}\")\n\n    return '\\n'.join(report)\n\n# Usage\ntracker = CitationTracker()\nreport = generate_citation_report(tracker)\n\nwith open('citation_report.txt', 'w') as f:\n    f.write(report)\n\nprint(report)\n</code></pre>"},{"location":"tutorials/export-citations/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Custom Searches to find more relevant sources</li> <li>Explore Visualization Dashboard to analyze citation patterns</li> <li>Check Extending the System to add custom citation formats</li> <li>Review Collecting Papers to expand your research database</li> </ul>"},{"location":"tutorials/extending/","title":"Tutorial: Extending the System","text":"<p>This tutorial teaches you how to extend and customize the Multi-Modal Academic Research System. You'll learn how to add new data collectors, create custom processors, modify the UI, add search filters, and contribute back to the project.</p>"},{"location":"tutorials/extending/#table-of-contents","title":"Table of Contents","text":"<ol> <li>System Architecture Overview</li> <li>Adding New Data Collectors</li> <li>Creating Custom Processors</li> <li>Modifying the UI</li> <li>Adding New Search Filters</li> <li>Contributing Back to the Project</li> </ol>"},{"location":"tutorials/extending/#system-architecture-overview","title":"System Architecture Overview","text":""},{"location":"tutorials/extending/#component-structure","title":"Component Structure","text":"<pre><code>multi_modal_rag/\n\u251c\u2500\u2500 data_collectors/      # Collect content from sources\n\u251c\u2500\u2500 data_processors/      # Process and extract information\n\u251c\u2500\u2500 indexing/            # OpenSearch indexing and search\n\u251c\u2500\u2500 orchestration/       # Query orchestration and citations\n\u251c\u2500\u2500 ui/                  # Gradio and web interfaces\n\u251c\u2500\u2500 api/                 # FastAPI endpoints\n\u2514\u2500\u2500 database/            # SQLite database management\n</code></pre>"},{"location":"tutorials/extending/#data-flow","title":"Data Flow","text":"<ol> <li>Collection - Data collectors fetch content</li> <li>Processing - Processors extract text, metadata, and insights</li> <li>Indexing - Content is indexed in OpenSearch</li> <li>Retrieval - Hybrid search retrieves relevant documents</li> <li>Generation - LLM generates answers with citations</li> </ol>"},{"location":"tutorials/extending/#key-design-principles","title":"Key Design Principles","text":"<ul> <li>Modularity: Each component is independent</li> <li>Extensibility: Easy to add new sources and processors</li> <li>Consistency: Standard interfaces for collectors and processors</li> <li>Robustness: Comprehensive error handling and logging</li> </ul>"},{"location":"tutorials/extending/#adding-new-data-collectors","title":"Adding New Data Collectors","text":""},{"location":"tutorials/extending/#data-collector-interface","title":"Data Collector Interface","text":"<p>All data collectors should follow this pattern:</p> <pre><code>from typing import List, Dict\nimport os\n\nclass BaseCollector:\n    \"\"\"Base class for data collectors\"\"\"\n\n    def __init__(self, save_dir: str = \"data/custom\"):\n        self.save_dir = save_dir\n        os.makedirs(save_dir, exist_ok=True)\n\n    def collect(self, query: str, max_results: int = 50) -&gt; List[Dict]:\n        \"\"\"\n        Collect data from source\n\n        Args:\n            query: Search query\n            max_results: Maximum number of results\n\n        Returns:\n            List of dictionaries with standardized fields:\n            - title: str\n            - content: str (or abstract, description)\n            - authors: List[str]\n            - url: str\n            - published: str (ISO format date)\n            - metadata: Dict (source-specific data)\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"tutorials/extending/#example-adding-a-blog-post-collector","title":"Example: Adding a Blog Post Collector","text":"<p>Create a new file: <code>multi_modal_rag/data_collectors/blog_collector.py</code></p> <pre><code>import requests\nfrom typing import List, Dict\nimport feedparser\nimport time\nfrom datetime import datetime\n\nclass BlogCollector:\n    \"\"\"Collect blog posts from RSS feeds\"\"\"\n\n    def __init__(self, save_dir: str = \"data/blogs\"):\n        self.save_dir = save_dir\n        os.makedirs(save_dir, exist_ok=True)\n\n    def collect_from_feed(self, feed_url: str, max_results: int = 20) -&gt; List[Dict]:\n        \"\"\"Collect posts from a single RSS feed\"\"\"\n\n        posts = []\n\n        try:\n            # Parse RSS feed\n            feed = feedparser.parse(feed_url)\n\n            for entry in feed.entries[:max_results]:\n                post_data = {\n                    'title': entry.get('title', 'Untitled'),\n                    'content': entry.get('summary', ''),\n                    'authors': [entry.get('author', 'Unknown')],\n                    'url': entry.get('link', ''),\n                    'published': entry.get('published', datetime.now().isoformat()),\n                    'metadata': {\n                        'feed_url': feed_url,\n                        'feed_title': feed.feed.get('title', ''),\n                        'tags': [tag.term for tag in entry.get('tags', [])]\n                    }\n                }\n\n                posts.append(post_data)\n\n            time.sleep(1)  # Be respectful\n\n        except Exception as e:\n            print(f\"Error collecting from {feed_url}: {e}\")\n\n        return posts\n\n    def collect_from_multiple_feeds(\n        self,\n        feed_urls: List[str],\n        max_per_feed: int = 10\n    ) -&gt; List[Dict]:\n        \"\"\"Collect from multiple RSS feeds\"\"\"\n\n        all_posts = []\n\n        for feed_url in feed_urls:\n            posts = self.collect_from_feed(feed_url, max_per_feed)\n            all_posts.extend(posts)\n\n        return all_posts\n\n    def get_ml_blogs(self) -&gt; Dict[str, str]:\n        \"\"\"Curated list of machine learning blogs\"\"\"\n        return {\n            'Google AI Blog': 'https://ai.googleblog.com/feeds/posts/default',\n            'OpenAI Blog': 'https://openai.com/blog/rss.xml',\n            'DeepMind Blog': 'https://deepmind.com/blog/feed/basic',\n            'Meta AI': 'https://ai.facebook.com/blog/rss/',\n            'Distill': 'https://distill.pub/rss.xml'\n        }\n\n    def collect_ml_blogs(self, max_per_blog: int = 5) -&gt; List[Dict]:\n        \"\"\"Collect posts from ML blogs\"\"\"\n\n        blogs = self.get_ml_blogs()\n        return self.collect_from_multiple_feeds(\n            list(blogs.values()),\n            max_per_blog\n        )\n</code></pre>"},{"location":"tutorials/extending/#example-adding-a-github-repository-collector","title":"Example: Adding a GitHub Repository Collector","text":"<pre><code>import requests\nfrom typing import List, Dict\nimport base64\nimport time\n\nclass GitHubCollector:\n    \"\"\"Collect content from GitHub repositories\"\"\"\n\n    def __init__(self, github_token: str = None):\n        self.token = github_token\n        self.headers = {}\n        if github_token:\n            self.headers['Authorization'] = f'token {github_token}'\n\n    def search_repositories(\n        self,\n        query: str,\n        max_results: int = 30\n    ) -&gt; List[Dict]:\n        \"\"\"Search GitHub repositories\"\"\"\n\n        repos = []\n        url = 'https://api.github.com/search/repositories'\n\n        params = {\n            'q': query,\n            'sort': 'stars',\n            'order': 'desc',\n            'per_page': min(max_results, 100)\n        }\n\n        try:\n            response = requests.get(url, params=params, headers=self.headers)\n            response.raise_for_status()\n            data = response.json()\n\n            for item in data.get('items', [])[:max_results]:\n                # Get README content\n                readme_content = self._get_readme(\n                    item['owner']['login'],\n                    item['name']\n                )\n\n                repo_data = {\n                    'title': f\"{item['full_name']}: {item['description'] or 'No description'}\",\n                    'content': readme_content,\n                    'authors': [item['owner']['login']],\n                    'url': item['html_url'],\n                    'published': item.get('created_at', ''),\n                    'metadata': {\n                        'stars': item['stargazers_count'],\n                        'forks': item['forks_count'],\n                        'language': item.get('language', 'Unknown'),\n                        'topics': item.get('topics', []),\n                        'updated_at': item.get('updated_at', '')\n                    }\n                }\n\n                repos.append(repo_data)\n\n                time.sleep(1)  # Rate limiting\n\n        except Exception as e:\n            print(f\"Error searching repositories: {e}\")\n\n        return repos\n\n    def _get_readme(self, owner: str, repo: str) -&gt; str:\n        \"\"\"Get README content from repository\"\"\"\n\n        url = f'https://api.github.com/repos/{owner}/{repo}/readme'\n\n        try:\n            response = requests.get(url, headers=self.headers)\n            response.raise_for_status()\n            data = response.json()\n\n            # Decode base64 content\n            content = base64.b64decode(data['content']).decode('utf-8')\n            return content\n\n        except Exception as e:\n            return f\"README not available: {e}\"\n</code></pre>"},{"location":"tutorials/extending/#registering-your-collector","title":"Registering Your Collector","text":"<p>Add your collector to <code>main.py</code>:</p> <pre><code>from multi_modal_rag.data_collectors.blog_collector import BlogCollector\nfrom multi_modal_rag.data_collectors.github_collector import GitHubCollector\n\n# In main() function\nblog_collector = BlogCollector()\ngithub_collector = GitHubCollector(github_token=os.getenv('GITHUB_TOKEN'))\n\ndata_collectors = {\n    'paper_collector': paper_collector,\n    'video_collector': video_collector,\n    'podcast_collector': podcast_collector,\n    'blog_collector': blog_collector,          # Add new collector\n    'github_collector': github_collector       # Add new collector\n}\n</code></pre> <p>Update the UI in <code>gradio_app.py</code>:</p> <pre><code># In create_interface() method\ncollection_type = gr.Radio(\n    [\"ArXiv Papers\", \"YouTube Lectures\", \"Podcasts\", \"Blog Posts\", \"GitHub Repos\"],\n    label=\"Data Source\"\n)\n</code></pre> <p>Add handling in <code>handle_data_collection()</code>:</p> <pre><code>elif source_type == \"Blog Posts\":\n    status_updates.append(\"Collecting blog posts...\")\n    posts = self.data_collectors['blog_collector'].collect_ml_blogs(max_results=max_results)\n    collected_items = posts\n    results['posts_collected'] = len(posts)\n    status_updates.append(f\"Collected {len(posts)} blog posts\")\n\nelif source_type == \"GitHub Repos\":\n    status_updates.append(\"Searching GitHub repositories...\")\n    repos = self.data_collectors['github_collector'].search_repositories(query, max_results)\n    collected_items = repos\n    results['repos_collected'] = len(repos)\n    status_updates.append(f\"Collected {len(repos)} repositories\")\n</code></pre>"},{"location":"tutorials/extending/#creating-custom-processors","title":"Creating Custom Processors","text":""},{"location":"tutorials/extending/#processor-interface","title":"Processor Interface","text":"<p>Processors transform raw content into searchable documents:</p> <pre><code>from typing import Dict, List\nimport os\n\nclass BaseProcessor:\n    \"\"\"Base class for data processors\"\"\"\n\n    def __init__(self, api_key: str = None):\n        self.api_key = api_key\n\n    def process(self, raw_data: Dict) -&gt; Dict:\n        \"\"\"\n        Process raw data into structured format\n\n        Args:\n            raw_data: Raw data from collector\n\n        Returns:\n            Processed document with fields:\n            - title: str\n            - content: str\n            - key_concepts: List[str]\n            - summary: str\n            - metadata: Dict\n        \"\"\"\n        raise NotImplementedError\n</code></pre>"},{"location":"tutorials/extending/#example-blog-post-processor","title":"Example: Blog Post Processor","text":"<p>Create <code>multi_modal_rag/data_processors/blog_processor.py</code>:</p> <pre><code>import google.generativeai as genai\nfrom typing import Dict, List\nimport re\n\nclass BlogProcessor:\n    \"\"\"Process blog posts with LLM analysis\"\"\"\n\n    def __init__(self, gemini_api_key: str):\n        self.api_key = gemini_api_key\n        genai.configure(api_key=gemini_api_key)\n        self.model = genai.GenerativeModel('gemini-pro')\n\n    def process(self, blog_post: Dict) -&gt; Dict:\n        \"\"\"Process a blog post\"\"\"\n\n        # Extract text content\n        content = blog_post.get('content', '')\n\n        # Remove HTML tags\n        content_clean = re.sub(r'&lt;[^&gt;]+&gt;', '', content)\n\n        # Use LLM to extract key concepts and summary\n        prompt = f\"\"\"\n        Analyze this blog post and extract:\n        1. Key concepts (5-10 main topics/technologies discussed)\n        2. A concise 2-3 sentence summary\n\n        Blog post:\n        {content_clean[:2000]}\n\n        Return in this format:\n        KEY CONCEPTS: concept1, concept2, concept3, ...\n        SUMMARY: summary text here\n        \"\"\"\n\n        try:\n            response = self.model.generate_content(prompt)\n            analysis = response.text\n\n            # Parse response\n            key_concepts = []\n            summary = \"\"\n\n            if \"KEY CONCEPTS:\" in analysis:\n                concepts_line = analysis.split(\"KEY CONCEPTS:\")[1].split(\"SUMMARY:\")[0]\n                key_concepts = [c.strip() for c in concepts_line.split(\",\")]\n\n            if \"SUMMARY:\" in analysis:\n                summary = analysis.split(\"SUMMARY:\")[1].strip()\n\n        except Exception as e:\n            print(f\"Error in LLM analysis: {e}\")\n            key_concepts = []\n            summary = content_clean[:200]\n\n        # Create processed document\n        processed = {\n            'title': blog_post['title'],\n            'content': content_clean,\n            'authors': blog_post.get('authors', []),\n            'url': blog_post.get('url', ''),\n            'publication_date': blog_post.get('published', ''),\n            'key_concepts': key_concepts,\n            'summary': summary,\n            'metadata': {\n                'source': 'blog',\n                'feed_url': blog_post.get('metadata', {}).get('feed_url', ''),\n                'tags': blog_post.get('metadata', {}).get('tags', [])\n            }\n        }\n\n        return processed\n\n    def batch_process(self, blog_posts: List[Dict]) -&gt; List[Dict]:\n        \"\"\"Process multiple blog posts\"\"\"\n\n        processed = []\n\n        for post in blog_posts:\n            try:\n                processed_post = self.process(post)\n                processed.append(processed_post)\n            except Exception as e:\n                print(f\"Error processing post '{post.get('title', 'Unknown')}': {e}\")\n\n        return processed\n</code></pre>"},{"location":"tutorials/extending/#example-code-repository-processor","title":"Example: Code Repository Processor","text":"<pre><code>import google.generativeai as genai\nfrom typing import Dict, List\n\nclass RepositoryProcessor:\n    \"\"\"Process GitHub repositories\"\"\"\n\n    def __init__(self, gemini_api_key: str):\n        self.api_key = gemini_api_key\n        genai.configure(api_key=gemini_api_key)\n        self.model = genai.GenerativeModel('gemini-pro')\n\n    def process(self, repo: Dict) -&gt; Dict:\n        \"\"\"Process a repository\"\"\"\n\n        readme = repo.get('content', '')\n        metadata = repo.get('metadata', {})\n\n        # Analyze README with LLM\n        prompt = f\"\"\"\n        Analyze this GitHub repository README and extract:\n        1. Main purpose/functionality\n        2. Key technologies used\n        3. Use cases\n        4. Target audience\n\n        Repository: {repo['title']}\n        Language: {metadata.get('language', 'Unknown')}\n        Stars: {metadata.get('stars', 0)}\n\n        README:\n        {readme[:3000]}\n\n        Provide a structured analysis.\n        \"\"\"\n\n        try:\n            response = self.model.generate_content(prompt)\n            analysis = response.text\n\n            # Extract key concepts from topics and language\n            key_concepts = metadata.get('topics', [])\n            if metadata.get('language'):\n                key_concepts.append(metadata['language'])\n\n        except Exception as e:\n            print(f\"Error analyzing repository: {e}\")\n            analysis = readme[:500]\n            key_concepts = metadata.get('topics', [])\n\n        processed = {\n            'title': repo['title'],\n            'content': readme,\n            'authors': repo.get('authors', []),\n            'url': repo.get('url', ''),\n            'publication_date': repo.get('published', ''),\n            'key_concepts': key_concepts,\n            'summary': analysis,\n            'metadata': {\n                'source': 'github',\n                'stars': metadata.get('stars', 0),\n                'forks': metadata.get('forks', 0),\n                'language': metadata.get('language', ''),\n                'topics': metadata.get('topics', [])\n            }\n        }\n\n        return processed\n</code></pre>"},{"location":"tutorials/extending/#modifying-the-ui","title":"Modifying the UI","text":""},{"location":"tutorials/extending/#adding-new-tabs-to-gradio","title":"Adding New Tabs to Gradio","text":"<p>Edit <code>multi_modal_rag/ui/gradio_app.py</code>:</p> <pre><code># In create_interface() method\n\nwith gr.Tabs():\n    # ... existing tabs ...\n\n    # Add new Analytics tab\n    with gr.TabItem(\"Analytics\"):\n        with gr.Row():\n            with gr.Column():\n                gr.Markdown(\"### Collection Analytics\")\n\n                date_range = gr.Radio(\n                    [\"Last 7 days\", \"Last 30 days\", \"All time\"],\n                    value=\"Last 30 days\",\n                    label=\"Time Range\"\n                )\n\n                metric_type = gr.Radio(\n                    [\"Collection Volume\", \"Source Distribution\", \"Popular Topics\"],\n                    value=\"Collection Volume\",\n                    label=\"Metric\"\n                )\n\n                generate_chart_btn = gr.Button(\"Generate Chart\")\n\n            with gr.Column():\n                chart_output = gr.Plot(label=\"Visualization\")\n                metrics_table = gr.Dataframe(label=\"Detailed Metrics\")\n\n        # Event handler\n        generate_chart_btn.click(\n            fn=self.generate_analytics,\n            inputs=[date_range, metric_type],\n            outputs=[chart_output, metrics_table]\n        )\n</code></pre> <p>Add the analytics method:</p> <pre><code>def generate_analytics(self, date_range: str, metric_type: str):\n    \"\"\"Generate analytics visualizations\"\"\"\n    import plotly.graph_objects as go\n    import pandas as pd\n    from datetime import datetime, timedelta\n\n    # Determine date filter\n    if date_range == \"Last 7 days\":\n        days = 7\n    elif date_range == \"Last 30 days\":\n        days = 30\n    else:\n        days = None\n\n    # Get collections from database\n    if days:\n        cutoff = (datetime.now() - timedelta(days=days)).isoformat()\n        collections = [\n            c for c in self.db_manager.get_all_collections(limit=1000)\n            if c['collection_date'] &gt;= cutoff\n        ]\n    else:\n        collections = self.db_manager.get_all_collections(limit=1000)\n\n    # Generate visualization based on metric type\n    if metric_type == \"Collection Volume\":\n        # Group by date\n        df = pd.DataFrame(collections)\n        df['date'] = pd.to_datetime(df['collection_date']).dt.date\n        daily_counts = df.groupby('date').size()\n\n        fig = go.Figure(data=[\n            go.Bar(x=daily_counts.index, y=daily_counts.values)\n        ])\n        fig.update_layout(title=\"Daily Collection Volume\")\n\n        metrics = daily_counts.reset_index()\n        metrics.columns = ['Date', 'Count']\n\n    elif metric_type == \"Source Distribution\":\n        # Group by source\n        df = pd.DataFrame(collections)\n        source_counts = df['source'].value_counts()\n\n        fig = go.Figure(data=[\n            go.Pie(labels=source_counts.index, values=source_counts.values)\n        ])\n        fig.update_layout(title=\"Distribution by Source\")\n\n        metrics = source_counts.reset_index()\n        metrics.columns = ['Source', 'Count']\n\n    else:  # Popular Topics\n        # Extract topics from metadata\n        topics = {}\n        for c in collections:\n            metadata = c.get('metadata', {})\n            if isinstance(metadata, dict):\n                for topic in metadata.get('topics', []):\n                    topics[topic] = topics.get(topic, 0) + 1\n\n        top_topics = sorted(topics.items(), key=lambda x: x[1], reverse=True)[:20]\n\n        fig = go.Figure(data=[\n            go.Bar(x=[t[0] for t in top_topics], y=[t[1] for t in top_topics])\n        ])\n        fig.update_layout(title=\"Top 20 Topics\")\n\n        metrics = pd.DataFrame(top_topics, columns=['Topic', 'Count'])\n\n    return fig, metrics\n</code></pre>"},{"location":"tutorials/extending/#customizing-the-ui-appearance","title":"Customizing the UI Appearance","text":"<p>Add custom CSS:</p> <pre><code># In create_interface() method\n\nwith gr.Blocks(\n    title=\"Multi-Modal Research Assistant\",\n    theme=gr.themes.Base(),\n    css=\"\"\"\n    .gradio-container {\n        max-width: 1200px !important;\n    }\n    .tab-nav button {\n        font-size: 16px;\n        font-weight: bold;\n    }\n    .citation-box {\n        background-color: #f0f0f0;\n        padding: 10px;\n        border-radius: 5px;\n        margin: 5px 0;\n    }\n    \"\"\"\n) as app:\n    # ... rest of UI code ...\n</code></pre>"},{"location":"tutorials/extending/#adding-custom-components","title":"Adding Custom Components","text":"<p>Create reusable UI components:</p> <pre><code>def create_search_filters(self):\n    \"\"\"Create reusable search filter component\"\"\"\n\n    with gr.Group():\n        gr.Markdown(\"### Search Filters\")\n\n        content_type = gr.CheckboxGroup(\n            [\"Papers\", \"Videos\", \"Podcasts\", \"Blogs\", \"Repositories\"],\n            value=[\"Papers\", \"Videos\", \"Podcasts\"],\n            label=\"Content Types\"\n        )\n\n        date_range = gr.Slider(\n            minimum=7,\n            maximum=365,\n            value=30,\n            step=1,\n            label=\"Days back\"\n        )\n\n        min_citations = gr.Slider(\n            minimum=0,\n            maximum=100,\n            value=0,\n            step=1,\n            label=\"Minimum citations\"\n        )\n\n    return content_type, date_range, min_citations\n</code></pre>"},{"location":"tutorials/extending/#adding-new-search-filters","title":"Adding New Search Filters","text":""},{"location":"tutorials/extending/#extending-opensearch-queries","title":"Extending OpenSearch Queries","text":"<p>Edit <code>multi_modal_rag/indexing/opensearch_manager.py</code>:</p> <pre><code>def advanced_search(\n    self,\n    index_name: str,\n    query: str,\n    content_types: List[str] = None,\n    min_date: str = None,\n    max_date: str = None,\n    authors: List[str] = None,\n    min_citations: int = 0,\n    k: int = 10\n) -&gt; List[Dict]:\n    \"\"\"Advanced search with multiple filters\"\"\"\n\n    # Build base query\n    must_clauses = [\n        {\n            'multi_match': {\n                'query': query,\n                'fields': ['title^3', 'abstract^2', 'content', 'transcript'],\n                'fuzziness': 'AUTO'\n            }\n        }\n    ]\n\n    # Build filters\n    filter_clauses = []\n\n    # Content type filter\n    if content_types:\n        filter_clauses.append({\n            'terms': {'content_type': content_types}\n        })\n\n    # Date range filter\n    if min_date or max_date:\n        date_filter = {'range': {'publication_date': {}}}\n        if min_date:\n            date_filter['range']['publication_date']['gte'] = min_date\n        if max_date:\n            date_filter['range']['publication_date']['lte'] = max_date\n        filter_clauses.append(date_filter)\n\n    # Author filter\n    if authors:\n        filter_clauses.append({\n            'terms': {'authors': authors}\n        })\n\n    # Citation count filter (if you track this)\n    if min_citations &gt; 0:\n        filter_clauses.append({\n            'range': {'metadata.citation_count': {'gte': min_citations}}\n        })\n\n    # Construct full query\n    search_query = {\n        'size': k,\n        'query': {\n            'bool': {\n                'must': must_clauses,\n                'filter': filter_clauses\n            }\n        }\n    }\n\n    response = self.client.search(index=index_name, body=search_query)\n\n    results = []\n    for hit in response['hits']['hits']:\n        results.append({\n            'score': hit['_score'],\n            'source': hit['_source']\n        })\n\n    return results\n</code></pre>"},{"location":"tutorials/extending/#adding-faceted-search","title":"Adding Faceted Search","text":"<pre><code>def faceted_search(\n    self,\n    index_name: str,\n    query: str,\n    k: int = 10\n) -&gt; Dict:\n    \"\"\"Search with facets for filtering\"\"\"\n\n    search_query = {\n        'size': k,\n        'query': {\n            'multi_match': {\n                'query': query,\n                'fields': ['title', 'abstract', 'content']\n            }\n        },\n        'aggs': {\n            'content_types': {\n                'terms': {'field': 'content_type', 'size': 10}\n            },\n            'authors': {\n                'terms': {'field': 'authors', 'size': 20}\n            },\n            'publication_years': {\n                'date_histogram': {\n                    'field': 'publication_date',\n                    'calendar_interval': 'year'\n                }\n            },\n            'topics': {\n                'terms': {'field': 'key_concepts', 'size': 30}\n            }\n        }\n    }\n\n    response = self.client.search(index=index_name, body=search_query)\n\n    return {\n        'results': [\n            {'score': hit['_score'], 'source': hit['_source']}\n            for hit in response['hits']['hits']\n        ],\n        'facets': response['aggregations']\n    }\n</code></pre>"},{"location":"tutorials/extending/#contributing-back-to-the-project","title":"Contributing Back to the Project","text":""},{"location":"tutorials/extending/#setting-up-for-development","title":"Setting Up for Development","text":"<ol> <li>Fork the repository</li> <li> <p>Clone your fork: <pre><code>git clone https://github.com/your-username/multi-modal-academic-research-system.git\ncd multi-modal-academic-research-system\n</code></pre></p> </li> <li> <p>Create a development branch: <pre><code>git checkout -b feature/new-collector\n</code></pre></p> </li> <li> <p>Install development dependencies: <pre><code>pip install -r requirements.txt\npip install pytest black flake8 mypy\n</code></pre></p> </li> </ol>"},{"location":"tutorials/extending/#code-quality-standards","title":"Code Quality Standards","text":"<p>Format code with Black: <pre><code>black multi_modal_rag/\n</code></pre></p> <p>Lint with flake8: <pre><code>flake8 multi_modal_rag/ --max-line-length=100\n</code></pre></p> <p>Type checking with mypy: <pre><code>mypy multi_modal_rag/\n</code></pre></p>"},{"location":"tutorials/extending/#writing-tests","title":"Writing Tests","text":"<p>Create tests in <code>tests/</code> directory:</p> <pre><code># tests/test_blog_collector.py\nimport pytest\nfrom multi_modal_rag.data_collectors.blog_collector import BlogCollector\n\ndef test_blog_collector_initialization():\n    \"\"\"Test blog collector initializes correctly\"\"\"\n    collector = BlogCollector()\n    assert collector.save_dir == \"data/blogs\"\n\ndef test_collect_from_feed():\n    \"\"\"Test collecting from a single feed\"\"\"\n    collector = BlogCollector()\n\n    # Use a known test feed\n    posts = collector.collect_from_feed(\n        'https://ai.googleblog.com/feeds/posts/default',\n        max_results=5\n    )\n\n    assert len(posts) &gt; 0\n    assert 'title' in posts[0]\n    assert 'content' in posts[0]\n    assert 'url' in posts[0]\n\ndef test_ml_blogs():\n    \"\"\"Test ML blog list\"\"\"\n    collector = BlogCollector()\n    blogs = collector.get_ml_blogs()\n\n    assert isinstance(blogs, dict)\n    assert len(blogs) &gt; 0\n</code></pre> <p>Run tests: <pre><code>pytest tests/\n</code></pre></p>"},{"location":"tutorials/extending/#documentation","title":"Documentation","text":"<p>Add docstrings to your code:</p> <pre><code>def collect_from_feed(self, feed_url: str, max_results: int = 20) -&gt; List[Dict]:\n    \"\"\"\n    Collect blog posts from an RSS feed.\n\n    Args:\n        feed_url (str): URL of the RSS feed\n        max_results (int): Maximum number of posts to collect\n\n    Returns:\n        List[Dict]: List of blog post dictionaries with keys:\n            - title: Post title\n            - content: Post content/summary\n            - authors: List of authors\n            - url: Post URL\n            - published: Publication date (ISO format)\n            - metadata: Additional metadata\n\n    Raises:\n        ValueError: If feed_url is invalid\n        ConnectionError: If feed cannot be accessed\n\n    Example:\n        &gt;&gt;&gt; collector = BlogCollector()\n        &gt;&gt;&gt; posts = collector.collect_from_feed(\n        ...     'https://example.com/feed.xml',\n        ...     max_results=10\n        ... )\n        &gt;&gt;&gt; len(posts)\n        10\n    \"\"\"\n    # Implementation\n</code></pre>"},{"location":"tutorials/extending/#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<ol> <li> <p>Commit your changes: <pre><code>git add .\ngit commit -m \"Add blog post collector with RSS feed support\"\n</code></pre></p> </li> <li> <p>Push to your fork: <pre><code>git push origin feature/new-collector\n</code></pre></p> </li> <li> <p>Create Pull Request:</p> </li> <li>Go to the original repository</li> <li>Click \"New Pull Request\"</li> <li>Select your branch</li> <li> <p>Describe your changes</p> </li> <li> <p>PR Description Template: <pre><code>## Description\nAdds a new blog post collector that can fetch posts from RSS feeds.\n\n## Changes\n- Added `BlogCollector` class in `data_collectors/blog_collector.py`\n- Added `BlogProcessor` class in `data_processors/blog_processor.py`\n- Updated `main.py` to register the new collector\n- Added tests in `tests/test_blog_collector.py`\n\n## Testing\n- [ ] Tested with multiple RSS feeds\n- [ ] Added unit tests\n- [ ] Verified integration with existing system\n- [ ] Checked code formatting (black, flake8)\n\n## Documentation\n- [ ] Added docstrings\n- [ ] Updated README if necessary\n- [ ] Added usage examples\n</code></pre></p> </li> </ol>"},{"location":"tutorials/extending/#best-practices-for-contributors","title":"Best Practices for Contributors","text":"<ol> <li>Keep changes focused: One feature per PR</li> <li>Write tests: Maintain test coverage</li> <li>Document thoroughly: Clear docstrings and comments</li> <li>Follow existing patterns: Match the codebase style</li> <li>Test integration: Ensure new code works with existing features</li> <li>Be responsive: Address review feedback promptly</li> </ol>"},{"location":"tutorials/extending/#next-steps","title":"Next Steps","text":"<ul> <li>Review Collecting Papers for data collection basics</li> <li>Explore Custom Searches for advanced queries</li> <li>Check Exporting Citations for citation management</li> <li>Learn Visualization Dashboard for data analysis</li> </ul>"},{"location":"tutorials/extending/#additional-resources","title":"Additional Resources","text":"<ul> <li>OpenSearch Documentation: https://opensearch.org/docs/</li> <li>Gradio Documentation: https://gradio.app/docs/</li> <li>FastAPI Documentation: https://fastapi.tiangolo.com/</li> <li>LangChain Documentation: https://python.langchain.com/</li> <li>Google Gemini API: https://ai.google.dev/docs</li> </ul>"},{"location":"tutorials/visualization/","title":"Tutorial: Visualization Dashboard","text":"<p>This tutorial shows you how to use the FastAPI visualization dashboard to explore and analyze your collected research data. You'll learn how to start the dashboard, interpret statistics, filter and search data, export visualizations, and create custom views.</p>"},{"location":"tutorials/visualization/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Starting the Dashboard</li> <li>Understanding Statistics</li> <li>Filtering and Searching</li> <li>Exporting Data</li> <li>Custom Visualizations</li> <li>Using the API</li> <li>Advanced Features</li> </ol>"},{"location":"tutorials/visualization/#starting-the-dashboard","title":"Starting the Dashboard","text":""},{"location":"tutorials/visualization/#prerequisites","title":"Prerequisites","text":"<p>Ensure your environment is set up:</p> <pre><code># Activate virtual environment\nsource venv/bin/activate  # Mac/Linux\nvenv\\Scripts\\activate     # Windows\n\n# Verify FastAPI and Uvicorn are installed\npip install fastapi uvicorn\n</code></pre>"},{"location":"tutorials/visualization/#method-1-using-the-start-script","title":"Method 1: Using the Start Script","text":"<p>The easiest way to start the dashboard:</p> <pre><code>python start_api_server.py\n</code></pre> <p>You should see output like: <pre><code>Starting FastAPI Visualization Server...\nDashboard will be available at: http://localhost:8000/viz\nAPI endpoints at: http://localhost:8000/api/\nAPI docs at: http://localhost:8000/docs\nPress CTRL+C to stop the server\n\nINFO:     Started server process\nINFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n</code></pre></p>"},{"location":"tutorials/visualization/#method-2-using-uvicorn-directly","title":"Method 2: Using Uvicorn Directly","text":"<p>For more control:</p> <pre><code>uvicorn multi_modal_rag.api.api_server:app --host 0.0.0.0 --port 8000 --reload\n</code></pre> <p>Options: - <code>--host 0.0.0.0</code>: Makes server accessible from network - <code>--port 8000</code>: Specify port (default 8000) - <code>--reload</code>: Auto-reload on code changes (development)</p>"},{"location":"tutorials/visualization/#method-3-custom-port","title":"Method 3: Custom Port","text":"<p>Run on a different port:</p> <pre><code>python -c \"import uvicorn; uvicorn.run('multi_modal_rag.api.api_server:app', host='0.0.0.0', port=8080)\"\n</code></pre>"},{"location":"tutorials/visualization/#accessing-the-dashboard","title":"Accessing the Dashboard","text":"<p>Once started, open your browser:</p> <ol> <li>Visualization Dashboard: http://localhost:8000/viz</li> <li>API Documentation: http://localhost:8000/docs</li> <li>API Root: http://localhost:8000/</li> </ol>"},{"location":"tutorials/visualization/#running-alongside-gradio-ui","title":"Running Alongside Gradio UI","text":"<p>You can run both interfaces simultaneously:</p> <p>Terminal 1 - Gradio UI: <pre><code>python main.py\n# Runs on port 7860\n</code></pre></p> <p>Terminal 2 - FastAPI Dashboard: <pre><code>python start_api_server.py\n# Runs on port 8000\n</code></pre></p>"},{"location":"tutorials/visualization/#understanding-statistics","title":"Understanding Statistics","text":""},{"location":"tutorials/visualization/#viewing-statistics-in-gradio-ui","title":"Viewing Statistics in Gradio UI","text":"<p>The Gradio UI provides basic statistics:</p> <ol> <li>Open Gradio interface at http://localhost:7860</li> <li>Go to \"Data Visualization\" tab</li> <li>Click \"Refresh Statistics\"</li> </ol>"},{"location":"tutorials/visualization/#understanding-the-statistics-display","title":"Understanding the Statistics Display","text":"<p>Quick Stats Section: <pre><code>Overview\n- Total Collections: 45\n- Indexed: 42 (93.3%)\n- Recent (7 days): 12\n\nBy Type\n- Papers: 30\n- Videos: 10\n- Podcasts: 5\n</code></pre></p> <p>JSON Statistics: <pre><code>{\n  \"total_collections\": 45,\n  \"by_type\": {\n    \"paper\": 30,\n    \"video\": 10,\n    \"podcast\": 5\n  },\n  \"indexed\": 42,\n  \"not_indexed\": 3,\n  \"recent_7_days\": 12,\n  \"recent_30_days\": 35,\n  \"by_source\": {\n    \"arxiv\": 25,\n    \"youtube\": 10,\n    \"semantic_scholar\": 5,\n    \"rss\": 5\n  }\n}\n</code></pre></p>"},{"location":"tutorials/visualization/#using-the-api-for-statistics","title":"Using the API for Statistics","text":"<p>Get statistics programmatically:</p> <pre><code>import requests\n\n# Get statistics\nresponse = requests.get('http://localhost:8000/api/statistics')\nstats = response.json()\n\nprint(f\"Total collections: {stats['total_collections']}\")\nprint(f\"Indexed: {stats['indexed']}\")\nprint(f\"By type: {stats['by_type']}\")\n</code></pre>"},{"location":"tutorials/visualization/#creating-visual-reports","title":"Creating Visual Reports","text":"<p>Generate visual statistics report:</p> <pre><code>import requests\nimport matplotlib.pyplot as plt\n\n# Fetch statistics\nresponse = requests.get('http://localhost:8000/api/statistics')\nstats = response.json()\n\n# Create pie chart of content types\nby_type = stats['by_type']\n\nplt.figure(figsize=(10, 5))\n\n# Pie chart for content types\nplt.subplot(1, 2, 1)\nplt.pie(\n    by_type.values(),\n    labels=by_type.keys(),\n    autopct='%1.1f%%',\n    startangle=90\n)\nplt.title('Collections by Content Type')\n\n# Bar chart for sources\nby_source = stats['by_source']\nplt.subplot(1, 2, 2)\nplt.bar(by_source.keys(), by_source.values())\nplt.title('Collections by Source')\nplt.xlabel('Source')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.savefig('collection_statistics.png')\nplt.show()\n\nprint(\"Statistics visualization saved to collection_statistics.png\")\n</code></pre>"},{"location":"tutorials/visualization/#time-based-statistics","title":"Time-Based Statistics","text":"<p>Analyze collection trends over time:</p> <pre><code>import requests\nfrom datetime import datetime, timedelta\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\n# Fetch all collections\nresponse = requests.get('http://localhost:8000/api/collections?limit=1000')\ncollections = response.json()['collections']\n\n# Group by date\nby_date = defaultdict(int)\n\nfor item in collections:\n    date = item['collection_date'].split('T')[0]  # Extract date part\n    by_date[date] += 1\n\n# Sort by date\ndates = sorted(by_date.keys())\ncounts = [by_date[d] for d in dates]\n\n# Plot timeline\nplt.figure(figsize=(12, 6))\nplt.plot(dates, counts, marker='o')\nplt.title('Collection Activity Over Time')\nplt.xlabel('Date')\nplt.ylabel('Number of Collections')\nplt.xticks(rotation=45)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig('collection_timeline.png')\nplt.show()\n\nprint(\"Timeline saved to collection_timeline.png\")\n</code></pre>"},{"location":"tutorials/visualization/#filtering-and-searching","title":"Filtering and Searching","text":""},{"location":"tutorials/visualization/#using-the-gradio-interface","title":"Using the Gradio Interface","text":"<p>Filter by Content Type:</p> <ol> <li>Go to \"Data Visualization\" tab</li> <li>Select content type: All, Papers, Videos, or Podcasts</li> <li>Adjust the limit slider (10-100 items)</li> <li>Click \"Load Collections\"</li> </ol> <p>Results displayed in table: <pre><code>ID | Type   | Title                           | Source  | Indexed | Date\n1  | paper  | Attention is All You Need      | arxiv   | Yes     | 2024-01-15\n2  | video  | Deep Learning Fundamentals     | youtube | Yes     | 2024-01-16\n</code></pre></p>"},{"location":"tutorials/visualization/#using-the-api-for-filtering","title":"Using the API for Filtering","text":"<p>Filter by content type:</p> <pre><code>import requests\n\n# Get only papers\nresponse = requests.get('http://localhost:8000/api/collections?content_type=paper&amp;limit=50')\npapers = response.json()\n\nprint(f\"Found {papers['count']} papers\")\nfor paper in papers['collections'][:5]:\n    print(f\"  - {paper['title']}\")\n</code></pre> <p>Filter with pagination:</p> <pre><code># Get first 20 items\nresponse = requests.get('http://localhost:8000/api/collections?limit=20&amp;offset=0')\npage1 = response.json()\n\n# Get next 20 items\nresponse = requests.get('http://localhost:8000/api/collections?limit=20&amp;offset=20')\npage2 = response.json()\n\nprint(f\"Page 1: {len(page1['collections'])} items\")\nprint(f\"Page 2: {len(page2['collections'])} items\")\n</code></pre>"},{"location":"tutorials/visualization/#search-functionality","title":"Search Functionality","text":"<p>Search by title or source:</p> <pre><code>import requests\n\n# Search for \"machine learning\"\nresponse = requests.get(\n    'http://localhost:8000/api/search',\n    params={'q': 'machine learning', 'limit': 20}\n)\n\nresults = response.json()\n\nprint(f\"Query: {results['query']}\")\nprint(f\"Found {results['count']} results\")\n\nfor item in results['results']:\n    print(f\"\\n{item['title']}\")\n    print(f\"  Type: {item['content_type']}\")\n    print(f\"  Source: {item['source']}\")\n</code></pre>"},{"location":"tutorials/visualization/#advanced-filtering-script","title":"Advanced Filtering Script","text":"<p>Create a comprehensive filtering script:</p> <pre><code>import requests\nfrom datetime import datetime, timedelta\n\ndef advanced_filter(\n    content_type=None,\n    indexed_only=True,\n    recent_days=None,\n    search_term=None,\n    limit=100\n):\n    \"\"\"Advanced filtering of collections\"\"\"\n\n    # Fetch all collections\n    params = {'limit': limit}\n    if content_type:\n        params['content_type'] = content_type\n\n    response = requests.get('http://localhost:8000/api/collections', params=params)\n    collections = response.json()['collections']\n\n    # Apply filters\n    filtered = collections\n\n    # Filter by indexed status\n    if indexed_only:\n        filtered = [c for c in filtered if c['indexed']]\n\n    # Filter by recency\n    if recent_days:\n        cutoff = datetime.now() - timedelta(days=recent_days)\n        filtered = [\n            c for c in filtered\n            if datetime.fromisoformat(c['collection_date'].replace('Z', '+00:00')) &gt; cutoff\n        ]\n\n    # Filter by search term\n    if search_term:\n        search_lower = search_term.lower()\n        filtered = [\n            c for c in filtered\n            if search_lower in c['title'].lower() or\n               search_lower in (c['source'] or '').lower()\n        ]\n\n    return filtered\n\n# Example usage\nresults = advanced_filter(\n    content_type='paper',\n    indexed_only=True,\n    recent_days=30,\n    search_term='neural network',\n    limit=200\n)\n\nprint(f\"Found {len(results)} matching collections\")\nfor item in results[:10]:\n    print(f\"  - {item['title']} ({item['collection_date'][:10]})\")\n</code></pre>"},{"location":"tutorials/visualization/#combining-multiple-filters","title":"Combining Multiple Filters","text":"<pre><code>import requests\n\ndef complex_search(\n    keywords,\n    content_types=['paper', 'video', 'podcast'],\n    min_date='2023-01-01',\n    sources=None\n):\n    \"\"\"Complex search with multiple criteria\"\"\"\n\n    all_results = []\n\n    for content_type in content_types:\n        response = requests.get(\n            'http://localhost:8000/api/collections',\n            params={'content_type': content_type, 'limit': 500}\n        )\n\n        items = response.json()['collections']\n\n        for item in items:\n            # Check date\n            if item['collection_date'] &lt; min_date:\n                continue\n\n            # Check source\n            if sources and item['source'] not in sources:\n                continue\n\n            # Check keywords\n            text = f\"{item['title']} {item.get('source', '')}\".lower()\n            if any(kw.lower() in text for kw in keywords):\n                all_results.append(item)\n\n    # Remove duplicates\n    seen = set()\n    unique_results = []\n\n    for item in all_results:\n        if item['id'] not in seen:\n            seen.add(item['id'])\n            unique_results.append(item)\n\n    return unique_results\n\n# Search for machine learning papers from arxiv in 2023+\nresults = complex_search(\n    keywords=['machine learning', 'deep learning'],\n    content_types=['paper'],\n    min_date='2023-01-01',\n    sources=['arxiv']\n)\n\nprint(f\"Found {len(results)} matching items\")\n</code></pre>"},{"location":"tutorials/visualization/#exporting-data","title":"Exporting Data","text":""},{"location":"tutorials/visualization/#export-collection-data","title":"Export Collection Data","text":"<p>Export as JSON:</p> <pre><code>import requests\nimport json\n\n# Fetch all collections\nresponse = requests.get('http://localhost:8000/api/collections?limit=1000')\ndata = response.json()\n\n# Save to file\nwith open('all_collections.json', 'w') as f:\n    json.dump(data, f, indent=2)\n\nprint(f\"Exported {data['count']} collections to all_collections.json\")\n</code></pre> <p>Export as CSV:</p> <pre><code>import requests\nimport csv\n\n# Fetch collections\nresponse = requests.get('http://localhost:8000/api/collections?limit=1000')\ncollections = response.json()['collections']\n\n# Write to CSV\nwith open('collections.csv', 'w', newline='', encoding='utf-8') as f:\n    writer = csv.writer(f)\n\n    # Header\n    writer.writerow(['ID', 'Type', 'Title', 'Source', 'Indexed', 'Date', 'URL'])\n\n    # Data\n    for item in collections:\n        writer.writerow([\n            item['id'],\n            item['content_type'],\n            item['title'],\n            item['source'] or 'N/A',\n            'Yes' if item['indexed'] else 'No',\n            item['collection_date'].split('T')[0],\n            item.get('url', 'N/A')\n        ])\n\nprint(f\"Exported {len(collections)} collections to collections.csv\")\n</code></pre> <p>Export filtered data:</p> <pre><code>import requests\nimport pandas as pd\n\n# Get papers only\nresponse = requests.get('http://localhost:8000/api/collections?content_type=paper&amp;limit=500')\npapers = response.json()['collections']\n\n# Create DataFrame\ndf = pd.DataFrame(papers)\n\n# Export to Excel\ndf.to_excel('papers_collection.xlsx', index=False)\n\n# Export to CSV\ndf.to_csv('papers_collection.csv', index=False)\n\nprint(f\"Exported {len(papers)} papers to Excel and CSV\")\n</code></pre>"},{"location":"tutorials/visualization/#export-statistics-summary","title":"Export Statistics Summary","text":"<pre><code>import requests\nimport json\n\n# Fetch statistics\nresponse = requests.get('http://localhost:8000/api/statistics')\nstats = response.json()\n\n# Create summary report\nreport = {\n    'generated_at': datetime.now().isoformat(),\n    'statistics': stats,\n    'summary': {\n        'total_items': stats['total_collections'],\n        'completion_rate': f\"{(stats['indexed'] / stats['total_collections'] * 100):.1f}%\",\n        'recent_activity_7d': stats['recent_7_days'],\n        'recent_activity_30d': stats['recent_30_days']\n    }\n}\n\n# Save report\nwith open('statistics_report.json', 'w') as f:\n    json.dump(report, f, indent=2)\n\nprint(\"Statistics report saved to statistics_report.json\")\n</code></pre>"},{"location":"tutorials/visualization/#custom-visualizations","title":"Custom Visualizations","text":""},{"location":"tutorials/visualization/#creating-interactive-charts","title":"Creating Interactive Charts","text":"<p>Using Plotly for interactive visualizations:</p> <pre><code>import requests\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Fetch statistics\nresponse = requests.get('http://localhost:8000/api/statistics')\nstats = response.json()\n\n# Create subplots\nfig = make_subplots(\n    rows=2, cols=2,\n    subplot_titles=(\n        'Content Type Distribution',\n        'Source Distribution',\n        'Indexing Status',\n        'Recent Activity'\n    ),\n    specs=[\n        [{'type': 'pie'}, {'type': 'bar'}],\n        [{'type': 'pie'}, {'type': 'bar'}]\n    ]\n)\n\n# Content type pie chart\nby_type = stats['by_type']\nfig.add_trace(\n    go.Pie(labels=list(by_type.keys()), values=list(by_type.values())),\n    row=1, col=1\n)\n\n# Source bar chart\nby_source = stats['by_source']\nfig.add_trace(\n    go.Bar(x=list(by_source.keys()), y=list(by_source.values())),\n    row=1, col=2\n)\n\n# Indexing status pie chart\nindexing = {\n    'Indexed': stats['indexed'],\n    'Not Indexed': stats['not_indexed']\n}\nfig.add_trace(\n    go.Pie(labels=list(indexing.keys()), values=list(indexing.values())),\n    row=2, col=1\n)\n\n# Recent activity bar chart\nrecent = {\n    '7 days': stats['recent_7_days'],\n    '30 days': stats['recent_30_days']\n}\nfig.add_trace(\n    go.Bar(x=list(recent.keys()), y=list(recent.values())),\n    row=2, col=2\n)\n\n# Update layout\nfig.update_layout(\n    height=800,\n    showlegend=True,\n    title_text=\"Research Collection Dashboard\"\n)\n\n# Save to HTML\nfig.write_html('dashboard.html')\nprint(\"Interactive dashboard saved to dashboard.html\")\n\n# Show in browser\nfig.show()\n</code></pre>"},{"location":"tutorials/visualization/#time-series-visualization","title":"Time Series Visualization","text":"<pre><code>import requests\nimport plotly.express as px\nfrom datetime import datetime\nimport pandas as pd\n\n# Fetch all collections\nresponse = requests.get('http://localhost:8000/api/collections?limit=1000')\ncollections = response.json()['collections']\n\n# Convert to DataFrame\ndf = pd.DataFrame(collections)\n\n# Parse dates\ndf['date'] = pd.to_datetime(df['collection_date']).dt.date\n\n# Count by date and type\ndaily_counts = df.groupby(['date', 'content_type']).size().reset_index(name='count')\n\n# Create time series plot\nfig = px.line(\n    daily_counts,\n    x='date',\n    y='count',\n    color='content_type',\n    title='Collection Activity Over Time',\n    labels={'count': 'Number of Collections', 'date': 'Date', 'content_type': 'Type'}\n)\n\nfig.update_layout(\n    xaxis_title='Date',\n    yaxis_title='Collections',\n    hovermode='x unified'\n)\n\nfig.write_html('timeline.html')\nfig.show()\n\nprint(\"Timeline visualization saved to timeline.html\")\n</code></pre>"},{"location":"tutorials/visualization/#heatmap-of-collection-activity","title":"Heatmap of Collection Activity","text":"<pre><code>import requests\nimport plotly.express as px\nimport pandas as pd\n\n# Fetch collections\nresponse = requests.get('http://localhost:8000/api/collections?limit=1000')\ncollections = response.json()['collections']\n\n# Convert to DataFrame\ndf = pd.DataFrame(collections)\ndf['datetime'] = pd.to_datetime(df['collection_date'])\ndf['date'] = df['datetime'].dt.date\ndf['weekday'] = df['datetime'].dt.day_name()\ndf['hour'] = df['datetime'].dt.hour\n\n# Count by day of week and hour\nheatmap_data = df.groupby(['weekday', 'hour']).size().reset_index(name='count')\n\n# Pivot for heatmap\nheatmap_pivot = heatmap_data.pivot(index='weekday', columns='hour', values='count').fillna(0)\n\n# Order days of week\nday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\nheatmap_pivot = heatmap_pivot.reindex(day_order)\n\n# Create heatmap\nfig = px.imshow(\n    heatmap_pivot,\n    labels=dict(x='Hour of Day', y='Day of Week', color='Collections'),\n    title='Collection Activity Heatmap',\n    aspect='auto',\n    color_continuous_scale='Blues'\n)\n\nfig.write_html('activity_heatmap.html')\nfig.show()\n\nprint(\"Activity heatmap saved to activity_heatmap.html\")\n</code></pre>"},{"location":"tutorials/visualization/#network-graph-of-related-topics","title":"Network Graph of Related Topics","text":"<pre><code>import requests\nimport networkx as nx\nimport plotly.graph_objects as go\nfrom collections import Counter\n\n# Fetch collections with metadata\nresponse = requests.get('http://localhost:8000/api/collections?limit=500')\ncollections = response.json()['collections']\n\n# Extract topics/categories from metadata\nG = nx.Graph()\n\nfor item in collections:\n    metadata = item.get('metadata', {})\n\n    # Add categories if available\n    if isinstance(metadata, dict):\n        categories = metadata.get('categories', [])\n        if categories:\n            for i, cat1 in enumerate(categories):\n                G.add_node(cat1)\n                for cat2 in categories[i+1:]:\n                    if G.has_edge(cat1, cat2):\n                        G[cat1][cat2]['weight'] += 1\n                    else:\n                        G.add_edge(cat1, cat2, weight=1)\n\n# Create positions\npos = nx.spring_layout(G, k=0.5, iterations=50)\n\n# Create edges\nedge_trace = []\nfor edge in G.edges():\n    x0, y0 = pos[edge[0]]\n    x1, y1 = pos[edge[1]]\n    weight = G[edge[0]][edge[1]]['weight']\n\n    edge_trace.append(\n        go.Scatter(\n            x=[x0, x1, None],\n            y=[y0, y1, None],\n            mode='lines',\n            line=dict(width=weight*0.5, color='#888'),\n            hoverinfo='none'\n        )\n    )\n\n# Create nodes\nnode_x = []\nnode_y = []\nnode_text = []\n\nfor node in G.nodes():\n    x, y = pos[node]\n    node_x.append(x)\n    node_y.append(y)\n    node_text.append(f\"{node}&lt;br&gt;Connections: {G.degree(node)}\")\n\nnode_trace = go.Scatter(\n    x=node_x,\n    y=node_y,\n    mode='markers+text',\n    text=list(G.nodes()),\n    textposition='top center',\n    hovertext=node_text,\n    marker=dict(\n        size=[G.degree(n)*5 for n in G.nodes()],\n        color=[G.degree(n) for n in G.nodes()],\n        colorscale='Viridis',\n        showscale=True,\n        colorbar=dict(title='Connections')\n    )\n)\n\n# Create figure\nfig = go.Figure(data=edge_trace + [node_trace])\nfig.update_layout(\n    title='Topic Network Graph',\n    showlegend=False,\n    hovermode='closest',\n    margin=dict(b=0, l=0, r=0, t=40),\n    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n)\n\nfig.write_html('topic_network.html')\nfig.show()\n\nprint(\"Topic network graph saved to topic_network.html\")\n</code></pre>"},{"location":"tutorials/visualization/#using-the-api","title":"Using the API","text":""},{"location":"tutorials/visualization/#api-endpoints","title":"API Endpoints","text":"<p>The FastAPI server provides several endpoints:</p> <p>Root: <pre><code>GET /\n</code></pre> Returns available endpoints.</p> <p>Collections: <pre><code>GET /api/collections?content_type={type}&amp;limit={n}&amp;offset={n}\n</code></pre> Get collections with optional filtering.</p> <p>Collection Details: <pre><code>GET /api/collections/{id}\n</code></pre> Get detailed information about a specific collection.</p> <p>Statistics: <pre><code>GET /api/statistics\n</code></pre> Get database statistics.</p> <p>Search: <pre><code>GET /api/search?q={query}&amp;limit={n}\n</code></pre> Search collections by title or source.</p> <p>Health Check: <pre><code>GET /health\n</code></pre> Check if API is running.</p>"},{"location":"tutorials/visualization/#python-api-client","title":"Python API Client","text":"<p>Create a reusable API client:</p> <pre><code>import requests\nfrom typing import Optional, List, Dict\n\nclass ResearchAPIClient:\n    \"\"\"Client for Research Data API\"\"\"\n\n    def __init__(self, base_url='http://localhost:8000'):\n        self.base_url = base_url\n\n    def get_collections(\n        self,\n        content_type: Optional[str] = None,\n        limit: int = 100,\n        offset: int = 0\n    ) -&gt; Dict:\n        \"\"\"Get collections with optional filtering\"\"\"\n        params = {'limit': limit, 'offset': offset}\n        if content_type:\n            params['content_type'] = content_type\n\n        response = requests.get(f'{self.base_url}/api/collections', params=params)\n        response.raise_for_status()\n        return response.json()\n\n    def get_collection(self, collection_id: int) -&gt; Dict:\n        \"\"\"Get specific collection\"\"\"\n        response = requests.get(f'{self.base_url}/api/collections/{collection_id}')\n        response.raise_for_status()\n        return response.json()\n\n    def get_statistics(self) -&gt; Dict:\n        \"\"\"Get statistics\"\"\"\n        response = requests.get(f'{self.base_url}/api/statistics')\n        response.raise_for_status()\n        return response.json()\n\n    def search(self, query: str, limit: int = 50) -&gt; Dict:\n        \"\"\"Search collections\"\"\"\n        params = {'q': query, 'limit': limit}\n        response = requests.get(f'{self.base_url}/api/search', params=params)\n        response.raise_for_status()\n        return response.json()\n\n    def health_check(self) -&gt; bool:\n        \"\"\"Check if API is healthy\"\"\"\n        try:\n            response = requests.get(f'{self.base_url}/health')\n            return response.status_code == 200\n        except:\n            return False\n\n# Usage\nclient = ResearchAPIClient()\n\n# Check health\nif not client.health_check():\n    print(\"API is not running!\")\n    exit(1)\n\n# Get statistics\nstats = client.get_statistics()\nprint(f\"Total collections: {stats['total_collections']}\")\n\n# Search\nresults = client.search('machine learning')\nprint(f\"Found {results['count']} results\")\n\n# Get all papers\npapers = client.get_collections(content_type='paper', limit=100)\nprint(f\"Retrieved {len(papers['collections'])} papers\")\n</code></pre>"},{"location":"tutorials/visualization/#advanced-features","title":"Advanced Features","text":""},{"location":"tutorials/visualization/#real-time-monitoring","title":"Real-Time Monitoring","text":"<p>Monitor collection activity in real-time:</p> <pre><code>import requests\nimport time\nfrom datetime import datetime\n\ndef monitor_collections(interval=10):\n    \"\"\"Monitor collection activity\"\"\"\n\n    client = ResearchAPIClient()\n    last_count = 0\n\n    print(\"Monitoring collection activity (Ctrl+C to stop)...\")\n    print(\"=\"*60)\n\n    try:\n        while True:\n            stats = client.get_statistics()\n            current_count = stats['total_collections']\n\n            if current_count != last_count:\n                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n                new_items = current_count - last_count\n\n                print(f\"[{timestamp}] New collections: {new_items}\")\n                print(f\"  Total: {current_count}\")\n                print(f\"  Papers: {stats['by_type'].get('paper', 0)}\")\n                print(f\"  Videos: {stats['by_type'].get('video', 0)}\")\n                print(f\"  Podcasts: {stats['by_type'].get('podcast', 0)}\")\n                print(\"-\"*60)\n\n                last_count = current_count\n\n            time.sleep(interval)\n\n    except KeyboardInterrupt:\n        print(\"\\nMonitoring stopped\")\n\n# Run monitor\nmonitor_collections(interval=30)\n</code></pre>"},{"location":"tutorials/visualization/#automated-report-generation","title":"Automated Report Generation","text":"<p>Generate regular reports:</p> <pre><code>import requests\nfrom datetime import datetime\nimport json\n\ndef generate_daily_report():\n    \"\"\"Generate daily collection report\"\"\"\n\n    client = ResearchAPIClient()\n\n    # Get statistics\n    stats = client.get_statistics()\n\n    # Get recent collections\n    collections = client.get_collections(limit=1000)\n\n    # Filter today's collections\n    today = datetime.now().date().isoformat()\n    today_collections = [\n        c for c in collections['collections']\n        if c['collection_date'].startswith(today)\n    ]\n\n    # Create report\n    report = {\n        'date': today,\n        'generated_at': datetime.now().isoformat(),\n        'overall_stats': stats,\n        'today': {\n            'total': len(today_collections),\n            'by_type': {}\n        },\n        'recent_items': today_collections[:20]\n    }\n\n    # Count by type\n    for item in today_collections:\n        content_type = item['content_type']\n        report['today']['by_type'][content_type] = \\\n            report['today']['by_type'].get(content_type, 0) + 1\n\n    # Save report\n    filename = f'daily_report_{today}.json'\n    with open(filename, 'w') as f:\n        json.dump(report, f, indent=2)\n\n    print(f\"Daily report saved to {filename}\")\n    print(f\"Collections today: {report['today']['total']}\")\n\n# Run daily report\ngenerate_daily_report()\n</code></pre>"},{"location":"tutorials/visualization/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Custom Searches to query your data</li> <li>Explore Exporting Citations for research writing</li> <li>Check Extending the System to add custom visualizations</li> <li>Review Collecting Papers to expand your database</li> </ul>"}]}